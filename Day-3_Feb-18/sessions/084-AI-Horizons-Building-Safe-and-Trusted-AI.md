# AI Horizons: Building Safe and Trusted AI

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room No. 6 |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/3R71D42pmKY?feature=share) |

## üé§ Speakers

- David Wroe, Australian Strategic Policy Institute
- Dr M M Oberoi, Google Cloud
- Dr Sanjay Bahl, CERT-In
- Kanishk Gaur, India Future Foundation
- Natasha Crampton, Microsoft

## ü§ù Knowledge Partners

- India Future Foundation

## üìù Summary

The session will examine key issues around AI safety, governance, ethics, and international collaboration. It aims to bring together regulators and leading technology organisations to share policy insights, best practices, and perspectives on the development of trustworthy and secure AI deployment. The session aims to encourage informed dialogue, strengthen responsible innovation frameworks, and advance global cooperation to build safe, transparent, and trusted AI ecosystems.

## üîë Key Takeaways

1. The session will examine key issues around AI safety, governance, ethics, and international collaboration.
2. It aims to bring together regulators and leading technology organisations to share policy insights, best practices, and perspectives on the development of trustworthy and secure AI deployment.
3. The session aims to encourage informed dialogue, strengthen responsible innovation frameworks, and advance global cooperation to build safe, transparent, and trusted AI ecosystems.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/3R71D42pmKY/maxresdefault.jpg)](https://youtube.com/live/3R71D42pmKY?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

of emerging technology. Even in Delhi if we can call key uh uh there are pockets which belongs to global north but there are also some pocket some pocket which belong to global south and we need to

understand and we have to also ensure how we can uh equitable distribution or important part I think it's a very important part

and people who are offering those data stakeholder justific. This is the you know key area just per I think our panel will discuss and we have

I think a very eminent personalities among us who have you know kind of a vast experience of handling not only handling data but to use those data for the public good for the public

consumption we have uh with uh Dr. uh MM Trapati who's a DG of Nilelet and Nilelet basically are using or creating data center AI labs and democratizing the you know data for the

public good. They are including and involving those communities who are earlier not part of the you know data ecosystem. So they have established lot of uh you know AI labs, lot of native

center those part of the country where people usually do not have any kind of you know emerging technology access uh we have professor Alukra he's the director of IM

Kolkata earlier he was with the Lacno University and he is a democratized educational institution not only uh Lacno University but I am Kolkata as Well to you know to involve the students

who earlier do not have the kind of you know quality educational lectures quality uh you know educational equipment. He has created lot of centers to promote and to make you know educ

education and technology accessible to all parts of the society. And we have professor Salah from IIT Kpur who is the professor of stat and he will explain the kind of the significantly

institutional structures incorporate elements of &gt;&gt; no who will you know explain the usage of data and first I will request uh uh Dr.

Dr. Pati to you know uh thank you. Uh this is a very important topic today and as uh um it has been told about NIL that uh

NILT has democratized the education. uh so I'll take just 2 minutes on that [laughter] that Nate has 56 centers across the country almost present in every state islands and deep into the

villages in northeast also uh we are almost skill 1 million every year through our various programs uh recently we created 28 India data lab in the country uh I think just 4 months

pack uh in 28 locations. But interestingly, you can see that three very important products are there on display. If you go to MI Pavilion,

you can see what our students can do if they're given the opportunity. Uh one product is sign word which converts any video or any audio in the Indian sign languages.

uh not in American sign language in the Indian sign language. Another is audio to audio translation of language in northeast like English to maripuri or Hindi to madipuri.

And yesterday also I was talking a third very simple tool to convert in in shinagar the artician which are you know making this uh khalen.

Uh normally it takes many months to design one khalen and now the tool generates in minutes just to do the GUI thing and it will make a output of the talim. So these are

the small interventions in uh very very small time uh which has been done. Along with that we have created a nillet digital industry platform which is first

digital industry platform for education in the country. It's very AI intensive platform and uh one of the best example of AI in education which is now in 4 months only we got

around 50,000 registered students on this platform and every minute one student is getting registered on this platform now. So these are the very useful data which

is going to be there uh on our platform and this data is open to any researcher to use it and develop a small models on the LLMs or whatever it is for different applications in education and also will

be used for research and collaboration. So now coming to the uh point in the global south we have different kind of data available with us and mostly the big tech companies who are

developing LLMs they look us as a consumer only. So these tools are coming up. We are giving our data and then again the data will be used to develop other different

products for our consumptions. So that's a [clears throat] challenge how to address this right because in the age of AI

any idea can be pushed. So when suppose you are teaching your children something else based on the our culture and ethos and other things and the child is going on

Google and uh some G chat GPT and all and trying to find some different answer and then there's a conflict that the child will trust you or child the teacher or child trust the child GPT

So these these kind of challenges will come up you know so it's very important for global south and India also that how we protect our data and how can we develop models for

ourself instead of relying on the large English models for everything because that is the area when there will be lot of competition in the But certainly we can use develop our own

small models. We can develop foundational models using our own data for our own applications. So I have just given three examples whatever the students have done. So like that there

are many many you know problems statements in the country. India is a very diverse country and we have different kind of set of the problems which Europe doesn't understand or the

US does not understand and at least we should create the solutions for our own problems ourself rather than taking a model and training on our data and customizing it to

provide a solutions because there are certain threats associated with this we have been listening to different kind of threats so it's important

Also if you use the model from different uh companies you have to see that do we have some safeguard that the input can be filtered or the output can be filtered.

So those things are are not available straight way you are using it. So we have to see if you're adopting the models from other institutions we have to see that proper safeguards are taken

and the important thing is that creating a small models for our data because that that also important for our economy you know I mean we have been seeing that we are creating products for many

companies but we are the only consumer economy and money flow is always going from India to outside if you can create at least in AI heavy

engineering you cannot do but if you can create AI models small models which are consumed in the India and the money can it stay with within the country that is also a very very

important perspective with that we have to see so these are the some important points which just I wanted to see in the beginning and then we'll be taking questions and answering some other

things also thank &gt;&gt; [clears throat] &gt;&gt; Uh look sir you we usually uh earlier we were talking about the roads, electricity, ports as a development

infrastructure and we basically consider them as you know very critical you know think in the development discourse. Now data is very important and we are also thinking about the data centers not only

in the in for the industry but also about the academic institution. How you imagine the role of data in you know for the future ready institutions and for the future of education the

importance of data can I speak from there? &gt;&gt; Yes. Yes sir. Yes sir. See basically I'm a teacher so I prefer speaking while standing.

Now before I specifically go on to what Dr. Dr. Ramanji was asking me. I have few fundamental questions for contemplation

of this August house of all the wise people sitting here. And these questions are coming from me as a student as a faculty faculty of a central institution which

has over 40,000 students on campus students as vice chancellor of a university which has had uh on campus and off-c campus close to five lakh students five lakh

students I'm telling you and Then I'm heading I am Kolkata which people say there is smaller but stronger lot which is characterized by certain peculiarities.

So at least I have been part of an ecosystem that provides data data to certain meaningful

um for for certain consumption by some corporates. I always wanted to see artificial intelligence as just an extension of an information

tool which keeps coming to our life and living in one form or the other. Few datas have always been there. Technologies have always been there.

Information technology was one tool that had come and that came to help us process those set of informations easier, transparent and faster. Now I see this largely as an extension

of the tool where our decision making is certainly going to be faster. I hope it is going to be more accurate and once it is faster and accurate it is

supposed to be transparent as well. I would contest and strongly contest the conception of artificial intelligence as a single

point remedy to all the ills. That is not what is going to [clears throat] make a difference at it is going to change the processing, way of processing, speed of processing and

accuracy of processing and so but then should we not be ready to take this extremely important information tool that is going to alter our decisions

speedily. faster, more accurate to take into our strides and use it for the greater good. We should and I believe such a huge summit and such a

tremendous response that the summit is receiving is largely because the basic background has already been prepared. the background I mean mentally and probably in terms of infrastructure

also India is now ready to take artificial intelligence 4A into a stride as institution I I'll share some of the examples from from the experience that I have had and some of the plans that we

are using in higher educational institutions you know one big problem as I said uh while serving as vice chancellor of a institution which has had of the campus

and also of affiliate colleges five lakh examination is you know something the most challenged thing here. Now five lakh students in one semester appears in six examinations.

So it makes out to be 30 lakh copies to be evaluated. Now you have limited number of faculties. So what they do is first of all they have had lot of criteria this

much of experience. This must be of the status of the faculty who would evaluate and you know after late what had happened especially after sixth pay commission and then subsequently seventh

pay commission especially after six pay commission with the salary of teachers went up so so high it was a nonreminerative assignment to evaluate copies those who come from academics may

may eco my sentiment that [clears throat] probably different institutions have been giving 10 rupees 15 rupees maybe 20 rupees is for evaluation of a copy your salary is

three lakh plus so you don't find it so who will evaluate this then if you evaluate say you bring in some some relatively less I mean based on perception some relatively less sincere

and faculty with proven credentials [snorts] they might come but they might not be doing justice with the task so you know tick tick t take number question

and you take it from here put it here then copy that was also not to be done these are the areas where we can actually bring in artificial

intelligence. If we scan the copy, put it in a screen, place the query, query questions, questions will have certain queries, queries in terms of machine language.

[snorts] These queries queries will provide you the most standard answer through through this technology. You can always find the most ideal answer. All the questions will be mapped against

those answers and based on certain common content it can easily be evaluated which can never ever be contested. Otherwise as vice chancellor we most of the time we used

to get confronted with the students who would come and say and so on. But this would ease the work, make it more

accurate and of course transparent. You have a contest. Come see the copy on the screen. See this is the ideal answer made available from the available literature

that are there on the net. Map it and get the marks. [snorts] Now this also poses a threat. A if there is a student who's very creative in terms of a expression

or in terms of bringing some newness to the answer that cannot be evaluated with the machine but then based on those except exceptions or only accounting for those

exceptions to the system you [snorts] would not design your your I mean you will not let all those laxos students suffer for the time and inaccuracies of the system.

&gt;&gt; [snorts and gasps] &gt;&gt; Now what we did when I came to Amalkata there I thought this is a smaller institution of course smaller but stronger institution so let us try and

experiment this so I called one of faculty there and I said uh can we do this so the faculty himself developed a tool and he said I'll evaluate based on that tool I said but also evaluate Ourel

I mean manually also. So when we are introducing thing we need a greater acceptance of the concept. So let us have this manual evaluation. There's the machine evaluation based on

artificial intelligence. See what artificial intelligence is. It projects the future based on the patterns of past. Isn't it? Nothing more nothing less.

Because of the technology it enables you to do it faster. Isn't it extrapolation? Now this extrapolation is not only mathematical but is all pervasive in all our

decisions. This kind of extrapolation can be done. Now so I said let us evaluate using both the tools manual as well as AI and then share this with the student. Let them select which answer

they want which which marks they want and then [clears throat] gradually this is what we've done in the last term where that was only for the course to assess what is the response of the

student because such a drastic change if you're going to to create there has to have greater acceptance also from the c customer side now in order to standardize it I said

let us not rely on one let us have three separate tools tools. [snorts] Expose the answer scripts with all these three tools and let us either take a mean value or the highest of the of them

all largely to be to be more student friendly or to be on the student side. Let the benefit of doubt be given to the student. So let us agree between the two that either a mean or the highest of the

three and then gradually it'll accept but in all these cases in all these discussions am I not finding or concluding that all that we are talking of be I talked to I

was just talking to some young people researchers of CPRG I have been talking to some very senior people from the system not just from uh academics but also from governance side.

You talk to them. Are we not talking of artificial intelligence largely from consumption side? Should we not also talk artificial intelligence from creation side? because

our manpower which is highly skilled and I'm telling you I've I've traveled um significantly and I can tell you India has one of the finest and most committed extremely

diligent workforce in order to leverage them we going to move beyond this artificial intelligence being seen as a consump uh from the consumer side we also going to see it

from the creation side as if can we create it. Now this is very important and I appreciate the government for taking such a strong measure and and taking it

this far is that largely and honorable prime minister I read the newspaper has talked about creation of artificial intelligence products. This is where we were miss we

missed the bus at the time of uh this software cranty software revolution where we largely concentrated on creating coders and that is why civil engineer is also

working in an IT company and mechanical engineer is also working in an IT company and some some some basic computer knowledge you you must master and then you would get the status of the

encoder our conscious contribution towards creation of software products have been something which we could have and we should have done a little more

[snorts] and this is a high time where India has got to take things in a in our stride and create the products which I mean creation side so that we can serve the rest of the world taking them as

consumer by selling our product not just consumers itself and this will also solve the larger issue of that is a much talked about issue of what will happen

to the fate of all these people who will get him unemployed because of this. So it is important [snorts] that all the data that comes out of I mean from the student fraternity which

is which is a very significant portion of our population. What is going to happen to this data? I can uh as as institutional academic administrator I would talk that we come

out with enormous data, enormous data. what are we doing it for with such high speeded uh AI I mean uh information technology tool which I still my underlying um thing is I still take it

as as an extension of an of an information technology tool designed to support our decisions to be made faster speedier I mean uh faster more transparent

and more accurate. So this is what I think is is the starting remark that I have with respect to what Dr. Raman G spoke about. Um I'll be ready to take up more questions as it comes. Thank you.

&gt;&gt; Thank you. [snorts] India's data issue especially from the educational perspective. uh professor Salaf you know uh global AI and data governance norms basically

dominated by or basically set by global north and economies more developed economies. how what could be the kind of a role of global south and you know the global south economics

economies and how they can you know better negotiate with global north in the age of AI &gt;&gt; yeah thank you very much uh Dr. Dr. Ramanandanand and uh thanks Dr. and Dr.

who already has created a pitch for me. So I'm basically a professor of statistics and data science and uh we are and I'm a professor at IT Kpur. So we are the people who are uh who are say

generating the manpower who are the people behind the creation of AI tools. So first very important responsibility comes on the academic institutions who are producing the students to to teach

them about what is an uh ethical AI and a non-ethical AI. AI as a for a common man it looks uh like a magician box which is trying to give something out of the box but the fact is this this is

based on the input what it is giving to the data how the data has to be used in the proper way. This is the biggest challenge and this is what we teach to our students so that they can implement

the right tool on the right data so that they get the right conclusion. Now coming to this global south issue if you try to see as Dr. Ramanand has pointed out that our south global

countries they are generating lot of data and we should not use them only as a consumer but we try to help them in developing their country and developing their society. So now recently if we try

to observe in the recent uh budget the honorable finance minister has declared and has invited the people to establish data center in the country and they have given different types of uh say uh the

facilities including the tax holidays etc. So the bigger company like as Amazon and as open AI etc they are the companies who are ruling the world uh with respect to AI. Now when we are

trying to create a data center here it's not only data center we are developing our own country also this is going to generate a lot of employment when we try to generate when we try to establish a

data center at any place that city that state becomes uh gets a lots of employment lot of revenue generation and this in turns uh in turn actually help the GDP of the country. So now when we

are looking at those south uh global countries, yes we have to help them so that they can generate the data in the right way. We can develop our here data center analytics companies and who are

going to develop the tools for them which are useful for their society. I personally believe that if my neighborhood is not having a good life then I also cannot have a good life. I

will always on the risk. So if we want to have a good and safer life, it is also important that our uh that other countries are that the people in other countries also they are having a good

life. So uh so in this uh age the creation of data centers creation of analytical tools creation of institutions who can teach that how to develop the AI tools, how to

use statistics, how to use data science, how to use ML in the right way. They are very important and this is the high time where uh the government has already taken some steps but we all have to take

them forward so that we are able to achieve what we really want. So now when we are looking at those south global countries this is the uh I always say that every trouble gives us some every

problem gives us some good opportunity. So because our south global countries are facing this problem. So this India has a very good opportunity where we can develop our analytics center, data

center, academic research institution, teaching uh teaching institutions by which our younger generation is going to be benefited and uh and one of the uh say important uh factor with India is

that we have a very huge population and and there is a very huge young population. So now with this uh data challenges they are going to uh going to get employment and in turn the the

country is going to it's not only our country but other countries are also going to be developed. So this is a golden opportunity in my opinion and we should look forward for these thing but

when we are trying to do these thing then we have to be very careful about other aspects also. India is a vast country. It is a very heterogeneous. It has many characters. Uh whenever we are

trying to develop a data center for example then this geopolitics geoloccation all these factors comes into picture. Even the political equation they also come into picture. So

they have to be taken proper care so that the creation of the data centers doesn't fall prey to the politics or the national level politics or the geopolitics or state level politics.

Number one. Number two, creation of data centers requires u the infrastructure uh loss of electricity, lot of uh water consumption. So uh so now we have to be very careful. It should not be only the

politics which should dominate the the place the choice of the place for the creation of data center. It should be where we uh it can go in a sustainable way. There at for example at those

places where we have excess of water the temperature is low possibly the the consumption of electricity for cooling the data centers and for using the water uh the amount of water will become less.

So definitely we have many places in India which are under underdeveloped which have not been developed tech technically and but they have all sorts of these such facilities. So this is a

very golden opportunity for the country uh that different sectors, different organization, different ministries of government of India they can come together and they can look for such

opportunity where just like uh we have religious tourism, we have medical tourism, we can have employment tourism places also and I'm sure that this type of opportunity will really boost the

economy of the country and uh it won't be difficult or it will be a very helpful step in uh in achieving the target of the country in 2047 to be a vixit bat. Thank you very much. Uh thank

you professor Salaf. Uh to highlight two major issue data role of data center in employment and how we can you know uh as a India as a diverse country to you know train uh you know our data center or

tools in to understand not only diversity but to how to work in you know very diverse setup diverse society and diverse global world. Uh we have 5 minutes for the you know to take some

questions and even if anyone in audience want to ask question to panelist they can raise their hand and we can take two or three question anyone

Oh yeah. Uh hi, my question is to the entire panelist since uh you are actually

having access to academia and you're working with people who are generating tools AI tools. So uh since I'm a lawyer and I'm a privacy council so my question is more towards the privacy while we are

building such tools how are we protecting or how these tools will ensure privacy of individuals can someone answer that &gt;&gt; you see the creation of AI tools doesn't

come from the god this is only you who create who give the input to the to the model that how the model has to think. So when you are trying to create such a model and at

that step only you have to create just take one more variable that is the privacy and what type of privacy in the beginning suppose if I say take say 20,000 cases you have to classify them

whether this uh case uh falls to the case of privacy or not and then gradually the model will understand what exactly do you want and after this the privacy issue will automatically be be

be created inside your model which in turn will give you the same output what you want that all the uh all the output taking care of the privacy &gt;&gt; see uh

we going to understand uh the tool as I said this is just an art this is to be seen just an artificial artificial intelligence be seen as an information technology tool

designed designed to support our decisions faster [clears throat] accurate. Now [snorts] there are two aspects to it

broadly to comprehend it there are two aspects to it a all the possible content available on internet that is in our hand all the possible content this is where

you'll filter the information from second is based on this my projection right [gasps] now both the cases if I do not provide you the basic raw material for your consumption to process it

further. This is I mean I'm I'm restricting it but I ego the sentiment that you have said not just that even before artificial intelligence come back to the

basic information technology tool like for example a CRM tool if I'm making myself or my information available for consumption to these corporates

as long as it stays with you fair enough. And this is what we believe in and that is why we allow you to to do this. But I raised a question once and uh in in one of my article also I had

employee made it made it questionable as to a student from my institute leaves and goes say for example from Kolkata to Bangalore to join her job. books a taxi.

Now all these informations are available to that taxi operator. Books a ticket that is that information is also available. And when she lands up in say Bangalore

and she reaches at around 10 [clears throat] 10 in night and then again she logs in for a um taxi. Immediately a message drops in that XYZ restaurant is to the left. assuming that

you would be hungry, you would be needing food, you feel good. But by making my s all these informations available to a third party, I'm also exposing myself to certain

avoidable threats. [snorts] How these IT people IT [laughter] people will will will tell us? But of course, this is a double-edged sword.

We are going to accept this All three of you are leading institutions. So all three of you are leading institutions and institutions that are themselves generating large

data sets in various ways admissions or data sets complete training programs. What could be possible measures at the institutional level that while taking care of all kinds of safeguards these

data sets could be made available for AI development like uh you know there are few informations that I cannot make public [laughter] right so the if you'll ask me

share the basic details of your students I we won't share their marks we Don't. So there are certain set of informations that are public like for example and you would

want me to make it public by after admissions admission process is going on. You would want the entire merit list to be there on the website for greater transparency. So name, father's name,

place etc. previous background, educational background, written marks, interview marks and so on. But when you ask me the cell number, I won't provide you. You ask me the email ID, I won't

provide you. You ask me the residential address I won't provide you. You ask me the likings it is likings I won't provide you. You ask me the previous company I won't provide you. So it is

for us and once these things will stabilize many of the issues will come come to the four and and it is coming as as situation is evolving it is certainly coming forward. I hope my co- panelist

will also be sharing something. I think uh one is uh we have like implemented a constraint mechanism see as for the DPDP act to adher it uh for the students and then data labeling is also being done so

that I mean the only the required data which is also important for the research purpose is made available in a separate entity like uh data coach and the and all and not all the data is transferred

to the centralized location because both things are required. So data is required for do the further research in the and then also important that privacy is being protected. So I think DPDP act has

adequate measures and if it is implemented by institutions they will take care of it. I will just add one line that sometime in order to develop a tool uh yes we can use the data but we

analyze the data. So that is one way out. If you um as I said there is an there's ethical AI. If you want to do something if you want to develop something for the welfare of the

humanity then people will come forward depending on your objective. &gt;&gt; I think she want &gt;&gt; uh I think we have to wrap up because now we have only 5 minute.

&gt;&gt; I think you can take she she just raised the hand earlier. [laughter] &gt;&gt; Okay. Yeah. She's &gt;&gt; Yeah. Yeah. &gt;&gt; Um can you all hear me?

&gt;&gt; Yes. &gt;&gt; Yeah. I think my biggest question here is we're talking about um building the south and there are some great possibilities

but are you all considering the algorithmic biases and the societal biases that also creep into AI? Um I often think about you know obviously class, cast and gender and uh weirdly I

felt a little sad that even this panel there there are no women here and I want to really understand that when when we are talking about uh building AI systems when we're talking about you know

bringing it into our lives and progressing then are you all actually taking all of these different things on board? You see uh as I said the AI will give

you output the it AI means artificial intelligence and above all there exists natural intelligence which god has given us. So so definitely AI will not be be AI cannot take a decision which is

comparable with a human being. So AI is simply just like your very obedient and efficient slave which to whom you you give hundreds of works the the human will uh will do it in 100 hours he will

do it in 5 minutes. So the so the so that AI will give you the output but it is only we people who are going to take the decision that how are we going to understand it and how we are going to

implement it. So all sorts of bias which you are apprehending yes they can be corrected but then you need a knowledgeable person who understand those human biases they can correct it

very easily. Uh I think you have you know asked very relevant question. Uh undoubtedly there are concern about the you know data biases and we can only stop through transparency of data how we

are using those data. If we are uh will not follow certain structure certain system there is a lot of possibility we will you know bring lot of uh not not only human bases but the message which

we are importing from the makers of those data you know uh sets and for the global south it's a very necessary to understand those biases to understand those ethical concerns because it's very

important to you know make a equable datadriven society uh it was very challenging job for our CPRG to bring uh you know speakers at one point of time. We have invited lot

of people but some of uh speakers from the you know uh you know from the diverse section of the society could not come because of they have already you know they have already committed uh we

have worked on the you know data as a job or future of job how you know data is going to you know influence uh future ready job and what could be the possible outcome impact on the industry and we

have one teacher which we just want to play and the report of future of job will come in next [music] Heat. Heat. [music]

&gt;&gt; [music] &gt;&gt; Thank you everyone for attending the session. Yeah. And I think we have safe and trustable. Uh we're just waiting for one more speaker to join us.

I'll invite our honorable panelist. Uh we have Dr. Sanjay Bell, Del General Surgeon, Dr. Well, can we have a round of applause for our speakers, please? Thank

you so much. uh Dr. Muay uh Dr. Pawu, [applause] we've got uh David Ro from the

Australian Strategic Policy Institute. Great. I'll let uh the speakers introduce themselves. Uh meanwhile, we've got one speaker from Microsoft who's joining in. Right. Uh we can start

with uh David. &gt;&gt; Sure. &gt;&gt; Uh thank you, Kishkin. Thank you so much for having me here. It's a real honor. It's been an amazing few days. Uh, I've

been wandering around the uh the building for uh since Monday and I just want to say how incredible it is to see so many young, keen, hungry, enthusiastic people who've all got their

own startups that they're working on or they're finishing their studies and thinking about what they're going to do next. It's uh it's it's both intimidating and uh hugely impressive.

So, um it's great to be here. I'm I've got a national security and international policy background. So, I I don't have a technical background. I will very much be coming at these

conversations from a geopolitical perspective and thinking about you talking about how how we cooperate, you know, those countries and Australia, my home country, not part of the global

south, but certainly included in the countries that are not close to becoming technical AI superpowers anytime soon. So, I think all of those countries that aren't a great power in AI need to think

about how they work together uh closely. So, that's the perspective I'll be coming from. Thank you. Uh hi, I'm Dr. Pawand Dougal. I'm a lawyer in the Supreme Court. I work on

the intersection of law and technology. I'm currently heading the global uh artificial intelligence accountability, law and governance institute. I also have been uh working on AI

accountability, liability and more significantly now trying to see how nation states can come up with new legal frameworks for the purposes of holistic AI sovereignity as we actually go

forward. apart from doing various other things. Thanks. &gt;&gt; Uh good afternoon everyone. My name is Mad Noy. I am working as director strategic engagements and chief security

adviser for Asia Pacific with Google. But I must not forget my roots especially since two of my batchmates are sitting in the audience. I am a Indian police service officer retired

and uh 92 batch and my last posting was as executive director for interupool looking after technology and innovation. Thank you. there's

three doctors Dr. Gar, Dr. Dougl Dr. and now we have Mandar coming in from Microsoft. &gt;&gt; So my name is Sanjabal and I'm the director general for the Indian computer

emergency response team. [clears throat] I think that should be more than enough because now we got a panel. He'll have to start otherwise we're getting out of time. Yes. And before I start uh I think

I need to thank the organizers the team from Ministry of Electronics Information Technology Ar Thank you so much for getting us here. We appreciate. Uh if you can have one

group photograph uh with everyone and then we can quickly start. &gt;&gt; Yeah. [clears throat] We also joined by Mandar Kulkarnney is

the national security officer for Microsoft. Mandar you want to just quickly introduce yourself? &gt;&gt; Thank you. I think you did it. We can get started. [laughter]

So I'm national security for for Microsoft India and South Asia. In that role I work uh closely with u all the cyber security agencies in India including what Dr. Bah leads uh for

collaboration between Microsoft our thread Intel and how we can uh work with those agencies. Number one a little bit more elaborate introduction I set up Microsoft's cloud 12 years back in India

uh and I laid their cloud business for few years before moving into national security. Thanks. &gt;&gt; Great. Uh I'm Ganesh. I'm the founder of India Future Foundation. We are a policy

think tank working on the intersection of technology, policy and geopolitics uh for last 7 years. Thank you everyone. I'll start with uh Dr. Beel. Uh we are here to talk about AI safety and

security. But today we see a big gap between the global south and the global north in terms of AI safety preparedness, AI safety resources. And this big divide leads to a constant

fight in terms of what [snorts] the governments can do the role which tech companies can play. So my key question to Dr. Beel is Dr. But hell, if you were to bridge this gap which the we are

facing between global south when it comes to AI risk management and incident response, what could be key things that we could do? See, if you've uh carefully looked into

this space, this space requires a lot of uh capital, it requires talent and it requires energy. So if you have a gap in capital you are challenged. If you have a gap in talent

you will be challenged and if you have a gap in uh energy you'll be fortunately for India we don't have a gap in the talent part. We have a abundant talent and we can provide that talent to the

rest of the world. Now those who have the capital will obviously pull that talent and now we have to be very clear as to how we keep that talent. That's number

one. From an energy perspective if you see there are challenges what you see in Europe they are facing already. So if there are some countries who and some companies who have these

things they will obviously be growing and then that divide starts increasing. So that's where the challenge for deficit in compute and data and models will start increasing.

Now if that uh divide increases how you going to handle those situations also if you see there's a today [laughter] there's a challenge in terms of transparency of these models there's a

challenge in terms of the behavioral ability of these AI models [snorts] there's also most of them are uh of course they're from two countries if you see primarily and the companies there so

there is a challenge in terms of the data which they have been trained on and the linguistic aspects because how do you address the local Indian dialects etc. Okay. So now I'm not saying just

Indian but if you look at any south global south so any of those so if you look at the African side or any of this uh latam etc. So you know we have to start addressing it from that

perspective and also there's a lack of maturity of uh frameworks and regulations. So if we are not in a position to address these aspects we will be

challenged from uh the perspective that you have raised. I hope uh that addresses some portion of what you &gt;&gt; Absolutely. David uh I want to bring you in here. Uh Dr. mentioned two countries

and the global divide we have and there's so much dependence on those two countries. Uh what's your view from Australian standpoint? What what do you think uh needs to be done?

&gt;&gt; Your mic I'll borrow your microphone. Thanks Kesh. Thank you uh for the question. Um so yeah I won't repeat what um Sanjay has said. I think all of his he's covered those uh those concrete

points very very adequately. So I I would take it back to start with just what are the risks and safety um what are the risks and dangers that we're actually talking about? What are the

threats? I mean there's a range of uh of of risks. One is obviously misaligned and uncontrolled artificial intelligence. That doesn't have to mean I hate the term rogue AI because it

conjures up those sort of destructive uh images. It's not necessarily that uh that concrete when we're talking about underlined or uncontrolled AI. It could simply be uh artificial intelligence

models and tools that start to lead us down a direction that if we stop and think about it, we actually we don't want to go down. I think we're already in, you know, social media is arguably

unaligned at the moment. There are lots of outcomes of uh social media platforms that we all agree are undesirable and yet they are sort of baked into that model and it's very difficult to come

back from them. Um another risk is you know the strategic danger that your rivals in the world are going to become more competent and more capable uh than you. That's obviously a risk for

countries well all countries outside of the US and China pretty much. um even those two superpowers themselves that are constantly worried about you know who's going to uh take the lead. It's

it's enormously consequential. We have the risks of rogue actors like you know the classic case being you know the extremist or the uh the extremist organization or even just the

disgruntled individual who takes AI takes an AI model or tool jailbreaks it uses it to create some sort of deadly weapon such as a bio a boweapon and then there are just the disruptive risks

let's say everything goes right uh in the progress of artificial intelligence it becomes highly capable. It will have disruptive effects on jobs on you know the basic economic models that have

applied since you know Adam Smith invented the field back in you know late 1700s whenever it was um the social and political upheaval that would follow from that and beyond the economy. I

heard the term there was an excellent session yesterday that I attended uh where the term cognitive sovereignty was used and I found that to be a really really useful phrase. I mean it was that

basic idea that if if you don't have ownership and you know a full sense of rights over your own uh attention and your own awareness of the world then really you don't have everything. that

is a that is a sovereign individual right uh that we should all uh hold on to and regard as very very precious. Now I would just point to the fact that the the the superpowers are themselves

vulnerable to a lot of those risks. So there isn't actually necessarily a divide between the superpowers and the non-suppowers or the you know the global north and the global south. A lot of

these risks are across the board. the I mean the the thing that I would point to most uh strongly in terms of what we can do, what all of our countries can do together uh to try and

fill the gap that that that does exist is through cooperation. we we you know we need to share we need to cooperate uh you know we we we need to sort of you know build our understanding together

and develop a kind of a network of countries that can uh can sort of push back against these threats and risks. So I think that's a very important point in terms of building

collaboration and I think where the role of big tech plays extremely important role. There are companies like Google uh which work both in the global south and in global north and they have tremendous

opportunity and also the resources. So Dr. What do you think companies like Google to do when it comes to embedding safety and security by design and preventing

misuse of AI? Thank you. Thank you for the question. And I would say uh Google being a hyperscaler uh one of the fundamental duties is to provide a secure infrastructure. And when we say

secure infrastructure and I would definitely like to refer to Google's safe AI uh framework which has basically six pillars but I'll stick to three interesting points. One

is the infrastructure security where it is secure by design at each stage of the AI life cycle. And how do we do that would also depend how secure uh uh our systems are. And then comes the issue of

uh providing uh automated guardrails. And when I uh say automated guardians, I mean things like um model armor where we are looking at u the [snorts] responses as well as the prompts so that uh harms

through things like prompt injection cannot happen or uh while giving out responses we are not exfiltrating any sensitive data. So those things can be brought in there. And the third aspect

which I would uh say is uh basically on the shared responsibility model and that is where each and everybody has to perform their role so that we are able to take care of the security [snorts]

and it is here I would say the role of uh uh big tech companies like Google would be in terms of providing tools to do this whether it is let's say synth ID where we are looking at uh watermarking

various uh defects etc. So that is very important where we can do it or even uh agentic identity uh management is concerned. Uh I'm also tempted here when I talk about identity management in

terms of the based on my previous experience in law enforcement the very uh the big uh attribution gap which exists. So unless we are able to bridge that we would be running into problems

and that's where the the security per se uh what hyperscalers can do if we compare it in terms of a uh safe city hyperscalers are providing infrastructure like roads etc. But the

ultimate security comes through the collaborative policing where each and every stakeholder has to play a part. So that is uh therefore unless all of us play our part we won't be able to ensure

that I'll pause here and say great thank you uh Manda when it comes to shared responsibility what role do you think people like you need to play uh you've been the national

security officer when doing work on cyber but the roles have changed now it's AI the ages of AI so what do you think has really changed for someone like you when it comes comes to share

responsibility. &gt;&gt; Um I think um what you said shared responsible is the key term here. Uh and while sometimes we uh talk about EU

being overregulated, they actually provided a good framework through EI EU AI act, right? Uh because many times we get very fixated when we talk about AI on models, right? How good are models?

how safe are models and all that. But I think u what we need to understand is AI is not only model right there are multiple layers multiple tiers that we need to secure when we talk about AI we

need to secure data we need to secure models of course and Dr. talked about model being uh black box not explainable or transparent. So that's that's a layer. So data model u content

infrastructure and then the application layer we need to and identity. Um Mr. Ober talked about identity. I think those are the layers that we need to secure right. Why is that your model

could be good but how is your application secure or not will determine ultimately whether your AI gets compromised. AI is not only model you're not you're not interacting with raw

models most of us interact with uh an interface right it could be copilot it could be geminina it could be GP jp we interact with that and I'm talking about the simplest of AI application as you

get into a little bit more complex application the business applications where AI is going to really make an impact uh the application the infrastructure the data layer is going

to be or identity layer is going to be even more critical so with that I think shared respon becomes extremely critical or uh uh is very very important because the responsibility is not only with one

party. So it's not only the guys who are developing models, right? They are providing you raw model, right? Then there is responsibility on the people who develop applications using those

model. Then there are guys who are using those applications, right? A bank, a government institution or anyone else, right? That's the third layer. And fourth is us who actually end consume

that application. So there is responsibility that is across those seven layers in AI application stack but also across these four. So it's a 7x4 matrix right those four people or uh

stakeholders who use build or use AI application have the responsibility. Uh I'll give you one simple example right. Uh there was a very popular uh trend that came up when um Chad GPD created

that Giblly images right everybody uploaded their pictures in it right now did we really think about how we are uploading why what we are uploading where it is going to go no disrespect to

what uh OpenAI did but the frenzy that we saw is the risk and that was a very simple example because that happened to us in consumer life very similar things are happening in business right when

people want to do let's say summarization right they are taking help of either an AI application that is deployed by an enterprise so governed by their IT and security team or many cases

if there is no AI application that is provided users are using application this is like a second generation right all of us dealt with shadow ID since cloud came now we are dealing with

shadow AI which is even more difficult for IT teams to manage and govern so that's going to be the important thing right one how we pin the responsibility and secure all seven layers of AI

application. Second, how we do how we pin responsibility on all the four constituents holding only the model or only the uh end user uh responsible will not work. We have to distribute that

&gt;&gt; Absolutely. &gt;&gt; Yes, Dr. B. Please go ahead. While Mandar has talked about this 7 into four, there's one thing which is conveniently or I don't know

conveniently also uh Dr. Why they've missed out is you will still have challenges and that is where the state would require certain details and that's where whether you call them uh through

the regulator or the law enforcement agencies etc demanding details and then that is where the shared responsibility aspect comes in but then that shared responsibility suddenly disappears from

the big tech because then you start coming through Mlat and you come through all sorts of other channels and that information is never received. So I don't know what happened to shared

responsibility at that time. That's that's a tricky one. I I'll [laughter] need to answer that. Okay. I I want you to hold on to it right now. This is getting really interesting. Right.

You've got a regulator and you've got a big tech. So So that's this was no guard rails, right? Absolutely no guardrails. [laughter] So Dr. Bul right and and we'll bring in Dr. Roy as well. Dr.

Google when we talk about those seven layers those seven layers can't be secured either by the developer or the deployer or by the platform alone [clears throat] it is collective

responsibility right so how do you think the liability and the accountability needs to evolve because we're talking about securing those seven layers and not one platform owns everything you've

got different platform providers the AI developers are different so how do you evolve in this space &gt;&gt; it's very clear that &gt;&gt; It's very clear that uh the six major AI

laws in the world so far, the European Union AI act, Chinese two laws on generative AI and AI labeling, South Korean law, Japan's basic AI law, Hungarian law, and El Salvador law are

nothing but a classical example of six blind men trying to describe an elephant. None of these laws have actually gone ahead and started addressing the fundamental issue of

accountability. Yes, the U AI approach of low risk, high risk is great starting point, but ultimately you will have to make things accountable. 2025 the issue was should we regulate AI or not? That's

no longer the position in 2026. 2026 is that once AI causes harm to humans, who's going to be accountable? And that's the reason accountability becomes of crucial necessity. If you're wanting

self-regulation to govern accountability, then you are on the wrong platform because the train is never going to arrive. uh you will never see self-regulation uh promoting

accountability. Why? Because monies are involved, finances are involved, effort is involved. That's the reason we'll have to come up with legal principles to govern accountability. In January 2026,

I launched the AI accountability framework which is a coalition of all legal principles, doctrines and philosophies which lawmakers across the world need to keep in mind as they come

up with new laws on AI accountability. How about liability? Can I just make only the coder liable? Can I make the company liable? I think I come up with the uh new concept of a graded uh

liability model where whenever a harm gets caused to a human uh there have to be equal or shall I say proportionate responsibility of various stakeholders some bit for the coder some bit for the

company who's uh giving the set model somebody who someone for the company who's uh marketing and someone even for uh the data principle the user I mean I recently got this case where this guy

was working with a particular AI model in central India and he's obviously been bullied in class and he decides to uh get solution from AI. AI says the best solution is go commit suicide. He argues

against that fails after 3 months AI is very successful. This man asks what's the best way to end my life? He says go and slit your wrists. He slits the risk wrists thinking that's the end of the

life. Parents come in and find him in a pool of blood. Take him to the hospital. He's now out of danger but his hand is paralyzed. Who's going to be accountable in such a scenario? I think we'll have

to have guided responsibilities. But for that you will have to have a regulatory approach. You cannot just leave it to self-regulation. You cannot leave it to cooperation. And how about

accountability in terms of transparency? I today I'm dealing with AI as a black box. I have a fundamental human right towards reality towards ensuring that my cognitive faculties are not interfered

with or colored with by AI. We need to incorporate all that as part of cognitive neuro rights of citizens as part of uh the legal frameworks that we talk about. Maybe we could look at an AI

constitution because the existing constitutions of countries including in India don't really have been uh shall I say made ready for the AI age in a scenario like this. So we'll have to

look at issues of transparency. Can we come up with an algorithmic transparency protocol which is mandating companies guys come up with these levels of transparency in order to make your your

AI model or AI algorithm more explainable and more significantly can you be the repository of AI rights today the advent of AI brings in new AI rights for the users nobody's talking about

them today your when a 399 pack is launched in a country like India uh it's not that worldclass services are given to you because you are kind or because you are so special. Sorry, you are the

fulcrum of all the data which the big tech companies want to ultimately collect. And if you talk of accountability, I have to also talk of a connected area of cognitive colonialism.

Indians have started walking towards back cognitive colonialism. They are ready to become cognitive slaves of big tech companies ready to mgage their cognitive faculties at the doors of AI

thinking well that's the best of the world. Well, hold on. With more Alzheimer's coming in your way because of your cognitive incapabilities, you have a bigger problem. And therefore, I

think the read the need ultimately to secure your cognitive spaces will have to be an integral part of the accountability governance model as you go forward. You'll have to make them

liable. But where do we make them liable? What legal remedies do we provide? Where do I actually sue them? Do I sue them within my own country or shall I say the El Salvador model who

says look use an El Salvador AL algorithm no problem wherever you are harm is caused to you come to El Salvador and sue me here only then will I be able to look at I think interesting

point made by Dr. Google one is the whole AI safety repository and the second part is particularly around uh your cognitive colonialism uh and I was on a TV panel yesterday and we spoke

about how Gen Z was becoming addicted and uh their brain was getting rot because all the kind of content they watch. When I go to business schools and I do leadership sessions, I find much of

the learning is not happening through classroom but it is actually happening through reals which is really bad because you have some superficial knowledge of a subject but you don't

know what it is there in the depth. So if you were to make a AI safety repository to bring more safety security and more ownership between regulators and developers in emerging economies,

what are some of the key things we need to do? And this is this question is for anyone who wants to take up from the panel. Uh Dr. Obi, you want to uh chime in?

So in terms of uh repositories and I assume you are referring to the regulatory repositories what I would say that there's a need for uh these kind of repositories because we need to learn

from each other we need to uh have repository at least uh regional hubs or regional alliances whereby we can exchange what is happening at the same time one point which I think Panji

mentioned was uh with regard to the uh ability of these regulations to be sensitive to the local languages, cultural nuances that is very important. So that also has to be kept in mind. But

at the same time we also in order to encourage u innovation part we also have to provide for the uh regulatory sandboxes and that's where a lot of things need to be developed and that's

where probably if you look at the overall uh environment about what all is happening on the regulatory front that comes into picture in so I'll summarize by one uh collaboration in terms of uh

repositories whether it is at regional level or global level, ideally at global level, but at the same time s being sensitive to the cultural nuances and the local language, dialects

[clears throat] etc. So that our uh uh notions of uh biases are not influenced only by the western uh norms. So it therefore it has to be uh sensitive to the local uh nuances also. at the same

time uh uh providing a environment for innovation uh through sandboxes and uh I think one uh I'll refer to one of the previous comments which was made in terms of providing enough uh regulations

uh uh to make sure that uh we do not cause any harm but at the same time I'll just like to point that we have to be careful that we do not curb the innovation part so it is it has to be as

has been one of the sutras of the seven sutras that innovation is much more important than the restraint. So we have to be more positive on that aspect. I was interesting David uh how do you

build interoperability in AI governance without compromising national sovereignity innovation. &gt;&gt; Okay thanks Kish. Um well I mean there are certainly some foundational and

fundamental things that you can do while still allowing for a lot of uh room to move at a national uh sovereign level. So I mean you know you can agree on some really basic things like for instance

the illegitimate use of AI to carry out uh force or violence for instance like a bioteterror attack. I think everyone can agree that that is something for which there should be very very strict uh

guard rails. Um but at the same time you can allow for a lot of sort of uh national approaches to allow for sort of local conditions. But I think like at a more basic level I want to get I think

we need to get away from this idea that every commitment to international cooperation is an undermining of sovereignty. Like that's actually the wrong way to think about it. All

international agreements require some compromise and you compromise because it creates a a common set of understandings where everyone is better off. You might not be able to do whatever you want but

across the board with each international agreement everyone is better off. it lifts all boats. That's the whole idea of multilateralism, of international cooperation. So, we've got to get away

with from this idea that it's a that it's a undermining of sovereignty. And I would point to the fact that with AI being a, you know, an a very strong example of this, what is what what could

be worse for national sovereignty than having excessive control in the hands of private sector companies, organizations in other countries? It's not an attack on big tech but at all. It's just the

point that um you know a [laughter] a private sector company that is not accountable to your state in any way is a much greater danger to your sovereignty than you know we started

during the time Grock was creating all those filthy images right certain countries decided to ban uh Grock and X and it's only after that the response came in certain countries just limited

themselves to leaving threats open threats I would call those uh Dr. What the hell? Any thoughts on this? I know you're looking on the other side, right?

No, I think uh David has made a few very critical points. Uh [snorts] one in his first uh session he mentioned about you know

uh people should be sovereign and you're going to have challenges. Now when you are looking at implants coming in and AI trying to tell you what to do now are you thinking on your own or someone else

is thinking for you. What happens if more and more people in the nation start getting those implants who is driving you is those probably those big tech

companies and that's what Dr. Rel talked about colonialism. So you become a slave again. And then what's happening from the perspective

if you see some of these research reports uh [clears throat] right in somewhere in the top few India is using AI. [snorts] The median age is

28 years. Whereas if you see that where does US stand is somewhere towards the bottom end. Why

has someone thought about it? Why is that so? I don't know what the right answer should be. But my view is that I want you to use it where I don't want

to use it so that you become a slave to me. Right? I will do critical thinking because that's one of the requirements as you go forward critical thinking. You have no critical thinking

anymore. I have the critical thinking. [snorts] I will be developing the models. I'll develop what I want and you use them. So you become a slave again as Dr. Doug mentioned. So I think there are

multiple things which are happening. We have to be careful about it. And then on the other side we say AI is going to have an impact on the economy. And as David just mentioned

the companies are driven by commercial aspects they want to make profits. I was just talking before we entered the room that if AI agents models and when you're looking at cognitive AI etc uh

they are going to be doing all the work for you. So you will have a challenge of uh resources actually earning money. So if there's no earning of money where is the

income tax? So if these models are going to do the work, where are the taxs go or where are the uh profits go? It's not to your country [clears throat] is somewhere else. So what happens to the

governments? Is it going to actually create a economic uh you know impact or a drain? And then what happens to your yearly [clears throat] budgets which come that income tax income tax?

No, &gt;&gt; absolutely. [snorts] That's a very valid point and um I've been holding you. So I think now is the time there's a lot of questions you want to chime in and give

some of those key answers. there's a lot of work you've been doing in this space working with different regulators whether it's cert uh NCIPC right so please thanks Kish so

uh three points here number one kind of a response to what Dr. Well mentioned uh so that four pillars four accountability big tech is one of them right so we're not saying in the four layers right

there is of course big tech so when you put accountability when there is a regulatory framework everybody including the big tech should be included you can't keep a stakeholder out uh that's

point number one so the accountability fment that both Dr. uh the girl talked about has to cover everybody right a great example actually even the end users we ourself in our personal life

can't escape so that's point number one point number two one of the thing that we will have to do right India is also not India is not only net user any technology right we are also the service

provider right we do application what we do great India is diffusion right you look at uh the biggest success that has come out of India our DPI stack right jam DPI stack right we didn't build

kubernetes right or we didn't build any of those tech many of those we did definitely build one of them but we used to diffuse technology right everybody without knowing what do what technology

drives it we use Aadhaar we use mobile we use the entire payment all of that right so where we are great at is diffusing technology uh in my opinion that's something that we need to also

keep in mind when we look at AI Should India be develop AI whether it is models or chips or all of that? Definitely. But while doing that we should not slow down and we should use

diffusion because if we slow down our competition is not going to slow down right we have countries to our left countries to our right and all around us right who are investing big on AI they

are doing it all they are developing their own models they're developing their their chips but they are great at diffusion. So the question that we need to ask is we have to slow down and wait

for everything that we want to use. We have to take AI and ensure that it goes to the bottommost section of our societies. What did DPI do? It got services to the people who were deprived

of the services. Whether it is banking, whether access to technology, right? They don't know technology, right? When somebody or state vendor is using UPI, he doesn't know what it runs on, right?

But it solves a big problem for him or her. Now one of the question that we all need to understand and address is how do we use AI for diffusion? How do we make that work for the common man? The big

techs and big enterprises both u Indian and multinationals they will take care of themsel right from how do they use AI right and most of us in the commercial segment are working with large

enterprises. There will be push pull there will be regulatory guid rails that will come in we'll definitely welcome that but that's happen that will happen I think we need to replicate our success

on DPI and ensure that AI works for the last person on the ground I think that will really make this impact summit useful if we can take AI get out of boardrooms and get to the common most

people and change their life in my opinion I think that will be the success of this summit &gt;&gt; while we spoke on DPIs another key element is the AI generated

misinformation which is impacting public discourse and election today. So Manda if you were to build cross- sector collaboration to prevent large scale trust version particularly with the kind

of content we are seeing being generated on different social media platforms and it's it's a combined collective responsibility what do you think needs to be done? Yeah, I think great question

and I think I'm sure uh sir is working on a lot of that I foresee but I think it is again a three-layered approach right first the industry will need to come out with something which is a

consensus right for example lot of content is going to come out of the big text so first we need to agree and there are efforts right C2P is an uh is a one of the frameworks but I think everybody

needs to come on that platform that's number one but that will not be enough because While Google's and Microsoft would probably ensure that the content is prevenance and all that there will be

no actors who will not. So that's where I think the role of uh search and everybody else even some law enforcement will need to come in. Sorry just one point. So three layer first is the big

tech or we create frameworks which are more voluntary. Second, there will be a regulation at maybe country level at that and third it will be sector level things like RBI and all of them will

need to come in. I think we'll need all unfortunately we are seeing gaps. We are seeing uh industry doing it. Not everybody's on board. We are seeing laws coming in. Not all countries are there

and even radiators there are various levels of maturity. All three things thing will need to happen so that we take care of both the legal tech as well as the rope tech.

&gt;&gt; Great. Thank you. Can we bring in collective responsibility? That's that's the key part. He mentioned about collective respon. Is it really possible to build collective responsibility? Can

you get the regulators and the big tech to agree? That's that's the million-dollar question. You want to chime in on this? I I was just going to make the point that um to to me with

something like uh miss and disinformation, the the the ultimate backs stop has got to be the resilience of your citizens. You are not going to stop deep fake disinformation. I think

that genie is so far out of the bottle that the bottle is just not even there anymore. Um you're you're not going to stop it. So the only way uh to deal with it is to have critically thinking

citizens who are you know from you know primary school from elementary school from primary school from kindergarten you know from the from the time they're crawling around they need to um be

helped to develop those skills. That means that they uh they they can resist disinformation. They can spot it. They can think critically about it. And and that is the solution. You're not going

to stop it from the government. Google you think we are overrelying on regulation here what David just mentioned is about citizen being more aware in a country with 1.4 4 billion

people. You think that level of awareness can be created? I don't think so. I think we need to be understanding it very clearly. You will have to drive it through regulation because

self-regulation is not working. The Dunda model is what's going to work in majority of the third world countries. Also, we'll have to understand that we must start get start getting empirical

evidence. Everybody is saying well everything is hunky dory. But AI has begun started causing harm to humans. In January, I launched the global AI harms registry which is collating nine

different categories of harms which AI is causing to humans. Once we have the tumerical evidence, we will be using it as a basis for developing legal principles for mitigating such harm. But

ultimately, why are we so much concerned about regulation? We all want innovation. Yes, but innovation is not possible without regulation. You will have to have minimal enabling regulation

so as to promote further innovation as we go forward. You are innovating. somebody goes and you know steals your innovation what happens what remedies do you have what legal frameworks do you

have unfortunately I have yesterday's laws which I'm using for the purposes of dealing with tomorrow's challenges and that doesn't work Indian IT act is a 26 year old legislation accepting and

wanting it to be interpreted in the context of AI when it was not never drafted and keeping that thing in mind is important what Prime Minister Modi said yesterday was very important he

said India has to have a very graded approach towards regulation So the message is loud and clear. The regulation has to come in. 200 bills are going to be passed on AI in this very

year across the world. So you are saying regulation is not there or overregulation. Sorry that's not happening. Regulation will have to start addressing meat by meat point by point

the various issues as we go forward otherwise the sovereignity of the countries the security and the integrity of countries shall stand in shall stand president. Thank you Dr. Dr.

uh I'll go back to the point Kesh which you mentioned in terms of how it has to be a collective responsibility between uh regulators and tech companies and everyone else also the point is uh uh

going by Pavan's statement regarding that we need regulations and there's no denying to that fact that regulations are needed but what is regulation or policy a policy at the end of the day is

just an intent ultimately it has to be enforced and how Do we enforce it? For that we need technology today. And that is where therefore the tech company's role comes

in building those technology, those guardrails so that the regulations which have been brought by government can be enforced on ground. Uh today uh imagine that uh uh the latest guidelines of

rules 2026 of IT act say that a deep fake uh closure window takedown window is 24 hours. &gt;&gt; 3 hours 3 hours 3 hours sorry 3 hours my mistake. So 3 hours how do we take down

that without the appropriate technology? So the unless we have that enabling technology these are just intents without any implementation mechanism. &gt;&gt; Dr. B.

So in this last 10 seconds all this actually needs to work the base layer has to be trust. If there is no trust between big tech and the regulators, there's going to be a challenge. There

will be gaps. And what David said was correct. You need people or children to be having critical thinking right from beginning. But you also need regulations. But the challenge is

regulations. As Dr. Dougal mentioned himself is you're dealing with yesterday's regulations for tomorrow's uh challenges. Even if you have today's regulations, you will still be dealing

with tomorrow's challenges. So how you going to be keeping up? So you need regulations which are going to be dynamic. You cannot have regulations made today and then say I'm still going

to be dealing. You will always be in that challenge situation feedback that loop is going to be closed only when you are starting to look at dynamic regulations. But the constant thing is

going to be whatever you mentioned have ensure that critical thinking is there so that people understand why these dynamic regulations are required and how do you address them. So I think that is

what has to be done and the layer of trust has to be cemented today. There's a huge challenge from that perspective. So I'll stop there. Thank you so much uh Dr. Well for summarizing it. The layer

of trust has to be last closing remarks 15 seconds with everyone. If I want to work with you and build trust and safe AI for the next five years, where do I need to start in 2026? Mand, we can

start with you. Yeah, I think uh I kind of said this earlier. Uh it will need to be rooted in these three layers, right? Uh where the industry will need to build a

trustworthy framework. uh there has to be regulation of course and a third layer where we do uh the user education David mentioned it will need to be all three of them and actually Dr. Bah sums

it well. There has to be trust in across three layers, right? All three layers we need to trust with each other and continue. &gt;&gt; Great.

&gt;&gt; Thanks. I mean trust follows safety without stating the obvious that I mean we've got to concentrate on safety in order to achieve that. I I think government needs to be the standard

setter for artificial intelligence. This is the most profound technology that humanity will ever invent ever introduce. Um there is nothing like the legitimate legitimacy of the state to

control well to to to direct and guide uh something so powerful. It cannot be left to the private sector. Uh the state the role of the state representing the people the citizens is absolutely

crucial. The government needs to be the standard set here. &gt;&gt; Collaboration and trust with all stakeholders is a given yes but distrust in AI has to be an even more absolute

yes. We must be learning to distrust AI. Why? Because AI has started going rogue. It's acting against human interests. And as we walk towards AGI and ultimately super intelligence, the important issue

will be how do we ensure that AI does not work against human interest because ultimately AI has become an existential threat. And in that regard, the policy and the legal guardrails have to be put

in the development process of AI today. And that's the best way how we can save the trust of all the stakeholders in the EI ecosystem. &gt;&gt; Thank you. Uh I would say that going

back again from for my policing background that uh trust uh and safety they are uh recognized when they are invisible. Uh a safety which is visible where visible efforts are made it means

there is no safety. Today we don't uh discuss that electricity wires will be leaking in the walls because we trust that the uh uh and therefore what has to be done is we have to move away from

this philosophical debate. We have to move into a stage of technological engineering uh enablement so that this trust is built. We have had enough debate about that and we that debate is

not going to stop. Uh technology whose time has come will come whether we like it or not. So we have to build around it. Thank you. I think I did summarize earlier, but

just as a last statement, when you're looking at trust, safety, security, it'll all at this point in time have to be a good balance between art and science. Without both these things, you

will not be able to achieve trust, safety, security. And we have enough examples from our old scriptures of ensuring science and art. Thank you.

&gt;&gt; Thank you. Thank you so much. &gt;&gt; Before I let my panelist go, if anyone wants to ask any questions, &gt;&gt; I'll I'll start with two question. &gt;&gt; I can take a couple of questions. So

[clears throat] right start senior policy advisor at CES. uh so when you're looking at this whole thing around trust I think what we also need to look at is as was mentioned earlier

in terms of this whole perpetuation about the and the tendency and the chances of postcolonial dependency and I think from that perspective it is important that the

communities companies as well as the citizenry and the countries in the global south also get equitable space at this global discussions around

three is equity, ethics and ecology. &gt;&gt; Thank you Dr. Mr. Maheshwari. Yeah, maybe uh going forward, what do you think should be the right model for governance or regulation?

Not just in view of maybe AI but maybe such future technologies which are going to be equally harmful and equally transformative &gt;&gt; or equally beneficial.

&gt;&gt; Yeah, I'll I'll let people face the questions. Noama, you wanted to ask, [laughter] &gt;&gt; Hi. Um so my question is um this is related to a situation. So we at this

point we've all been discussing about humans and AI. Um my question to all of you is a situation when agents are interacting with each other and especially when we're talking about uh

agent to agent being developed um concepts like MCP. So if in in in the next 5 years it's when the agents which are talking uh within themselves and this is when we're building up agents

let's say for government organizations or let's say &gt;&gt; one one last question I want to take up someone from the back uh right uh someone's uh yeah you want to go ahead

&gt;&gt; I have a quick question uh two gentlemen [clears throat] over here mentioned that um onus is on the regulators uh for making sure their guardrails in case and the onus is on the citizens for having

critical thinking. But why did the big tech platforms have to rush to release models like LMA models uh without having the guardrails in place in in advance? Why was what was the need for having

rushed it all out without ensuring that people were ready to use it more responsibly especially at a time where uh you know organizations like fact-checking organizations are

retreating their budgets are crunching down and people whose job it is to even detect fake news or fight fake news or fight deep fakes uh they themselves are retreating uh you'll see the number of

facteing organizations and fact checkers is also going down. So why not replace version uh which one pick up? Okay, let me pick up the regulation part. I think uh countries in the global south

particularly India cannot do a cut copy paste. We cannot have an EU model applicable here. Why? Because the ground realities are different. Number two, in the developing countries going back to

regulators or to the legislature and getting amendments is going to be a tall process. So I advocate a principle based approach. Let's look at broad legal principles which can be effective both

narrow AI, agentic AI, AGI and super intelligence and then give sectoral regulators the flexibility to come up with sectoral specific regulations. That's the best way going forward

otherwise it's going to be difficult because even if if I make a law today in the next 6 months it's going to be obsolete the DPDP act is obsolete with a v AI because it does not mention AI. So

obviously I'll have to give that flexibility to the government to come up in that regard and also we have to look at the common minimum denominators. Let's not reinvent the wheel. Let's look

at the expenses of other countries and then try to see how can we go ahead and do things in this regard. Hello. [cough] [clears throat] Hello. What is our strategy about developing the critical

thinking among the people? We have millions of people who are studying in higher education. But the way we are teaching, way we are doing the critical thinking is a key part. So we also

thinking of developing a a a model. We should inculcate critical thinking among the people in different domains. Not only single domain but different domains. We have a question. Just one

last comment and we can have the speaker speak to you offline. They are here. All right. Yeah. I I'll take the the agency question. I think that the recent Maltbook um case was incredible for the

fact that if you leave agents in a uh in a space together, they don't just sit there and do nothing. That's the most incredible thing about it. Even if the more extreme response, you know, even

even if the more extreme things that they were saying, some of those were fake because they were actually put in by human beings. But even if you knock off the most extreme ones, they actually

don't just sit there and do nothing. They start talking to each other. We are in a really profound new era and that's why I think a lot of the conversations are actually kind of legacy

conversations. I still I think we're talking as if we're still in the same old world. We're not. &gt;&gt; Actually, we have to go and re reinvent our legal principles. Actress menria are

irrelevant today in the context of AI and therefore new legal principles, new legal futuristic approaches will have to guide us as we go forward. &gt;&gt; Absolutely. Thank you so much. But this

we run out of time. I'll thank the mighty team for the support. Can we have a round of applause for our speakers, the audience and also the team from India future foundation if you can stand

up please you have been working for the last 20 years please come forward my India foundation team as well join us token of thanks to the speaker &gt;&gt; yeah we'll give the token of thanks uh

I'll just get one of my team members pankage can you come in forward yeah pankage uh we have a token of thanks from the mighty team uh I'll ask one of my colleagues to come

as well. &gt;&gt; Pankage, &gt;&gt; can you come forward please? Ashish, &gt;&gt; yes. [applause] &gt;&gt; Deepak.

&gt;&gt; Shange. Yeah. Can if you guys can come forward please. Panka can join. Thank you, ma'am.
