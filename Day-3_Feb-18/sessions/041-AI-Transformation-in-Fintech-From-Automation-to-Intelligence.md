# AI Transformation in Fintech: From Automation to Intelligence

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Chanakya Auditorium |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/sKs0dz5HOGQ?feature=share) |

## üé§ Speakers

- Anjani Bharadwaj, HDFC ERGO
- Ashutosh Gupta, IITB
- Dr Prasad Ramanathan, TIH IIT Bombay
- Mr Harsh Kumar, Poonawalla Fincorp
- Mr Sriram Naganathan, HDFC ERGO
- Mukund Kannan, Mphasis
- Prof Dipak Gupta, Mehta School of Management, IIT Bombay

## ü§ù Knowledge Partners

- Technology Innovation Hub IIT Bombay

## üìù Summary

A deep dive into AI's fintech evolution, from automation to intelligence, enabling smarter decisions, scalable innovation, risk resilience, personalization, and transformative impact across financial ecosystems.

## üîë Key Takeaways

1. A deep dive into AI's fintech evolution, from automation to intelligence, enabling smarter decisions, scalable innovation, risk resilience, personalization, and transformative impact across financial ecosystems.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/sKs0dz5HOGQ/maxresdefault.jpg)](https://youtube.com/live/sKs0dz5HOGQ?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

IAT Bombay Mr. Mukun Khan head of applied AI emphasis Mr. Anjani Bhardwaj, Senior Vice President, HDFC Ergo. So I would request all of you to begin the session with a group picture. So I

request you to kindly come in front of the stage. Thank you. &gt;&gt; Sir, you may begin. &gt;&gt; Good morning.

It gives me great great pleasure to uh have a set of esteemed panelists to uh discuss this topic on AI transformation in fintech. To introduce myself, I am Dr. Prasad Ranatan, the chief technology

officer at the technology innovation hub at IIT Bombay. I have about 32 years of uh experience in the industry working with uh companies like Honeywell, GE, uh Capgeemini and now at the technology

innovation hub. We have a group of experts at the technology innovation hub who bring ideas from lab to market. We create impactful solutions that will be of value to the industry and the society

at large. With that brief introduction about myself, may I request each of the panelists to provide an introduction about themselves? Uh, Mr. Hush, can you please?

&gt;&gt; Hi, good morning. Uh, my name is Hush Kumar. I'm heading C HR and AI for Punal of Financ. So, intelligence in any other form I guess is uh what I manage and look at.

It's been uh and thank you for the invite. Um it's a pleasure being here. Uh and well I've got about what 25 years of experience. Uh more than that actually don't want to reveal the age. U

so I'm here because uh thanks for the invite from th itself. Uh it's a pleasure and uh well we have got a bunch of experts too within uh our setup which are helping us be build AI solutions as

we speak and T specifically has been very helpful. So we'll cover that in one of the questions I'm assuming. Uh thank you professor Rajatosh. &gt;&gt; Uh hello uh I am a faculty at IIT

Bombay. My area of research is uh verification of systems. Uh we are recently been looking at last let's say uh 7 8 years uh in verification of AI models. So what do I mean by that is

that if you deploy an AI model and you want to make sure that it does the right thing, we we we define what is the right thing and then check that property in the in in the model. In our discussion,

I will give you more detail as we go along. So u we we focused on building AI model which you can trust and it is just not an accuracy is not enough which is typically uh measure metric that is used

in this field. So I have been working in the area of verification for let's say 15 years uh and uh mostly in academia and we are right now transforming ourselves into a to serve this uh uh

this need when we deploying AI model everywhere and uh we do not know how to trust these models and nobody seems to understand how to make them trustworthy. &gt;&gt; Thanks uh Mr. Mukund. Hi um I am Mukun

Kanan. I am a head of uh applied AI at emphasis. I'm part of an organization called emphasis.ai. Um I've been actually in the AI area for about 10 years now. I started off my

journey setting up a center of excellence elsewhere. Then I worked in the startup and now I'm actually uh trying to build custom solutions and u you know build u you know model at heart

kind of solutions for different customers at u emphasis. Um so I'm a technologist at heart so I still love actually um to make things work and uh this is an area where I think every day

you end up actually finding something new. It's like a kid in the toy shop kind of a thing I get pretty much keeps me young. I'm not going to say how many years of experience. So,

&gt;&gt; thank you Mr. Anjini. &gt;&gt; Hi, good morning everyone. This is Anjini Badwaj. I'm part of HDFC group. I had digital and AI for the company. I carry around 20 years within the BSI BSI

domain and happy to have being here amongst you. &gt;&gt; Thank you. So we have a fantastic mix of uh industry practitioners uh IT service providers and academia in

this uh elite panel and uh when we talk about AI transformation in the fintech industry typically what comes to mind is okay November 30th 2022 is when chat GPD got released and everybody talks about

are you using chat GPT are you using Google Gemini are you using uh Microsoft copilot Is it quen model that is better? Is it a model from uh claude that is better or whatever? The discussion often

tends to surround around tools. But truly speaking in the context of fintech is tools the real context of how AI has to be leveraged. And my thesis today is going to be that

largely speaking when we talk about AI, it is not something that has come about new. It is something that has been around for some time. We are leveraging it in a slightly more effective manner.

Now over the past decade, most of the fintech companies have undertaken several steps towards uh automating what would have been otherwise manual processes. some rule-based automation,

some aspects which are largely covered under the aspect of improving efficiency. So where does AI take us? And my thesis is that AI is helping us in decision

making. And that is really what I would like to talk to our panelists today about in terms of how this transformation of going from automation to intelligent decision making is uh

where the industry seems to be headed towards. And so my first question to uh Hersh here is what are some use cases that you are seeing most adopted in your fintech sector primarily in the NVFC

space and what are some examples of quantifiable benefits that you can share with the audience. &gt;&gt; Sure. So actually we'll let me take two flagship projects both accidentally uh

were the genesis of our movement onto AI and not just geni as you rightly pointed out so traditionally we had automation for let's say department and sarti is the something that I want to discuss

shati is a project that we are doing along with t um so what it does or what was happening earlier is you had machine learning models so it's not that and you had scorecards and you had automation to

ensure that there's a smooth progression of any document. Today as we speak what has happened in the in this particular project is that uh thanks to TI and IIT our project ensures that all the

document verification testing checking summarization which would ordinarily have taken a credit analyst or credit manager an hour and a half if not more depending on how the time is consumed.

That part is taken care of. Writing of CAM is taken care of. The summarization of document which is a gen piece along with the machine learning that you're using ensures that there's a higher

productivity. They're not busy writing and understanding document. They know what to look at specifically. Let's say mitigant how how do they ensure that the mitigants are in place right earlier

they would have to go line by line item by line item even if it was presented the machine learning would score it but it will not explain it. So today as we speak uh we are seeing a between 15 to

40% uh improvement in productivity only on this particular site. So uh and we keep on measuring uh we started as you know that we started with personal loan and today I think we have seven project

product lines in which uh the system has already been incorporated and yeah further road to go. Uh &gt;&gt; thanks that is pretty insightful in terms of being able to do a significant

amount of loan processing the ability to extract summarized documents. These are some of the classic use cases where uh um Punavala Corp has seen significant amount of benefits. Uh on the insurance

side uh may I uh direct this question to uh Anjeni. uh what are some use cases where you uh see the insurance industry actually uh see the most amount of benefits both from the traditional AI as

well as the genai pieces of it. uh I think hers largely covered a piece of you know the extraction and summarizing piece which is becoming very prominent across the industry not only insurance

per se right so when it comes to HDFC as a brand right so been mostly digital savvy and we've been using both technology and AI you know extensively to get into solutions which are hyper

personalized for our customers right uh we have seen you know around 84% of our servicing happening through digital channels and 10% is a dable so that's that's where we are and in fact we

started our AI journey around five sixes back. Now Jenna is being augmented across our you know ecosystem. Uh when it comes to use cases primarily two one is around you know how

do we make it more uh assistive in nature right and definitely you know how do you use it across you know extraction of you know various documents. So if you look at insurance chain per se you know

being from policy is insurance to servicing to claims you know to decisioning you know and then operations in the back end everywhere across we look at uh accumulating assessing you

know assimilating a lot of textual unstructured data. So obviously AI geni combined together with traditional models and scoring plus you know making some sense out of using geni has been

very very you know impactful for us and across the various functions we see 20 30% of gains easily we get that right it's more of how we are processing or re-engineering our processes to get it

more efficient is what I'll say right so claims underwriting all of it and definitely when it comes to our customers you know how do we ensure that we are able to go to the market very

fast build some products you know or services which are very quick and easy to understand is where we have been uh getting into recently you know if I give you one special example we launched our

policy system right which is AI enabled and today uh products that we churn out which used to take months are now coming out in weeks so that's that's the definition I would say thank you

&gt;&gt; thanks Anjeni so there is a lot of uh capability related to summarization the ability to explain the ability to delegate uh activities uh or at least get some

assistance from these automated agents which uh seems to have a significant resonance both in the NBFC space as well as in the insurance uh space as a service provider as an IT service

provider Mr. Mukund where are the are you seeing the broad uh use cases uh that are coming across from the industry and uh I know that many of you uh who are in the audience may be thinking okay

how are these guys not talking about the ubiquitous application called chatbot right I mean the moment you talk about anything related to genai then the first thing that comes to mind is is it a chat

GPT enabled interface can I actually ask any questions to it and so Yes, chat bots and their ability to uh leverage the corporate documents and being able to answer questions is clearly one of

the things that uh I'm sure you are also seeing as an area. But other than chat bots, what are some use cases where emphasis seems to be providing a lot of uh attention to for their customers?

&gt;&gt; Uh so I'll probably take a little bit of a um little bit of a different view in terms of adoption in uh a right. So if you really look at it um the challenges for adoption are actually I put them in

two buckets. One is on the technology and business related issues of um you know taking AI into production and actually seeing value and the other one is

actually the uh user adoption and change management. Right? So these are the two large buckets. Let just kind of expand on that. The first one is um if you really look at uh AI projects, they get

launched in a lot of enterprises for various wrong reasons, right? So if you really look at it, uh FOMO is the top most recent a lot of projects get launched in the industry. So fear of

missing out. So a lot of people get pressurized into actually having to do something in a and projects get launched and then you end up actually another crowd which is typically that want

people like me who get excited by the technology and then start something right and these are not how anything should get started especially in u in um you know in a new technology area like

AI right so this basically you know gives us the first issue of why uh DC adoption actually getting a little bit of a problem, right? So you if a project needs to succeed, you need to have a

good problem statement that has a business value and actually you should use a technology that suits the pro you know the challenge that you're trying to solve. Um we had u as an a good example

I'll take um we uh uh we have a department called uh digital risk which has been in the business for a while but I think currently we basically identifying pretty much everything that

happens through the process right so it's actually the business that uh DR is on is u a mortgage u uh loan processing underwriting automation So we are actually going to currently we combine

you know the IDP which is intelligent document processing. Um Anjini touched upon some of that and we basically bring in a lot of insights into that for the loan processor to actually take actions

on and then certain technologies to nudge them in the right direction when it comes down to actually taking those decisions and passing it downstream to the other applications. This actually is

solves a big problem and if you really look at the scale that we are handling uh we handle the top five banks um in the US loans that come to top five banks and we basically have uh currently about

uh largest four um home loans processing companies in US most of that comes to us. So this is actually a really scaled uh scaled uh solution uh solves a real business problem with huge benefits. Um

then the second adoption challenge is actually a little uh different. So if you really look at it we get we get you know end up actually creating projects uh and then we basically take it to uh

live systems and then we figure out a lot of things that we should have thought about it from the user and stakeholder perspective before we started the project. Right? So that

actually causes quite a lot of issues in terms of scaling it to the next level, right? Um as an example, I um uh I used to work for uh I used to basically work for a startup before I came in I came

into emphasis and there we ended up actually creating a um you know um discharge summary digitization what we used to call as discharge summary digitization. you take the discharge

summary. This is in the healthcare claims value chain. Uh and then we end up actually picking out um diagnosis condition all of that and codify that and provide it to the adjudication

systems. So we ended up having uh I mean that one actually was it performed very well in the lab. Uh the customer was very excited. They wanted it to be taken live and we took it live very quickly.

when the customer says take it live you can't have a better you know uh you won't have a different answer anyways right we took it live then we figured out that I think there were lot of

change management issues that we ended up actually not thinking through so there was one case where I think we ended up getting a little bit of a neg uh you know negative publicity it was

actually a case where uh it was a chemotherapy case and uh the you know side effect is basically hair fall, right? So in that case, it actually the our model ended up

picking hair fall as the you know uh diagnosis, right? If insurance companies could pay pay for hair fall, um you know, I would have made I would have been a millionaire actually. Um but uh

anyway, that is actually certainly not there in that you know uh allowed uh uh things and it's silly to kind of have that and we ended up getting quite a lot of heat for that. So we took it back put

a lot of guardrails and relaunched it. So this is actually the change management thing. The moment you actually end up providing uh the model ends up providing something which is you

know counterintuitive or even common sense u missing kind of an answer it actually gets a wrap right. So typically the models will have to provide all the tools that actually either the user ends

up using or the downstream systems using so that the confidence trust is something that uh you know the other panelist spoke about as well. So the trust is something that the model has to

actually take into account before it goes live. So that's actually very important for us to scale. So there is um I mean there's one uh cyber security related u thing which we do for a third

party vendor risk assessment and emphasis. It's actually built with all those components and it actually is used by large companies. Uh today uh originally it went with the same

approach I said but I think we put in so many guardrails and actually made it more valuable so that it is trusted by all the uh risk assessors today. Yeah. &gt;&gt; Okay. Great. U uh thanks Mukund for

that. So one of the key things is the ability to actually change manage this entire process of introducing AI capabilities within the organization. And then Pokun's very uh poignantly

brought out this statement that unless we gain the trust of the user there is not going to be a huge amount of adoption. And that leads me to the next uh question to professor Asho in fact

who has been working in this area related to verifiability and the ability to actually validate AI models. Professor, what is your opinion on how can we build trust in these models in an

algorithmic algorithmic manner rather than by a manner that is largely going to be driven by users who say yeah I think it is okay but it still fails a few times. So what are some thoughts

that you have in this space professor? Uh okay. Hi. So before uh getting into my opinion on trust uh I would like to showcase two examples of of use in education of

of the latest development genai. So one example is we are I'm teaching a large course of 700 students. A lot of students don't have a proficiency in English. So I am teaching providing the

content in four languages at the same time. We we are doing English. Uh I'm in IT Bombay. So it's Marati and uh Hindi and Telu because we get a lot of students from from Andhra Pradesh. So um

so and the automated translation of course it creates a lot of errors. So you need human in the loop who checks. So uh what I did I I just uh entire course content has about 3 4,000

sentences that needs to be translated and I tracked how many times you need a correction. So actually the project started one year back and uh we we start translating and then we are about one in

20 sentences you need to change and the technology is moving so fast today if you translate something you need to one in a 100 you need to change. So uh to fix the sentence. Okay. So so so there

is a big opportunity in in education also. The second uh application which we have implemented is in in interview processes when students professor is interviewing a student and immediately

professor asks this question to himself. Look what is his marks in this subject in his undergraduate degree? What is his high school score? See there's a chatbot. He immediately asks the

question. It goes in a document and bring the information and also shows the the document from which the information is extracted says then you know human validation is in there right there and

there. So there is a lot of efficiency can be gained uh uh but it has to be deployed very carefully. For example the first example human has to check the translation. The second case when you

provided an answer you should provide an evidence where did you get the answer. Okay if you're saying this student has this subject that marks you show me the mark sheet. Okay. Uh which where you

picking up the information. So um so that means you need when you apply start deploying your s your AI in such a critical applications as then loan dispersal or healthcare decisions or you

know in interview process when you're interfering interview process. It's it's it's I mean we cannot reject a candidate because the AI gave a wrong answer. Okay. So uh so then you need to bring

lot of testing and analysis needed in AI models. So a software anyway is very very blackbox in nature. I mean if you use a software you know really how do they really work and the today AI models

are even blacker. Okay even the people who build them often find hard to explain what it is doing. So what we do we bring a technology in a table in which uh not only on the data set you

you check you say what are the possible future decisions this AI model can make. Is it biased against women? Is it biased towards a particular community in society? it may reject loan of

particular class of people all the time and where we have analyzed some models which is used by some banks uh which is we found that you know up to age 55 it works perfectly but between 55 to 60 it

doesn't work very well and after 60 it start working well again so why that that gap was there because the data was missing okay they didn't have proper data set for that particular age so this

kind of deep analysis you can bring in to bring more trust like somebody has done this in-depth analysis. Okay. Uh so then then you bring out these facts and then you fix them and then it brings uh

uh more more trust and for example one case they have uh you have mentioned is about you know uh the missing this common sense answers. Okay. So those can be automatically hunted and searched

today the technology exist and corrected before deployment. Okay. So we we we need this this this this is the technology we are building and it can be deployed. But the there's another issue

that is happening which is worrisome is sometimes problem is much more simpler and people just throw LLM at it. Okay is LM is just too big too complex and problem is actually much simpler. So if

you use much simpler AI models to solve the same problem you will get solved with similar accuracy instead of throwing LLM at it. If you have a simpler system then you can even deeper

analysis you can do and more trust can be built. Okay. So this is something uh uh has to be calibrated in the industry what the problem is what kind of tool chain is being applied and is it

matching it correctly. If it is matches better then you can someone like me who do analysis of systems can provide better guarantees and better uh answers to your question that am I is it biased

and I will say no it's not vir it's fair I can prove it okay but if model is like llm too big to really explain &gt;&gt; perfect thank you uh professor and uh

that probably gives some food for thought to hers and anjeni also in terms of is it always necessary to go for an LLM based solution. Can we actually make do with less than an LLM? And is if it

is less than an LLM then does it actually give you all of the features uh that you are looking for. So these are all things that uh you can ponder about and but I actually uh think that this

question of explanability, trust, speed, agility, efficiency all of these are intertwined and uh so hers from your perspective from a business perspective I'm sure there is a need to

take uh or adopt technologies in order to meet the business challenges and uh go forward. So how do you see this dichotomy of explanability versus trust versus speed versus uh verifiability and

all that? Any thoughts around this? &gt;&gt; Yeah. So let's start with trust and that's something that uh as you rightly pointed out a large language model can sometimes give you an answer which can

surprise you. So so we were facing a challenge too and u we were giving an answer and this was a simpler chatbot. We didn't want to use very heavy duty stuff. uh it still was fetching data

from somewhere we didn't know. So instead of trying to solve that and that was leading to certain trust issue change management becomes impossible if people are not going to trust the data

that it throws up. So we made it solve a puzzle. We we as rightly pointed out we just didn't ask one source we asked another slave to get us a source. So what

happened is that the information now being presented was verified by two models rather than just one. and one was acting as a slave. So the advantage was trust was built. But from a change

management perspective, another thing from explaining explanability is we are using ER governance tool. So it does right from incident mapping to what is the charge sheet or show cost to an

employee. Not a best of example to be given here but we needed to have all the case history of past and what decision has the EDC taken. That's a ethics and disciplinary committee, right?

Now you have to present it to EDC that in the past similar cases these were the actions that you did. Why? because it becomes incredibly important in court of law to say this is all the decisions you

have taken in past and this is the rational that you have used without which uh EDC would be uh would have taken a much longer deliberation or my team would have taken much longer

deliberation and from a speed perspective again it's not necessarily that you'll use a large language model as I said there are machine learning models that one can use for solving a

specific problem rather than using a heavyduty large language model to solve all and as far as change management from a speed perspective we are very clear another of the project that we have

jointly done um we have reduced that talent hub we have reduced 81% of our cost just hiring talent per se in the industry we are now I think arguably uh the fastest in the industry we had news

we had said about one day we release an offer from selection I think it's down to about 49 seconds today as we speak. So that change management became easy. My whole talent acquisition team of

course has uh now been reduced to zero. Uh that's a different story altogether. Nobody lost the job just in case everybody's wondering. But what happened is that the business which was using the

system suddenly said oh there's potential. So the change management actually thanks to again uh T and few of the team members here ensured that we could pick this up and run with it

faster and change management happened on its own. Great Anjeni. Uh any perspectives on explanability and uh verifiability and all these things that actually govern your uh industry too?

&gt;&gt; Yeah, it does. In fact, that's exactly where we are little cautious around, you know, trying to make it autonomous in many possible ways, right? So, while the technology is promising, it's already

showing outcomes. I think we're very cautious about, you know, in which uh context we using it. So as I had said earlier you know three possible ways agentic is coming agentic is going to be

there right but autonomy can be only given to a level where there supervision by a human right so the models are intelligent every day they are you know evolving and we are getting new versions

coming up across the leading providers right I think three use cases are still very relevant we are there up to the second one it's some supervision third one is something which we very cautious

about because we can rent technology but not the accountability so I think it's very important as a regulated entity that we are very careful about you how we handle data, how our customers are

seeing our services, how we are able to explain every decision that we make and they are given a choice to decide in their language which they understand especially in terms of insurance

context, right? And when it comes to explanability, you know, we we already talked about, you know, web bias, you know, and all that stuff which happens across models, right? For regulator, you

know, it's very important that they're able to actually scrutinize look at the entire flowchain of how the decision was made. You know, they're logged and they're available when this audit comes

up. which is very very important for us and that's why we are a little you know cautious around looking at that level of autonomy. So no matter what we do and how we adopt the technology, I think

humans would be there and that's how it should be. I think because humans have art at the end of it, right? So human in the loop is uh definitely something that all of us advocate

including the panelists and it is in that context that I would uh check with mukund are there any governance guardrails that you're putting in place in order to ensure that anything that

you build for your customers continue to meet these uh uh criteria of uh verifiability and explanability and all these &gt;&gt; right yeah actually um that is probably

one of the most important things I mean uh since the switch that we made from you know the quote unquote legacy a which is you know the machine learning deep learning world to the LLMs I think

there is a lot of fear in terms of uh you know they could potentially go wrong so there is we end up actually figuring out the choice of use cases to apply which is actually a standard practice

now and more importantly we look at you know the agent behavior or in even if it is non-aggentic LLM there are certain behavior patterns that to look for and the guardrails are uh you know pretty

much now uh starting to get more and more stronger in uh in the industry right so I mean if you really look at it even the regulatory aspects are actually coming in surprisingly as a help right

regulatory is not necessarily becoming more of an impediment in terms of what we end up delivering they are actually starting to become more of a support um so it's actually uh now it is all coming

together slowly in in the gen side. Um yeah, I mean we we have our own uh approaches towards and our own opinionated you know points of view in terms of how we bring in u uh you know

the guardrails and uh the the necessary uh you know support infrastructure to ensure that the you know the LLM don't fly up the handle. Actually interestingly I saw something yesterday

wherein I think uh things are starting to flip. I mean I'm not sure it's a one-off news but uh the there is a one company which is actually using the agents are actually employing humans.

Okay. So it's a they end up doing a lot of stuff but obviously there are only agents can do a few things. In fact the tagline goes something like we cannot touch grass you can right and the

payment is on um uh bitcoin. So which is actually a very suspect thing with the grass and the tagline and bitcoin and uh you know payment we tend to wonder what it is but I think nevertheless I think

it is starting to flip where the agents are employing humans. Um so we have come to a point where I think we have to live with agents doing a lot of things and the guardrails are necessary going

forward. Great answer and professor Ashotoh with your kind of uh balcony view of what is happening in the research world and especially with what we just heard about

agents actually using humans for some of their activities and uh we are actually making sure that we are still in the loop but at the mercy of the agents or actually as programmed by us for the

agents to invoke us whenever we need. So uh with your ringside view, balcony view whatever you want to call it into the future of uh AI in general, chai in particular, traditional AI also. What

are some uh broad use cases that you think uh will be of uh value? Uh obviously all students uh use it for writing code or doing their assignments and things like that. Uh on in the

industry side there would be a human in the loop who is kind of kind of acting as a reviewer. there could be a decision making type of an element which we kind of uh heard from the panelists here.

What are some things that you uh can see uh in uh your view going ahead. &gt;&gt; Okay. So uh but there's one point I want to connect to what he uh you said uh so the he talked about regulation and it's

amazing that regulation in India also in RBI's regulation is also very much in this way. They are saying use AI as much as possible be cautious and they are very helpful and supportive right now

they is not becoming impediment and so so they are mostly trusting industry to to bring technology which you can trust uh but they are saying be cautious. So right now this the the regulation is not

very strict but if something goes really wrong then they can come back okay with heavy-handed approach. We do not know. Okay. So, but let me back to your actual question. Okay. So, uh yes. So, the

genai and and this is a big the code writing has become very easy. I mean if you you are if you're a regular programmer which I am you realize that you know thing I used to take like 1

hour I can get it done in 5 minutes. Okay. However, sometimes this five minute is not really helpful. Okay. because actually next day I realize actually I wanted something else and I

read back at the code. I do not understand what this is. Okay. [laughter] So, so then I lost touch what actually I wanted and over time I forget because I didn't put much effort. It

didn't it didn't sink in my head what my system is. So I cannot think I can't even come up with a prompt. What change do I want in this code anymore? So this uh this over reliance on on on this this

this artifact development writing a document or writing a code and then humans having a disconnect with with with actually what is being produced leads to sort of a you're running on on

some kind of it's called technological debt. Okay. When you have some technology but you really do not know where things are. Okay. Then how do you manage this? This is a big risk coming

uh and people are up I I can complete assure you that you know it is very helpful to program okay but this extra risk my PhD student writing showing me code which works but they can't explain

okay so um yeah so in this area it's very effective but this is one big risk I'm seeing that I don't know what is going to happen in five years down the line to these systems um in in in

finance domain specifically where where you know these these technology decision making is going to be a much much bigger thing. Okay. the the right now document summarization has been being actually

the main you know uh main point has been put forward but the decision- making will become more and more uh done by these agents and the the question is can you trust this okay and uh already

you're seeing many places people are deciding things based on AI models okay and uh when this happens people have to design systems which can take care of this trust issues you can explain things

what why it is done. The problem is that lot of notion of explanation is being proposed in in academia and you can find every year you know dozens of maybe hundreds of papers are being written in

top conferences. What do you mean by explanation? Okay. And you you know you you basically you if if you were walking on a street and you fell I mean my my foot uh was not in the right place

therefore I fell. It's not the right question. Maybe there was a ditch there. Okay. So, who put the ditch? Why was ditch was there? So, so the all what exactly constitutes an explanation is a

very tricky business. Okay. And uh so far there's no agreement and this is a big area of opportunity both for industry and academia whoever wants to work on it to come up with a good idea

in of of what is an explanation in a given context. If you can do this, you'll be extremely uh successful company or academic ship. Okay. Thank you professor. So actually

the question uh in general to the all the panelists is and a very quick answer probably uh is it a question of either a reviewer or an assistant or a decision maker or is it a combination of all

three uh and depending on the circumstance and uh I'm assuming that the answer is a combination of all three but in case somebody some of the panelists have any uh variation of this

opinion uh I just want to pass this question here hers Is it a combo or is it a uh uh are you seeing a unateral direction towards decision- making?

&gt;&gt; I think all three. &gt;&gt; Sorry, I think it's all three. U at the end of the day, why would you use all the power that is being given but yes, you rightly pointed out sometimes

explanability and the concept of explanability itself is tough to explain to the end user. But yeah, use all three and actually much more. today they are able to write their own code and review

it themselves. Yes, human is required before it goes into production or even for UAT sorry uh but but I think that's something that uh all of us are going to use. Mund any

&gt;&gt; yeah I mean I don't think you can go wrong if you say all three uh uh that's better than none of the above um but I think um typically you pick and choose what you want to apply in lot of cases

if it's basically a you know a discrete answer that you're looking for it is better to go with more like a generic kind of a thing wherein you are actually able to cross validate it with other

models and other you know domain expert expertise that you have built within the systems but otherwise uh it's better to kind of you know look for you know lowrisk areas where you can actually

just bring in those elements in there yeah I mean reviewer is always going to be there it's not going to go away for for quite a while uh any thoughts

&gt;&gt; yeah I'll concur I think basically depends on the use case that we choose and it's largely driven towards you know what kind of risk compliance aspects are coming into picture. These three are

going to be staying and we have to you know decide which one fits the best and then use it that way. So &gt;&gt; perfect. Uh we are at the last 5 minutes of the uh session and if there are any

questions from the audience uh I'm sure the panelists would like to uh answer those questions. Yeah. &gt;&gt; Uh good morning. Uh thank you for giving me a chance.

for last 2 three years blockchain I don't know if it took off or not at least I'm not a bear is there some level of integration that

is possible or is it going on or can we see some products after such kind of integration in next 2 three years that's question number One. Question number two is which products um fintex related

generative AI proceed they just taken off but can we see some products in next two three years related to that and third is

a general question key financial system one of the main objectives is to produce affordable and accessible capital to uh in the medium term next 3 four years are there

products and services which are on the anvil which we will see capital accessible or affordable mobile app that's thank you

any of you want to uh this thing so first question u was related to well is this really a hype or is there anything that is realistic that is happening and is it uh like blockchain we heard about

it a lot of hype uh is this genai also a hype the short answer is yes there is a huge amount of hype that is going on and as all good things that happen there will be a hype cycle after which the

so-called slope of enlightenment dons in and we start realizing the value of uh this technology so uh yes uh and AI is not a newcomer in the field. It has been there since 1950s and on November 30th

2022 after the release of chat GPT is when the third generation of AI actually has got rekindled. Uh in my opinion uh there is a huge potential for leveraging this technology and we will see a large

number of applications leveraging Gen AI going beyond chatbots in order to deliver decisions which will uh make the enterprise a lot more uh efficient uh lot more a lot less dependent on manual

labor uh is the way things are going and we are witnessing that already with our uh uh conversations with Punavala Fininn Corp with a few other organizations that we are dealing with. So that is the

answer to the first question. Uh if any of you remember the second question yeah &gt;&gt; I will add to the first question. Uh just short answer the blockchain they could not find an application that

connects to common person and therefore it did not live up to their hype. But think about your life. How many of you are daily using chatbot? Nobody told you to use it. You just start using. You saw

it. Oh, it works. It it works for me. Now it found a connection to common person. And that is your answer. It's not only hype. It actually works. Okay. It affects your life. Therefore, it is

going to be used. Okay. &gt;&gt; Let me answer the third question. actually previous with government initiative on multiple

front including opening of bank account. It is possible. But history bank account that's I presume an answer that you'll be able to see very very soon and new

product lines will get opened up. That's without a doubt. &gt;&gt; There's a question there. &gt;&gt; I have a question. May I? &gt;&gt; Yeah.

&gt;&gt; May I? Thank you. Like um I have been noticing all these startups are mushrooming every day. New companies are think because everybody's saying AI is booming. It's an AI era and all this.

You think similar thing is going to happen with these AI companies also like earlier this companies were started and they just fell flat. So you think they really have a bright future or are they

going to survive or thrive or the same thing will happen with them also because market is really competitive. If one company is saying that we're going to give the result in five minutes time,

the other is saying within few seconds we're going to give. So they are just you know competing with each other only. So what what's your take on this? &gt;&gt; Right. So I'll take the question. Um it

is true with all the hype surrounding pretty much um you know startups are mushrooming on a daily basis but that is part and parcel of you know how the growth happens. It's always been that

you end up having large quantity before the quality emerges. Right? Uh see the same thing happening in China and other places as well. It is not something that's happening in one place and even

every technology ended up having that kind of a you know uh you know the large quantity comes before you know the winners emerge and it is just that given the size and accessibility that is

available today the numbers are quite significant and more importantly in Indian context is the uh you know the startup money the seed money that comes in is actually available too. So we are

seeing that effect today but it is not something that has not been happening earlier as well. Very similar numbers you would have seen in comb bust period in US as well. So this is a cycle and it

will happen and it's not a bad thing per se. &gt;&gt; Okay. Uh I have a question uh &gt;&gt; we are we are probably at the end of the hour but we will take your question.

&gt;&gt; So I have a this question is for professor Gupta. uh you touched upon the uh concept of explanability and AI engineer remembering the code uh where exactly they have uh what exactly they

were thinking when they were writing the code or they couldn't identify the problem. Um now Mr. Karnan said that uh FOMO lot of organizations are actually jumping onto AI. Now as an organization

from the outside in perspective uh research perspective what are the organizations supposed to what kind of guardrails they put what kind of governance checks they can put so that

uh if the outcomes are not delivered they're going to actually face problem if the outcome outcomes are delivered no questions asked. uh so what's your view on organizations what approach they

should take uh when it comes to explanability and uh the AI engineers accountability in terms of what they have written and where they have gone wrong

so uh it's it's very simple I mean the the ultimately your code your document you are responsible you can't say AI generated it okay if the bug founds two years down the line 3 years down the

line you will be held responsible okay so You basically organizations this is happening in academia. You submit a paper they say okay you can have an assistant to write you help you write

the paper but at the end you're responsible. If you write a sentence which is autogenerated which is says factually incorrect thing you will be banned for 3 four years in submitting a

conference paper. Okay you can't just blame it to AI. Similar thing basically organization has to be very clear at the end you are answerable and uh if company loses money because of this AI generated

code it's you okay who pays okay how in what form and what severity a company has to organization has to decide but this is has been a a trend emerging how to help hold like how to hold this

entire sit control this situation we want to use we a bicycle has been invented use it but then you knife has been invented let's say use it but don't cut yourself okay so how do you do this

okay so basically whoever is wielding a knife has to be held responsible if you hurt someone you're responsible not the knife okay so this is the really but you need to codify it like how much uh what

kind of uh you know penalty it should be you know benign it should not be overwhelming you know says that people so scared of using AI so you need to balance it out but this is the

ultimately that comes down to it human is ultimately responsible. A small question please. &gt;&gt; Sure. Next question. Sir Vive P from Japur

say like presently we are into a consultancy advisory business offline. Just want to know sir K when we want to shift in AI model or online what will be the first

step we need to take like from the offline business to into on the online business a consultancy and advisory company like what need to do first like we are looking for a tech we are looking

for something else just want to know please [bell] answer &gt;&gt; there's a company in a which presented a

paper in Australia for Australian government turned out generated Ready in the sense. customer. But as Ashto Ashto pointed out,

responsibility key. Thank you sir. Thank you. &gt;&gt; So we are truly at the end of the hour and uh I do need to bring this uh panel discussion to a close. Let me take this

opportunity to thank each one of the faculty panel members here for spending the time and sharing their views with us. Uh I'm sure all of us will be available outside the auditorium also

for any follow-on questions and thank you all for being uh so patiently uh listening to us. Uh really appreciate it. Thanks.
