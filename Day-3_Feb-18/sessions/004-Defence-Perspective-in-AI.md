# Defence Perspective in AI

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room No. 6 |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/sp4PAlp1_YU?feature=share) |

## üé§ Speakers

- Dr. Vikram Jayaram, Neuralix Ai Private Limited
- Lt Gen Harsh Chhibber, AVSM, VSM, Phd, Indian Army
- Lt Gen Vipun shinghal, AVSM, SM, Indian Army
- Maj Gen Pawan Anand, AVSM Phd (Retd), Centre for Emerging Technologies for Atma Nirbhar Bharat (USI-CETANB)
- Mrs Madhumita Mohapatra, Deloitte
- Subimal Bhattacharjee, Individual

## ü§ù Knowledge Partners

- Indian Army

## üìù Summary

This session will examine the transformative role of Artificial Intelligence in enhancing operational readiness, decision-making, and force modernisation within the Armed Forces. Senior military leadership, academia, and industry experts will deliberate on emerging AI-driven capabilities, human‚Äìmachine teaming, autonomous systems, data-centric warfare, and secure digital ecosystems. ations in an increasingly complex security environment.

## üîë Key Takeaways

1. This session will examine the transformative role of Artificial Intelligence in enhancing operational readiness, decision-making, and force modernisation within the Armed Forces.
2. Senior military leadership, academia, and industry experts will deliberate on emerging AI-driven capabilities, human‚Äìmachine teaming, autonomous systems, data-centric warfare, and secure digital ecosystems.
3. ations in an increasingly complex security environment.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/sp4PAlp1_YU/maxresdefault.jpg)](https://youtube.com/live/sp4PAlp1_YU?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

this event and most of the sessions uh have had very well turnout and uh while there's a lot of excitement around AI in India and uh in almost every dimension and in every

angle including the consumers and all but one of the very important topics is where the artificial intelligence operates or enhances or impacts uh the defense ecosystem. And

uh as much as uh we would have wanted to deliberate on it uh in the 55 minutes that we have uh we would try and cover uh most of the grounds with uh the questions to the panelists. But before

that uh um the address uh by the respected uh deputy chief uh is uh [clears throat] you know we are at a point of time where in the country we are trying to look at infusion of

technology on so many areas and uh even beyond what's we are doing in the country we are also looking at all the global linkages and the partnerships. Yesterday the French president Emmanuel

Macarron was in Mumbai and if you saw the 21 outcome statements uh five of them were related to defense and then of course there is one very specifically on the critical and emerging technologies

and uh in the defense ecosystem. uh same if you look at uh the conversations with us that has been happening AI remains at the forefront of all the cutting edge technologies and

the areas where we want to cooperate and nevertheless with all these efforts and what we are trying to do here we are also trying to see that how responsively we use uh AI in all our activities and

that is very very important when you look even at the defense ecosystem. So AI being a force multiplier, AI trying to uh you know improve and maybe modernize the battlefield tactics, look

at the doctrines, look at how you manage these supplies and of course enabling the equipments uh to be performing much more optimally or in newer horizons. So the changing battlefield that we all see

uh will have a significant impact uh with the usage of artificial intelligence and uh you know the emerging technologies. So this is where I think you know we have a fantastic

panel. We are very lucky that this panel is uh confined to experts and the number is less many sessions have had huge number of experts who who actually cannot do justice in the time of 55

minutes that's there. Uh with all of that and uh I would like to invite the respected deputy chief of the army's staff information systems technology uh general

uh shingle to deliver the keynote address. &gt;&gt; Thank you sir. Thank you. I close this. &gt;&gt; Yeah. Thank you.

Thank you so much uh and uh good to be here in this panel in the keynote discussion like I was saying uh just previously that they are the experts and uh I am the journalist that is why I'm

called a general and uh you know one more thing uh for senior officer like us addressing gathering like this is very daunting because normally we are addressing gathering uh which of uniform

people and at our uh by by my service they are generally all junior to me. So they have no option but to you know firstly clap at my punch line, laugh at my jokes and so on. Here here that is

not a necessary necessity. So we'll have a rule when I have a when I give a punch and I'll raise my left hand. So all of you clap when I give a joke I'll raise my right hand and all of you laugh

because uh you know that's the only way that I'll uh be able to interact. Anyway that's on lighter way. Uh let me start. uh distinguished guests, the late leaders, innovators from the AI

community, my colleagues in uniform, some of whom are also innovators in the AI field, students, ladies and gentlemen, a very good morning to you all.

It is a privilege and honor to be uh addressing this uh important forum in this uh uh pathbreaking India AI summit impact AI summit and uh there are capish professionals who are going to be

speaking about AI and its impact on warfare and conflict. So allow me to focus on a different aspect which concerns us all that is military leadership and the responsible or

responsibility of ethics regulations in AI and what is that military leaders need to look at when they are applying AI enabled systems in conflict. Let me begin with a brief operational

moment. During a recent high tempmpo military operation, a senior commander was presented with a machine generated recommendation based on multiple sensor

threats and AI analysis to engage a target immediately. The system was confident. The probability score was high. The decision window was measured in seconds.

But the commander paused. Something was a miss. So he asked the question, what does the machine not know? The pause revealed something.

The area that the sensors were looking at had adversary troops. But there was also a civilian evacuation underway which had just started which had not yet been fed into the data.

It is possible that there were some troops also of the adversary with the civil evacuation. However, the commander excised judgment and restraint, stopped the strike and prevented loss of

innocent lives. The mission later on was completed and also won. But at that point he exercise judgment. This brings us to a fundamental truth.

AI can inform decisions but only humans can exercise judgment and bear responsibility for them. AI is today having an unprecedented speed, scale and efficiency. Those

attributes are real and are very well understood in this room. What deserves deeper reflection is something else. The new burdens AI places on leadership, command responsibility and strategic

stability. I use the burden I use the word burden with care. Autonomous and AI enabled systems advance at extraordinary speed. Therefore, four questions deserve our

attention. Firstly, which decisions must remain with the commanders and which decisions can be delegated to data or algorithms. No matter how accurate [laughter] or or

efficient they become, when must human judgment, moral responsibility and command authority remain paramount. Secondly, have our rules of engagement and safety

frameworks kept pace with systems that rely on data? Do we fully understand how these systems are trained, the quality of their data, and the assumptions that they make?

It is also called the blackbox phenomena. Today, even the creator of an AI does not know what is happening inside the black box.

So, you can let alone how can commanders trust it. Thirdly, are we subjecting AI enabled systems to the same rigor that we subject new weapon systems to trial

evaluating them, fielding them in contested conditions and then applying them? After all, an AI enabled system is not a software, it's a weapon. Thirdly or fourthly, are we

preparing our commanders and staff to lead in a world where machines can recommend, predict, and act faster than humans without allowing speed to substitute judgment?

Command and control by commanders will exercise life and death decisions. Can be given to machines? If a machine recommends a strike with 90% accuracy and the commander

takes a decision and it's the wrong decision, it gives him a moral buffer to say that it was a machine that recommended it. But is that correct? These are questions that we need to

answer. It is also important to understand that these concerns are not in the military domain alone. In fact during this summit we have

released the or India has released the India AI governance guidelines which is a pathing pathbreaking document on a pragmatic approach to AI governance duly supported by a technolal framework. The

framework identifies that since AIS are probabilistic generative and adapted adaptive they can lead to unintended consequences. These are lessons for military planners too.

The second thing that uh the framework talks about are risks and within that the sixth risk is national security. One of them is which identifies that AI facilitated disinformation campaigns,

cyber attacks on critical infrastructure and the use of lethal autonomous weapon systems as looming threats to public safety. Policy makers and defense planners need

to be cognizant of these threats and also make people aware of them so that we can be resilient to them to remain relevant. I must say military leaders must stay on the learning curve.

Understand technology both its challenges, pitfalls and uses while also ensuring that technology is absorbed and adopted by our units and troops. That is our responsibility.

Having said that, let me be very clear that we as the Indian armed forces and the Indian army are fully cognizant of the transformative power of AI to increase our official efficiency

and we are making every effort the direction to ensure that AI is incorporated into our decision support systems into our surveillance reki and all the other function they do.

We are actively working with industry leaders, some of over here, startups and academic institutions to harness AI for military applications, drawing strength from India's vibrant innovation

ecosystem and our own growing band of uniformed innovators. In fact to give push this to this direction the Indian army has declared this year as the year of data centricity

and networking by which we are acknowledging that data is the new oil and datacentric warfare is what we need to fight. In fact we have set up a booth in the

expo as well and I will urge all of you to go and encourage and see it and encourage our young innovators there for India. Therefore the question is never as to whether we should adopt AI enabled

systems but how and we are clear that this transition must be undertaken responsibly. So what does responsible and effective approach look like? Firstly we must

institutionalize human control not as a slogan but as law. This requires clearly defining which functions may be assisted by AI, which may be recommended by AI and which may

always remain human decisions. Secondly, like I said earlier, AI enabled systems need to be treated as a weapon system and be tested accordingly. Remember that the most chaotic

data environment is the battlefield. An AI trained on very clear satellite images given to it in a computer lab will fail when it sees grainy mud soaked smoke deception like images in a

battlefield and can produce a wrong decision and therefore there needs to be the same certification same red teaming and same tile evaluation of AI enabled systems.

Thirdly is about sovereignty and trust. The how does a commander trust the data that is being fed into the AI enabled system to give him the decision support. There needs to be more clarity on that.

There are systems in place which are doing it and commanders themselves must learn about it. And lastly, leadership development must involve must evolve so that commanders

who are now going to be interrogating systems going to be uh you know not only leading troops was also going to be uh I would say interacting with systems and taking decision on them should know as

to what are the pitfalls what are the challenges how best to use them. Moral responsibility remains with the commander. But ultimately I would like to say that

we must remember a historical truth. I personally believe in the wisdom of humanity. Whenever faced with a new crisis we have responded well. The rules governing the use of NBC weapons.

The rules the framework that has come into place for governing landmines. the Geneva Convention itself which talks about conduct with prisons of war have all stood the test of time even in

conflict. So I'm confident that AI as the new looming technology on the forefront will also find ways and means to be regulated. In fact as we speak the United Nations convention on certain

conventional weapons is already on. There are many uh many governments, many states which are which are part of the discussion. Consensus is complex but it will come.

India today stands at the cusp of three powerful realities. We are a major military power. We are a rapidly growing AI country or AI ecosystem and we are a civilization that has long understood

that power must be governed by restraint. Shy must go hand in hand with dharma or righteousness. This particular thing or particular uh you know ethos gives us

both capability and credibility to lead the world in using AI responsibly in conflict as a line from popular culture which says that with great power comes great

responsibility. I think the time has come how wisely we carry the responsibility will shape not only future wars but the moral leadership we choose to project. The character of war

may change our conscience cannot. With that I would end here and I look forward to the insights by the accomplished panelists on subjects related more closely to AI and its use in conflict.

Thank you and Jind. [applause and cheering] Thank you so much sir for bringing out uh many perspective but the most important point that to make is that the

humans must be on top. AI cannot uh you know dictate humans and that moral responsibility of the leadership and how do you cultivate the new leadership towards that and how the Geneva

convention had has stood the test of time. I think these are very very significant and this gives all of us a guidance about the ethos and the direction with which you are taking the

AI uh enablement in the Indian army forward. Now let me go to the panel so that uh you know we get more you know ideas and uh what uh you know they are doing in their

areas because uh I am left with uh uh I think uh about 40 minutes. So we'll try and uh a portion uh 7 minutes to each speaker uh 35 minutes and then uh 5 minutes we'll keep for questions and if

uh maybe the organizers allow maybe we'll go a little bit more but let me start with you uh General Cher the DJI you know the AI disruption in military operations uh uh have uh already

gained the grounds in terms of uh you know conversations uh that happen at strategic level as well as uh now even in media circles also uh basically how the integration of AI

into military operations is aligned to the changing character of warfare including ISR cyber security information operations and decision support systems. So my first question to

you would be how can military forces effectively integrate AI enabled ISR and decision support systems while maintaining human judgment in the UDA loop particularly in time compressed

operational environments where the speed advantage of AI may conflict with the principles of proportionality distinction and command responsibility. And in fact that question flows uh very

naturally from uh what the deputy chief just mentioned. So uh I would like you to respond to that sir. &gt;&gt; So thank you Subimal. So as you have rightly pointed out certain parts get

answered in the opening address itself and it it's part of a global debate. Now u the issues which you have raised the requirement actually is to make better decisions and not bad decisions

faster. In this context, let me highlight where AI can help us make better decisions. AI can in fact help us to overcome what Herbert Simon calls it bounded

rationality that human beings tend to make a satisfying decision rather than a optimum or a best decision and that is because of four factors. The first factor being the information is never

complete when humans have to make a decision. Second is there's a cognitive limitation. Uh if say multiple factors have to be considered, multi criteria, human mind can easily decide between two

factor analysis. If there are 20 factors which have to be taken into consideration for a decision, then uh it is challenging then you tend to choose only one or two you know factors and

make your decision. That is the second limitation. Third is the time is always short. You have to take a decision in a very uh you know quick time frame. So therefore time to analyze all factors is

not available. And fourth factor of bounded rationality is the human attention span. It is very difficult to keep attention for a very long time. All these limitations artificial

intelligence can very easily uh overcome. So therefore the decision making in all the domains what you talked about uh can be superior to what a human would make without AI

enablement. So that is the advantage of artificial intelligence. There are also some limitations and let me highlight some limitations were highlighted by deputy chief in his address. There are

there are certain limitations. Uh when we are talking about artificial intelligence today we are primarily talking about GPT large language models. We are talking about generative

pre-trained transformer. So as the name suggests it is pre-trained. There's a training cycle and there's a inference cycle. There is no realtime learning which is happening. If additional

learning has to take place, it has to go back to the training cycle. Whereas in a battlefield, you'll have to learn as you go. There will many factor which will emerge where you have to learn as you

go. And the transformer technology itself is actually a probabilistic model of finding the next token, the next word or part of word. It is very good at that. But it fails wherever there are

computational kind of, you know, algorithm to be run. So therefore to rely on an LLM for such factors uh it's better to have a hard-coded program to give such kind of computation. So that

is another limitation. AI also starts to fail the moment context changes. If it has been trained in one context the moment you change the context the result will be uh erroneous.

That is another limitation. Um and the major limitation of an AI model is that it lacks abductive reasoning. Reasoning when the facts are not complete. reasoning when the new situation has

come up that kind of decision making if it is left to the artificial intelligence will be disastrous. So these are the limitations. I would highlight another issues. Viml

we we normally when we discuss this u uh you know challenge our discussion is either in the technology domain the reasons which I or the argument which I highlighted or it goes into ethical

domain what you have said proportionality or distinction. These two are fine. I think the discussion should also be at a deeper level at a foundational level at a you

know uh psychological or philosophical level how should this be this technology be dealt with especially in the warfare so in that context let me highlight and I'm sure the other two that technology

and ethical part is important and there are people on the panel who who are better experts than me let me deal this foundational aspect uh let me quote two examples we recently had And it has been

reported in the media that IDF used Lavender database to identify the low-level operatives in Hammers and then they you know eliminated them and the authorization was done that if the AI

engine was more than 90% accurate. You can mark that person as a target and then eliminate him. 37,000 people were identified by this AI engine and uh you know eliminated as per reported in open

source. So if it is a 10% accepted error, there were 3,700 people who were actually innocent as were the logic itself and if there was a collateral damage that that uh goes uh that can be

put on one side. So can you rely on that? Let me now relate it to another incident and most of you have learned it during Vietnam war. The incident of my life

when a whole village was massacred in revenge right ladies children old people because ablebodied men would have run away it was massacred there was no AI engine there so who was guiding that

kind of justification or a decision-m so which is better uh I think we can address it in this manner in my incident there was a human agency

therefore attribution you know William Cal could be fixed you could put checks and balances that no military decision take is done by any person in future you could put deterrence in a human mind

because there was attributability whereas in case of uh later or the earlier example where we are using an AI engine where is the attributability that 10% innocent people who can you

attribute those deaths to is it attributable to the algorithm is it the person who made the database is it the person who wrote the code that attributability part is missing. So if

we have to deal with this technology into military uh domain, I think we need to address this foundational question. And that brings me to the last part of your uh you know query on the command

responsibility. Who's responsible? Is it the coder? Is it the person who authorized? Is it the decision maker who laid down that 10% error is acceptable? Who's responsible?

So as far as military leader is concerned, I think command responsibility can be defined in two ways. One is it it involves a commander needs to have competence that is how to

do what to do and second is the human skill why to do it. These two functions of command make a commander a good or a bad commander and command responsibility in military parlance is is absolute. It

it cannot be delegated. You cannot do your cognitive offloading to a machine. it it's not expected in the present circumstances to another human being and in a future warfare maybe even to a

machine. So one is that second should we authorize a uh you know lethal kind of decision or causing violence or divorce it from human agency I don't think that that would be a wise decision AI is a

tool we need to treat it as a tool we need to use it effectively any decision which affects uh application of lethality will remain with a human agency so if I have to

conclude uh I would say that uh the entire proportionality uh distinction and command responsibility in ethos of the Indian armed forces would uh remain with the human agency. The

accountability the responsibility u uh cannot be delegated to even another human let alone a machine. Thank [clears throat] you very much. &gt;&gt; Thank you sir. This was uh brilliant

which uh gives me a lot of order for the next question but I'll come back to you. Uh let me come to professor Ramak Krishna who has been at the forefront of uh building a lot of uh solutions and

getting the you know forces also involved in the AI age. Now you have been of course tracking the global landscape around how the whole AI ecosystem is evolving and particularly

if the AI integration in defense. [snorts] So uh you know how would you see and what are what have the major military powers uh have been implementing AI in

the command and control systems and intelligence gathering operations over the last over the next past 3 five years and what specific capabilities have been demonstrated in

real world conflicts or exercises. You see the information not always uh is accurate and uh you know look at our adversaries you know some people what they do now they spring surprises very

regularly when it comes to the AI space but even if you look with the friendly countries there is different level there is a skewed approach around this whole understanding and all so what are the

comparative advantages and limitations that you have observed in different national approaches to AIcentric uh warfare and how do you think you we are also aligning ourselves.

&gt;&gt; Uh thank you for that question. Alluding to what the deputy chief spoke in the beginning and sir what you u emphasized I think no command center will trust AI as a black box. I think that's key.

Everyone here is on the same page there. Um what AI can be used for is situation summarization pattern detection at scale because what machines are good at what AI is good at

is recall. We are very good at precision right the domain experts are good at precision also the capability to correlate across multiple sensors again AI brings that

big advantage uh it's a force multiplier there and finally recommending course of action right or taking cue from what Dr. Rajiv Bell uh uh the DJICMR always tells me he says that it's basically you are

presenting scenarios here's a one scenario I mean and that also you know reminds us of war games but basically multiple scenarios and what are recommendations so alternatives I think

what AI can give you is alternatives right technology alternatives procedure alternatives and present with each alternative the provenence now I'll use some more technical keywords here.

Provenence as originated with databases, right? If you write a database query, you have the execution plan and you know why a particular result came up, right? So that provenence is very key. When I

was at uh [snorts] IBM research before joining IIT Bombay, uh we were actually quite frustrated with AI overpromising and underd delivering and we were so inspired by databases, we said let's

extend a SQL language, right? uh structured query language to annotate a query language. We actually created an annotator query language which uses a bit of AI and it a product was launched

when I was at IBM research and it had its own uh you know algebra just like SQL has its own algebra it was very interesting exercise why because we can get provenence so

that's one provenence to sources when we met the honorable PM on 8th Jan a long conversation he said we also need attribution so there's provenence in terms of sources but there's attribution

in terms of experts again AI can if you can get to the attribution mileing alternatives that would be great and third is the most technical part which is observability stack right when

processes get executed I mean today when training happens at Bajen we have our uh deputy um director Prasad and we have this section at company at I Bombay called Bharaj Jen where we building

models on u know thousands of GPUs training models even inference you need to ultimately delegate to a cluster of GPUs observability becomes very important what is being delegated to

CPUs GPUs versus the network switch because network switch is also kind of used as a virtual memory today that's how we are able to run computation across multiple uh GPUs observability is

there a data leakage so having recipes having these models as glass boxes with observability will ensure that you're running in very secure environments in air gap situations without leaving any

footprint at all. So I I think this attributability at every level is very important. Now the question you also brought up was specific examples of what other countries are doing from an

academic perspective. Stanford University released this very interesting open-source platform called Snorkel. So sir you mentioned programs right? Sometimes programs are more

reliable than AI models. So what's Doral does? It lets humans design programs, right? Complex programs. Sometimes you annotate data and you have annotative guidelines. What they say is translate

all those annotative guidelines into programs [snorts] and these programs coexist with your model can coexist with your model. Now what Stanford did was they actually use these programs to

annotate data learn parameters of these programs. So these programs are parameterized and then these programs are thrown away. What we realize is India I mean India we

like to always complement our UPI complemented our savings economy. Can we complement what exists? So we try to differ from them. We said well programs are important but programs cannot be

used and through programs are not just to annotate data. These data programs which you mentioned should have the ability to override the ML model output. So we actually created an open source

platform called Spear semi-supervised data programming and my PhD student Janvi is also here in the audience. She worked very closely with Sama with the DGIS. So the idea there is our program

should be able to override the models right because as you pointed out ultimately trust is a problem and uh it took quite some time for the academic community to appreciate because anything

that comes from India is not necessarily viewed right as uh as state-of-the-art but finally the community accepted that this is a very good paradigm. I think we'll also have to innovate

technologically to make sure that the human the domain experts are the command center is in the driver's wheel and not AI. I'm really enjoying this conversation. Thank you for bringing

this up. &gt;&gt; Lovely. I think uh you hit the nail when you said attribution because that's possibly the biggest uh issue with cyber security for decades now and we still

don't have any solution in the horizon. uh let me uh turn to General Anand at this stage you know and look at uh the again the governance regulation and the policy enablement for responsible AI. I

think the deputy chief's speech was very much uh clear and uh uh both the panelists have also uh spoken around that you know that that responsibility is very very crucial you know maybe in a

civilian domain we really don't bother much about responsibility and etc but here it has to be absolutely the command remains uh with an individual and it's not uh delegated so what are the

regulatory approaches that defense organizations adopt to enable rapid AI deployment and development for maintaining strategic advantage while ensuring

adequate testing, validation and human oversight mechanisms are in place and how can policy framework manage the tensions between operational urgency in military context and the precautionary

principles required for high stakes a AI system. I'm sure sir you know there are a lot of uh precedents uh that uh we are sort of uh building up. So where do you see this whole landscape?

Yeah. Uh it's you know it's it's a pretty complex situation and [clears throat] it's probably as complex as how how new technologies uh come in and then need to be regulated. So we've

been facing it earlier on also. It's not that we haven't faced such situations. uh there was a very uh potent technology which came in in terms of nuclear technology and people were wondering how

to control it and [snorts] then you did reach certain conclusions as was mentioned by General Shingle as well but the only change I see here is that you know that was a technology which was

very few people had and AI is going to be much more democratic so it it'll be approachable by a lot of people the second thing is the pace at which it is changing nuclear technology didn't

change as fast so uh we'll have to keep up with it. So the policies that we bring into this will have to take both these factors into consideration. Uh mainly I would say that AI with its

civilian uses and as compared to what we have in the military is characterized by two or three differences. So in our case it's it's as complex perhaps as AI anywhere. But the complexity then comes

in terms of the fielding of or the deployment of that uh technology. The second is the urgency. There are constraints of time. And the third is the risk. The risk is very high. It is

lethal. It it costs lives. It's not just a system going uh off course. So with these three constraints, we still have to function in the fog of war. So while there is noise and there is physicality

and there is dust, there is also communication which has to take place with the machine which can be interdicted and probably even jammed completely. So at one point it'll have

to go autonomous or at one point completely human controlled by human physical means. Right? So again it gets very complex over there but yet we have to use it in an environment

where we can be sure that it is delivering results. So it has to be absolutely reliable and that is where it becomes very different from civilian applications. It has to be absolutely

reliable. If it has to kill it has to kill. And the second thing is we have to make sure that with all this we still keep in mind responsibility and international human law and

international human laws will have to be adhered to otherwise humanity is lost. So [snorts] somewhere in between this when you use a probabilistic technology but you're getting very deterministic

outcomes there is a fundamental uh kind of a difference which which we are bringing in here and that's what I wanted to highlight in the first place and the complexity comes in here. Now

how are we going to do this? [snorts] I think when it comes to uh governance of AI um generally uh we may still accept that governance lags behind how AI begins to advance faster and faster

but in the military perhaps we can't do that. We don't have that luxury. So therefore AI responsibility will have to be inserted at every stage every stage of the life cycle of the development of

the AI system itself in the military and therefore [clears throat] right from the ideation stage to the design stage to the development stage to the deployment stage. But not only that I would say

even as you spirally develop the systems you have to keep uh putting the trust factor and the reaim the responsible AI factor into it. And then finally you even have to ensure

that you destroy it at the right time because before it mutates and goes a muck you will have to make sure that it comes under control. If you've lost use of it you have to destroy it in its

completion. So at every stage of the life cycle and that these later parts I find are completely missing from our debates. So as you go into agentic AI I think

that the later part becomes more and more important. Now um as we go from the lab into the simulation stage and into the deployment stage, what is it that I would say we

should have in our phases. How do we identify each phase itself is a question mark. They are not very well defined. So you may try to define each phase but even within that there are

various spaces which you need to ensure that you have inserted responsibility into it. The second is bias mitigation. Biases are bound to creep in. How do you keep detecting those biases and that

requires a very high amount of alertness? So while we develop a system, the responsible aspect also and we need to be alert to all along. And the third aspect is safety when it comes to

critical use especially when you're talking about lethal autonomous weapon systems because that is where you're bringing in uh uh uh you know uh the drift uh which needs to be checked and

kept controlled [snorts] uh drift detection is very important but I also feel that you have to create certain bounded envelopes under which you use your weapon systems. So those bounded

operational envelopes will need to be clearly defined as to where those weapon systems will be used and that once defined by us will have to be adhered to by our adversaries and therefore we need

to bring in these policy decisions. Of course we have to have national policies and then we'll have to start looking at the international policies. Work is happening at both ends. We need to plug

them together. But there are differences in capabilities between the US and China and US and maybe Europe and how will we balance that out? That's the kind of discussion that we did in the REAM

summit where I just came back from at Spain and I had suggested that our uh confidence building measures amongst ourselves would have to be not only uh tiered between various between the

advanced PS in AI and the middle path but will also have to be tailored according to the requirement of each. So and these will have to be acceptable to everyone. So I'll pause here and then u

go on uh if we get time together. &gt;&gt; Thank you sir. I I sometimes rise to see what's going there so that [snorts] I'm still able to come for a second question. Uh Vikram Jaram and founder

Neurelix you are already uh working with the forces and particularly you have a wider industry perspective at this stage uh how things are happening in this country. So what mechanisms and

institutional frameworks you feel are required to foster effective collaboration between the defense professional, academic researchers, technology startups, established

industry players to create a vibrant AI ecosystem in the defense applications here in the country. Thank you. First of all, I think everybody's able to hear me. Okay. Um

first of all thanks for the panel distinguished panels for uh for inviting us to be here. Uh this is one of a kind and uh we are also at the inflection point of how AI is getting adopted in

India and it's uh it's it's a great uh time to be present as part of this engagement here. Um what I wanted to first talk about is uh how we are able to essentially bring these clusters

together and when I say cluster it is the combination of deep tech startups um the nodal agencies the military coming together the uh the system integrator uh some something that we

don't pay a lot of attention to and uh and finally the domain experts Not a problem. &gt;&gt; Yeah. &gt;&gt; So uh

so it was it is one of those things that uh that we have to ensure that such clusters come together uh and they are they are moving forward in terms of uh developing uh systems that are providing

what is called as an ROI. Now ROI for defense uh is not profitability. ROI for defense is security. ROI for defense is getting intelligence at its at its faster pace.

ROI for defense is building uh effective decision support systems. So if if that has to happen uh there are certain plumbing system that has to come in place and these plumbing systems are

nothing but um you know AI models being deployed being served there is constant incoming of the data that we are uh that we are often build these sovereign models on and other things. Now what is

what is really important here is how is it that uh uh something like this comes apart and I want to take an example of uh my past life [snorts] as a post-doal researcher uh at at MD

Anderson cancer center uh again very similar things it's a question of life and death when it comes to cancer is concerned how is it that we bring together the domain experts uh there is

certain policies set by uh the government especially in this case the uh the the the on the health side of things whenever we build new instrumentation

how is it that they are they they go through what is called as basic research basic research goes into clinical research clinical research then goes applied on what is called as um imaging

technologies like and you try them out on small animal imaging you you take FDA approval to try it on trials on humans and then finally it becomes a technology that moves forward. I think defense is

also very similar to the medical industry where lives matter and when lives matter such decisions have to be taken in this clustal approach that the other industries have taken. So there's

a lot of things that is drawn from all of these different avenues that are all there. Secondly, there has to be a form wherein the uh the founders are now embedded within the army uh in terms of

how uh we are able to understand the domain. Um I I was uh uh you know uh privileged enough to be born to the olive green. So I've seen this from the very beginning but more importantly how

is it that the teams are able to understand um the the various nuances the limitations also of putting such such systems together and proceeding with

what is called as an iterative approach is you build something fast enough you test it out you see the outcomes of it then go back and build again. You cannot come up with something which is the

greatest form of it at the very first stage itself. You've got to go back and keep iterating on it to do that. The the finest models that you see today in the [clears throat] world whether it is

Gemini, whether it is anthropic, whether it is uh Chad GPT or any of this have gone through these these uh uh these phases from where we where they are today at this point. And then more

importantly it is the embed of the other side also. It is the the the members of the armed forces should also embed themselves into the startup uh foundation. How do they think about it?

Because uh you know as a founders some of us have left 8 figure jobs. Um in US we have left uh what is called as u you know a tenure position. I was a university professor at University of

Oklahoma. left in your jobs and uh we have come here and we're doing this kind of stuff. The only way to be able to have that uh passion in your bone to doing innovation is is when the other

side also understands and have empathy for what it takes to go build technologies and if that happens in a in a very bilinear in fashion you'll see the great outcomes coming out of it. I

think this is something has also been adopted very recently although there is uh with DARPA in the US and how they are doing it at the same time. So uh this is something that is of uh a great

monumental value of people understanding each other and how we go ahead and pro you know prolifically be able to apply technologies going further. Um the um other area that I wanted to kind of also

mention is when it when I when I come back to the uh the plumbing system is making sure that they are effective we test them out very quickly. I I'm grateful to the IDEX program um you know

15 20 years ago something like this never existed uh wherein startups could come and innovate so fast. uh the IDEX program has given us the opportunity to to be able to come and very quickly

produce something um and be able to apply it uh to the various agencies very and see what the outcomes could come out. The earlier we see the outcomes the earlier the impact of all these

technologies are happening. So um in short the what I wanted to kind of conclude again is the plumbing system has to be together making sure that we have an iterative process for testing

and uh Gen AI if you look at it is only a very small portion of the entire AI umbrella about 15 years back 97 when I actually came out uh when I took my first grad course um in UT um in um in

AI people were laughed at it that you know uh you're taking a neural networks. It's a theoretical subject. Nobody is even going to ask anything about it. You're not going to find a job. You're

going to be jobless. And if you if you look at it, fast forward so many number of years now, there's not a sentence that does not start with it. But as a matter of fact, what's really important

is there is a whole area of AI and data science that also needs attention at the same time. There's so many other areas uh wherein uh especially some of my own employees they are PhDs in um uh from

UCLA and they're data scientist they wouldn't know D of deep learning today because they're very good at certain things of data science and they want to make sure that the deterministic

algorithms are also part of this understanding how do we use deterministic algorithms how do we utilize game theory concepts how do we make sure that we are learning from data

at the same time and all of these aspects have to come together to understand it. It's not being AI cannot be at the fashion of what comes in and what goes out. I think that is one thing

that we have to realize that the moment something else becomes more important. We can't be on top of that. We have to make sure that we build discipline based upon uh what are the outcomes of it. So

Vikram I think this is fantastic and this totally you [applause] know takes me to what Madumita has to speak about because she's already uh into this whole seeing

the military side as well as the industry and particularly one of the areas supply chain you know that's again a area where a lot of transformation happens uh but I just wanted to mention

that almost the same period of time I was a student of mathematics pursuing my postgraduation and when I had artificial intelligence the special paper people laughed at me and today it's changed so

much you know when the moment you looked at Python programming and uh looked at everything of statistics through that lens everything has changed uh over to you

&gt;&gt; are you going to ask me the question [laughter] mentioned about supply chain and uh the defense consulting but maybe you know what I can uh tell a little bit that uh

how are the defense organ organizations adapting as far as the supply chain management is concerned deploying AI particularly from that purpose so that uh you know the demand forecasting

inventory management root optimization and real-time asset tracking I would want you to speak on that &gt;&gt; that was a large question thank you so much and firstly thank you everyone for

having me here indeed my privilege to be a part of such an august panel and such a lovely audience um so uh to answer your question I think globally defense supply chain is now moving from what it

used to be like forecasting, stocking and then reacting to actually sensing, predicting and then adapting. So we have demand forecasting uh embedded in AI embedded across demand forecasting,

inventory routing and and all sorts of you know in uh through the entire supply chain not as a pilot but as a missionritical systems tied to readiness. Why this is important is

because we um and why it's very uh specific to India is because we do not have a linear supply chain. We are operating you know through jungles, through oceans, through really long

borders and through very many threat vectors. So um how then we should be able to sustain uh you know combat and be ready for combat is what is something that our uh supply chain networks have

to address. So to give an example in terms of you know sustained supply chain and demand forecasting that has been implemented worldwide and because I'm a consultant is uh you know if you could

draw from the US defend logistics organization which has which uses machine learning to predict spares failure and they have a very efficient uh inventory management

system currently at play and the NATO as well uh you know uses this predictive analytics ICS to ensure that you know they take into ingesting a lot of algorithms on operational tempo, terrain

and weather and do not only rely on past data and past orders. So you see a very very effective you know inventory management system at play here and there is something that we can learn from how

they have taken this uh uh beyond. What also is very very essential is effective warehouse and distribution and AI has specifically played a large role here. uh globally I think we have seen uh you

know AIdriven warehouse automation in UK and US defense depots wherein you they utilize robotics vision systems and intelligence slotting in making sure they have an efficient warehousing

automation system. We also see the ministry of defense in UK uh wherein they have taken the owners of implementing uh supply chain digitization which focuses clearly on AI

enabled demand forecasting and of course automated fulfillment for defense uh uh forces that are deployed. These are some of the good best practices that we can see the world over and of course the

Russia and Ukraine war has taught us in terms of how root optimization and uh you know how they are actually operating and showcasing resilience under fire in which they're utilizing uh you know uh

AI enabled technologies for root obs optimization to plan their convoys. So these are some of the uh you know examples that I can uh think of and you know in closing I'd like to say for

India specifically I think AI and defense logistics is not about copying global markets. It's about building a resilient and indigenous system which will actually uh help adapt our supply

chain networks to ensure that we are uh turning the Atman Nirhar Bharat initiative into our operational advantage. Thank you Madumita. Uh

I would be unfair uh to the audience if I don't take your question. I know we are out of time. Uh so just one question you know if anyone has just just give the mic can you come and

tell me just be loud. &gt;&gt; Okay. Uh sir as uh we have seen that uh in the recent operations uh of Chindor we have seen that the adversary was using the AI at a large pace and uh we

do have indigenous capabilities but we are much uh though we have developed certain softwares but for the hardware part we are still dependent on other countries. So what are your perspective

uh how we are uh going ahead in building capabilities in that &gt;&gt; uh chipper? All right. So probably um you are referring to the hardware supply chain

uh issues and primarily because uh artificial intelligence um uh present technology relies on the GPUs and we are reliant for um imports for GPUs. So uh this vulnerabilities are known they can

be addressed through multiple means. One one is you have multiple sources then is you have alternate technologies and we are working towards that. And we today develop instead of a large language

model which runs on a GPU, a small language model which runs even on a CPU and then have a large this agentic garden which small language models are running on a farm of CPUs and then you

can uh uh serve the same purpose which a GPU based large language model will give. that is another third is which is um uh related to a longer time span is having an indigenous capability to

develop these hardware. So that uh uh again that activity is being taken up very seriously. There are four lead agencies which are working on producing these semiconductors uh uh within India.

We lost that opportunity once in the 80s when our semiconductor limited got burned down in 1986 and we became import reliant. uh TSMC came up in 1987 one year later today controls 75% of the

market so we are starting late but uh as I say that there is a advantages of the first movers they get a lead but there are advantages of the last mover you get the clarity so we are moving in all

three directions actually very [clears throat] beautifully articulated the last more advantage can also be used to do better hardware design for example the new architecture the mixture of

experts we just launched a 17 billion parameter mix of expert with just two shared uh you know mixture experts. Now the advantage is you can do very quick inference even at the level of CPUs how

can we use the workload I think how do you turn your software into hardware advantage how do you turn your software workloads to design better hardware that's an advantage we can get through

the late more uh story &gt;&gt; I know a lot of fans are still there but you know we are extremely short of time I wanted to just acknowledge Mr. Praep Gupta who wanted to raise a he has

worked with EM RM finance minister all of them but you know you are seeing all the changes that are happening so we'll have a conversation outside Mr. Gupta uh thank you uh uh to all of you uh the

deputy chief sir for giving a great context and uh motivating everyone to speak so well uh I know we were short of time uh even at the start uh general chip so nice uh to hear your uh thoughts

and how the DJIS is proceeding at at pace around all of the uh army of force around AI general anal the um Vikram Ganesh and uh Madumita. I think you all have done a fantastic job and thank you

to all of you in the audience and also to the organizers for your support too. &gt;&gt; I'd like to just thank everybody. &gt;&gt; Yes, just please be I'd like to thank everybody uh for being here as also the

panel. uh we put it together in uh quick time and I think you saw that there were experts in the field would have gone on till the evening and I'd like to assure you uh both the industry the academy and

all the others uh and of course there would be people in the industry that uh we are committed to uh you know uh committed to committed to ensuring that the AI ecosystem that is there in the

country whether it be startups or large players and innovators that we incorporate them into building uh AI enabled your systems.
