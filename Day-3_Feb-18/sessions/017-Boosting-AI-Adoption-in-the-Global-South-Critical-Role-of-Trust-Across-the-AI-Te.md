# Boosting AI Adoption in the Global South: Critical Role of Trust Across the AI Tech Stack

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 15 |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/JqnIuxd0dkk?feature=share) |

## üé§ Speakers

- Denise Wong, Infocomm Media Development Authority, Ministry of Digital Development and Information, Singapore
- Rebecca Finlay, Partnership on AI
- Ria Strasser-Galvis, Anthropic
- Terah Lyons, JP Morgan Chase

## ü§ù Knowledge Partners

- JPMorganChase

## üìù Summary

This discussion explores how trust enables responsible and scalable AI adoption across sectors, especially in emerging economies. It focuses on shared accountability across the technology lifecycle, practical governance measures, and deployment safeguards that build public confidence. The conversation highlights collaboration, transparency, and real-world assurance practices as foundations for broader, inclusive AI uptake.

## üîë Key Takeaways

1. This discussion explores how trust enables responsible and scalable AI adoption across sectors, especially in emerging economies.
2. It focuses on shared accountability across the technology lifecycle, practical governance measures, and deployment safeguards that build public confidence.
3. The conversation highlights collaboration, transparency, and real-world assurance practices as foundations for broader, inclusive AI uptake.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/JqnIuxd0dkk/maxresdefault.jpg)](https://youtube.com/live/JqnIuxd0dkk?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

India's future because we know that the talent pool is leading the way for new business and innovation for for the region and across the globe. In this room, we have already moved past

the theoretical. To build trust across the tech stack, we need to acknowledge the role of both developers who build the models and deployers who use them. JP Morgan Chase

as a leading deployer. We have over 400 AI use cases in production to manage risk, optimize trade, improve the experience of our customers, and crucially protect our customers from

fraud. We are operating real systems, serving real customers, and managing real risk. Every day, we have learned that accountability must be shared and explicit. Creators must own how

technology is designed and its limits. Deployers must own how it's applied and the results because real people feel the impact of these tools. Builders and deployers must work together to optimize

and use AI to enable solutions. That is the only way to build confidence that is required for mass adoption. As we look at the global regulatory environment, it's clear that technology

is moving faster than the frameworks around it. This includes governance, coordination, and shared norms across borders and sectors. Based on JP Morgan Chase's experience in

highly regulated markets, the best approach is to govern for outcomes, not just the technology itself. We should set the bars that matter, treating customers fairly,

delivering better outcomes, and maintaining market integrity. While national innovation agendas and sovereign AI strategies are understandable and often necessary, we

must ensure they do not lead to fragmentation. Fragmentation slows progress. We need rules that are interoperable across borders so that an innovation developed in India

can be trusted and scaled globally. For the global south, trust is not just a safety measure. It is a key enabler of adoption. If we can close the governance gap between developers and deployers, we

can unlock AI's economic potential across all markets. JP Morgan Chase is a committed to being a responsible leader modeling safety, transparency, and accountability while deploying at speed

and scale. I look forward to this discussion on how we can move beyond general agreement towards shared approaches that actually work in practice, at scale, and across borders.

I want to now introduce and and pass over to our moderator, Rebecca Finlay, our very good friend and CEO of the Partnership on AI. &gt;&gt; Thank you, John. Welcome everyone. We

have a real treat for you this morning because as John said, we really want to get deep and substantive about the question of trust across the AI value chain and how that is core and essential

to adoption and deployment wherever it might happen. across borders uh in the in the global north or in the global south. So this impressive panel that I'm going to introduce to you are going to

be our experts today to talk a little bit about this. Right to my left I have Denise Wong who is the assistant chief executive data innovation and protection at the Infocom Media Development

Authority or IMDA uh and at the Ministry of Digital Development and Information in Singapore. Hello Denise, great to have you with us. Uh beside Denise we have Tara Lions who is the global head

of AI policy at JP Morgan Chase a deeply established leader in the field of AI governance and AI trust and looking forward to her contributions. And then we have Ria Straer Galvvis the

international policy special projects leads at anthropic. Hello Ria good to have you with us. And Dr. Mangul Sarin co-founder and executive director of AI safety Asia. Thank you for joining. So

before I uh uh move to my first question, I wanted to say a little bit about the organization that I lead which is the partnership on AI. We are a global nonprofit. We bring together 140

partners in 18 countries. And what's unique about our organization is that we breathe and live multistakeholder cross- sectoral collaboration on the core elements of responsible AI

innovation. And so that means we are very honored to have uh technology companies at the table, technology companies that sit in all sorts of sectors, whether that be financial

services like JP Morgan Chase, but also civil society organizations and academics at research institutions around the world. And we believe that it is only by creating spaces for these

very diverse perspectives to come together that we can solve the real challenges to promote responsible and beneficial AI adoption globally. We have been doing some work on trust across the

AI value chain and later this week we'll be issuing two reports to really scope out for policy makers what does it mean to have a thriving and vibrant assurance ecosystem. I think all of us in this

room can agree that without trust you cannot have innovation and we want to help policymakers to better understand what it means to have a thriving assurance ecosystem and how to have

trust across the value chain. And we had the opportunity to begin to have a deep conversation about this with some of our partners uh in New York City last week and we were hosted by JP Morgan Chase to

have what we had was an AI enterprise forum and it was a fascinating discussion uh with three themes that really emerged around AI trust. So the first being that governance of AI is

governance. Good governance matters whether it's AI technologies or otherwise even if there might be some defining characteristics about AI technologies and we need to integrate

governance into all aspects of our operations. The second is that we really need to think about collaborating across the value chain and we're going to talk a little bit about that today. The third

is that with AI deployment we will see changes and evolutions and iterations of the model. So it has to be a dynamic level of risk management and that does change the parameters of traditional

risk management within within many organizations. And then finally we have to be focused on the societal and real world outcomes of whatever decisions we are making as businesses. So how do we

center the human experience? Because at the end of the day, trust is about the trust that our customers have in our products, that our clients have in working with us. And then of course that

our citizens have in the technologies that they are interacting with every day, whether it be in financial services or with chat bots or in any other way uh with AI. So with that um I will turn to

Denise with my with my first question. tell us a little bit I mean Singapore has really led the world around uh many of the work uh and efforts that you're doing around AI assurance. So let us

know how you define trusted AI and what are some of the policy tools and frameworks that you have put in place to ensure um trust across the tech stack. &gt;&gt; Thanks so much Rebecca and firstly thank

you to JP Morgan Chase uh for for having us. Rebecca, I remember that two years ago I attended your partners um conference and we were just beginning to have this conversation on generative AI

and what safety and what trust means and here we are two years later um I think we've moved a few steps forward um in this conversation for us as a country and I think I speak for many countries

it's about um giving your citizens the trust and confidence to use the technology especially in the global south especially for a small country like Singapore but it's also about

having companies, organizations big and small, use the technology confidently and creating an an environment for them to do so in a way that is safe and trusted, but also gives them space to

really use and explore and exploit because that's what companies should do. Um, so for us in Singapore, it's been about putting in place just the right amount of guard rails. Um and and to be

honest, that's still an ongoing conversation about what right is. Uh but then creating those safe spaces where people can take use and innovate. As a policy maker, what does that mean? It

means you have to be really humble because we don't know what the answers are. Um we have to be agile. We have to try and keep up with understanding what the technology is and how it's changing.

Um and we have to put out sort of guidelines and tools that are adaptive you know that that can be quickly updated that can be experimental. You know concrete has set the same way for

the last 50 years but AI changes every day. Um so the the regulatory approach has to be uh adaptive to that reality. Um so what we've done recently is as as John has mentioned as you've mentioned

you know worked in the space of sort of guidelines and frameworks and we don't see that as um soft we see that as sort of laying the foundation and the groundwork of what good looks like um so

we did that with the model governance framework in 2019 we updated it for genai um and recently we uh we just launched one for agentic AI we've also done um AI sharing sandbox because we do

believe that while it's important to regulate for specific things like online harms and we've done that with elections and with um scams, uh for the rest of it, a lot of it is about trying to

convince companies that there is corporate benefit and reputational benefit to doing AI well and doing AI safety safely. Uh so we've worked in the space of standards um to try and get

techn a technical consensus on what good looks like. uh we have the AI verify foundation where we've brought together demand and supply um as well as testers to kind of experiment on real world use

cases uh and we've put that together in a community of testers, deployers, developers um so that we can have conversations about what uh what good looks like and how we can move forward

on that. &gt;&gt; Okay, so now you know why Singapore is a leader in this field and why they come up. It's really impressive. Thank you so much. And by the way, if anybody wants

to jump in at any point, feel free to do so. So, let's move into um who is responsible and how do we define responsibility uh when it comes to trust. And Ria, let's start with you.

Give us a sense from the developers perspective about what technical and non-technical safeguards anthropic is including in in some of your code models as they're being released.

&gt;&gt; Great. Thank you so much for for having me. Uh before I answer your question, I just want to quickly say how excited Anthropic is to be here in India. Just a

few days ago, we opened our very first office in India and Bangalore and it's a really exciting moment. We see India actually using Claude as the number two country in the entire world. So there is

so much potential uh for growth here and we're already excited to be able to hire a local team. um about trust. That is something that Anthropic thinks very deeply about across all of our teams,

including of course our safeguard teams and all of our security teams. There's a variety of ways that we build in trust to the stack to everything that we do. Uh one of those ways that, you know, I'd

like to call out here today is the work that we've done on Claude's constitution. That's a really interesting document that is living and always being updated and really provides

guidelines for claude to think about how it interacts with humans, how it comes up with its answers and helps it resolve conflicts whenever that occurs. So the constitution has four categories that it

really tries to uh break down not just in rules but in explanations of how we got to those rules. So, we hope that this constitution will help Claude be safe, ethical, helpful, and compliant

with our regulations. And when I say compliant, I mean around rules that we've built around jailbreaking, things like cyber security, queries around mental health, all of these issues that

are very serious and we need to be able to describe how Claude should come up when it faces conflicts around these issues. This constitution is used in various parts of our training. So, it is

really built into the core of the model. Sometimes we even colloally refer to it as Claude's soul. Um, and it helps prioritize whenever there are potential decisions or choices that Claude has to

make about what it serves you. Um, it's also public, so we think that's a really important part of transparency so everyone can see exactly the the way that Claude is coming up with these

answers. Um, we just released an update to the constitution and like I said, it's constantly being changed. The latest change is really to adapt to the egentic world which as Singapore

mentioned they're working very deeply on as well. &gt;&gt; Thanks Ria Tara. I mean we can talk about constitutions but then we can talk about financial services where you are

holding people's money and their trust and their wealth. I mean this is a key element of people's banking experiences. talk to us a little bit about being the AI sometimes developer but also deployer

and what does that mean in terms of managing trust when we're thinking about transparency, auditability, ethical safeguards, all of the things that you're putting into place at JP Morgan.

&gt;&gt; Sure. Um well I think actually you said some of this earlier Rebecca and so did Denise. So I'll just underscore some of your remarks with respect to the importance of actually putting AI

products and services in the hands of real people every day and that being the real focus of what I think is an evolving conversation in the field about governance. Um many of us I think all of

us actually up here have been in the field for a long time and have sort of seen the field move from what we used to call principles to the direction of practice now. And I think um I think

that it's you know our interest as a deployer of these technologies most often characterized um is in making sure that they are inherently trustworthy because otherwise we can't do our jobs

effectively as a as a major financial services um firm globally. So what that means for us and and I think the o overlay here that I also just want to mention I I appreciate constitutional AI

and I think anthropics done you know a great job being sort of valuesoriented about the work that they're doing but our company faces real regulations um that we are you know we are designed to

comply with every single day. We have a credential regulatory system to which we have to be responsive in in banking. Um there are obviously other sectors that you know are similarly regulated like

healthcare and pharmaceuticals but um but what that looks like materially from a trust perspective translated into AI is thinking about explanability requirements in very concrete ways um

which support you know for example um our capability of leading an audit trail for every single model that we deploy. Um it looks like us having uh a capability of adverse action. Um which

means that we can you know we we can have customers come to us and actually request reasons for having been denied a credit score you know of a certain level for example or um or in an underwriting

context. Um it allows us to uh place fairness very materially and legally at the center of all the work that we do deploying models in everyday context. And I think that I think it's really

important for deployers like us to ground the conversation we're having about AI governance in these types of material impacts to real consumers um in that very way. So um so that's a little

bit of what I'd kind of describe as our focus right now. &gt;&gt; Yeah, deep deep deep commitment to trust and many many years we heard 80 years in in India alone, right? So yeah, many

years of of trust uh and customer trust to build on. Monold talk tell us a little bit about what it's you know this this question between developers and deployers through through the context of

what's happening in Asia there may be different dimensions with we think about the number of open models that are coming out in Asia otherwise give us a sense of of what that looks like

&gt;&gt; yeah thank thank you so much um delighted to be here and hijack the all female panel here as &gt;&gt; we needed you [laughter] &gt;&gt; um and yeah um so we are um I'm from AI

safety Asia we build AI uh governance um ecosystem in in in Asia mainly in Southeast Asia. So I think the conversation as um Denise pointed out we move a little bit forward. Uh now the

conversation started uh a little bit wake and and and all of this and now we move a little bit uh in Asia in particular like with the work of uh Singapore. I think Singapore is

leading a lot of work on on all of these. Um we moving a little bit that people understand that it's not just the responsibility should be a share responsibility right um developer has

responsibility deployer has responsibility but also the regulator also has the responsibility it's a shared responsibility and we are still far away from that but I think we're

moving toward that with with the work of the verify foundation of of Singapore that's leading some of uh the work uh around that I think everyone knows that we cannot not put responsibility on just

one actor uh and it's a stakeholder responsibility. I think the three actors that I mentioned just just the three actors that mainly involved on that but also there civil society the citizen

themselves that need to play a role in in all of these ecosystem uh so that we create trust for the society. &gt;&gt; Did you look at the questions ahead of time because we are going right into

that shared responsibility question now. So thank you very much. Um, okay, let's talk about that. There's there's the the the notion of how you build shared respon responsibility across the value

chain has been a topic of conversation for a long time. I'm not sure that we've gotten really to the essence of what it means and now we're in a we're in a space where we are actively seeing these

models being uh developed and deployed across. So, let's let's try to dig into that a little bit and learn a little bit more. So why don't we start with you Denise and then we'll come to you Tara

and to and to Ria. Um uh give us a sense from you've been doing the work around your model framework around Agentic AI. Give us a sense from from your perspective of how you're thinking about

shared responsibility. &gt;&gt; I think and it's been mentioned a few times already. It has to start with the AI supply chain and that value chain. Um and and then I'll jump straight to the

difficulties and challenges. It's be this is a different type of technology from what we've seen in the sense that you have the foundational model and you have raffers and rappers built around

it. The supply chain is global, the usage is global um in a way that I think we started off with social media but you know this has added on layers of complexity going to to your point. I

think we need to be very concrete in a way that the lawyers can apply um and and and the the regulators can apply and we haven't quite gotten there yet. We're still um having I would say conceptual

conversations about accountability that's important. Um but to then move into the space of liability, causation, insurance, um and assignment of that, uh we're still some ways away. We've done

some of that work now. We're continuing to do that work. Um the starting point will have to be what does good governance look like for each of these actors? Once we can concretize that,

then we can get a sense of well, if you don't do your job, what does that mean and and what what should happen? Um, so it's it's a nonregulatory conversation. It's just that this technology moves

quickly, but we'll have to stick to those established principles of coming up with legal frameworks. Um, and we have to do that internationally in a coordinated manner so that um,

fragmentation has been mentioned. I don't think we can do this if everyone has the conversation separately and in silos. &gt;&gt; I couldn't agree more with Denise and I

I think what I'd add is that um I there's a I think governance means a lot of different things especially these days depending on what context you are operating in but I think we have to sort

of draw back and consider it from a holistic perspective. What I mean by that is to say that it's going to take action of a number of different stripes and at different levels of the

ecosystem, the supply chain that Denise is talking about in order for us to effectively do the type of thing that she's describing. And I think it starts with

voluntary commitments by tech companies and I think a lot of the work that the partnership in AI is leading um in terms of a verification ecosystem and really driving best practice in the field um

really shaping what the principal levels conversation should look like amidst a whole host of other civil society and other institutional actors is really really key there. I think there's a

layer of technical standards generation that really needs to be paid attention to as well. And so at JP Morgan Chase, for example, we're really leaning in um you know, not just on the first part of

that stripe that I mentioned with the partnership and other partners, but um in that kind of second layer of standards generation because that's really critical to feeding what

ultimately ends up impacting regulatory guidance um actuated by governments and regulators. um which I would say is kind of the third layer of governance and ultimately the most accountable um part

of that that kind of work stream because it is a set of legal requirements ultimately that gets codified into law or regulation. Um I think depending on the country in which we're operating um

we're at different parts of that maturity stack but um but I think you know it's it's all kind of being progressed in the ways that it can be right now by an ecosystem of actors. And

I think that last point is also a really important point for us to make which is um you know again speaking to Denise's Denise's point raised about the supply chain really really critical here and I

think we've all echoed points related to that this morning but um this is not just about frontier model developers. This is about tooling providers. This is about um end users like us um you know

supplying products and services to citizens um and customers. It's also about cloud service providers and infrastructure. Um and so um I think the more we can kind of open the aperture to

really think comprehensively about these questions the better. &gt;&gt; Yeah. And as mentioned uh Anthropic has joined a number of partnerships and commitments itself. Just recently at

Munich Security Conference we signed one with Microsoft and Ericson and other companies to be committed to a trusted tech stack. So these are really powerful commitments I think especially coming

from industry themselves. Uh but maybe I'll give a technical example of how we're building trust into the process and then sharing it. uh model context protocol MCP is a technical standard for

connecting uh chat bots to tools and data that make it much more useful. Even the most advanced chatbot is really nothing if it's not connected to things that is useful for you and builds a

context for how you're trying to actually use it. So we released this in 2024 really before agentic AI was in the modern uh area but it's looking forward to ways that people can securely connect

to tools. We were really excited to see there was great uptake of this. As of now pretty much everyone is using it. If you use chat GBT um co-working

to all your tools through MCP and as we saw this uptake we ensured that this was completely open source and actually just a few weeks ago we handed off ownership of NC MCP to the Linux Foundation

ensuring that it was useful for everyone and not just one company because it's become such a great standard for everyone to use and feel confident that their data is secure. So I think this is

just one way that developers can build trust and then share it with the entire ecosystem. &gt;&gt; Thanks very much Ria. Okay, let's let's turn to uh a piece of this question

around adoption which is really thinking through what are we seeing in the global south appreciating that that is an extremely diverse set of countries and cultures and languages and all sorts of

different uh adoption models. Uh, Mongol, why don't you start tell us a little bit about what you're seeing maybe particularly from the government side with regard to supporting um

different uh different levels of adoption across different different countries. Yeah, I mean uh the good things about global south is that the trust on technology and AI is usually

higher than the global north. But we should not take it for granted because something happened trust can be eroded very quickly. Right. Um my concern is that government are not or deployer

themselves are not ready in term of um understanding and adopting this technology in a safe way. Right? there's an institutional assurance that need to be built in the developer themsel and

also in the government uh there there's lack of capacity um across um uh different jurisdiction uh in in Asia alone there's um Asia is 60% of the world and that's the all the deployment

of the technology will be stress tested in Asia right uh all the things that developing in in in the Bay Area will be stress tested here and the people will have the live experience on what's

happening whether it's incident whether it's good or bad so so we need to making sure that there is an institutional assurance if we want AI to be assure in in Asia and Asia has to lead the way in

in that so when we talk with with the government uh what we are uh trying to to convey the message is that um you don't need not every country need to build the frontier model and when we

talk about sovereignty it's about control like whether you what are the procurement checklist what are the monitoring mechanism what are the evaluation um how do you enforce the

accountability and trans uh transpar trans transparency across the value chains so so that's the sovereignties that's is the control that you can do and and not just about building

everything uh from the the the full stack of of AI &gt;&gt; okay so the sovereignty word has come up um which I think every panel has touched on. So let's let's integrate that into

into some of our discussion about the about the global south. Denise, the association of Southeast Asian Nations, Azion that you lead uh and work with your partners in uh at Singapore is one

as aspect of a regional group that is coming together to think through some of uh these questions around AI adoption and uh grassroots deployment. Do you want to talk a little bit about that?

&gt;&gt; Yeah, happy to. Association of Southeast Asian Nations or ASEAN is a very diverse group of 11 countries um economically heterogeneous, socially, culturally very different uh across the countries.

Cambodia is is is a member. Um and the work that we've been doing in leading the working group on AI within ASEAN has been really about understanding the local context but still trying to find

commonalities across um and that's been uh a big theme uh for for the grouping. It's about what does inclusion mean in your context? What does uh localization mean and representation mean in your

context? So respecting those sovereign aspects of the country uh but working together to find a common platform because you know businesses will have to operate across people do have to move

across and the technology will be transcending across the data will be moving across um and so finding those common principles uh uplifting the understanding but still ensuring that

that local uh context and representation is respected has been very important. So we've been doing a lot of work in multilingual and multicultural context within models. On the technical side um

and on the sort of governmental policy side it's been about um putting out frameworks that everyone can agree on um that governments can have conversations and dialogues about. Um again still

ongoing work starting points uh but we'll continue to do more of that to kind of strengthen the regional understanding and consensus around that. But still bearing in mind that broader

global conversation that is quite critical &gt;&gt; and so much of it is just about creating the space for those conversations to take place right so that one can better

understand the different contexts from from which people are coming. U Ria talk to us a little bit you mentioned India um a little bit about your work here uh tell talk us a little about some of the

other countries you may be and and also I think this question of multilingual um yeah I think would be interesting to hear from your perspective as well. &gt;&gt; Um this is a really exciting year for

anthropic. This is pretty much the year that we're going international. So, this is one of the first for us international offices that we're opening in India. And yes, we just announced a new model

launch and we were very excited to do some testing on Indic languages. And it's our best model so far on Indic languages. And in general, testing on languages and improving their

performance is a really big focus for us, especially during this year when we're trying to go international. Um it's it's not just that but it's being able to have benchmarks that are

relevant for the culture and so we're working with many organizations that are on the ground here in India to ensure that we're actually meeting the needs of its users and trying to determine how

that is different and has the correct context from what we're used to in the United States. uh India really is a model for us of how we build this partnerships working with the government

working with NOS's and it's very exciting because of all the enthusiasm as you you mentioned in this region for enacting AI across various use cases um we're really excited to see how it's

used in agriculture in healthcare in industry and there's unique trust needs for all of those industries so we're working together really to to make it happen

&gt;&gt; great and did you want to touch on any of your work in any other countries or just specifically on India right now. &gt;&gt; Well, we really haven't announced too many launches. More to come, but we've

opened in Japan. Uh, that's one of our main hubs in Apac and we have a few offices in Europe, but I think by the end of the year I'll be able to have a much more interesting conversation with

you all. &gt;&gt; Okay. Just wondered if we could get a sneak peek if there was anything coming up. Great. Thank you very much. So, Tara, maybe you can talk a little bit

about the work you're doing at JP Morgan Chase. And I also think we're sort of the the flip side of the question is, you know, what are and how are you supporting your workers here to be

upskilled and to better understand what what uh how these models are working and how they're integrating into your banking practices and operations. &gt;&gt; Yeah, absolutely. Um well, I think maybe

just a a zoom out for one moment. JP Morgan Chase is a global bank. Obviously, we operate in over a hundred countries in the world. Um and I think one key aspect of our work globally is

just being intensely customer focused because as a deployer um delivering to end users every day we we have to be um it's part of our imperative. So um and and I think the trust piece um really

comes into play there as we talked about earlier um we are it because we deploy in countries different financial services and products we have to tailor them to any given market and so that

sort of um sensitivity the focus on listening multistakeholderism that Denise mentioned um cooperation with local governments and regulators is just inherently a part of our kind of um

day-to-day prioriz ation of um of kind of more localized focus and activities. I think to speak to your question about our workforce um as John said earlier, this is our second largest hub of

employees outside of the continental United States. So, it's a really really important market for us here in India. Um most of our corporate philanthropy investments in India have been focused

on workforce upskilling um and support for training here. Um we have a huge tech hub and I think the point to emphasize or re-emphasize that John mentioned earlier is that um this isn't

just back office operations for us. This is really like critical um leading technology provision um in in in India and and the talent here um supports it accordingly. So um I think I think that

that aspect is really key and there's a huge focus on the kind of work that's happening coming out of Silicon Valley these days. But there are there are huge talent hubs um that are really driving

the AI revolution in other places. And I think just recognizing um the role that India has played and and the conversations that we're all here celebrating and and talking about the um

you know kind of addressing the current moment is really important too. &gt;&gt; Absolutely. Great. Okay. I think we have a few minutes to open up for uh some questions from the audience. Do we have

a microphone? Anybody assisting us with a microphone? There we go. She's going to help us out. Just one give us one second.

There we go. Okay. So, we have some questions in the front. Why don't we take why don't we take um two or three questions and then the panel can can respond and and we'll go

from there. So my question is to I think Ria and Dr. Sin can also come in. So when we look at uh trust trust is often uh in a spectrum trust and vulnerabilities for a educated

person might be very different from a farmer. So how do you solve for that spectrum of trust when you are creating models let's say for a farmer because the model gets trained on multiple

variables. I might be a farmer who might be in a very good weather or a climate but my soil might not be as fertile. So how do you create embed a trust and this might be like cloud has said that they

have a constitution. So how can you enforce these compliance by design and solve for that different spectrum of vulnerabilities. So how can these models be trained that way?

&gt;&gt; Great. Thanks. So our first question is trust by design. Can you pass the microphone on to this gentleman and then we'll come back to you. &gt;&gt; Uh myself Pur my question is to Riya. So

you said multilingual implementation of GDK solutions. So in India lot of languages are there. So I considering all the languages because you know lot of people they don't know English you

know but they need to read they use AI but we need to make sure that you know they understand that language. So are you considering implementation of all the Indian languages or how that

&gt;&gt; okay all the Indian languages or not? And then we're coming back to this woman here. She had her hand up in the second row. &gt;&gt; Hi, I'm Fernando from an internet lab

from the internet lab think tank in Brazil. Uh Denise mentioned uh gathering a community of testers uh and I would like to know more about how does it work methodologies for that and if you anyone

can comment on the role of open source in building trust. &gt;&gt; Great thank you. Okay so we have trust by design we have languages and we have open source and testing community. Who

would like to go first? &gt;&gt; I we'll start with you. We'll start with you. Why don't we start at the far end and then we'll get to &gt;&gt; Yeah. Uh so I can start I think uh in

some way you've already answer your own question right it's it's by design that you have to start uh involving the user uh when you start designing this model right um and then it's different layer

of assurance how would that trust is built right uh the user themsel will probably need to empower them with the new education on understanding what does trust mean what does what is privacies

and all of these sometime the user um will need to understand the spectrum of and then you already answer your question that trust is a spectrum right uh so we need to understand what are the

the different layer of trust what are the nuance um and then there's different um actor in the whole ecosystem uh from the model uh developer from the deployer uh and then from the regulator right in

term of enforcements and and and all of these and civil society as well that help in in term of being uh the angel of the society to help u uh monitoring uh what trust mean and and what are the

verifiable what are the retrust mechanism around that &gt;&gt; okay great ria &gt;&gt; yeah ab absolutely everything that was just said and I'll share you know a

specific example I mentioned the claude constitution is built to ensure that we stay by our guidelines and those guidelines are always changing and adapting to what local needs are um here

in India actually I love the example of agriculture because we're partnering with an NGO to build agriculture benchmarks specific for India. So it does need to be local. Another example

from the United States is uh mental health which has been raised to us as a big problem with chat bots and so we've come up with new guidelines for when queries are indicating if there is a

mental health um issue that we should serve information from a web web search about for example. And then on the flip side, we're also looking at the technical aspects that bring this risk.

Maybe things like syc. Um, and so those are just two examples of how we're building more trust based on local issues that we're seeing evolve currently.

&gt;&gt; Great. Thanks, Tara. Or do you want to jump in? &gt;&gt; Sure. I mean, I think on this question in particular, I I want to bring use cases into the lens view here because I

think trust and accountability by design is really really key in contextual relationship to the way in which AI is being deployed. And so um I'll sound like a broken record a bit as the

deployer on the panel talking about you know our financial service use cases but um I think that applying the lens of localization that we describe or locality um and and then exactly how

you're using technology who it's serving and for what purpose is is really key. So that's just what I'd add. &gt;&gt; Thank you. &gt;&gt; Just quickly answering the question um

30 seconds on AI verify foundations. It's an open source foundation u based in Singapore but membership is global. uh it's got frameworks um it's got tools and the tools are connected to

benchmarks. It's all open source so you can sort of it's a reference architecture you can take and use um to really sort of test real world systems but I also wanted to mention the uh AI

assurance sandbox that's part of the foundation and that's not a regulatory sandbox it's about matching real world deployers um and their use cases with uh testers from around the world uh and the

testers will kind of work with the deployers to figure out what they worry about and what's the best method to test that. uh the reports are then we don't look at whether your model is good or

bad. We don't really care about that for now. Um but we care about the methodology that you use and the testings of um protocols that you used. All of that comes out in a report again

all open sourced and used. And so in that way it's really almost a community of practice completely global completely open so that we can have conversations about what good testing of AI systems

looks like. &gt;&gt; Yeah. And I'll just jump in. There's risk with all models whether they are open- sourced models or they are closed models. There's differential risk and

differential potential impacts. We at the partnership on AI believe fundamentally that there is a real role for open model development in terms of driving innovation and competition and

in fact some of the work that we have done on characterizing and articulating the value chain has only been possible because we've had open source models that have allowed us to do that. So I

really think we have to have a very nuanced and it comes right back to the point that Tara made around use cases, right? There's levels of risk with the models, but there's also risk around the

around the use cases as well. Okay, you have 30 seconds if you want to jump in. &gt;&gt; So I I want to acknowledge the the question around uh diversity of the language, right? Um it's a requirement

like uh India has thousands of languages. Uh Southeast Asia alone has more than a thousand languages. So uh it's not uh it's a misleading if we say that we

only build for English right um the system will fail if you don't treat all the languages it's a requirement it's not an additional um uh inclusion uh add-on it's a

requirement that we have to work it everything has to work for all the languages &gt;&gt; fantastic okay we have a lightning round and then we were are concluding in time

I'm afraid we don't have time for any more questions questions. What uh we still have time. Um what what in your perspective across each member is the most critical enabler in this

moment? What we've tried to do in this panel is get underneath the three to the actionable as John as John charged us with as we begin. What do you think is one of the most critical enablers of

making that happen and moving that forward? &gt;&gt; Inclusion, representation, but in a very sort of trusted way. Uh I think uh the shared accountability

model we've all spoken to needs to be clarified and made explicit and there needs to be transparency between actors who are sharing in that supply chain that Denise spoke to

&gt;&gt; 100%. &gt;&gt; Well representing a frontier lab it's transparency sharing how we're thinking about things sharing how we develop our principles and making partnerships where

that is open source. uh representing civil society. I think it's about verifiability. How we can verify that everything will work, everything is transparent and how

can we we do that on a larger scale. &gt;&gt; Wonderful. Thank you all. Thank you. Please join me in thanking the speakers that we have with us today. Good morning everybody. I'll just

briefly take up
