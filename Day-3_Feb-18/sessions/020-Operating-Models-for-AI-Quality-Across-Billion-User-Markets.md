# Operating Models for AI Quality Across Billion-User Markets

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Chanakya Auditorium |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/lfz3KuvWzHo?feature=share) |

## üé§ Speakers

- Aneesh Chopra, innovativestate
- Rahul Kapoor, PwC
- Richard Vose, PwC Strategy
- Sarala Jonnalagadda, Google Technical Services

## ü§ù Knowledge Partners

- PwC

## üìù Summary

AI at a billion-user scale strains traditional operating models. Quality, cost, and speed collide as organizations expand across languages, markets, and use cases‚Äîparticularly in mega-markets like India. This panel brings leaders on the front lines of AI transformation to unpack how operating models are evolving. The conversation will explore approaches to AI quality, governance and metrics, global feedback loops, and human-AI workflows that deliver results while embedding AI skills and novel ways of working.

## üîë Key Takeaways

1. AI at a billion-user scale strains traditional operating models.
2. Quality, cost, and speed collide as organizations expand across languages, markets, and use cases‚Äîparticularly in mega-markets like India.
3. This panel brings leaders on the front lines of AI transformation to unpack how operating models are evolving.
4. The conversation will explore approaches to AI quality, governance and metrics, global feedback loops, and human-AI workflows that deliver results while embedding AI skills and novel ways of working.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/lfz3KuvWzHo/maxresdefault.jpg)](https://youtube.com/live/lfz3KuvWzHo?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

is a partner for PWCUS. Again, he's been helping uh very large online platforms for a number of years now. So again, just incredible experience. I know that's going to be

very applicable uh to AI. So Sarah, I'd love to get your uh perspective here because I know that you live AI every single day and scaled operations. How do you think about quality given the

volumes that are now coming your way? &gt;&gt; That's actually a very interesting question. Uh Richard, um I think I would start by saying managing quality

um at the speed with which we operate is literally like non-negotiable, right? And that's paramount. And the way to look at it is we need to make that happen. The move has to be

from reactive checks to proactive calibrations. Um and if you if you were to actually take a step from there as volumes move up, one of the things to also look at is

the focus needs to shift more towards how to builds architectures that are more resilient and that can be supported with two very key and important uh levers. I think the first one is more

around how do you do intelligent sampling and the second one very very critical and very close to that is that needs to be supported well with automated

evaluation frameworks. Now these two put together will actually give us the kind of outcomes that we're looking at right um and here is where I would say that this

particular structure enables us to keep giving outcomes and outputs that works like a literal system right and you are able to pull humans then at the right space right time because the expertise

that humans bring the specialization is very very powerful uh and that's where you have the whole verifi you know trust and verify that that model needs to come in and kick in there so I think the way

to look at this this overall is it's not about matching or keeping pace with the speed but it's what's more important is as speed picks up how do you make sure that's enabling us to keep creating data

that we really really need. That's going to be very foundational and fundamental to how we operate and how good that golden data set is. So that's the way I would look at the the overall ecosystem.

&gt;&gt; I like it. Now Nish, you've seen this from the highest levels. How do you approach challenges like this? Uh &gt;&gt; to set the stage uh in the United States, digital platforms uh have

largely been governed under a provision of our law called section 230. and create these closed loops. So you're continuously using operations not as a backend for just delivering work and

checking the box that we've done enforcement but really to feed the machine and start to think about how are we driving better products, how are we driving better policy ultimately how are

we driving better user outcomes. I guess and increasingly today as folks implement AI, it's, you know, how do you how do you design this airplane as we're trying to fly it and go through that

transformation? Um, so I'd love to get your take. What does AI first actually mean for established companies? Again, this is something that I know you're living through.

&gt;&gt; You know, this is something that I keep talking uh to to anybody who's passionate about the space, right? Actually, AI first is a mindset shift. And that mindset shift is to be to be

curious and to also be open to a lot of experimentation and it requires that uh that motivation. Um if I were to look at three large

parts to this. The first one is as we empower our teams to start using a lot of AI tools um they should start looking at it as an enabler. they should also start looking

at it as a way that has a multiplier effect and the moment the that that realization comes through there is automatically that shift in mindset that will come. So that's the first pillar I

would say is AI first is all about the mindset. The second is skill set. As you move into this space, it's critical to understand that foundational to this work is going to be the business acumen.

And you can use a lot of of synonyms to this. It could be subject matter expert, it could be domain expert, it could be workflow expert, but finally we're looking at somebody who has that skill

set. And it has to be a good balance between domain knowledge and technical skill sets. So that will be the second one. And I think third very critical is as you have the mindset

as you have a skill set how open are you to the shift and the shift is you move away from being operational to being transformational to be somebody who is orchestrating

right and who is also in a space to to build and set up the architects. So to me these are the three key pillars to be AI first. The mindset, the skill set and the shift to be a architect.

So Nish, I bet you've seen a lot here where companies have been preparing for new regulation or if they're trying to transform themselves, but then you've got the EUA act or something like this.

How do you get that right skill set inhouse? Are they just trying their best or again what do you see works given your your experience? Well, the the current state is uh almost a false

choice that we've imposed as a society. We either express through policy a desire not to have adverse effects and create blunt instruments that frankly kick the can to courts to decide whether

your regulation interpreted by one implement is meeting the rule or not. And that's sort of a tough world to be in where not a lot of certainty in the world when you've got, you know, kind of

a rigid regulatory framework or you say nothing and you leave it to the market to kind of figure out which, you know, obviously people have a perspective about the challenges that we've seen

there. I view this as a third path and it's ultimately about the lack of consensus on standards and so AI creates an opportunity to close some of these gaps. What I mean by that is uh part of

the reason different countries have different um regulatory regimes is the frustration is high everywhere and then the willingness to do something you know that's unique to each political

environment. But if we solved the underlying problem, if we reduced the amount of harm on on these platforms and we increased societal good, you know, reduce the false positive, reduce the

false negative, naturally as a as a sector, this would be seen as a good, this thing is moving. uh as I mentioned section 230 originally dreamed, hey, we'll give you the liability uh shield,

but you got to, you know, proactively engage in solving problems. And so that creates um a third way. And the third way, and we wrote an executive order on this that still holds to this day on how

new technologies should be regulated in the Obama years and we basically said, let's obviously we need to have capacity improvement inside the government. So there is a little bit of back to skill

set mindset for the companies. Same thing has to apply to government but you can't rely on that because this is a difficult uh you know skill set to learn. So you you you yes you have to

get better but you also want to encourage maybe even demand uh industry collaboration to set these guard rails. So uh when you get there uh now the question is most of these policies are

words on a page and uh Sara may interpret the words one way and run her team to execute. I may interpret them a different way and so who's right? One of the interesting

things in the era of AI is we can now start to expose reasoning APIs where you can actually get to consensus computational what you'll call layer 2 uh consensus on what the interpretation

of the paper should be. So you could bring scenarios. If this image is not supposed to be present, you presented against this image based on these policies. Here's an objective uh

reasoning to explain why. And then we can argue whether we agree or disagree with that reasoning. This AI first mindset that you asked Sarah introduces a new concept of almost you know

regulatory uh product innovation essentially. you know, could we in advance uh almost prevent uh the ad showing up in the wrong way by having that reasoning appear uh before uh

stated harm is identified? Could you uh fasttrack like we we were talking about TSA pre-check? Could you submit an ad online and have it reason against policy and give feedback before you even hit

publish? uh and and that that type of capability. These reasoning APIs are a new concept that could introduce um you know more tools to reduce the outcome harms that we're worried about. And so

with my mindset on AI first is what's the northstar problem to solve? We want to minimize adverse effects where possible and society has kind of roughly explained what those topic categories

are. Okay. So now can we use AI to help address more of that on the front end and to get more industry consensus? I mean I I remain a fan of community notes

as almost a crowdsourced model where there's been kind of like you know reasoning by human expertise you know collated and now AI may introduce a version of that that is sort of like

against these you know global norms this this thing should not have been identified or flag if you think it should or shouldn't. So anyway, I I think it's it's it you you want to

embrace these new technologies to solve the problems as much as you want to use them to make your staff more effective and efficient. I I love the idea of pre-check. Um Ro, I know you work with a

lot of different uh companies, especially as they expand into international markets. Is there an emerging pre-check standard coming out there for everywhere they're going? They

still have to do everything manually. &gt;&gt; I think that I think that the idea of the standard and mindset is so important here. I couldn't amplify those points more. I think the past 5 to 10 years

showed us that companies in the age of content moderation went down at their own way, enforced in their own way. But that doesn't work in the age of AI. as you evaluate um models, as you evaluate

integrations and you really think about what is the impact that AI is having on users and on populations, the volume of workflows, the volume of um issues that are hitting teams, the complexity of

those issues, novel new use cases that need to be defined, understood, and then enforced at scale. It's so significant that we need more standards. We need more of an idea of really how do we work

as an industry to understand that idea of a pre-check? How do we have common standards for what is and isn't acceptable. In the past, we had things like we still have Nickmick. Nickmick is

a great example of the industry working together and really thinking about how do we prevent child harms. I think as novel and new issues emerge, companies really need to start to work together to

create shared understanding using things like community notes, community forums, which has been a really big project we've been pursuing with one of our platform clients to understand for niche

specific populations. How do they interact with their AI? What are the use cases that are emerging? and how do we really train the models to exist in those contexts so that we don't

overgeneralize but we can meet the needs of a specific population while still having a standard that we operate against. All right, I'm very optimistic about

this just generally at heart, but um given the complexities are increasing, the volumes continue to go up exponentially, especially AI generated content. I feel like these tools, you

know, we can use them to compound on each other, but you know, the title of our session here is operating models for for AI and safety. So, Sarah, I'd love to get your take. What does the

operating model of the future look like? What glimpse can you give us? I'll probably keep it very simple because um in this in I think in this context simple is very powerful. Um, I

think the way I see the future is it's going to be specialized teams that will be augmented by agents and they will absolutely need a lot of policy

and model eval handy and that the combination of those three is what the future looks like. &gt;&gt; Very interesting. Rohul, I'd love to get

your take on that as well because I know this is something you focus on quite a lot. &gt;&gt; Yeah, I think that in the future you're going to start to see this concept of

small mighty teams really start to emerge. You're going to start to see that really the reliance on large complex organizations to create safety to create um protections for users and

how they operate that'll start to evaporate. You'll start to see the role of Agentic play a larger and larger role in really driving operations enforcement guard rails for platforms and those

agents will then be augmented by the idea of these small mighty teams really specialists and niche skill sets that come in to operate the way in which the agent op the way in which the agent

delivers an outcome and the way in which you're ultimately affecting your operations and driving better model use, better model design and better user outcomes. Again, I think all of that's

amplified by the idea of better standards across the industry for what we do, how we do it, and then that idea that you can go deeper into niche populations, understand their needs, but

roll that back up to the enterprise and the way the larger product operates. &gt;&gt; Yeah, I agree. And I think you know going right along with the idea of you know getting transparency building

consensus across industry again to these standards you know we already have these benchmark evals that try to track performance so we can see whose model is better you know I I think that there's

an emerging need out here to also create these standards or rather these evals that can show hey look there may not be a perfectly right answer but you can find a current best answer uh and then

try to build consensus around that. Um but again Anishh I know that this is also a space that you've been working on and have a good perspective on. I think the flywheel that we're hearing from

Sarah and Rahul is you've got, you know, clearly an abundant world where AI agents can allow you to create these niche expertise teams. You can do your job better. That I love the simplicity

framework. But now let's close that loop. So let's assume we want to label AI generated content to make sure people understand what it is or it isn't. Door one, no standards. So Sarah's team has

to figure that out internally. And yes, she could deploy AI agents to try to reverse engineer whether or not something looks like it was AI generated. And that takes effort. And

let's assume there's a error rate tied to that effort. Now, let's imagine door number two. Uh, hi Deepa. Uh, door number two, let's ask the flip question. What if the

industry reached consensus on how to watermark AI generated content no matter where it was published? So the key creativity outlets, the publishing arms that generate uh AI generated content

agree to a watermark. Now you've reduced the complexity in the operating model because now you're flagging for something that's already been agreed upon by industry standard. And oh by the

way, if it turns out something fell through the cracks, and this is an important point I want to highlight, industry standards work when there's enforcability on the behavior.

And just to give you some context on the United States, if you promise your customers that you will give them a watermarked AI generated output and that is stated in your objectives as a

business, I will give you AI generated content and by the way I will meet the standard for watermarking. And it turns out that was used in an ad that SARS team never saw the watermark and it made

it through. Who's at fault? the publisher of the AI content that did not add the watermark when they committed to doing so would hold liability for effectively misleading their customers

that they were offering a service that didn't do it. So it starts to create you can create more in a fragmented very dynamic uh market economy. you can start to see pieces and parts come

together. And let's say in that same flywheel, the uh teams that Sarah has and the agents running figure out there's oh by the way, there's a new trend emerging.

There's this new audio thing that wasn't even envisioned in the watermark and we got to figure out a way to identify that that can be flagged as recommendations to get industry consensus for future uh

norms that then could be hardwired and then the loop closes. So you sort of have to have two operating models inside the enterprise which I think is exactly what Rahul and Sarv described and then

one that has dependencies on how external stakeholders engage that reduce the burden on the internal models and if you get do both of those right not easy then I think we get more of the good

from all of these investments and less of the bad. So, as you as you work with your clients, you know, they're they're reskilling. They're investing in whatever they need to from an IT

perspective, they're also building up their skills, but they need an entire new ecosystem of of vendors to work with. Have you what have you seen here? &gt;&gt; So, I think I think the ideas that we're

describing here, they're wonderful. This is like exactly the approach that the industry needs to move towards. The challenge is the models that exist today are so entrenched. Behaviors are so

entrenched. Silos exist. policy complexity exists shifting the org in that direction. This is a multi-year sometimes three fivey year journey for platforms and just come fortune 500s to

really think about how do we shift towards this AI first mindset. This is something that I can see just working with my own clients. This isn't something that'll happen this year or

next year. But that process is incredibly gradual. And so what we're starting to observe more and more is this shift from really how do we do work and that idea of small and mighty teams,

right? highly specialized niche skill sets augmented by AI. While that sounds wonderful today, that's a vision that's really going to take shape over two or three years. But we're starting to see

that shift towards higher volumes, more regulated markets, more complexity, more novel use cases emerging. You're having to see that we're shifting from generalized service providers who

enforce at scale to now a long tale of skill sets and suppliers coming into the mix. And these skill sets really augmenting now a novel set of harms that we don't really understand. There is no

industry consensus on really trying to understand what those mean and drive enforcement or operations or eval. But that shift again is it's a multi-year process to get to this point.

&gt;&gt; Oh, and a lot of stakeholders to engage there too to get all the details right. Again, Anish, I know that you've been uh have a lot of experience bringing everybody to the table, making sure they

all get a a fair piece of the pie. That's my first question is how do you how do you accomplish that practically and efficiently but then the second question I have for you is um as folks

try as companies try to do the right thing here sometimes they do need ex outside help you know I'm a consultant so I can say that um but you know what what benefit does that uh bring and more

importantly um what's the risk if they don't well I'd certainly defer to Sarah on the context of of how to get expertise in the right location to execute a plan I think that's a very

critical In a world with changing uh policies and objectives, you kind of need to have agile teams to support. I think that's a given. Uh leadership matters. And so let me let me draw this

scenario about transparency. I think Sarah you may have mentioned some of this and Rahul did on some of the reports. I'm a healthcare guy in the current state. So let's use that as an

example. Open AI has been transparent that people are basically uploading screenshots of their medical records into OpenAI and I think it's like doubledigit share of OpenAI queries are

very uh health related and people are willing to upload very sensitive protected health information. Now this is not CS SAM and harm. This is like my personal medical records and I'm people

are uploading them into chat GPT and sharing all of the benefits that they're getting from understanding and also Gemini respectful all the platforms. So here's the question

when this report is released about the reality that there's all of this activity. Now there's no government regulation globally that answers this question cleanly. uh is this a harmful

uh activity or not? I think intuitively you would say, gosh, I be you want the platforms to be careful not to make sure that that information is misused uh or have ads run against it. Sorry, back to

this. I I put up my health records and all of a sudden I've got ads running that describe my health condition. That may freak people out. So the leadership moment was in the United

States uh the president. Now when the president of any uh you know any party, President Obama, President Bush, President Trump, all three use their role to explicitly talk about the need

to get more health information into the hands of consumers and as President Obama said to allow them to connect it to the tools and services that can help them make sense of it.

&gt;&gt; It takes leadership to say I want to create a whole new uh framework. And so July of last year, I'm with Rahul. These things can take years because of the level complexity, but sometimes

leadership cuts that faster. You could fasttrack some of the years. So Trump basically said, I want healthcare uh to move uh at a fast pace, but I want you to bring responsibility and uh here's a

framework and I want your commitment that you're going to implement this framework. So he didn't wait for the industry to come up with a framework. Here's my framework published in July.

Within six months, ChatGpt for Health and Claude for Healthcare launched where they basically embodied all of the principles that were outlined by the government and shipped a product that

now creates a separate data store for your health records that almost looks like it's HIPPA protected without being HIPPA protected. Now, that was a policy change that the platforms adopted in

response to a leadership call to action on a consensus approach where they could iterate as to how they, you know, Claude took a little bit of a different answer than Chat GPT. And we're waiting for

Google. I think by April, we're going to see Google, Apple, and uh Microsoft and Samsung, you know, honor their commitments which were all publicly stated in July. So this notion of uh

pace of change and the need of address complexity, the elephant in the room is when there's leadership, &gt;&gt; you can almost fastass your way through some of these issues and just shift the

dynamics so that you can ship in days and weeks what otherwise would take months or years. &gt;&gt; Yeah. You know, in our discussion here, there's a word that I haven't yet heard,

but I think is really critical as we talk about governance and all the change that's happening and that's accountability. You know, um I'd love to get your take on this one, too. So what

roles do humans play to ensure this quality and accountability? Um what new models are you seeing as they actually try to do this because someone's got to someone's got to look at it.

Yeah, I think um I think humans their expertise and how we evolve that over a period of time will be paramount and over a period of time you would see the way humans are

in the loop, engage in the loop and are also um auditing it. They are not just executing but they're also directing it. Right? Um and more importantly they are reviewing this whole output

that I think is is critical and over a period of time we need to start doubling down on that that that human expertise and how [snorts] much and where do we bring humans in the loop uh and you know

tap on that expertise and you know it goes back to the conversation that we had earlier that domain knowledge is like a given. Business acument, domain knowledge, super critical. Overlay that

with tech skill sets, that's actually the package that's required. &gt;&gt; Yeah, Rohul, I know again you work with a bunch of clients across domains, too. I'd love to get your take on this. Uh

given that, you know, you can take some experience in one area and try to cross-pollinate or transplant it. Uh again, I'd love to know what you've seen.

&gt;&gt; Yeah. On on the idea of accountability and I think on the idea of leadership, there's there's two things that come to mind. I do think that leadership especially from the top and from from

our elected officials from regulators I think it's critical. I think setting a standard, setting a vision, it gives the industry a direction to move into. We saw this for example with DSA, right? Um

the European Commission announced this is a standard. This is how companies are expected to operate and we saw the platforms move in that direction. The version of implementation varied at

each. The quality of implementation as shown in transparency reports varied at each. And so while we can get the industry to start moving in a direction ultimately on the shareholder value side

driving excellence in the way in which that vision is ultimately executed with efficiency with quality that can take time but that comes once that vision exists and I think as industry consensus

starts to build on what that looks like. From my vantage point as as a strategy and operations consultant, I really think I have a preference for the operations teams and I really think

about the importance that operations teams play in creating accountability and quality. I think a lot of the buzz, a lot of the hype exists in policy and upstream very important sets the

foundation for what ultimately happens. But if operations teams really work well and are embedded in that mindset of the small mighty team, integrated back into policy and really thinking about what

are we observing, what are we learning from our users, what are we able to feed back to our policy, research, product team, so they can go and do external research and understand externally what

do our users need. That creates that accountability loop that drives better user outcomes and better performance for the platform. &gt;&gt; Very cool. I think that's again great

insight very very micro I'd love to get the macro perspective because Anish you've negotiated a lot of these big picture items here what was that like well when there's motivation to reach

consensus because you want to move forward people are willing to collaborate I remember uh at the end of the Biden administration there had been a initial regulation in electronic

health records to uh create more transparency and governance obligations when you imp implement AI in a physician's uh electronic health record, but it left

to the industry a lot of the specific details as to how they would go about it. And so sometimes like you not too cold, right? So you have a scenario where maybe in DSA would be another

example where you feel like you've got a very strict detail as to what you have to accomplish. It creates that variability that Rahul outlined that it may not be great. You want to have, you

know, consistency and high quality. Uh if you do nothing, then they don't move at all. So you don't get much. It's molasses. So the Goldilocks what we did as soon as the Bit the day the Biden

team uh finalized the regulation on the need to have transparency and governance in AI models that are running in a physician's electronic health record. That day, uh, I helped recruit about 25

health organizations, large health systems, and health plans who published essentially a commitments document that was essentially an enforceable code of conduct

&gt;&gt; to say what we're going to do is we're going to watermark, we're going to create um, so we're going to explain to doctors and consumers. uh as as a small example, if you emailed your doctor

today, there's a reasonable chance that the doctor's response to your message has been generated by AI and there was no industry consensus that you had to disclose that

&gt;&gt; because people said, "Oh, it's like spellch check. It's like a tool." I don't say this email was written with the help of spellch check. That maybe feels weird. But there was a sense that

uh in University of California, San Diego said, you know, in our experience, we ran it and we did an experiment and patients actually valued the disclosure that the message was partially automated

and reviewed by Dr. X. &gt;&gt; That was the watermark. &gt;&gt; And when they shared that with our working group, everybody said, "Hey, that's a good idea. We should agree to

do that." And so that became one of the commitments that was uh published at the same time. So look to Rahul's point when a leader does create a a direction and people move the second step is is there

a vehicle to get consensus on how to move effectively and efficiently. And that's what we did with the healthcare commitments.com project was to get consensus. And that has grown. I think

50 or so organizations have adopted it and and and uh the premise is yin and yang have to be in place and you want Sarah and her team as she was sharing as they get to this you know feedback loop

of simplicity that maybe they get they can interact with these stakeholder vehicles to say this isn't working on the ground this this is we're getting negative consumer feedback on the

watermark maybe we should think about that in a different way you you if you don't have that feedback loop you've oified uh the operations so anyway I think that's why it's possible uh when

when you have leadership to execute things that are not natural for people to do which is to come together in a competitive market to do something in a a collaborative way.

&gt;&gt; Okay. So we've got that top down mandate from the boss Rahul. You've designed a bunch of these operating models. What have you seen? What works? What doesn't work? And with all the experimentation

going on again I'd love to get your perspective on how quality is increasing and the and the pitfalls along the way. Yeah, happy to. You know, building on Anisha's idea, I love that, right? The

idea comes from the top. Someone sets the vision, the government, a regulator, whoever it is. I think one of the pitfalls that these types of governance models can run into is that after that,

you see kind of a middle tier of organizations trying to affect really what implementation looks like. I think after you know Anishh's point on set the vision start to set standards you really

need to see the industry leaders the CEOs the top executives being a layer of governance to continue to shape that mandate to hold their teams accountable so that when the middle starts working

on this actual execution and its implementation they're subject to what their leaders their CEOs their CXOs actually have in mind and those CXOs continue to sustain the momentum of of

uh of how that's actually affected I I think within organizations it again comes back to this idea that you create these closed loops. you have really well-defined processes not as not

opposed to the idea of being agile or nimble or aligned to the idea of agentic in this age of AI but this idea of structure in terms of like how do we really build what are we building and

you design the right mix of controls that don't create friction but create the right levels of accountability along the way so that as you're releasing models as you're building new systems as

you're building new tools um running operations you're actually able to feed meaningful insight back into your teams who then go execute an action items. I think the pitfall of a lot of

organizations with their governance is they run in these linear processes where there is no end or there is no outcome that's ultimately measured or delivered. Creating that continuous loop is in my

view what makes these governance models effective. &gt;&gt; Okay, so we've gotten the mandate from the boss, we've got our operating model, but we need to reskill our people again.

And Sara, I know that one of your passions is making sure that your team is very well supported and that they're well equipped for the future. Um, what do you what skills do you see as being

more valuable going forward? &gt;&gt; I think um I'll continue to double down on expertise, right? Because um I keep my teams true to that. So I'm going to continue sharing that. I think in

addition to to expertise, what is also required is sometimes being open to how the ecosystem is changing and adapting to that. And I feel um the more we do that the the the

transformations will be clearer and I think partnerships will be far more stronger. So I think the skill set will be have very good strong foundation of the domain that you're in.

&gt;&gt; Be very observant of how the ecosystem is changing to learn to learn be agile &gt;&gt; and then partner to to spread that that the best of the learnings that you've have had.

Anish, I'd love to get your perspective as well. You know, as you see all these skills uh or as people trying to experiment and and develop their own skill sets, you know, what advice, I

guess, would you give to everybody out there who's maybe a little AI anxious? Well, I mean scale the challenge is at the scale you can you can have the expertise in in given areas but when the

volumes just become so vast there is a societal question about how does one shift the labor market uh education supply to be more responsive to these needs. This has been a challenge in

education for many many many years and uh maybe there's a internal Google center of excellence that keeps the expertise you know humming uh maybe there's a you know an educational

ecosystem that's you know government uh or university funded that supports not just Google but others to kind of get that talent uh organized. This is one of the conundrums in the AI moment which is

that to some degree there's a perception that we're going to see significant job losses &gt;&gt; in in the again in healthcare radiology was supposed to be eliminated years ago

with AI &gt;&gt; and yet radiologist openings have exceeded more than in history. &gt;&gt; Yeah. &gt;&gt; So I don't know this concept of

expertise and scale when we bring in AI tools. Maybe there is a new uh equilibrium where we actually get far better output from the investments in human capital expertise that's

supplemented by the agentic uh workflows. Rahul, I think you highlighted that uh very nicely. Maybe there is a path forward that looks like on on on the margin we can have our cake

and eat it too. We can have the expertise at scale powered by some of these tools that support, but we still have aggregate labor participation in ways that just generate, you know,

double-digit economic growth. Maybe that's the equilibrium we're going to find uh as we, you know, wrap up this week's AI summit that we'll see hope and optimism uh exceed uh some of the

concerns others may have that uh this this circle doesn't square. So maybe we can square this circle and uh get the expertise that Sarah is describing powered by some of the agent plus human

interactions that Rahul described. So put these two together and make magic happen. &gt;&gt; I think um you know this is a good segue. I also think it's very important

for for us to recognize that switching contexts in this ever adapting and evolving AI tools the ability for anybody to understand and switch contexts in in the space that they're

working is also going to be very very important and critical. So uh and that that comes as a part of what we feel is an expertise. Speaking of switching contexts again,

Rahul, I know you work with a lot of different clients here. And again, I'm very optimistic now. Productivity, I think, is is the word that we're we're going for here. I'd love to get your

perspective on uh what you're seeing your teams produce. Are we seeing like a 2x fold in in how fast PowerPoints can be produced? No, I'm I'm kidding. But &gt;&gt; yeah. Yeah,

&gt;&gt; I wish. Um, no, I don't I don't know that we're seeing that yet. I think what we're seeing is I think we're seeing probably two things. I think we're seeing still a lot of hype and a lot of

anticipation around what AI is doing. And then I think you see the use of AI as a way to maybe game insights and game the delivery of something. My advice to what I

affectionately call the young people is think about how you really build context and judgment because value in your career, value for all of us will exist in context and judgment supplemented by

AI. And I think one of the key things for us to keep doing as leaders is to really keep training that next generation and for that generation to train the next generation on context and

judgment to really understand how is work delivered, how is a model built, how is financial analysis done, how is a research report written, what is meaningful insight and not just rely on

the AI to do that because we need to really be able to understand how to deploy AI and use it and treat it as an augmentation versus as a replacement for us in some dystopian universe where AI

serves AI in in the form of products and services. I I don't think we're going to get there. I think it's really how do we continue to generate context and judgment for ourselves.

&gt;&gt; Yeah. No, I'm I'm I'm relieved. I I don't want to be replaced by Grock. Uh but yeah, I I think we'll be all right. Um I see we only have a couple minutes left, but if there are any questions

from the audience, again, I want to make sure that there's time for folks to uh to ask any. But yeah, I see a couple of hands here if there microphones. Yeah.

I can hear you. Yeah. Why don't you come up if you can hear us? &gt;&gt; Yeah, thanks very much. Uh, excellent panel. Thanks for the discussion. Uh, this is really the a question really a

waterfall as it were. Um, maybe ending in a niche, right? Rahul just foot stomping on a lot of the things. I hear the there were standards a lot, right? And we're here at the we're in the

middle of the world's most populous country, largest democracy, right? It's open. And so open societies run and get to standards at a slower rate in general than more autocratic top down, right?

Because the risk of being top down and niche kind of touched on this is you can be efficient but you could be wrong and that's deletterious to the industry etc. How might we be able to develop these

standards? Right? And then there's also the issue of even in open societies like in the US you have an versus ISO versus IE E like my standards are better than yours yet. I was wondering to see what

that is maybe start with Sarala on what do you want as the ultimate user of a standard right and then Rahul what you see in the sector and Anishh how can we get there because you've had that

leadership role. Thank you. you know, in the in the work that that we do on a day-to-day basis, what we look at is um what's the ecosystem like? How is it

evolving? How are the needs and customers from both customers and users evolving and therefore working backwards? Because at the end of the day, it's that experience

that matters, right? Um, and I I want to I I don't think there is ever going to be a right answer for this except to say that it's going to be a journey and and we pretty much have started on that

journey. &gt;&gt; I think from an industry standpoint, I think it comes down to humility. um on the part of uh corporate actors on the part of individuals or corporations and

just across the board I think that in the past platforms have moved so fast to own their space to build products they've also kept information insights and approaches in a silo I think with

humility and the recognition of the increase in volumes the complexity of work that's headed our way the risks that AI pose that need to be addressed that humility to think that how do we

really work across the board how do we share share information. How do we start to bridge the gap of what we understand is good and harm good good for users and harmful to users and be willing to share

that across platforms? That humility is what's needed here. And just so we get to the next question, I will say uh some standards look like Moses tablets and they're dictated from the top. Um I

believe in lowercase s uh standards that are really enforceable codes of conduct. And so you if you have a convenor that has a leadership role to bring people together, they don't really care what

noun is involved. They get towards a verb and they can reach consensus. And so that's where you need industry collaboration and that is best done I think public private partnership that's

the US model but it can also be done just through industry consensus if there's enough leadership. &gt;&gt; Yeah. uh so uh I want to ask uh India being with the supply of biggest data

sets maybe with 1.43 43 million population. So uh what are the policy decisions you would like to suggest when agenta comes into place more in usage in India? Uh yeah

&gt;&gt; was that directed to any one panelist? &gt;&gt; All the above. &gt;&gt; All the above. What policy sets would you recommend to what was the second bid &gt;&gt; in India? Basically at scale right?

Yeah. &gt;&gt; So, uh I think you know even with the scale that we're describing there is an opportunity to create uh you know more consensus and just a part of the

discussion later today uh Anna is joining me this afternoon. India has embraced the same uh industry consensus standards for moving health records over the internet.

&gt;&gt; And so you have the US, India, many parts of Europe have embraced this uh fire API standard as a mechanism. So even the country is vast and diverse in terms of India's population and

technical readiness. Okay, Sarah, that means to you, you get the last word. But anyway, that's how I see it. &gt;&gt; I think very well said. I think both of us will say a plus one to

&gt;&gt; Yeah. Thank you. &gt;&gt; very good. Uh thank you all for joining us. &gt;&gt; Knockout blow if we just knock out the panel with the the ring.

&gt;&gt; Thank you for moderating. &gt;&gt; No, I appreciate it. Noah, thank you also to our wonderful hosts at the AI India Summit. It's been a pleasure.
