# Governing Safe and Responsible AI within Digital Public Infrastructure

**India AI Impact Summit 2026 ‚Äî Day 3 (2026-02-18)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 6 |
| üìÖ **Date** | 2026-02-18 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/Uxcxu5xIurg?feature=share) |

## üé§ Speakers

- Alexandria Walden, Google
- H E Alar Karis, Republic of Estonia
- H E Harry Verweij, Ministry of Foreign Affairs, The Kingdom of the Netherlands
- H.E. Bernard Maissen, Head of the Federal Office for Communications, Switzerland
- H.E. Taurimas Valys, Lithuania
- Juan Carlos Lara, Derechos Digitales
- Norman Schulz, Federal Foreign Office, Germany
- Sabhanaz Rashid Diya, Tech Global Institute, India
- Zach Lampell, ICNL FOC‚ÄìTFAIR

## ü§ù Knowledge Partners

- Freedom Online Coalition - Task Force on Artificial Intelligence and Human Rights

## üìù Summary

This session will explore safe and responsible AI in Digital Public Infrastructure (DPI), with a focus on algorithmic transparency, human-centred governance, regulatory best practices, and inclusion, including perspectives from the Global South. Distinguished speakers from government, civil society, and industry will offer brief remarks, followed by a moderated discussion and audience Q&A.

## üîë Key Takeaways

1. This session will explore safe and responsible AI in Digital Public Infrastructure (DPI), with a focus on algorithmic transparency, human-centred governance, regulatory best practices, and inclusion, including perspectives from the Global South.
2. Distinguished speakers from government, civil society, and industry will offer brief remarks, followed by a moderated discussion and audience Q&A.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/Uxcxu5xIurg/maxresdefault.jpg)](https://youtube.com/live/Uxcxu5xIurg?feature=share)

---

_[‚Üê Back to Day 3 Sessions](../README.md)_


## üìù Transcript

Good morning your excellencies, ladies and gentlemen. Welcome to this session governing safe and responsible AI public infrastructure. My name is Zach Lampel. I'm senior legal adviser and

coordinator of rights programming national assembly and expression and the right to privacy offlined and online. Over the next 55 minutes, we will explore how AI

can be deployed in public sector systems safely, responsibly, and inclusively. This includes algorithmic transparency, human- centered governance, regulatory best practices, and lessons from the

global south. This session is convened with the support of the Freedom Online Coalition, a partnership of 41 governments committed to protecting and ensuring that the rights people enjoy

offline, like the freedom of expression, the freedom of association, and the right to privacy, are upheld in digital spaces. The coalition advances internet freedoms

through multistakeholder engagement, diplomatic coordination, and policy advocacy. Within the Freedom Online Coalition, the task force of AI and human rights brings

together states, civil society, academics, and industry to promote rights respecting AI. The task force coordinates knowledge sharing and develops policy guidance

across all regions of the world. It is truly an honor today to be joined by a full set of distinguished diverse speakers. We'll first hear brief introductory

remarks from our distinguished high-level speakers followed by a panel and ending or concluding with an audience question and answer session. It is my great pleasure and honor to

welcome his excellency Allah Carus, president of the Republic of Estonia. President Carus is a molecular geneticist and developmental biologist, former director of the University of

Tartu, and an internationally recognized academic leader who has guided Estonia's innovation and digital governance initiatives. Mr. President, excellencies, prime ministers,

distinguished colleagues from government, civil society, academia and the private sectors. Ladies and gentlemen, it is a great pleasure to join you today in India, a country whose

ambition and leadership in digital public infrastructure are shaping global conversations about the future of technology, governance and inclusion. I would like to thank our hosts and the

organizers of the India AI impact summit for bringing together such a diverse and thoughtful group of participants at a moment when decisions about artificial intelligence are rapidly becoming

decisions about democracy itself. The focus of this session governing safe and responsible AI within digital public infrastructure is a question many of our societies are grappling with with how to

ensure that the increasing use of AI in public systems strengthens trust rather than undermining it. Digital public infrastructure is no longer simply a technical backbone for service delivery.

It is a foundation of which modern states operate. When AI systems are embedded into these infrastructures, whether in education, health care, social services, justice, or public

administration, they shape how decisions are made, how resources are allocated, and how rights are exercised. This creates enormous opportunities to

improve efficiency, accessibility, and responsiveness. But it also introduces new risks. When algorithms are opac, when accountability is unclear, or when systems are designed without meaningful

human oversight, public trust can erode quickly. For this reason, algorithmic transparency and responsible governance are not optional additions to digital

public infrastructure. They are essential conditions for its legitimacy. Estonia's own experience as a highly digitalized society has taught us that technology alone does not create trust.

Trust is built through choices. Choices about design, governance, and values. From the very beginning of our digital transformation, we made a deliberate decision that technology must serve

people, not the other way around. Today nearly all public services in Estonia available digitally and artificial intelligence is increasingly used to support decision making and

improve public services. Yet we remain clear that AI must complement human judgment not replace it. Public authorities must be able to explain how decisions are made. system

must be able to question outcomes and safeguards must exist to prevent bias, discrimination or unintended harm. One area where this approach is particularly visible is education.

Estonia has long invested in digital education and today AI literacy is becoming a core part of our educational system. We are introducing AI supported tools in schools by ensuring

transparency, data protection and pedagogical oversight. Students have thought not only how to use AI but how to understand it, how algorithm work, where their limits lie

and why critical thinking remains essential. We believe that societies that understand AI are far better equipped to govern it responsibility responsibly.

This commitment to human- centered and right respected digital governance was also central to Estonia's role as chair of a freedom online coalition in 2025. The coalition brings together 42

governments alongside civil society and the private sector to advance human rights online. During Estonia's chairship, we placed a strong focus on digital public

infrastructure recognizing that DPI is where digital rights are increasingly realized in practice. Under Estonia's leadership, the Freedom Online Coalition has developed principles for rights

respecting digital public infrastructure grounded firmly in international human rights law. These principles emphasize transparency and explanability of digital and AIdriven systems.

Accountability through the life cycle, inclusive design that works for all communities, strong protection for privacy and freedom of expression and meaningful participation by civil

society and effective communities. These are not abstract ideals. They are practical guideposts for policy makers, regulators, and system designers alike. What matters just as much as rules or

technologies is how AI is introduced into public systems and how it is experienced by people in their daily lives. In many parts of the world, digital public infrastructure is

expanding rapidly and often at significant scale. When systems grow quickly, trust becomes the most valuable, but also the most fragile resource.

Experience shows that trust is not built through perfection, but truly clarity, responsiveness, and the ability to correct cause. People need to know when AI is is being used, what is purpose and

where responsibility ultimately lies. When governments are open about these choices and when systems allow for explanation and readiness, confidence in public institution can grow even in

complex or resource constrained environments. Responsible AI governance must be collaborative by design. Governments, civil society, academia, and the private sector each see

different risks and different possibilities. Bringing these perspective together is not a luxury. It is a practical necessity.

What makes today's discussion especially important is the diversity of perspectives represented here. Countries in Asia, Africa, and Latin America are demonstrating new models of inclusion,

resilience, and service delivery under complex conditions. These experiences must be represented in global AI governance debates. Estonia is honored to co-f facilitate

with El Salvador. The general assembly established the global dialogue on AI governance. A dialogue that provides an inclusive multistakeholder platform for governments, industry, academia, and

civil society jointly shape the future of AI governance by bridging regions and development levels. The dialogue helps contribute that global AI rules promote innovation

and growth while remaining anchored in human rights, trust, and shared responsibility. Estonia believes that digital public infrastructure can be both innovative

and rights respecting, both efficient and democratic. Achieving requires cooperation across borders and sectors and a shared commitment to keeping people at the

center of our digital futures. I look forward to continuing this important work together. Thank you very much for your Thank you, Mr. President, for those

insightful opening remarks. Next, we are pleased to welcome his excellency Bernard Mesen, state secretary and director of the Federal Office of Communications, Ofcom, in

Switzerland, and current chair of the Freedom Online Coalition in 2026. He brings extensive experience in communications regulation, media policy, and advancing human rights based

approaches in digital governance. Your excellency Excellences, distinguished colleagues, ladies and gentlemen,

thank you for the opportunity to speak on a topic at the intersection of digital transformation and the protection of human rights. Digital public infrastructure such as

digital identities, public services, platforms, data systems, and AI enabled public decision support tools has become central to how states deliver services and interact with citizens. Its

governance must reflect the highest standards of human rights, accountability, inclusivity, and transparency. This is why the freedom online coalition

adopted the rights respecting digital public infrastructure principles to ensure DPI promotes public trust and protects fundamental rights that Switzerland fully supports.

These principles underscore that technology must serve people not the other way around. DPIs should be developed through processes that are human- centered, participatory, and

responsive to the needs of all communities, including marginalized and vulnerable groups. They must uphold privacy, non-discrimination, and equal access.

For AI systems embedded in DPIs, these principles translate into three core imperatives. First, anchored and international human rights law. DPI systems that rely on AI

must be built on clear legal basis with defined purposes, robust data governance, and meaningful safeguards against bias and abuse. Human rights impact assessment should not be optional

or exposed. They should be an integral part of public sector AI procurement and deployment. Second, accountability and oversight. Public authorities remain responsible

for decisions taken or supported by AI even when systems are developed or operated by private actors. This requires transparency standards, auditability, independent oversight

mechanisms and accessible avenues for redress. Without accountability, trust in digital public infrastructure cannot be sustained. Third, international cooperation and

capacity building. Many countries are developing digital public infrastructure under significant resource constraints and uh with increasing reliance on external vendors.

International cooperation is essential to promote interoperability st standards and good practices and avoid a global fragmentation of safeguards. In this respect, initiatives such as the

AI summit hosted in India demonstrate the value of convening inclusive global south focused discussions on AI governance by centering development needs, public interest use cases and

right suspecting approaches to digital public infrastructure. Such forums help bring the global conversation to context where DPI is being deployed at scale and where safeguards are most urgently need.

In Switzerland's view, safe and responsible AI governance within DPI requires multistakeholder engagement, sustained civil society participation, robust legal frameworks and

international cooperation. Only by aligning AI and DPI governance with human rights principles can we ensure that digital public infrastructures support dignity, equity,

and democratic accountability. Switzerland remains committed to advancing these aims within the Freedom Online Coalition and across international fora. Thank you very much.

Thank you, your excellency, for those interesting perspectives. From Lithuania, it is my pleasure to welcome his excellency Taras Balis, Vice Minister of Foreign Affairs. He oversees

economic diplomacy, trade policy, and international cooperation in digital technologies. and he also serves as the governor on the board of governors of the international atomic energy agency.

He brings deep experience linking technology, economic policy and international collaboration. Vice Master, [clears throat]

your excellences, ladies and gentlemen, uh, thank you for Freedom Online Coalition for its continued leadership in promoting an open, secure, and humanentric digital future.

Lithuania is honored to contribute to today's discussion on governing safe and responsible AI with a digital public infrastructure. Lithuania's experience shows that responsible AI begins with a

strong public sector foundations. Over the past two decades, we have built one of the most advanced systems of inter interoperaiable uh state registers in our region from

population and property to business and address registers. These trusted data systems together with our e health platform eax administration qualified e signature used is used by

more than 90% of adults and our e- residency program from the back from uh form the backbone of our digital state. They ensure efficient transparent public services and provide a solid foundation

for AIdriven innovation. Secondly, trust digital resilience and cyber security are essential. As an as an EU frontier state facing persistent hybrid threats, Lithuania has

made cyber security a strategic priority. Our national cyber security center leads the threat monitoring incident response and public awareness. We enforce mandatory cyber hygiene

across hug government, protect critical infrastructure and run regular national exercises. Our hybrid state cloud further enhances security and interoperability.

Lithuania ranks among the EU leaders in cyber security capacity and digital public service maturity. And because digital transformation must include everyone, we invest in digital skills

for seniors, rural communities and v vulnerable groups, ensuring that AI empowers rather than excludes. Thirdly, AI in digital public infrastructure must never be become a tool for surveillance

or discrimination. Our approach is grounded in human rights, democratic values, and international cooperation. We firmly believe that technology must serve people, not the other way around.

Lithuania proudly promotes villainous convention, the world's first legally binding threat on AI adopted by this council of Europe. It sets baseline global standards to protect human

rights, democracy and rules and rule of law in the AIA era. We encourage partners to join and advance this milestone effort. Domestically, we're esta establishing the a the lit AI

center, a national hub that will unite computer capacity, high quality public sector data and interdisciplinary ex experience. Its mission is to is to drive secure, responsible and human-

centered AI innovation across public administration, health security and green transformation. But but no country can do this alone. Safe AI in digital public infrastructure

requirements shared responsibility. Lithuania continue working within the EU within within the OECD UNESCO the freedom online coalition and partners worldwide to strengthen transparency

accountability and rights based governance. Dear colleagues, go governing AI in digital public infrastructure is not only the technological task. It is institutional

and ethical one. It demands clear standards, resilient systems and shield values right by design, resilience by architecture and inclusion by policy. Lithuania stands ready to advance an

open, secure, interoperable and human- centered digital future together with all of you. Thank you. &gt;&gt; Thank you, Mr. Minister, for those remarks. And finally, we are honored to

welcome his excellency Harry Boise, ambassador at large for artificial intelligence and the special envoy on AI for the Kingdom of the Netherlands. A seasoned diplomat, he has decades of

experience in international law, multilateral diplomacy, and advancing human rights based governance in emerging technologies. Mr. Ambassador, &gt;&gt; your excellencies, their colleagues,

their partners, it's a great honor to join this um coalition composition along distinguished leaders from Estonia, Switzerland, Lithuania, and so many committed partners from government,

civil society, and industry. As we discuss safe and responsible AI in digital public infrastructure, we're reminded that this is not merely a technical debate. It is a debate about

public trust, about democ democratic legitimacy, and ultimately about the relationship between governments and the people they serve. In the Netherlands, this understanding

shapes our national approach. We're clear on one point. AI must strengthen public values and not erode them. That means human rights, transparency, accountability, and inclusion are not

optional add-ons. They are foundational design principles. And we see digital public infrastructure more than systems and code. We see it as social contract technology.

infrastructure that must be transparent, contestable and governed in the public interest. This vision of social contract technology also means that governance

cannot be left to governments alone. It must be accepted by society. We need a genuine multistakeholder approach involving civil society, the private sector, techno communities, academia and

affected communities from design to Only by bringing these perspectives together can we anticipate risks, embed public values in practice, and build the trust and legitimacy that digital public

infrastructure requires. The Netherlands used this approach in setting up several DPIs, including our COVID response app. at the time. Algorithms used in public

services must be explainable, auditable, and always embedded in human Efficiency can never come at the cost of dignity and fairness. But we're also realistic.

No country, not even the most technologically advanced, can shape the future of AI governance alone. Earlier this year in Davos, Prime Minister Marani spoke about the

collective strength of middle powers in a fragmented global order. His message resonates clearly in the AI domain. When countries that share democratic values and commitment to public interest act

together, they amplify influence and their ability to set norms rather than simply adapt them to them. such as through the Council of Europe's Framework Convention on AI, Democracy,

Human Rights, and the role of law. This insight matters deeply for digital public infrastructure and for our cooperation with partners in the global south. Many countries,

many countries that are already leading through modular, inclusive, and resilient DPI systems built for real society needs. The Netherlands does not see the global south as a testing

ground, but as a source of innovation, a source of governance, and a source of leadership. We are glering with grappling with these policy challenges just as you are.

Indeed, as countries all across the world are, we continuously develop and refine our policies and programs, learn from the experiences of others, and actively share our own practices in the

spirit of mutual progress. And this requires coordination between national and international efforts. Our national algorithm register now includes public information on some 1350 AI systems and

algorithms submitted by over 320 public authorities uh from all levels of administration and providing transparency for citizens and businesses on how the system intersect with their

rights. And at the same time, we're committed to international cooperation that focuses on algorithmic transparency and accountability from design to

Inclusive human- centered government that leaves no one behind, fair procurement and regulatory practices that reward trustworthy AI and capacity building partnership that strengthen

local agency and ownership. Our mission is clear. To help build interoperable frameworks, shared standards, and durable partnership that allow all countries, large and small, to harness

AI for the public good. By acting together with clarity, shared values, and mutual accountability, we can ensure that AI and digital public infrastructure truly serve our

societies. Thank you. Thank you distinguished guests for your incredible opening remarks and for setting the stage for all of us today. I think a central theme we heard from

these four champions of multistakeholder and multilateral efforts to support rights respecting artificial intelligence is that technology should serve humanity and not the other way

around. With that, I would like to open up our panel discussion and introduce our four panelists. Um, Pratik Wagger is head of programs and partnerships at the Tech

Global Institute. Juan Carlos Lara is the executive director of Do's Digital. Mr. Norman Schultz is the deputy head of unit coordination staff for AI and digital technologies in the foreign

policy office at the Federal Foreign Office of Germany. And finally, Alex Walden, global head of human rights for Google. Thank you everyone for joining us today.

Um, and thank you all in the audience for being here as well. Uh, we'll start with uh, Prateique. What mechanisms exist to review decisions made by AI and public services

and how effective are they? Uh thanks thanks Zach. uh and you know I think um probably going to build off on some of the remarks that uh distinguished speakers uh made made

earlier today uh and make the point that uh a lot of these conversations you even though the title today is you know within AI I think we also some sometime need to uh need to take a step back and

sometimes the the process of of of accountability etc begins even before uh the you know the the deployment phase and then how you sort of go on to through through the life cycle

of it, right? And so there are a couple of basics in there that we've also seen uh from you know uh the experience around the world which is you know uh the first thing is that you have we have

to be sure whether we're actually addressing a problem or are we papering over cracks when we're uh when we're thinking about an an intervention this way. Um and also looking at the the

local context and the regional context in terms of how a particular country is functioning uh what you know uh and this is very very Gran's work first law right that technology is neither good nor bad

it's neutral uh sorry is is not it neutral uh because it takes on the shape of the system uh in in which it's deployed and so so if you have historical patterns of of discrimination

if you have limited state capacity if you have various form of power asymmetries uh regulatory capture and you know and and and political economy issues. Uh that's something to sort of

uh to sort of keep in mind, right? And then from there you go on to do you have the regulatory frameworks in place? Do you have data protection uh you know data protection functional data

protection regimes uh in in place? Do you have right to what form of right to redressal and what type of right protection do you have from being subject to automated decision-m uh and

you know and uh and and those sort of things and uh in in in terms of uh then being able to uh you know you go into the question of before deployment do you do you want uh do you mandate impact

assessments and uh and algorithmic impact assessments and and and that and once uh this is deployed uh what sort of checks and balances you have when uh someone is at the receiving end of uh of

a you know of of a bad quality decision or a poor decision right what how how do your grievance redressal mechanisms work because that becomes very important uh you know some sometimes you we've had

we've had for example here instances where uh people who are you know receiving uh welfare assistance from the government have been labeled dead right and there was they were then caught in

this bureaucratic nightmare or bureaucratic loop to declare themselves alive. Uh and this 100-year-old gentleman actually had to take out a wedding procession uh to prove to the

local administration that uh that that he was alive, right? Uh and so so you you need to also make sure that you have these uh uh you know grievance address mechanisms uh functional uh because you

know mistakes are going to be made in in these sort of systems. they are deterministic. They're nondeterministic. Uh so what happens when something goes wrong? Uh and that you know again ties

back to the point of the existing uh existing context uh as well right and you need to have I think there's a point about procurement made earlier. Uh you also need to make sure that uh you know

the procurement process follows follows due process rather than sometimes where you have people just coming together and volunteering and building up a system. uh which which may function well in some

some cases and and that's fine but in terms of uh you know long-term durable sustainable processes that are that aren't fragile uh you need to have those uh those processes uh built in and you

know that there are other things that that people could explore with things like uh participatory design and making sure that the community is involved in the design process and civil society is

involved in in the in the design process and in terms of even actually redteameing in some cases, right, where you're trying to identify the edge cases and

the and the boundary conditions before you actually roll it out at uh at at population scale. Uh so and and you know and so you have those sort of systems that that uh that we could think about.

&gt;&gt; Thank you. Thank you, Prate. Um in the interest of time, I think um we had initially designed two questions for everyone. We want to make sure we have some time for Q&amp;A. So we may just uh do

one question for each of the panelists. Um JC, over to you. What lessons from the global south can inform AI deployment in DPIs elsewhere? &gt;&gt; Thank you. Uh good morning everyone. I

am Jara from the Reosales. We're a non-governmental organization working at the intersection of human rights and digital technologies in all of Latin America. And as part of that work, we

have been working on these issues mostly through one of our programs that is called AI and inclusion by which we have been studying in several countries in the Latin American region uh what the

deployments of algorithmic systems have been by governments by uh public authorities and that has been a very uh a a very uh good opportunity for us to learn how things are being done but also

the kinds of things that uh we highlight as the common ground between high level principles and international standards as well as what happens within the Latin American region. And I think uh to the

question you're you're you're proposing Zach about the lessons I think there are some things that are particular to the Latin American region whilst others are very much common to the rest of the

world and we may be in a situation in which uh the states in which uh we find ourselves as global south economies as global south societies with regards to high level principles might differ.

However, we still have some common challenges and I wish to highlight here the something that was also mentioned during the high level presentations which is the the right uh respecting

principles uh for DPI from the freedom online coalition. Um so one of the lessons that we have from the work that we have conducted in Latin America has to do with transparency frameworks that

uh we might see as focus on algorithms uh but that might be insufficient if they do not extend to the data infrastructure on which algorithms depend and in many cases there is a

normative infrastructure of public transparency that can be leveraged towards that kind of information being accessed. However, in uh the enforcements of that type of regulation

is paramount. Uh another thing that we have found that can be useful throughout the world as well has to do with auditability and the level of engagement of civil society of

academia of non-governmental experts in their process of formulation and deployment but also before that in the decision making uh part of the deployment of uh digital public

infrastructure. Which is to say what we have found is that there are many instances of exclusion of certain groups throughout the deployment of technical capacities. However, the points at which

that exclusion happens is not necessarily within the algorithmic systems, but rather before in political decisions and the lack of involvement of affected communities or potentially

affected communities or in general of the public in how systems are designed has more to do with the politics behind how a system is implemented and for what and what is the reason behind the

deployment of public resources than just the algorithm itself. And finally on accountability and I think this is one of the lessons that uh we have to learn by ourselves in the Latin American

region. In Latin America we share a a um human rights system the interamerican human rights systems which has obligations for states which has mandatory uh aspects for states that are

being developed by jurist prudence. However, to the point to which uh each country has managed to implement those things into their legislation for access to information for equality of in the

provision of services for economic, social, cultural rights or for uh in general for the respect of fundamental rights such as the the right to privacy is something that is continuously uh

demanded from state by organizations like mine and I think that is something that is common throughout the world. But those standards are rising and therefore their implementation to DPI is a big

part of the challenge that we have today. The principles from the FOC are useful in that sense and operationalization is a is the challenge that we have now. Thank you.

&gt;&gt; Thank you JC. Um Alex, I may turn to you to you next. I'm going a little bit out of order but um yeah, sorry about that. Um, I think we've heard a lot um about moving quickly and innovating um but

also questions we have about how quickly um that innovation happens and what that does to safety and and trust. So the question for you is how are you at Google and and how should others be

thinking about balancing innovation with safety, accountability and public trust regarding DPI? &gt;&gt; Sure. Uh thanks for the question. I think so the way we think about it at

Google is really from the highest level we talk about being in in our responsible AI work and our work uh developing and deploying AI. We talk about being bold and responsible

together. So bold in our innovations that we will seek to launch things quickly. um responsible and that we will be doing that in a manner that is responsible both the development and

deployment um and the ongoing monitoring of the services that we launch and then together because it's important for us to continue to engage with government alongside civil society, academia,

researchers, etc. to make sure that people understand what the technology is and that we are getting appropriate feedback and continuing to iterate. So that's how we think about it from a big

picture. Um I think you know an a really important piece of that work for us is transparency and so that's transparency in terms of governance ensuring that we have um a a robust approach to

governance and that we are being transparent about that we produce an annual responsible AI report that talks about all of the ways in which we do that across the company. Um and that's

also transparency to the people and consumers who are using our products. And so um that means that in the products when you're using it, it's important for us to think about what

cues someone might need. Um for example, in Gemini, we're very clear that there Gemini might have errors or hallucinations and we do things like put the link to um in the response to a

Gemini prompt, we put links to the underlying information where that came from so that someone can check on it. And so that's ways we're thinking about being transparent in a product for

users. Um and the other piece and so like that's something that government should reflect in the way that they're thinking about being responsible when they're um procuring and using and

deploying AI as well. And then last, I think a huge opportunity where there's opportunity for collaboration between private sector, civil society, communities and government is around AI

literacy and making sure that the public who can and should use this technology and that can and will benefit from it understand how it's working uh how it's working for them and ways that they need

to be also informing accountability where it might go wrong and where they need to address risks. &gt;&gt; Thank you, Alex. That's that's great to hear. And uh Norman, final question.

Since you are the the sole government representative, we're curious as to how multilateral coordination, including groups like the Freedom Online Coalition and the frameworks that the FOC has, how

can that strengthen safe and responsible AI governance? &gt;&gt; Oh, that's a big question. C can I have another another hour to talk about that? &gt;&gt; Uh, sure. The organizers [laughter] over

in the back. &gt;&gt; Okay. Okay. Sorry. I I'll try to to be very brief and concise. Uh no, I I mean uh we have heard already from our distinguished speakers how

multilateralism uh can help um um uh provide for for safeguards so that governments are using AI uh in in a responsible way. Um I I would I would just like to draw your

attention not only to the 2025 guidelines on digital public infrastructure that h has already been mentioned by by the distinguished speakers uh but also to uh one year

before the FOC has also worked on uh what's this exactly called um a joint statement on responsible government practices for AI technologies and the um the joy and and The the the good thing

about this statement is that the US if I remember correctly was that was the lead um uh drafter of this statement and uh I found this on in the archives of the DOS. So I have a feeling that they are

still bound by this uh and if not I will remind them &gt;&gt; obviously uh but well this leads to to your question. It is sad that the US has decided to leave the freedom online

coalition because the freedom freedom online coalition is a is let's say a safe space for for like-minded governments to talk about how do we bring our principles our values into

this new uh modern uh world of technology. So I would say we are like-minded, we are partners, we are sort of friends uh and where we can uh discuss freely on how do we bring that

about. It is also a marketplace of um how do we do things effectively uh if we want to enforce principles like or or these uh requirements like an impact assessment before we procure uh um AI

technology? Uh, are there any good examples or also bad examples? We we learn much more from bad examples. It's it's it's a a pity that the uh ambassador from the Netherlands has left

us. I'm sure he has more important things to attend to at the moment. But uh they had this uh um tolah. It was a um it was a uh maybe not AI but a digital system that uh automatically

would uh uh search for people uh who are not trustworthy who uh and and then you you have to uh the the government uh asked back for money that they gave them as a as a subsidy for for having and

raising children. a good thing altogether but uh taking it back uh created a lot of uh social upheaval in in the Netherlands. Uh they have done this quite well. They have uh um

effectively solved this problem. But this is one example. Uh and if we have this kind of multilateral um um uh yeah platforms and communities where we can exchange uh those types of examples.

That is the perfect way to uh to learn and to make uh uh to make public services better for the people and ensure that uh we uh uh that we have all the values or the all the human rights

uh uh that we want to pro uh promote and uh project uh included and secured. Maybe that's a short way. &gt;&gt; Yes. Thank you. Thank you. Yes, we could definitely talk about this for for much

longer. I think we have time for one maybe two questions from the audience. So if anybody has a question, could you please raise your hand? Uh should the gentleman uh here in the second row

please uh here here in the second row please and um please just be concise. So as we're running out of time thank you. &gt;&gt; Um yes hi good uh good morning and uh thank you so much for all your lovely

remarks. Uh my name is Sanhit. I work on questions related to technology governance and institutional readiness. Um and one theme that I've been seeing for the past two days now come up a lot

is um explanability um auditability and also now um this nature of wanting to have your these AI models be auditable and I imagine it's easier said than done because if it were

so easy to be done then we would not be discussing it so much. So since the panel has someone from Google and also people from the government, I wanted to understand what the actual challenges

are from both a policy level and from a technology level. Why like why is this not being able to um why are we not able to execute these models which can be actually explainable easily auditable

contestable so on and so forth. So yeah that's question. Thank you. &gt;&gt; Thank you. That's a great question. I think Alex do you want to give a quick stab at it?

&gt;&gt; A quick stab. So I mean I think and we spent a lot of time yesterday across um a multistakeholder conversation talking about in particular explanability. I think that is certainly something that

we've been committed to since the beginning. But obviously and as we see here at this conference there are varying levels of technical expertise and different ways people are engaging

with the technology. So it's um I think there is generally an understanding across all stakeholder groups including private sector that we want explanability. We want to deliver that

to everyone including our users. But sort of getting to the point where anyone who's using our product understands what it is, how it's developed and how they might be

encountering an error or not um is less simple. Certainly that's true when you get when you're a deployer also um and you are less close to the technology and you're dealing with a broader user base

um and those people are citizens seeking um public benefits. So there it's just complicated. I think there is general agreement though that that is what we're aiming towards.

&gt;&gt; Thanks Alex and thank you again. It's a great question. I'm sorry we're we are out of time but I'd be happy to um speak to you after the the panel. Um I think it's a great point and Norman, thank you

for mentioning the DPI principles that the Freedom Online Coalition published in December of 2025. Earlier in 2025, the Freedom Online Coalition also published a joint statement on AI and

human rights. Those two documents combined bind member states of the Freedom Online Coalition to create legal and regulatory frameworks that specifically allow for

auditing of DPI systems as well um as well as a right to remedy for automatic decision-making. So we look forward to continuing to work with all of you as well as the governments from

the Freedom Online Coalition to making sure that digital public infrastructure utilizes AI in a safe and responsible manner. Thank you so much to all of the panelists today.
