# Making AI for everyone: The case for personal, local, multilingual AI

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:30 ‚Äì 16:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 7 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/77AfVm96BgA?feature=share) |

## üé§ Speakers

- Andrew Tergis, Current AI
- Anne Bouverot, Government of France
- Ayah Bdeir, Current AI
- Martin Tisn√©, Current AI
- Shailendra Pal Singh, Bhashini
- Shri. Abhishek Singh, Meity, GoI
- Shri. Amitabh Nag, Bhashini
- Sushant Kumar, Kalpa Impact

## ü§ù Knowledge Partners

- Current AI

## üìù Summary

This session will look at a collaborative build, i.e. a local AI device platform that empowers communities to create their own AI tools, in their own language, for their own needs, with complete privacy and control; and a video projection of the build in use. It will also include a fireside chat between AI leaders, and a high-level dialogue between senior delegation of French and Indian officials. Jointly these interventions will explore a multilingual, public-interest AI ecosystem.

## üîë Key Takeaways

1. This session will look at a collaborative build, i.e.
2. a local AI device platform that empowers communities to create their own AI tools, in their own language, for their own needs, with complete privacy and control; and a video projection of the build in use.
3. It will also include a fireside chat between AI leaders, and a high-level dialogue between senior delegation of French and Indian officials.
4. Jointly these interventions will explore a multilingual, public-interest AI ecosystem.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/77AfVm96BgA/maxresdefault.jpg)](https://youtube.com/live/77AfVm96BgA?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Well, and therefore, how do we develop and support a paradigm that can make AI work for everyone? And that's what we are here today. The session today is very

aptly called the case for personal local and multilingual AI through a collaboration between Bhashini and current AI orchestrated by Kalpa impact. We are proud to present to you

today a seinal open-source AI hardware device, one that is multilingual, handheld, privacy preserving and works in zero connectivity settings. So what we are going to show you after this will

be a video that presents the imagination of what such a device could lead to in terms of making AI work for everyone. And once we have done that there's a special treat for all of you. The maker

of the device and the collaborators at Bhashini are there in the room and they will demonstrate the product to you. So why don't I begin with playing this video which captures

which takes some creative liberties and captures our imagination of what this product would look like &gt;&gt; entering on western languages. Audio please.

Most today are built behind closed doors being trained on western languages. If they're entering our worlds, our bodies, our personal spaces, then they

need to be open. to be personal to us something towards partnership with current AI focuses on building a public good addressing our big problem in AI that is linguistic diversity

&gt;&gt; we'll be able to seize the opportunities given to us by technology if the people who are most affected by the problems are the ones leading the charge &gt;&gt; we have been building India's first

national open-source AI enabled language platform 350 AI models in 22 indic languages transforming billions of lives. &gt;&gt; The device with Rashi is a handheld

device. It's open source. It's running on local models and most importantly it's offline. &gt;&gt; India's design journey is no longer about pilots or promises. It's about

populations can reach clear use cases last mile by delivery. This is real world impact. Everybody At AI, our goal is to build a truly

global, collaborative and connective vision for AI. Not one that is governed by any one country or one company. All countries have a huge amount to bring to the table and I'm a big believer in the

power of collaboration. &gt;&gt; The house has ready. The soft is open. Now we need you come innovate AI for your own language for your own community.

Yes, we're back on. And uh for the next segment I would like to invite ya bed the CEO of uh current AI to take us through uh the product demonstration. I is an engineer and an

entrepreneur with 20 years of experience building open-source technology infrastructure that works at global scale. Ha, over to you.

&gt;&gt; I have a quick I have a quick interruption. I have to ask everybody to come here to take a picture so that the picture can be ready by the end of the panel. So, uh you have

90 seconds free to speak amongst yourselves. Thank you. &gt;&gt; All right. Um All right. Thank you so much uh for coming everyone. Um I'd like

to introduce um Andrew Turgis who was the lead engineer on this project from the current AI team who's going to uh take us through again you are um and also Shahim Paling who is um general

manager at Bashi who is Andrew's collaborator and worked very closely to integrate the uh Bashi models into the device and I uh just want to say a couple of things this project was uh

undertaken in in a in a six week period. I think maybe closer to five weeks actually. Uh so I just joined uh current AI in January of this year. Uh when I came in the partnership with Bashni had

already uh been in discussion. uh and I was very inspired by Bashn's work on uh linguistic diversity and their 350 models and we thought this is an opportunity for us to go all the way uh

to the user and create something where really people can create AI that works for themselves for their communities and for their languages. So uh this prototype is the beginning of a journey

and uh and also a platform to imagine infinite things that are possible. uh and so you'll show you'll see how it works. But as it's working, I also would like you to imagine what you could do

with it and where you could take it. Um and from our perspective, I'll just say uh for current AI, this is an example of how we'd like to work with partners where uh we we learn more about their uh

interest and their focus areas and their priorities and we zero in on a collaboration that we can develop together. We build it together and then we release it as a public good. So in

this case it's a piece of hardware and a development platform. In another case it could be something else. Uh but we're really proud that this collaboration with Brashi is our first collaborative

build and you get to see it kind of firsthand um as you're sitting here. So um Andrea and Shidra please uh join me on stage and I'll let you take us away for the demo.

&gt;&gt; Thank you. All right. Perfect. Uh hello. Um I'm so pleased to be able to show you this prototype that we've created. Um yes. Oh, thank you. In

front of the table. Wonderful. So this is our uh prototype open AI uh inference device. So you know unlike some other AI products you might have seen at this conference which might be designed for

one very specific user or one very specific use case. Um this device is designed to be used by any number of users for any number of use cases. The our hope is that anyone could feel

empowered to connect up to this device uh write their own application, pull any number of models onto the device and run inference locally in their hand. Um we have one flagship application that we've

developed in concert with Bashni that demonstrates their uh the models that they've been developing over so much time. Um in this uh sample application we call hear the world which is an

application where uh a vision impaired user can uh press a button ask a question in their native language about their surrounding uh uh and have the device read back their response again in

their native language leveraging posh these 22 plus languages and in particular we're leveraging um an ASR and automatic speech recognition module to convert the audio into text in their

native language. We'll be leveraging an NMT, neural machine translation module to convert that text into English. We'll be running it through a large language model with the image data to answer the

question and then we'll be converting it back into their native language using again the NMT model and finally a TTS module to convert it back into audio. So this device is able to run all of those

modules in concert. So without further ado, let's try and give it a test query. Shelinder, do you think you can help me out here? Um, I guess you'll take the photo and then I'll spin it around

quickly so uh the audience can see what's happening. &gt;&gt; Ask in Hindi. &gt;&gt; We'll ask in Hindi. &gt;&gt; Let me just triple check. Yep, you're

all good. What it has done is it it has taken the image and then it has taken the automatic speech recognition model kicks in and then neural machine translation

is happening and then uh again the response is getting from the LLM that we have embedded and the translation is happening and the text to speech which is being spoken out. So we have uh

quantized the model in such a way that it's fit in. Uh usually when we do the quantization there is always a trade-off that there is a hit on the accuracy but we have reached to a point where there

is no hit on the accuracy fronts. This is a a true a truly huge effort from your team and we wouldn't have been able to fit such a high fidelity LLM on this if

you didn't do that great optimization work. So, let's see. Let's ask another question there. We have a couple of candy bars on this desk here, which we can show you. Let's see. Uh, let's try

it. I'm going to put this in English. Uh, what is on this table? &gt;&gt; The table has candy wrappers of Twix, Milky Way, and Kit Kat. &gt;&gt; All right. It actually got the brands.

And we have one more question of importance, but I'll ask in Hindi. That's right. I got it. There we go. Would anyone like a candy bar? Anyone? Anyone?

There we go. So just very briefly while um while we're handing those out, you know, this is currently based on the uh Intel Jetson um the NVIDI NVIDIA Jetson um uh uh processing platform. Uh but we

hope to support other platforms as well because the processing that we're doing does not depend on that. That just happens to be the platform we've chosen at the moment. Um and uh yeah, there's

we're working on the ability to deploy any module that you like, any model that you you could dream of onto this device. back to you. Thank you very much. Uh how did everyone

feel about that demonstration? Are there things that can be done? Thank you. Thank you. And uh kudos to the Bhashini team which worked tirelessly and of course Andrew and the current AI team

which worked tirelessly to make sure the hardware software all of that was integrated. We had uh to get a device through customs as well. So uh that took some time but uh eventually it's here

and it's working which is amazing uh and the best part is that the device is offline all those queries all the AI processing was happening on the device and there are four or five models

operational four models operational on that particular device no mean feat I salute the engineers who have worked on this and there's more to come and uh we know we have to get in a lot in a short

period of time. So we will I will invite Ayadv the CEO of uh current AI and Shri Amitab Nam G um the CEO of Bhashini to join me for a fireside chat and we'll try and understand you know what about

the personal local multilingual AI is uh what they are passionate about. So this is also about you know what is what what are their motivations. So why don't we start with you Anitab G. So we all know

a lot about Bhashni. We have heard about it and you know it's it's it's a superstar at this point in time in terms of what you've achieved. Tell us about the origins. Tell us about how this all

started and why this is personal to you. &gt;&gt; See uh we all are uh born with our mother tongue right? uh we learn our mother tongues uh for good four five years before we

land up in a school and when we land up in a school it's a three language formula so uh I am a Bengali and uh I talk about you know when it is Bengali everything is eaten so joe is the right

word so when you go to the school and you have to do Hindi and English you know how It could be for first 6 months you are a you know people would be laughing at you when you are translating

and speaking because that's the first way of speaking you're not a native language speaker so you will be translating and speaking so you &gt;&gt; that's the linguistic nuance that you

went after &gt;&gt; so uh you know over a period of time of course we grew up we were told that you have to learn English to succeed in life so that's another given which was there

and uh obviously this opportunity came up you know uh you There was already a concept which was there and obviously we started with uh you know one room uh office first

employee. &gt;&gt; When was this? Which year? &gt;&gt; This was in 2023 and &gt;&gt; that recent &gt;&gt; that recent and then obviously we

started growing up as a team uh looking at various use cases. people started initially looking at uh the first thing was uh what's the accuracy which was the first question which used to come up but

in you know our models were built up in a difficult condition because we didn't have digital data to build up the AI model and which we collected it the data through a brute force and then we built

up the models which were there because we went across to multiple places where with translators who actually created the corpus which is digital corpus purpose. We still had deficient data but

we went across to build the model and deploy it under deployment. We had challenges which obviously came up uh from all all aspects. And today when we have actually deployed the use cases,

learned from it, improved it, we are now in a situation where we are running about 15 million inferences a day uh with a 200 GPU system and all having dashboards which actually give you every

inference time, timeliness, how much time it takes, etc., etc. So we are able to realtime monitor what is happening in our system, who are our customers, how they are using it.

&gt;&gt; Fantastic. It's wonderful to hear about your personal motivation. So I'll move to you. Uh how many languages do you speak? &gt;&gt; Um my native tongue is Arabic. Uh and

then I speak French, English and I'm learning Spanish. &gt;&gt; Very multilingual. So very apt you know to make this personal and multilingual. Uh I have two questions for you. One

tell us a little bit about current AI and why this interest in uh you know this open hardware and partnership with Bhashini. How does this tie back to current AI strategy? And second, why is

this personal to you? &gt;&gt; So, current AI was actually born out of the um AI action summit last year in Paris. Uh it's a public private partnership uh with a mission uh to

create AI for the public interest. Uh and so it's a partnership between philanthropy, government, and the private sector to really say we're going to tackle public interest AI at scale.

Uh and the reason we're going to do that is because the dominant uh companies that are uh governing our lives in AI, operate at a scale, a financial scale, operate at an ambition level, uh that if

we don't match it, we don't really have a chance to be a real alternative. And so current AI was born out of that um desire. uh the uh the goal is to rally a global community and collaboratively and

collectively to build uh a public stack for open AI that's completely vertically integrated. And so the way um we work is we work with partners uh because the the the core um the core premise is

collaboration. work with partners where we'll identify an area of common interest uh and a priority and uh a gap in technology and then we'll zero in on that gap, work on it together and then

uh and then develop uh a piece of tech and release it as a public good and and and so encourage uh this create this creation of technology that is put back in the public good as well as have grant

making under sort of like our our fund pillar in order to encourage people already doing this work um this this topic uh was uh is important to me has been important to me for many years um

I'm from Lebanon from Beirut and like I said I my native tongue is Arabic uh for the past many years you know our use of WhatsApp and mobile and social and everything um we a lot of us uh in the

Arab world lost use of Arabic you know my family and I my sisters my mom and my sisters and I speak in English to each other online all day we speak on WhatsApp in English the voice

recognition is never good enough in Arabic. Uh you spend more time correcting it than you do doing anything else. And so now it's improved a little bit. But really, you know, technologies

had an effect on the way we communicate with each other. And so for many years, it's been a real concern for me that, you know, technology if it's not made by us, it's not for us. And so when I

joined Current AI early this year, multilingual diversity was already a topic. Um, and I was very happy about that and and sort of really wanted to expand it into this idea of uh not just

um language diversity but cultural diversity and culture preservation as a whole. Um and uh and so this this sort of uh idea came about and can tell more about it.

&gt;&gt; Fantastic. What a story of genesis and of course silicon value making devices on AI for local use cases is uh going to be as effective as giving power in the hands of people. So on inclusivity

Anutab G uh one of the visions of uh Bahashini is to to expand access. So when you think of this partnership with the current AI, what is the future you envision in terms of expanding access

and creating inclusion with Bahashini as the lynch pin? So a few things. So you know uh when you look at the size of the device you know we have almost reached a form factor which is quite small right

and it can be carried through at the last mile and since it works offline you are in a position to actually use it anywhere almost. So that's the first part of inclusivity.

Uh we obviously have you know plans to look at uh smaller form factor as we go uh forward. The second thing which is there is to look at the language coverage. We currently cover 22

languages in our system. We already have uh 16 languages 14 more languages on text. So total 36 languages and we would like to increase that on breadth and recently we have

digitized one of the tribal languages which is BI which doesn't have screen so that also gets added to it. So that is about breadth of languages which is there which will be continuously added.

So when we are talking about form factor second we are talking about offline. Third we are talking about creating a breadth of languages so that no p no language is left behind. Hence no person

is left behind including the tribal languages. The fourth factor is all about how do [snorts] we you know enrich the models which are there which is a continuous activity which bashny takes

over means uh there can be there are multiple things where the models still have to be enriched means uh India has got about means we were talking to survey of India and they have about 16

lakh places name uh which is still to be digitized so you know and put into the system so those are glosseries which we are building there are contextualization efforts which are happening. So over a

period of time the language enrichment as far as depth is concerned is another thing which we are looking at. So we're looking at v depth offline form factor as the four things which will move

forward in this. &gt;&gt; Fantastic. I can certainly see the open hardware playing uh a big role in that as well. I a question to you on how you look at future. So what gives you uh the

most hope and the most concern about the future of language and you start talking about how you know you feel like Arabic and the nuances are getting lost. So uh what gives you most hope or most concern

about the future of language in an AIdriven world? Could you uh talk about that? &gt;&gt; So I'll start with the concern. Um I'm concerned about this new frontier of

embodied AI. So um over the past um you know year or so uh every big tech company has released their version of an embodied AI device that wants to enter your home wants to enter that wants to

be close to your body wants to u you know enter uh enter your personal space. So whether metal is glasses or whether the butler robots or whether uh Amazon Alexa and they're in full control of

these devices and we don't know how they're developed and we don't know how they're trained. Um you know la last week or the week before Meta announces that the glasses are going to start

doing facial recognition on every person you encounter in the street. So now unknowingly you're walking down the street if somebody's wearing Meta glasses you are being photo recorded and

facially recognized. So, um, we have these devices. We don't know how they work. They're continuously recording our data, sending it out to the cloud. We also don't know how they're trained. And

oftent times, they're trained on Western languages. And so, um, that hardware is where the lockup first starts. It's how the it's how the iPhone locked up a lot of technology innovation because what

happens is these companies will then develop give give us APIs into their devices. startups will start forming and building on top of these devices and then the startups start building a

dependency on the device and you start to build a whole stack on a core piece of hardware that you do not control. So it's it's really kind of like a core you know building block that we have to

crack before we let them sort of own the entire stack or the supply chain. Um I spent 15 years you know before current AI in open source hardware. I've seen how powerful it is when you develop on

an open platform and people do what they want with it. It's it's this, you know, the same power that you get from something like Linux. And so that's sort of a big area of concern. The area of

hope for me is uh you know there are many trajectories for us to kind of improve from here. Um on one side you can improve the device itself. You lower its cost, you improve its uh its battery

life. Uh you shrink its size, you make it more beautiful. So you know that's one access. Then there's another access that you can develop. You can um have multiple of these devices together

connect them in a mesh network. Now you have a distributed inference that you can run something larger on. Uh you can have a larger version of this device that's stationary. It can be like a

micro data center. Uh you can put a solar panel on it. Now suddenly it doesn't need a battery. So you can you know infinitely innovate on the possibilities of this core building

block. And then the third um kind of track is on what you do with it. You make a device for a farmer to identify how to deal with their crops. You make a device uh for a parent who wants to give

their kid a toy but doesn't want the toy to be communicating their private data back to the cloud. Uh you uh you create uh you know some sort of I don't know uh tourism device uh that you can put

around your neck and helps you move around. uh various sorts of things and the the opportunities are are infinite. &gt;&gt; Fantastic. And uh I wish we had more time to just continue going we just

scratching the surface but we are at time and I thank you Anitab G for uh the good great work that you and your team are doing and uh I wish you uh all the all the best and all the luck for making

that vision into a reality. Thank you very much. &gt;&gt; Thank you. Thank you. Um and with that we move into our next segment which is uh another fireside

chat and for that uh I would now hand the floor to a longtime friend and colleague uh Martin Tis. Uh Martin Tis leads the AI collaborative, an organization working on building AI

grounded in democratic values and principles and he's also the chair of current AI. Uh Martin over to you. Thanks very much. Um and my first task is going to be to welcome Abishek Singh

who everyone knows who is the master orchestrator of this in summit. Congratulations, Abishek. I'm amazed you're still standing. Welcome. And and ano who was the

orchestrator of the Paris summit. Welcome and special envoy to the president. Thank you very much. Please please sit down. Um I hope that was enough.

It was the next step. So we are setting something to follow. Absolutely. So as as Susan was saying um and I'm extraordinarily excited um by Ya's leadership when it comes to current AI

and the work in really turning this work around linguistic diversity to the question of cultural preservation seems to me that having ensuring that AI isn't squashing all of these incredible

cultures that make the the beauty of the world into a monoculture or into a small number of monocultures is one of the most important questions that we have today. So my my first question to both

of you maybe starting with you Abby Shek and then to an it's the same question is what is your vision? What what is the world that you would like us to live in when it comes to this intersection of AI

and culture if we get it right? How do what does it look like whether it's 5 years 10 years from now? What does it look like if we get it right? See like uh ultimately like when I look at

technology like when we're building the digital India stack or whenever now we in the AI age the ultimate objective remains is that what is it in it for citizens and what is it for businesses

or enterprises organizations for it it's not about the tech it's not about the models it's not about the uh hardware it's not about the GPUs it's not about even the data set platform it's about

ultimately what's the end objective is the end user whether it's a citizen or whether it's small business or a retailer or a industrial unit what is it we get it out of it so that's where the

objective lies and when we start thinking of use cases problem statements and we start working everything puts in place so in fact one example as what we did is like today what we demonstrated

today clearly shows what technology can mean to someone who does not even have access to internet or who does not have access to to languages he knows only his local term. He does not even know how to

key in or how to navigate a capture or he gets lost with the hashtags and the ambers. So for such people if they are able to talk to a device put their query which internet or bandwidth of

connectivity and get a reply back that will be empowering and that's what I think ultimate objective was of this summit also democratizing use of AI and ultimately making AI work for all.

&gt;&gt; Thanks. Thank you very much. Abishek, what is what is your vision? &gt;&gt; Um, so of course I I share a lot of what Abishek said. Um, I I also think that um uh using AI through our phones and and

maybe one way to uh say this is that when I get online through my phone, I mean, I love San Francisco. I love Shanghai, but but I'd like to have uh a wider choice. uh uh I don't necessarily

want to be transported to Silicon Valley or transported to Shanghai when when I get into uh AI and and that's a little bit of a joke but but if all the the cultural representation if all the um uh

legal background if all the um uh customs that are you know uh taken as just the um uh de facto way you interact with people uh if that's the choice well that that's just such a reduction of

cultural diversity um that and I think it's just not okay. It's not just about being able to have access to uh a French AI or an Indian AI. It's even more than that. If I'm interested in music and if

I come from a particular area in France where I'd like to be able to have that community and its culture represented there. So I think that's that's part of my vision.

&gt;&gt; Thank you. And if I can if I can stay with you just a second and um from a from a French perspective from France's point of view how do you see um culture and AI playing together? What does it

look like? So when I was a kid growing up in France from a cultural perspective it was at a time where it was actually think it was a good idea in retrospect. You'll tell us what you think that there

was a law that mandated a certain percentage of music on radio to be sung in French. there was a law that mandated a certain amount of productions, movie productions to be in French and that's

ended up it seems to me with a certain amount of you know sort of cultural as we say to exist so from a policy perspective in France when it comes to artificial intelligence and culture do

you think that at some point there needs to be a sort of a set norm like we did in sort of in in movies and radio what do you think &gt;&gt; that's a good question I don't know

whether we need a set norm but that yes these mechanisms to encourage privilege uh creation uh in in France and in Europe that that's quite important the um uh uh will every movie that you go

and see which can be from any uh country that gives a there certain tax on this a certain amount of money goes to a fund uh that then helps um uh French creators uh to go and and and prepare whatever

they want uh as as their uh next film and and that mechanism doesn't make it hgemonious. I mean, of course, we love culture from all over the world, but it helps ensure that there's an element of

of of French cultural creation and that that's what we definitely want to continue to have. uh and we want people to have the ability to see that in France but all over the world just like

we love to see uh Indian movies or listen to Indian um uh music or or or from Singap or from uh uh wondering that's that diversity needs to be maintained needs to be um uh uh ensured

in in including through some mechanisms to fund it. Yes, &gt;&gt; thank you and so thank you very much Alan Abbishek similar question to you. India with not only the incredible

wealth of languages with well over a hundred languages but as an was mentioned the movie industry the writing the music how does that intersect with artificial intelligence with the work

you're doing at a national level from the policy side how do you how do you think about that &gt;&gt; if AI has to be like uh covering all aspects then it has to be rooted into

into data sets that are diverse and data sets when you talk about in any cultural context it will include not only languages but it will also include the culture, the heritage, the music, the

movies, the songs and lots of folklore because in fact if you look at uh across India if you go to the rural areas and all there are lots of traditions which are not even documented well so those

things are not even available in a digital format they are known for for they're known to people like in fact recently I was watching a documentary on Netflix called human in the moon it's

set up in a in a in a state of India jarhand with a lot tribal population and there is there are these tribal women who are doing data annotation for an American firm and it shows that they

have to they have seen uh leaves and pests and they have to mark it whether it's a pest or not. So this young girl is there and what she does is that she sees a pest the image and she marks it

not a pest. Her manager comes down heavily on her and says that this is obviously a pest. How are you saying there's not a pest? She says that this tree grows in my local forest around

where I live and I know that this this worm eats only leaves which are dying in a way it helps the plant. So it's not a pest. So again having this traditional knowledge built into the corpus of data

sets on which we train AI models will be very very vital if you have to ensure that AI would hassle hallucinate if AI becomes near to what human is. So it becomes very important to capture this

cultural context from all across the world from all communities all cultures all traditions and then only we'll be able to build something which is more human like other this just technological

pursuit of AGI and all will not solve the problem that we are living &gt;&gt; now that's a great example thank you but then maybe staying with you for a second and I'll I'll come back to you on the

question of reciprocity so you talked about the data sets communities cultures and all diversity are sharing their data or we want them to be sharing their data with different uh with different AI

models. What does it look like from the community perspective do you think like should they be involved in it? Should they be have rights over the data? How do you how do you think about that?

&gt;&gt; See like uh it was a very interesting question was about sharing of data sharing of data across uh across companies across industry. We have to kind of build frameworks which allows

use of data for purposes and use of data in any which does not violate the privacy or the personal identifier of the person who owns the data person to whom the data belongs the data principle

per se. So when data sharing the data in the community will need to be involved. If you don't do that then in the increase of businesses and increase of commercial

requirements the misuse of the possibility missing the data that goes up. So it's very important to have standards not only technical standards but it comes to standards which are

rooted in the culture and the belief systems of a place from where data is coming from in order to ensure that the models and the applications become more accessible. And thank you. If I can get

a little bit um further on that question, there's the question about the rights of the individual and the rights of the communities towards the data. Do you think in the way that you're working

is there also a reciprocity in terms of if data about them is used for a particular purpose that they then the community should benefit from it? How do you think about that from they should

benefit whether it's a translation or other device? How do you how do you think about that? So you need to think about like the different use cases may have different applications like for

example if it's data about say agriculture and if I have aggregate data about a particular area and that kind of to should agree advisories so farmers with regard to which they should show

for maximum benefits at what time they should show maybe that data should be sharable and that's in the benefit of everyone but they say for example health data then there individuals might not be

wanting to share that data with the larger ecosystem. So I think it will it will be context specific context specific and we cannot have general rules about sharing of data and the

recipro reciprocity principles across the across different sectors. &gt;&gt; Thank you very much and I have a similar question for you on this question of reciprocity. What's your what's your

take? &gt;&gt; I think that's a very profound question. uh part of the reason why you want to share cultural data is so that cultures um are preserved and and and you don't

end up with one or two or three cultures in in the world but uh something that is more diverse. So uh it is in the interest of a cultural group of a civilization that uh in the world of uh

AI this culture is represented and from that perspective you have a very natural um uh uh reciprocity loop but but at the same time creators are saying I don't want my data to be used if I don't have

a u mode of being compensated or recognized or a way to oppose and and so you have this tension uh uh between artists s for example who say uh well I want uh uh my rights to be um uh uh to

be to be maintained and I want some sort of some type of compensation if this is being used to uh feed AI models and then uh uh for people to earn money out of it. Uh but then on a collective basis

you do want that culture to be represented. So it's a I I'm not sure I have a solution but I I very clearly see the tension. uh and and maybe ways we can navigate that is to uh have a right

of opposition by specific artists so that they can say no my data my creations are not going to be used. And at the same time you can certainly have historical information and and and

things that that are not so subject to uh maybe having remineration for living artists be part of the general um uh uh cultural data that you use to train AI. But but beyond these two obvious things,

I'm not really sure. So, we need to continue to work on this. &gt;&gt; Thank you. And and again, just to go a bit deeper question, it's a &gt;&gt; it it's a it's a f it really is it's a

fascinating question because from the perspective of the communities, I would imagine whose whose data it is. It's data about them. As you say, you want people to know about your culture, you

want the culture to be preserved, and at the same time, you want a certain degree of agency over how the data is used. In an earlier panel I was talking about or we were talking about indigenous data

sovereignty and we were talking about the Maui community in New Zealand and the degree to which as I understand it in Maui culture any data and information that pertains to marry culture is

effectively part of mar culture. So there's a real question of agency. My question is in the runup and when we were working together on the Paris summit, we talked quite a bit about the

relation between open-source AI on one hand and then the governance of the data and the governance of the data then to be controlled in different ways. So how do you think about this balance because

it strikes me that getting the balance right between on one hand the open-source component and I'll come to the same question to you in a second Abishek and on the other hand a more

controlled approach around data governance that's the special source what what do you think &gt;&gt; yeah I completely agree and maybe that as Abishek was saying maybe the example

of health data is is a good one there because for cultural data you you want the general uh benefit and you want to preserve artists right I think Those are the two dynamics for health data. Um uh

you do want uh as I mean as as an individual as as a patient if you're being asked the question, do you want to protect your personal data? The answer is yes. If you're being asked the

question, are you willing to share your data with other people who have um or are at risk of a similar ill illness so that it can help them? Your answer is yes. Um and then how do you balance the

two? Um and and so you need to find some ways to share data in a uh uh platform or in a way that you have trust into. And so it needs to be privacy preserving. It needs to be held by an

actor you trust. Um uh uh even if you don't go and look at all the terms and conditions, but you need to understand that it's an institution or a third party that you can trust. And then you

want to be able to rely on that third party to make the right decisions. uh like yes sharing the data to enable research and and find um uh new cures uh but maybe to sharing it to insurance

companies so that you can be charged a different rate uh depending on on what personal situation is. Uh and then when you get into sovereignty, maybe you're happy for this to be shared with um

innovative startups in your country or your region that will develop um uh new um uh cures in new but maybe not with some other actors. So so you you get to a number of of of different levels and

questions. uh and and for that having third parties trusted third parties that can hopefully make the right decisions I think is is very important. &gt;&gt; Thank you. Same question to you. How do

you see that balance between on the one hand we've talked a lot about open source open source AI over the course of the week. How do you see the balance between on one hand open source on the

other hand the question of the cultural data that we've been talking about? So again ultimately I will go back to the end approach with regard to the end objectives. What is the purpose for

which we are sharing the data? Is it serving public interest or is it serving private interest or is there a benefit for the user to whom the data belongs? So for example health data is there if

aggregate level data is there for example we keep on hearing about outbreaks of we are over but we keep on hearing about outbreaks of flu and other ailments. If aggregate data about

incidence of such diseases and linkages with other factors, environmental factors, weather factors, rain factors is shared so that people can think of devising AI enabled solutions of

integrating various data sets and trying to see why in a particular geography in a particular locality some ailment is happening then that's a public interest. So we'll have to define in a case by

case basis whenever data is being shared whether open source or in a proprietary solution what is the end objective what are the problem that I'm going to solve and is it serving the larger interest of

the community is it serving larger public interest or is it being done to benefit a few corporations like for example the example she gave about insurance companies if it leads to if

like data about food consumption or something leads to increase in my insurance premiums that's like not there where they're linking that data with the individuals who to whom the data

belongs. So there we will need to think of privacy recation techniques. We need to think of analyzing techniques so that in no ways the data principle to whom the data belongs is harmed in an adverse

manner. So we have to do this in a very nuanced manner. There is not one size fits all solution because if we do that we end the works of the Egypt dominating the humanity and we

want the president that would rather come. Okay. Thank you very much. So then there's a question I can't resist asking you which is what's your definition of sovereignty because an you mentioned the

term we've talked a lot about this this week and in the in the context of this conversation it's really interesting because there's a question of sovereignty from a nation's perspective

there's a question of sovereignty I mentioned that Mar example indigenous data sovereignty from a community's perspective and then both have been talking about health so there's a

question of you know at an individual level the sovereignty I have over a data about me so with your experience events coming towards the end of the summit and the experience that India has how do you

when you think about sovereignty and AI what do you what do you think of &gt;&gt; like sovereignty of course traditionally it's a political science concept wherein it says that nations which are sovereign

need to have complete control over what they do how they do with whom [clears throat] the entire control of their decisions when it apply when you apply to technology or when you apply to

AI specifically the same concepts will apply with regard to only what I want to do with whom I want to do and how I want to do. Nobody else should decide to make decisions on my behalf. So maybe in the

short term I believe a complete sovereign AI stack will mean that you should have complete control over all the five layers of AI whether it's the energy layer or the data center

infrastructure chips models applications use cases you should have complete control over it. The way technology is evolving right now in fact uh look for a few countries in fact look for even I

don't think any other country has complete control over the entire AI stack every other country has we are there we are there sufficiency we have their data centers we have our

models we have applications but we don't have the compute we have the capability to design the compute and we do hope that in 3 to 5 years we design our own future and in 5 to 10 years we'll be

able to have a fab which will I can uh take it out also in the short term if I decide that which chip I want to use how I want to use how I procure rather than be subject to conditionality rather be

forced to do something it should be sovereignty the sovereignty will apply the same concept of sovereignty that we apply in political science where in complete controls

lie in the sovereign government that should be the way we should look at sovereignty in AI as well thank you very much so just As we're as we're ending and we're with an eye on the time, feel

free to weave in the questions of sovereignty and I'm curious in the wake of President Mron's state visit um and the bilateral relationship between France and India. What do you both see?

So starting with an finishing with Yabishek, what do you both see as opportunities for France and India to jointly work on these global norms, global approaches for a more contextual

approach to artificial intelligence, for a culturally inclusive approach to AI? Well, I I'll try to be short, but this is the year of joint uh innovation between India and France. There's many

areas where we're collaborating and will continue to collaborate. Uh clearly, current AI and this work on multi- lingual uh uh AI is is is one. Uh working on uh AI that is resilient and

sustainable by design as we were just discussing um earlier uh uh with Abishek is is clearly a priority. um uh joint research uh and and then just just to weave I can't resist weaving your work

on um uh sovereignty um I think sovereignty no one actually not even the US they don't have the chips so nobody can do everything alone I believe that means um having a choice and building

alternative solutions uh and and I really think we can and we will jointly build alternative solutions between France and India &gt;&gt; last one I don't go

And in fact the partnership between India and France have there for quite some time. In fact, last year we co-ched both funds action summit and the partnership has continued this year and

this year of course as you know we have launched the year of innovation and there are many more activities as been announced by the president and our prime minister in the last week and uh we are

looking forward to joining you at the rotech in few next few months and uh there are many more activities partnership at the university level partnership the research level

partnership at the business level partnership at the government level. So I strongly believe that uh working jointly with especially a trusted partner like France and India we have

complimentary strengths and we can together try to present an approach toward building UI and solution that can become an example for the whole world. Thank you very much. Thank you both of

you. It was an honor to launch in Paris and a pleasure to launch this part. &gt;&gt; Hello. Thanks Martin. Um Abishek Singh I'd request you to stay on stage and a we'd love to have you on to launch the

global innovation challenge in spirit of what an said and as well Please make session first. First,

&gt;&gt; huh? I'm going first. Okay. Okay. Great. So, great session, great thoughts, great demo. So all of us have seen the demo of the reference device the device which has been built in

partnership with Bhashini and current AI and in fact I must mention that it was just a few weeks back when we had this discussion because I've been discussing Martin with after the discussions and

announcement at public interest AI like what will current AI do with the $400 million that they have euros that they have raised and I was saying that let's do something which can really make an

impact and if we can do something at the impact summit it will be worthwhile but kudos to the teams and they have built the collaborative build design which were designed by both the engineers from

Bhashini and the current AI support is been done in such a way that it's a it's a it's a platform it's a prototype on which we can innovate it does not it's completely open source it's hackable

it's privacy preserving it's multilingual and with ondevice AI this prototype is capable of functioning in remote locations in not not only India but anywhere else in the world where

connectivity is a challenge or for any reason if there's an earthquake or there's a problem or if there is a natural calamity and we can't have connectivity it can work so that can be

really transformational for people to access services and in partnership with current AI and Bhashini in fact it's my honor and privilege to announce the India AI innovation challenge which will

give an opportunity to researchers to engineers to developers to entrepreneurs to build on this prototype and this prototype will be available in an open source manner for everyone to hack it

and make it more you can make it smaller. You can make it more sleeker. You can solve individual use cases for different sectors and it can it's based on an open-source software and hardware

design and the kind of use cases one can think of will be limitless. So there will not one but multiple solutions that can be built on it and we are opening it today and in the next few weeks the the

date here says that submissions will open on 25th Feb. the 25th Feb on our website, we'll launch the uh the challenge on which applications can be submitted and there will be some time to

build the build the actual device and those who will win will get a very handsome reward that will be funded both by Vashini and current AI and together we will try to ensure that we are able

to build a product that the whole world can use. Well, uh we will continue to you know support this uh effort through our quantization mechanism and also the

technical support will be available with respect to the model enrichment etc. So this will be a joint effort. So people are supposed to put in the effort and come back to us if on the challenges and

we will work on that together. I just say um for Amitab because maybe he's trying to say Bash is offering uh I think $110,000 uh prize to to the winners. Um

&gt;&gt; maybe no I guess. Oh, so should people make a demand? How how does the number increase on your way out? Please make a make a request everyone the number to go up. So

um so there's a big page to it. We'll also support the participants to make sure that they have support while they're developing the hardware and the software and showcase the work online to

inspire many other people. Really the point of it is to kind of like expand imagination and start this conversation about making your own AI and start the conversation about AI being personal and

multilingual and uh solving communities and individuals own problems. And today it's a piece of hardware. Tomorrow it could be something in the something in in software. The day after can be in

data. So really uh this is the beginning of the journey. Thank you so much for coming everyone. Thank you for being such good partners. Thank you Amitra and Dashnik team. Thank you to the current

AI team. Thank you Martin for bringing us together and um have a great festive week and and rest hopefully for you. Turn on. Number

seven.
