# Edge AI in Action: Accelerating Development across the Global South

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 10 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/51X9kf574vA?feature=share) |

## üé§ Speakers

- Alagan Mahalingam, Rootcode
- Dr. Ranjitha Prasad, IIT Delhi
- Dr. Rathinamala Vijay, ARTPARK
- Frederic Werner, International Telecommunication Union
- H.E Amb Lavina Ramkissoon, African Union
- Ms. Doreen Bogdan-Martin, ITU
- Prof Brejesh Lall, IIT Delhi
- Vinesh Sukumar, Qualcomm
- Vishnu Ram OV, ITU

## ü§ù Knowledge Partners

- International Telecommunication Union

## üìù Summary

As AI evolves, the shift from centralized cloud computing to edge AI is transforming how data is processed and acted upon. By moving intelligence closer to data sources such as sensors, mobile devices, and IoT systems, edge AI reduces latency, bandwidth usage, and energy consumption while improving real-time decision-making, privacy, and security. Real-world applications will be highlighted along with emerging lightweight and generative AI models designed for resource-constrained edge environments.

## üîë Key Takeaways

1. As AI evolves, the shift from centralized cloud computing to edge AI is transforming how data is processed and acted upon.
2. By moving intelligence closer to data sources such as sensors, mobile devices, and IoT systems, edge AI reduces latency, bandwidth usage, and energy consumption while improving real-time decision-making, privacy, and security.
3. Real-world applications will be highlighted along with emerging lightweight and generative AI models designed for resource-constrained edge environments.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/51X9kf574vA/maxresdefault.jpg)](https://youtube.com/live/51X9kf574vA?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Where? Are you Okay, thank you very much. Uh we we have uh we have very little time. So I want to first of all introduce uh Fred. Uh

Fred Vana is the chief of uh strategic engagement department at ITU. Uh welcome Fred to give the opening remarks. Hello. &gt;&gt; Let me start with a question.

What if the last thing that humans ever invent is invention itself? Now, what what do I mean by this? Um, we had, if you're familiar with Roman Yolski, he's a leading AI safety expert

and I met him in New York at the UNGA last fall and he said, "Fred, what is AI for good?" I said, "Well, what do you mean?" He said, "Well, is it for good or for good?" What do you mean? And he

said, "Well, for good as in beneficial, as in good, or as in for good? Forever?" I said, "Hm, good point." and he said, "What if AI is the last thing that humans ever invent?" Now, you might

agree or disagree with that statement, but it's not hard to imagine a future where most future inventions will either be invented by an AI or with the help and of an AI. And if that is the case,

then I think we do need to make sure that AI, if it's going to be for good, is indeed for good. So, my name is Fred Werner from the ITU. It's the United Nations specialized agency for digital

technologies and we're also the organizers of AI for good with 50 plus UN sister agencies. Now AI for good was created in 2017 and if you think about that that's basically an eternity in

terms of AI years looking at how fast it's been developing and back then it was really all about the fear and the promise and the hype of AI. Most solutions existed in fancy PowerPoint

slides uh but there wasn't a whole lot of substance but that changed rather quickly. Uh in 2023 we saw the advent of generative AI. Last year the unofficial theme of the summit was the rise of the

AI agents. And now we're looking at a world where you're basically entering a zero-click world where agents are not waiting for our prompts. They're actually acting on our behalf. And in

addition, you have the physical embodiment of AI in the form of robotics, embodied AI, brain computer interfaces, and we're even looking at space AI computing now. So, I think

there's safe to say there's no shortage of high potential AI use cases that can be used to help solve global challenges. Anything from affordable healthcare to education for all, food security,

disaster response, the use cases are definitely there. So what is the goal of AI for good? Well, simply put, it's to unlock AI's potential to serve humanity. And how do we do this? Well, first of

all, we can't do this alone. Nobody can. That's why we have 50 UN sister agencies as partners of AI for good contributing knowledge, sharing expertise, helping to drive our standards work, building

cooperation around AI governance. And we're very privileged to have here the two co-chairs and facilitators of the UN AI global dialogue who will be doing the closing remarks. Now I could talk about

AI for good for days. U but to save us some time I just want to show you a little video so you can actually see AI for good in action from our last summit. If we could please play the video.

I have a joke that I always say for these occasions. AI is easy. AV is difficult. Um, actually, we don't need to see the video. Ah, [laughter] &gt;&gt; is it going to happen?

&gt;&gt; Yes. &gt;&gt; But now we need sound. since there's no sound. Uh, that's lovely. Geneva, we are more than the AI generation. We

are the generation that is determined, ladies and gentlemen, determined to shape AI for good. So no matter how fast technology moves, let us never stop putting AI at the [music] service of all

people and our planet. &gt;&gt; If we want an AI [music] literate society, meaning resilient and ready for the future, we need to integrate these new tools into school curriculum.

Let's build a future where AI advances progress for all humanity. A shared digital future that is again inclusive, equitable, prosperous, and sustainable for all.

It is no coincidence that this era of profound innovation has prompted many to reflect [music] on what it means to be human and on humanity's role in the world. AI must

help bring us closer, not to divide us apart. That's one of the foundational promises of AI culture. &gt;&gt; We all now have I think a much greater

level of awareness around AI and we all need to shift into that as fast as possible because this technology is moving so fast. Ladies and gentlemen, this was a real uh fast track operation

that we did which we call the international AI standards exchange database. Push for standards [music] in your domain or industry that require this

type of trigger. And we have just started the last semi fight of the junior division. Let's go. I think it's fair to say that AI for good is indeed more than a summit. It's

a movement. It's a global community and it would be nothing without you, the participants. &gt;&gt; Three, two, one. &gt;&gt; Thanks for watching. I'm not sure who my

last guy was, but um now I think one of our I think people often misunderstand that AI for good it's known as a summit that takes place each year in Geneva, but

it's actually a year-long activity. We have online events almost every day of the week all year long. And we're organized around three pillars, solutions, skills, and standards. And if

you look at the solutions pillar, we have machine learning challenges, we have startup pitching competitions, all types of activities to identify real practical applications of AI that you

could use here and today. And on the topic of edge AI, we had a build buildathon on edge AI just a few weeks ago here in India. And we also had machine learning challenges on tiny ML,

tiny machine learning devices. And when we're looking at skills, we launched the AI skills coalition. And a big piece of that is going to be creating basically machine learning environment sandboxes

where we can do training and mentoring for governments to upskill their constituencies on the use of AI using the data from our machine learning challenges. So it's not hypothetical.

It's using real data for real solutions. And the last piece of course the bread and butter of ITU is standards. And we have uh over 400 AI standards published or in development covering a whole suite

of topics. But more specifically related to the session, we have a standards work on future networks basically 5G, 6G and beyond and a pre-standardization effort on AI native networks. So basically

these are examples of AI for good in action and the theme of this session is actually edge AI in action in the global south and I'm very much looking forward to the discussion and thank you for your

time and attention. Thank you so much Fred. Now um we have uh we have uh the keynotes coming. Thank you. Uh we first of all let me call professor Lal Brides is my great friend

as well as colleague. He was um uh the the bharti school chairman but also right now he was currently looking at AJI research. Our touch points with ITO are many where he hosted AI for good

challenges WTSA hackathon. He was a judge as well as kaleidoscope. He's very active. Thank you very much Vijay for coming and over to you. Yeah. So it's been a while. Thank you

Vishnu G for having me that I've been participating in these AI for good activities. So there's been a lot happening not just these uh talks that you have but also something on the

ground hackathon is an example of that with participation from all over the globe. So today I'm going to talk about some of the work that's happening here at IIT Delhi where we're trying to

leverage the edge and the other thing that I'm going to run through very quickly is PSI and its role in edge. So because we're focusing here on accelerating development across the

global south so I'm going to pick up those two examples today. Right. So what what we're trying to say is that you have lots and lots of edge agents

that will now act simultaneously and in coordination. So the reason why edge is becoming more and more important is this converge of communication, compute and control. Uh and this convergence is now

quite real. And because this uh convergence is real, it is enabled at least in today's technology only by a strong edge control specifically for tasks in the area of haptics as I will

show in the next slide require you to not miss or make mistakes because some of them are catastrophic and for that reason a strong development in the area of edge is important. The other reason

why uh looking at edge is important from the perspective of glo global south is that while it might not be easy to have foundation models that solve all the problems of the world at least to an

extent context has become increasingly important in modern times. people solve want to provide solutions which are very very specific to to the task at hand and context can be best leveraged or used if

there's a strong edge capability that is present. So in that light it's important that the global south focuses on uh building its strength in the area of edge. This slide here talks about some

of the work that we're doing with respect to haptics. Haptics as you know is this sense of touch primarily consists of two aspects. One is kinesesthetics which is the pressure

that we feel and the second is tactile or texture which is the quality of of surface that we you know the the fine grained texture of the surface that we we are able to measure using our skin.

So uh the the thing with this kind of a of a modality is that while it seems to be almost absent it is quite pervasive. It's all around us. the the temperature including uh you know the the hardness

uh the the softness or the uh the way people meet each other greet each other you know all of that is is very very important we just don't you know it's not uh overt but but it's important

nonetheless so we sort of take it for granted however it is very very important and therefore it needs to uh be looked at a little carefully now the challenge with u [clears throat] haptics

is that While uh as we moved from speech to video, people did talk about bandwidth and they did talk about latency and there were quality of experience measures that evolved. With

haptics, it goes to the next level because u if you have unsynced and delayed uh haptic uh inputs or feedback, then it becomes quite confounding and it it confuses the person and it sometimes

can be quite uh disconcerting. So for this reason it is extremely important that the haptics data that you receive is accurate and received on time. So for this it becomes extremely important that

there's a strong capability that's present at the edge. Now here at IIT we try to implement it using two ways. One is what we term as split control where we've tried to move from having

solutions deployed only in the cloud and the endpoint. We try to put in significant amount of capability on the edge itself. The other aspect that we're looking at carefully is trying to

convert signals which are haptic in form to signals which give you the intent rather than actual measurements of pressure as what haptics is to to machines. So these two things are

primarily handled at the edge. Uh the first one is quite clear. Let me just uh say a few words about the second. So when we talk about intent uh in in today's world uh when whenever you look

at a haptic solution it's sort of locked in right from the operator to the end point where you you'd have some kind of manipulation dextrous manipulation of the environment around around the

device. However, it's very very hard for devices of different oper different uh manufacturers to interoperate and this happens because it is very very tightly coupled to all the signals that are

generated and the form factor of the devices. It's not as simple as pick up any camera and the image that you get you can show it on any display. So for that reason the idea is to convert those

signals into intent send the intent to the other side and the edge on the other side uh makes sense of the intent and converts into a into a signal that the other or the faroint can then use to do

whatever works needed. So these are the two things that we sort of look at um with with reasonable amount of interest at IIT Delhi and we continue to contribute to standards primarily in the

area of MEC and quality of experience where where multimodality is involved. Right? Um now this is the edge foundation network. I'll skip this in interest of time because I do have a

couple of slides that I want to uh uh walk you through because there's some work that's also being done by TSDSI which is our SDO at here in India and they have in um conjunction with ITU

doing quite a lot of interesting work which is edge centric. So uh let me talk about few of those. So there are a few technical reports that have come out of late there there there's this talk of

dynamic AI ML models for self- sustainable V2X applications. So B2X applications is being looked at carefully. There's also work in the area of uh security aspects and advanced and

AI enhanced passive digital twinning uh initiative. So we have uh some technical reports that have happened in this area. There's also uh developing of standards work that's happening. There's

architectural support for tactile applications that I just spoke about. There's talk of 6G AI architecture for RAN and also AI native scalable reference architectures. uh I think

maybe you'll talk about quality of experience in the next slide but that's another thing we're looking at we're also carrying out technical studies in all of these areas in interest of time

uh you'll have the slides you can uh go through them when you uh find the time uh this is the other thing that they wanted me to [clears throat] uh bring to light to this audience yeah uh just a

couple of minutes so so the global standard forums that that are of interest to the audience here people who look at edge carefully there's ITUR IMT 2030 framework for included

ubiquitous intelligence for overarching uh design and then there's I2T related standards there are 3GPP standards and of course the one M2M so all of these standards are of interest to the

audience there and people trying to do research in this area and besides this TSDSI has been uh trying to be inclusive by holding these flagship conferences annual ones so that more and more people

get insight into what's happening. With that, I'll close because we're really uh short of time here. Wish back to you. &gt;&gt; Thank you Vijay. Uh thank you for bringing out the Indian research in the

topic and bringing out the AJI framework also. It's very less time. Let me invite Ranjida. Ranjida obtained her PhD from IC. Her current research involves causal inference, survival analysis and basian

neural networks. over to you. &gt;&gt; Yeah. So something that uh he also missed. I actually do work in federated learning uh and many other learning paradigms. So uh let me just start. So

uh mine is going to be a technical talk where I'll uh tell you the motivation for using federated learning um especially the role of federated learning in uh telecom networks and uh

why really are people discussing about this. Uh the motivation is of course data explosion. uh there's exponential growth of uh in mobile data traffic and you have all these diverse uh services

that are there in 6G, EMBB, URLC. I'm sure this audience is uh well well aware of this. Um then there are bottlenecks in these legacy networks which actually motivated moving more towards

edcententric uh architectures. uh the goal is of course I think this is something very important that uh most of the standards uh are looking at predictive zero-ouch automation closed

loop wireless control and this loop closure latency requirement about less than 10 milliseconds uh for mission critical optimization and this is exactly where federated learning comes

in as a key enabler of privacy preserving and distributed intelligence. Um so all of this is captured in the AI native uh network concept. uh where now AI is no longer a peripheral layer but

it's actually coming into the RAN right so uh this is enabled by what is called as this ORAN alliance particularly the RAIC or the RAN intelligence controller and this is how the whole uh sub 10

millisecond latency requirement is fulfilled uh but something that is not very clear here is um why do you really require edge intelligence right so to make it even faster and achieve this sub

10 millisecond you actually have to bring in uh um bring in inference and training to the edge rather than taking data to the cloud. Right? So that's where the whole

paradigm shifted and this argument about uh edge intelligence or edge native intelligence came in and uh especially something called as MEC or multiaxis edge computing also uh was introduced.

So this brought in a huge architectural change that is now we have the core network talking to RAN and then RAN talking to the B to the UEES um and this is where the whole you know the uh UIS

basically now have uh the intelligence along with the MEC uh controllers um so federated learning upon all these things one very important aspect that's how we relate to AI for good is that of privacy

right so think of the use case of traffic prediction where there's you know there's a need for loads and loads of data but you know this data consists of uh raw user logs location history or

I mean if you share it with the uh with the centralized controller it's just privacy violation so the solution is to now bring code to the data and not take data to the code right so that's the uh

that's where fedited learning comes in the intelligence now or the training happens at the edge and only certain metadata is given to the cloud um so what is this what is its implication in

telecom? So there's impact on privacy that's exactly where uh it it's supposed to make the impact and then of course there's impact on latency and bandwidth. So personalization of AI models is

possible in real time. large scale uh training can still happen in the core network but uh the personalization of smaller models for uh uh localized applications can happen actually at the

edge and there's impact on bandwidth because I no longer need to send data to the uh server and of course there's a huge impact on architecture because you saw there that it's becomes a

hierarchical uh style of an architecture where core network is at the top and user uees are at the uh bottom okay so uh I just wanted to introduce uce quickly introduce two use cases uh in

fact left it's in fact a use case from uh from France it was this is for um a traffic prediction in fact uh predicting certain traffic spikes when they had a football match and uh this scenario is

where you need to allocate dynamically uh resources for this particular stadium event. So here what's happening is each of these uh UEIES or base stations are picking up uh the traffic in their local

area sharing it with a core network sharing it with a MEC controller and then the core network is able to say how to really route the traffic so that you know there's less congestion. The other

one is V2X. So this is again for uh sharing road conditions or you know accident information and other things. It's very easy to see why uh FL may be useful here. Each cars can talk to its

own edge server and then go to the cloud server where the global model is trained. So this this sort of envisages how fed learning has become a very important technology. So last but not

the least uh I come from I have I'm the PI of the lab which is called as intellom lab at triple IT Delhi. uh we have a collaboration with IIT Delhi uh for this entire work on uh federated

learning on on systems and this project is funded by uh matey and the India initiative. Uh this is actually more of a security use case. I'll not go too much into the use case but we have built

a very similar I mean it's a prototype of the federated learning use case that I just showed you where we have like a main server we have some federated clients and uh we are looking at uh

certain security incidents that happen only at one client the client picks it up uh and then now the entire network knows about the possible security issues that can come up uh in such uh scenarios

and we have some couple of publications questions on this. I'll really not go into this. Um, thank you so much for the opportunity and please do visit our exhibit which is at hall 2 in mate

pavilion. Yeah, thank you. [applause] &gt;&gt; Thank you Ranida for the excellent talk. We had a introduction at least for federated running and also the framework

that architecture that she explained is really interesting. Last time when I uh colleagues were here we had visited the lab. If you haven't done that, please talk to her. It's an very exciting

research which they do and we also have great collaboration with uh BPI and colleagues in uh triplet Delhi. Thank you for coming. We have a panel now. Uh we have approximately 20 minutes maybe

for the panel. Let's uh kick off the panel. Can I invite Fred to moderate the panel and can I invite the panelists uh Mala Alagan and Sakshi to please take the

seats uh Fred to kick off. Thank you very much. Over to you Fred. &gt;&gt; Thank you. So I'm looking forward to this panel where we can aim to demystify edge AI a little bit and explore the

practical use cases and AI strategies. But first I'll introduce the panel. So the first panelist, her name is Mala. She has a full name, but she personally asked me to just call her Mala. And I I

wish all panelists would do that. It's much easier that way. So Mala is currently a technologist at the center of excellence wired and wireless technologies at at Art Park. Sorry, Art

Park. Prior to this, she was a post-doal research at the Teaang Group at Technical University Berlin. She's also involved in 6G initiatives such as AI RAM for efficient resource

allocation and millimeter wave communications and she also has been a visiting researcher at UC Davis and TU Berlin. All welcome. Our next panelist is Alagan Mahaling, founder, CEO, chief

software architect of Root Code. Alagan is the founder of root code and in his early 20s he worked as a researcher at international research organizations such as the geoinformatics center at the

Asian Institute of Technology Thailand also the University of Tokyo Japan where he worked on satellite communications and solar panel optimization algorithms. Alagam was also awarded the special

title of ICT entrepreneur of the year at the national ICT awards in 2021 and also the young entrepreneur of the year in 2024 and he's also the envoy for the government for the government of Estonia

e residency. So I see a lot of Estonia connections here today. Um last but not least we have uh Shakshi Gupta. So she's the global government affairs uh responsible for Qualcomm. Uh she's a

tech policy professional in AI and emerging technology policy analysis, market research and stakeholder engagement. So if we could have a please warm welcome for the panel. [applause]

So first question is is for Mala as an AI enabled XR applications and they're split between 5G and public sorry private 5G and on premise uh public 5G. Could you please give us some examples

of XR applications in different scenarios and what are the trade-offs in scalability, security, cost, quality of experience that you've seen in real deployments and

use cases? Thank you. So we at Artpack have developed several um applications um which is like uh AI and 5G enabled uh uh XR assisted um um medical emergency care and also on the

XR assisted u facility tour. So um 5G plays a major role in this uh both these applications and um um one of the application that uh we have uh developed is that uh XR assisted facility tour for

our art garage facility. So this um a art park stands for AI and robotics technological park and which is the DST's top innovation hub and um there are several startups incubated within

this uh facility and uh there's also a center for excellence in wired and wireless technology. Um so we have several 5G test labs and every year there is around uh thousands of visitors

who are uh um ready to um explore our facility. So in this scenario um XR assisted facility tour will [clears throat] be very ideal like um visitors from diverse backgrounds will

be wearing an XR going around the facility and exploring each setup. So um the inclusive experience is also included in this uh and they get the

immersive experience in their own preferred uh regional languages. And um the other um most one other um um application that we have done is the uh XR assisted medical emergency care. Here

the focus is on the um um to provide timely medical response to the uh patient who was um suffering with a cardiac arrest and so on. and um an SOS alert would be sent from the um by

the bystanders from the life circuit um XAP um to the um first responders and the uh medical experts and the ambulance through 5G connectivity. Um once the first responder gets the

alert he arrives at the scene with XR glasses and IoT variables and um also the AED kit. So um and while giving the CPR the um the IoT uh patient um vitals would be

displayed augmented onto the real time video and the real time video would also be sent to the medical expert and the medical expert will guide whether um to give continue the CPR or it could be the

uh AED and so on. Um so the family response will save multiple lives. So in this case we have used public 5G network but for the XR assisted facility tour we have used private 5G network. So the

private 5G network is mainly to have on premise edge AI applications and um this would bring the core next to the data generation and then we can also um do realtime decision making

for industry 5.0 applications and going forward we would like to have uh some of our applications in uh to be in the open source and um have it in uh the best place like I use the AI for good right

so then the international community uh can access this opensource uh AI models and um they can fine-tune the models and they can do the rigorous testing before it is bringing it to a um real

world deployment. Um that is what I'm looking forward for this. &gt;&gt; Yeah, thanks so much Mala and I think this really is a good example of AI for good in action and I think to your point

um these don't solutions or these solutions rather they they don't happen by magic. uh there's a lot of uh difficult problems to solve and by putting these solutions in the AI for

good sandbox um that might lead to future standards which could make them replicable and then you could have that adoption at scale. So I'll just go to the next uh panelist uh Alagan. Uh given

your rich experience in developing AI solutions for partners in different geographies, can you please give us some examples of edge AI deployment in real world scenarios, their impacts, the

nuances you see in AI strategies on edge AI in the different regions because I I from your bio you've been involved in many different parts of the world. &gt;&gt; Yeah. I I I started root code 11 years

back because I was in love with building AI solutions as a co student and then now 11 years later we the technology that we have built um is used by more than 92 million people across 27

countries including many European governments like government of Estonia, Portugal and many others. Um we chose to build edge in many cases um the obvious one to to uh to bring

technology to underconnected spaces and also to increase speed in many cases and and sovereignity and the most interesting project that we have done recently let me tell that story a couple

of years back Portugal realized uh that uh their farmers especially the smallcale farmers didn't get enough access to advisory and intelligence uh to grow their crops and things have been

changing because um climate change and unpredictability in growing crops. A lot of people were leaving uh farming and uh so we built a solution from a hardware a software products and also an AI model.

the hardware goes into the soil. So you understand the soil nutritions and then you take pictures with the mobile app and we can process the pictures to understand is there a problem with the

plant right and uh we built and it worked out fantastically well and then I tried to bring that to Sri Lanka. I I grew up in Sri Lanka and today a big part of our development team is in Colbo

and Sri Lanka more than 120 people and so we went into one of these villages in the middle of the mountains of Sri Lanka nowhere and uh I was super fascinated and then when we tried to uh deploy this

we realized they don't have reliable connectivity in some corners of the villages and uh uh our solution was worthless and that's where we started bringing in edge. So we we we brought in

a new version. We had a Raspberry Pi uh and and we started testing models like Gemma. We uh and also we did our own convolutional uh networks like 2D uh things to figure out like where do you

optimize? You don't want you don't want to use a LLM for everything, right? Um and by the end of it, we managed to bring the same value that the software gave uh to connected users in Portugal

to people who didn't even have internet in some part of Sri Lanka and that that reminded me how much edge is needed especially in the global south and u and then yesterday I was in a at a

dinner talking to some of the development finance colleagues from DC and somebody was talking about why don't we put computes on the wheels in a tuk tuk so imagine like we can't process too

many things on a small device of Raspberry Pi what if you get a tuk tuk coming to your village um every other day or once a week and with the data center built in with Wi-Fi land so

farmers can connect and do the processing um smaller banks, smaller institutions can do. I was like yeah so this week has been super fascinating and sometimes when we think about um edge we

think it's needed only in places that are not really connected like like rural parts. We have built this. We have built a beautiful solution that's used in America. If you if you think America is

well connected, you should take a road trip. When you go out of the city, uh you realize some parts are very disconnected. And we built for one of our clients, we built a solution that

helps rural patients who are at high risk uh with remote patient monitoring. And then yeah, edge works all around the world, not just in the in the south. Um I when I think about all my learnings

because there there are so many learnings building edge for multiple geographies, multiple customers, multiple uh communities. If I were to single out, I would single

out the fact that when you are trying to do something in the edge, we shouldn't try to think of the model and uh go find a solution. But instead think of the task and then work backwards on how do

you build uh and distill or or fine-tune a smaller model that runs on the edge because in the edge you can't do everything, right? I mean, if you are building a AI assistant for farmers, you

don't want the AI to to be able to tell why two of the famous CEOs didn't want to hold hands. I mean that doesn't matter. You wanted to answer about plants and agriculture. So the heavier

the model is it becomes impossible to deploy. So we work on multiple technologies to uh one quantize or prune the models in a way uh that that that that creates a smaller version that does

exactly what's supposed to happen. Yeah. And I think um uh the global south needs to grow with this AI transformation of the world uh because uh infrastructure takes decades but the next few years is

going to change the way we live and that's why we are here. So I'm excited to have this conversation. &gt;&gt; Yeah. Thanks a lot. And I think what you're saying here has almost been the

the theme of this week where you don't need the biggest AI or the biggest large language model. And I think if you look at the example of India where they've managed to enable billions to have a

digital ID to enable financial inclusion, financial payments uh with the public interest at heart and with you know relatively low tech solutions um you can indeed bring AI to the edge

in cases that make a lot of sense. So thanks for that. Um, Sakski, question for you. In your experience with Europe, the intersection of technology, innovation, and AI strategies, what do

you think are the metrics to evaluate the usage of edge AI such as availability and capability of hardware at the edge and also the connectivity, privacy, and data issues that you see in

your line of work. &gt;&gt; Thank you, Fred. And let me start by saying it's an absolute pleasure to be sitting with uh fellow panelists and speakers who have preceded me who are

deploying AJI and are doing research on AGI at Qualcomm. Uh we are uh very focused on AJI and think that that's going to be the future of how not just global south but globally we're going to

be using AI. So um and I really relate to uh what you said about the way to think about deployment of AI is actually to think backwards about what is the use case that you're trying to solve and

then you think about that what is the best architecture that you want to use is it the just cloud is it onrem is it uh an edge cloud or is it ondevice AI so we have to think about it from a

distributed architecture point of view when we think about the use cases that we have uh here in the globe South and I do want to mention one uh important distinction here that uh which which was

touched upon earlier also is that when we think about AI there's the training part of it and then there's the inferencing part of it. Inferencing is where you're thinking uh processing is

actually happening. So while uh training can continue to happen on the cloud a lot of it the lot of the inferencing as we are seeing is moving towards the edge.

Now in terms of uh availability if I want to talk about it I think we're increasingly seeing and Qualcomm is uh deploying this at the edge of uh you know AI being available at the edge not

from you know the very basic thing that we all use every day is your smartphones that we have on device capabilities coming onto smartphones with 10 billion uh parameters models already running on

device. So that means that you do not need to be connected if you're in flight mode, you do not need to be connected on internet and you can still use AI. So that's amazing in my uh point of view.

We also have uh it coming to actually cars. So Qualcomm has developed that technology where uh you can now use uh edgi onto the or it's actually in development. uh we have demos at the

call booth which I'll come to later but uh which you can uh so AGI is coming to the cars as well and uh it's increasingly coming to IoT devices um and your smart glasses um as well so in

terms of availability I think we are seeing increasingly that it's coming to all types of devices that are connected to internet uh now now why is AGI relevant and some of my

panelists have already touched on it I think latency Security, privacy, personalization, low cost, low power are all very important factors for why AGI becomes

important for global south. We may not have access to as much power. We may not have access to as much water as needed, but with AGI, we don't have to worry about that.

Um, apart from that, I do want to touch upon one thing that as Qualcomm, one of the things that we have is a program called Tech for Good. uh wherein we partner and work with uh startups and uh

small businesses around the world where we pro we invest in them we mentor them uh they use Qualcomm hardware to develop solutions at the edge uh in fact I do want to encourage that in hall four at

our Qualcomm booth we have some of these startups who are displaying this technology uh one of them examples is actually from India uh it's called Draxa health they've actually built an

ondevice uh AI healthcare uh assistant where you can for it's for doctors and patients both where the doctors can take down uh symptoms and uh provide solutions for their patients and for

patients to actually look up their prescriptions and be able to access all their records offline and ask questions about it. So yeah, I think that's how we're seeing the transition happen.

&gt;&gt; Thank you. Thank you. Um yeah, some amazing use cases and I think uh just weeks coming out of Davos where the narrative was all about go the insatiable demands for energy. uh

there's talk of putting data centers in space but I think this uh panel also brings things a bit down to earth where you know you can have AI on the edge and of course there's a lot of things to

solve there uh when it comes to connectivity uh when it comes to data uh compute I I think there'll be a lot of uh standards development work that needs to emerge from this to make this work at

scale but I think your your use cases and the way you're approaching the problem especially starting from the what are you trying to solve and work backwards from that I think it's very

refreshing compared to all the headlines we've been seeing lately and I don't see it either all I see it as you know a big piece complimentary piece of the puzzle so with that I really want to thank the

panel and if we could have a round of applause for thank you [applause] thank you very much Fred for running the tight panel now we are coming to the closing thank you panelists in

insightful uh remarks yes Okay, we done Can I Can I ask a quick uh group photo of the panelists, please? Panelists. Thank you very much. Thank you very

much. Now uh we are coming to the closing. There are there are excellent closing remarks coming. Can I please request the uh her excellency Miss Lopez ambassador permanent representative

permanent mission of the republic of El Salvador to United Nations office and other international organizations Geneva to please give her closing remarks. &gt;&gt; I'm actually based in New York. Thank

you. Well, good afternoon. I know that I don't have much time but I had just uh to say that this discussion was very enlightening. Thank you so much for sharing everything what you're doing on

the ground and I guess that it was very clear to me that HAI means simply using an AI closer to where things happen. That means closer to people, closer to services, communities rather than

deepening only far away systems. So amazing what you're already doing. So this can be important for development because it can work better in places with limited connectivity as we were

hearing and it can help with speed um coast and privacy since not everything has to be sent everywhere. So I guess that I had to begin also with something um I am also um the co-chair of the

global dialogue on AI governance. This is going to happen in July this year and it's going to be the first dialogue of its kind. So trying to also bring together what we have been hearing from

member states and also other stakeholders in these months. I can tell you three specific things connecting with what we have just heard today. first that people must remain at the

center and we have heard with all these examples and I guess that a common message that we have been hearing also in this week is that AI should be developed and used in a way that

protects but also help people. Second, closing the gap is not a slogan. We are hearing this a lot. It requires decisive support and I was very pleased for instance saying that you've been trying

to replicate in some countries what it in others for instance this information sharing this is critical if we're talking about uh closing the gaps and the third message the final one is that

we should avoid a world of disconnected approaches and this also is align what I was just saying that cooperation across different national but also regional approaches.

It will help us to reduce fragmentation. So with that, I just have to uh tell you that we're very looking forward to see some of you in Geneva in July so we can hear and learn more about what edge AI

it is. So it's my pleasure to give the floor to my distinguished um co-chair ambassador Rain Tamsar. He's going to explain you very very shortly what the global dialogue on AI governance is and

and this is really important a work that we are uh putting a lot of effort to it. Thank you so much again for the invitation. Thank you. &gt;&gt; Yes. Hello uh hello everyone. Uh frankly

I really feel humbled among uh real experts not to say uh I feel uh helpless. So uh please allow me then to do a little bit of uh awareness raising uh when it comes to the first global

dialogue on AI governance and maybe this way I'll try to fit into the discussion that we've heard here today. So three points on my side. First um about tasking. So the tasking was to put

together a distinctive identifiable UN global dialogue with all the elements that are prescribed in the uh mandate. So bringing governments and stakeholders to together to exchange

best practices and of course to focus on cooperation and to execute it backtoback with ITU uh AI for good uh um summit in July in Geneva produce co-chair summary. So this is what we uh are going to do.

So so far we've engaged with member states with stakeholders uh multistakeholders and from member states we we've kind of gathered three different approaches I would say a

little bit risk versus opportunities state ccentric approach versus multistakeholder approach closing AI divide versus free market innovation but we also were able to pick up three uh

convergencies practical outcomes preferred over endless theoretical discussions, alignment with existing UN processes, avoiding duplication, uh clear timeline, formats and thematic

focus to produce actionable insights and the unified element I would say in this discussions is that the dialogue needs to be inclusive and capacity building was absolutely crucial element that is

of course one of the most important uh uh things to uh global So from multistakeholders what we've heard the the key words so to say were trust transparency note application

interoperability equal access and participation for everyone rooting the dialogue in uh human rights and to be of a practical value and innovative in form. So um what we are going to do we

will guide the discussions but we will not predetermine the outcome. It's for member states it's for you for stakeholders. Um and of course we will engage also

with international scientific panel that was uh also established uh through the same uh um resolution. We will rely on member states and your wisdom. Uh we would need to collect this

wisdom somehow and uh and and this is something that we are uh going to do. Uh because we would need this wisdom so that the dialogue would be really inclusive. uh we would come up on

certain point with a road map to Geneva where you would see what are the building blocks uh towards the uh a dialogue and what are the opportunities to engage into dialogue and of course I

very much uh hope that you know all these fantastic ideas and frankly I mean shapo to the panel because you're already uh making or changing life on the ground and it's absolutely fantastic

we really need this also to um inform our dialogue and so that the dialogue would be also resultoriented on the ground. Thank you very much. Thank you very much your excellencies.

At this point I would like to call uh Fred to give out the momentos if you don't mind Fred please. And uh we can we have can we have the moments for uh Besa please?

Can I request not n officer to please uh felicitate uh &gt;&gt; uh Fred? Yeah, &gt;&gt; we have an event with &gt;&gt; Thank you very much uh for attending the

session. Session is closed. Thank you. Uh dear panelist, you are requested to please move out as the next session is going to start very shortly. Thank you.
