# Peace, Power and Perspectives: A Value-Based Approach to Trustworthy AI

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 19 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/iw8k7gsSCCc?feature=share) |

## üé§ Speakers

- Amlan Mohanty, NITI Aayog, GoI
- Heather Broomfield, Norwegian Government AI Unit, Norwegian Digitalisation Agency
- Hildegunn McLernon, Kongsberg Maritime
- Karianne Oldernes Tung, Norwegian Ministry of Digitalisation and Public Governance
- Mala Wang-Naveen, Norwegian Digitalisation Agency
- Morten D√¶hlen, University of Oslo Trusted AI for a Sustainable Global Future
- Niels Nagelhus Schia, Norwegian Institute of International Affairs, , Norwegian Institute of International Affairs (NUPI) Global Cooperation for Responsible and Trustworthy AI.
- Roberto Viola, European Commission
- Sindhu Gangadharan, Nasscom
- Yoshimasa Uno, Prime Minister's Office of Japan

## ü§ù Knowledge Partners

- Norwegian Digitalisation Agency (Digdir)

## üìù Summary

Against the backdrop of a rapidly evolving geopolitical and technological landscape, this session will examine how trustworthy AI can be developed, governed, and implemented across society. Key practical challenges in real-world AI systems‚Äîsuch as safety, accountability, sustainability, and governance‚Äîwill be explored.
The session will open with perspectives from knowledge partners representatives, representing research, government, and industry, followed by a panel discussion with prominent figures from across the globe.

## üîë Key Takeaways

1. Against the backdrop of a rapidly evolving geopolitical and technological landscape, this session will examine how trustworthy AI can be developed, governed, and implemented across society.
2. Key practical challenges in real-world AI systems‚Äîsuch as safety, accountability, sustainability, and governance‚Äîwill be explored.
The session will open with perspectives from knowledge partners representatives, representing research, government, and industry, followed by a panel discussion with prominent figures from across the globe.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/iw8k7gsSCCc/maxresdefault.jpg)](https://youtube.com/live/iw8k7gsSCCc?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Reason is simple. There is no such thing as trustworthy AI in one country alone. As President Mcron said at this summit yesterday, the old world says you compete or you lose. The new world says

you can connect and collaborate or you fall behind. In today's geopolitical landscape, this is not a slogan. It is a structural reality.

Major powers are competing for technological dominance. Supply chains are weaponized. Export controls shape alliances. Private technology companies exercise

geopolitical influence. Technology is no longer just innovation policy. It is foreign policy. It is security policy and increasingly it is trust policy.

From a geopolitical perspective, three dynamics matter for trustworthy AI. First technology structure power AI systems shape decision making information flows military capabilities

and economic compet competitiveness. The actors who design foundational models control cloud infrastructure or dominate semiconductor production shape the rules of the game. When

technology structures power, it also structures trust. If AI systems are developed within fragmented geopolitical blocks, trust becomes segmented.

If standards diverge, interoperability declines. If governance frame frameworks conflict, legitimacy erodess. Trustworthy AI cannot emerge from technological fragmentation alone.

And second, AI supply chains are global, but control is concentrated. Advanced chips are produced in very few places. Foundation models are trained by a handful of companies. Critical

minerals are geographically concentrated and this creates strategic dependencies and dependencies create vulnerability not only economic vulnerability but trust vulnerabilities.

If access to compute models or infrastructure can be restricted overnight due to geopolitical tensions, then trust in AI systems become fragile.

Resilience and trust therefore require cooperation across supply chains, across jurisdictions and across political systems. And third, AI affect democracy and so societal stability across

borders. Digital platforms shape public discourse. AI influences elections, information flows and political mobilization. We have already seen that elections do

not need to be hacked to be to be destab stabilized. Tempo amplification and algorithmic visibility are enough. These systems operate across

jurisdictions. Regulation is national. Impact is global. If you want trustworthy AI in democrat in democratic societies, we cannot regulate in isolation.

So what does this mean? Trustworthy AI is not only about model alignment or technical robustness. It rests on three layers of trust. First, technical trust that systems are

safe, reliable, and explainable. Second, institutional trust that governance frameworks are legitimate and accountable. Third, geopolitical trust

that states cooperate rather than weaponize inter interdependence. And without the third, the first two will not hold. And this is where international cooperation becomes

decisive. We need cooperation on standards and inter interoperability, transparency mechanisms across borders, agreements on dual use AI in military contexts,

safeguards against the weaponization of supply chains, inclusion of developing countries to avoid a widening AI divide and because AI

development becomes a serosome geopolitical contest. If AI development becomes a serious and geopolitical contest, trust will collapse into blocks and fragmented trust is not trustworthy

AI. So let me conclude with a simple observation. Trustworthy AI ultimately depends on whether we treat technological interdependence as a vulnerability to

weaponize or as a foundation for cooperation and collaboration. So thank you very much for listening to me and I will now introduce the next speaker which is Heather Broomfeld

uh who is the director general at the Norwegian digitalization agency. She has experience from experience from public and private sectors as well as academia and she has worked extensively on legal

issues related to data sharing. Her focus areas includes open data, artificial intelligence and datadriven government. And she has a PhD in law from the

University of Oslo on how to realize responsibil responsible datadriven public administration. So give her a big hand and Heather the floor is yours. Thank you very much Neils. Um so I'm

going to outline a framework for trustworthy artificial intelligence in the public sector that we use in Norway. Now I just want to preface this. It's not a formal framework or an official

framework that we have but it's very much the elements that we use for trustworthy AI um in the public sector. So we see a huge opportunity in Norway for um the use of AI in the public

sector both to deliver better and more timely and and indeed more contextaware services while also creating the efficiencies we so urgently need and these aren't just effic not we're Norway

is certainly not unique here in needing to create efficiencies with the public sector but at the same time we're hugely aware of the um challenges that artificial intelligence brings. We're

walking this tight rope here and I'll just show you kind of on the slide here as well. We're kind of walking a tight rope here of trying to get a balance for how do we

harness this really powerful technology while at the same time ensuring that it respects trust uh remains trustworthy because losing trust in the Norwegian public administration is quite frankly

just simply not an option. trust has been hard-earned over very many generations and it must be renewed every single day. So, we also don't claim to have all the

answers. I'm not going to stand up here and tell you all that this we have this all um solved in Norway. I don't think anyone would believe me. Um but we're building on very strong foundations and

we're putting new building blocks in place systematically, systematically [clears throat] and deliberately to enable innovation without compromising trust. that

balancing act that we're all trying to achieve. So, one example here is the establishment of our government AI unit in the digitalization agency of Norway, which I'm currently um uh leading the

establishment of. It's designed to accelerate innovative and responsible AI development and use. So, I'm just going to outline the six core elements of our framework and

you'll see them here behind me as well. So, first is legitimate and trusted institutions. Norway benefits from high institutional trust

and safeguarding these institutions is just simply non-negotiable. We cannot lose trust in these institutions. They must be safeguarded. Second is shared public values. In the

public sector, AI must reflect our fundamental values. Equality, fairness, accountability. We openly acknowledge risks like bias and power asymmetries.

And trust requires confronting these risks. We don't ignore them. Third then is robust governance. Guard rails must be in place if AI is to strengthen rather than undermine trust.

So we combine extensive national legislation governing public services um decades old legislation together with European regulation including the forthcoming transposition of the

artificial intelligence act the Europe um in Europe and we do complimentary law soft law mechanisms as well such as of course standards and guidelines and as our minister who will join the panel

quite soon um will likely elaborate upon we also um are safeguarding ing children online is also very high on the governance agenda um in Norway. Fourth then is high quality public data.

As Neil's mentioned there, it's very close to my heart. Um and AI is only as trustworthy as the data it relies upon. Deaf for decades now, Norway has collected high high quality public

sector data both to build and support our welfare state. This data is professionally managed and we it's highly um prioritized to share this data both openly and under controlled access.

Public data is merely not not merely a technical asset but is also a societal one. Fifth then is a well-informed and highly digitalized population. Norwegians are

digitally mature as exactly as as uh we um the population here in India and we but and there are very high expectations for transparency, explanability and fairness.

Sixth then is targeted research. AI presents very complex and often unpredictable risks as we are all aware of. Addressing them requires deep multiddisciplinary expertise. Close

engagement with research is therefore essential and Norway is investing heavily in public sector artificial intelligent research. One great example of this is the trust research center

which is organized this session and we are all members here. So the Norwegian digitalization agency is a core partner here along with many other public and private sector bodies. So it's very much

research public and private sector. So to conclude our framework as a balancing act and we tried to depict this on the on the diagram here be behind me. Each element is dependent

upon the other. So there's an interdependency here. If one fails the whole structure fails. We do not claim to have solved every challenge. Like all countries this is a

work in progress but Norway is entering this transformation consciously and deliberately. So that's thank you from me and I'm handing over now to Hilden Glen McLaren from uh Kongsburg Maritime.

[applause] &gt;&gt; Yeah. No, thank you very much uh Heather H and good afternoon everyone. So my name is Hilligan McLaren. I'm the senior vice president of technology office at

Konger Maritime. uh and I will show a little bit about AI in the industry. Uh it's similar aspects as the public sector um on many aspects uh and I will give some examples of also how we need

trustworthy AI going forward. So a little bit about Kong Maritime. Uh we are a leading uh global technology partner for the maritime industry specializing in innovative and

integrable uh systems that can enable a safer, cleaner and more efficient operations. So our products they range from uh digital uh and emerging technologies. We

have the energy systems on board vessel. We have the controls and automation including dynamic positioning for example. And we also have one of the largest uh portfolio of propulsion and

handling equipment. And all of this is serviced with 247 uh global customer support. We are today over 8,000 employees uh and operating out of 35 uh countries. And I think what's most

importantly when it comes to AI and digitalization is that we have equipment on over 30,000 vessel and this is onethird of the international maritime fleet. So you can imagine the impact and

amount of data and opportunities that are out there. Some of the drivers in the industry uh is uh shown on this slide. uh waterbornne trade is about 80 to 90% of

the global transportation. So it's a really critical uh factor across the world. It's also increasing. It's the most sustainable mode of transport and with an increasing population there is

an increase in also waterborn trade. At the same time we have a decline in uh workers in the industry. We need to attract talents. So we need to have attractive technology and we also need

to have smarter technology so that we can automate uh and have uh less people on board the vessel required in the future. The other trend is uh decarbonization

and digitalization. So the the maritime industry is going towards net zero by 2050. uh and we're doing this uh jointly using also digitalization as one of the key enablers using the insights that we

have from data to integrate solutions uh is really helping us to also have smarter integrable solutions that can decarbonize better and then with the increase of uh digitalization it's also

the increase of security threat and the focus on safety and cyber security in particular there is a increase in uh regulations. Uh and we see because we are a global industry uh the regulations

can be quite diverse coming from different uh uh parts of the world and it can be complex to operate in a safe and secure manner but this is one of the key drivers also on new technology and

we need to stay ahead and make sure that we have safe and secure operations. So what do we think that the future looks like? So we believe that in the future all vessel will be connected and

this is really uh shaping the next frontier of digital integration. This is changing the way that we're operating. So we will have uh to be continuously updating our solutions. The

vessels are built today to last for at least 25 years but the technology is evolving very fast. So setting up the correct infrastructure and also having the support from land is very key and

this can provide a lot of new uh solutions going forward. We will do remote support so you don't need to send a service engineer out on the vessel to do upgrades as we are doing today but we

will have more continuous and preventive maintenance and overthe-air upgrades. we can also integrate a lot more what's happening on the vessel, what's happening on the port and what's

happening in the broader logistic change. So the value chain integration uh optimizing the vessel performance and even the flea fleet operation will be possible in the future. And then we're

seeing uh the shift already we have some remote and autonomous vessels operating. It's really exciting technology and we believe this will really optimize how uh the whole industry goes forward with the

increase on waterbornne trade the lack of workers and attractiveness. I think having autonomous vessel and having remote support is really changing. So this is how we see the industry is

going and I think AI is really a key enabler in many of these aspects and here is one example. uh we have uh a lot of focus on hydrodnamic. How can we have a competitive and the best uh

equipment out there and we do a lot of developments and research over the years on hydrodnamic. Every hull and propeller are unique and then uh from the design we can also then monitor and collect

data in operation. So when we collect that data data real time information on how the propeller is performing, we can also then apply AI and learn from the patterns and we can optimize when it

comes to underwater radiated noise which will affect our biodiversity for example. We can have more efficient operation. we can have faster acceleration on fairies for example and

it can give many benefits like also preventing uh and um measuring wear and tear on the propeller and we can avoid that we will have failures in operations. So this is just one example

on what type of value will this type of data that we will gather um create. So that's uh we can apply AI and we are doing it today. We're doing a lot of research but what we see is very key is

we need to have the human interaction and we need to ensure that human accept uh and trust the solutions that we have. So bridging the gap between human expectation and the AI output it's

really key to us and that's why we are doing a lot of research into uh AI. um how can we uh make sure that we have robust and sound and secure solutions and that they operates in the uh

expected way. So one of the centers that we have joined is the AI research center the Norwegian center for trustworthy AI that is led by uh professor Martin Dalan from University of Oslo and I'll hand it

now over to him. Thank you. &gt;&gt; Thank you very much, Hiligan. If you have trust in something, that thing should be trustworthy. And if you develop something that is trustworthy, I

or anyone else should have trust in that thing. And trustworthiness and trust is kind of difficult. Some people will say am mission impossible. I will come back to this title. What we have done at

trust together with our partners we have we have three of four of us here even more and we have also have cintfare is that we try to define the direction where we want to go. The first direction

we want to have accuracy we want AI to be precise at least we want to know the precision. We want those who is producing a system to explain what's behind the hood.

We want AI to be fair, inclusive and protect our autonomy. We want AI to be safe, secure and protect our privacy. And we want AI to be sustainable. We want to develop green

AI for the green transition. And finally also want this AI to be well governed on all level and Neils talked about this both on international level on national level on organizational level and even

on individual level. However, D6 is not enough. We can do this in the lab or very locally. We have to scale it. So trustworthiness is also what happens when we scale things.

The title I have what uh is about that AI is heavy [snorts] industry. It's basically hunting for critical minerals. It's very thirsty because these data

centers is using a lot of water and it's uh also using a lot of energy. Where are the direction? Where are the pathways for this? It has been mentioned by both Hildigun Heather and Nils

different pathways here. What we see here is that we we have to move from large to small models maybe moving the intelligence closer to the edge. Within hardware side we have neuromorphic uh

development across the world. The most eff effective thinking instrument we have is between our ears. Neuromorphisms is about copying what we doing between our ears. And optimal comput optical

computing is about using photons instead of electrons. Data sharing is something we have to think about. Maybe we should also refine all the data we have around. Data reduction is something that many

many researchers are looking into because we are filling up data centers with a huge huge huge huge amount of data. And of course there are also research groups around the world

including trust looking at how can we organize data centers in the future. The other pathway is of course the governance pathway that has been mentioned

when we develop future environmental social governance frameworks we have to think of the AI awareness Neils also mentioned standardization also mentioned by header are there any what are the key

performance indicators for the futures because we can solve one problem but that might create another problem so these indicators are important to develop

And how do we prioritize earth health alongside human user needs? Human users, we are a part of the planet, but there are also other things on this planet. And of course, I am in favor of looking

into how can we tax these systems? How can we tax digital resources and use these types of money to really reproduce what we want in the future. So far, I've been a little bit negative. However,

there is also some positive things when it comes to AI because AI also can be a catalyst for the green transition. I don't have time to talk about all of these things. Uh this has been mentioned

by Hildig Gundils and and Heather. But uh one of the issues we are going into and one of the projects we are launching these days interest is that we combine climate data health data to look at

climate sensitive diseases and on Monday two and a half day from now we are starting a seminar in Tigali in Rwanda on these questions. My big question there are many big

questions within the realm of AI. Can AI help decouple economic growth from overuse of Earth's resources? Thank you very much. And then Mala, the bod is yours.

Thank you, Morton. And thank you to uh all our speakers. [snorts] Norway may be a small country, but we have always had a global outlook. From the Viking voyages to the polar

expeditions and to modern maritime innovation. Today, as you know, we are entering a new era of exploration, artificial intelligence.

[snorts] So, let us once again turn to the central question of this session. What does it truly take to build trustworthy AI? To deepen our understanding on this

topic, we are joined by an outstanding panel. as you can see. But first, as this is a Norwegian le session, it is my great pleasure to welcome our welcome Norway's Minister of

Digitalization and Public Governance, Kariama Tong. Excellencies, ladies and gentlemen, thank you everyone for being here. Also, dear co-panelists, thank you for joining

us here today. Um and thank you to Trust and their partners for and I would say particular the Norwegian Digitalization Agency for putting together today's program uh for raising this important

issue related to the responsible and trustworthy use of artificial intelligence. As we all know uh and I think we see it already, artificial intelligence will play a decisive role

in shaping future innovation, future growth and also future competitiveness. And importantly and I think this is the best sentence of today. So listen very carefully. [laughter]

I think artificial intelligence can help create a better world by reducing inequality, improving health and safety, supporting green transition, and promoting creativity and education.

However, to realize this potential, AI must be safe, it must be trustworthy, and it must be secure. It is a priority for the Norwegian government to establish sound and reliable frameworks

for all development and use in this era. [snorts] In Norway, the government is taking action. We are in the process of implementing the EU AI act into Norwegian law and we are also ensuring

that Norwegian actors have access to high performance computing and data storage capacity and also we are developing national foundation and language models that everyone can use

free of charge. At the same time we are establishing something we in Norwegian called Koi Nora. It's directly translated to AI uh Norway even that is might not the official title yet we are

working on that one. Um but I really believe that this establishment of AI Norway uh will strengthen national guidance on responsible use uh of AI and if there is one thing I hear from

business leaders or if it's the public sector they are uncertain. So establishing this good body of guidance will be really important to make sure that we adopt and implement and use AI

in a proper way. We are also investing in knowledge. That's why we are here. That's why we're here at trust. Norway has allocated more than uh 1 billion Norwegian crowners. That is about 100

million dollars uh to six research centers on artificial intelligence and trust is of course one of them. At the same time and crucial for success, Norway must cooperate with likeminded

countries. We are already already participate actively and exert influence through the UN, the OECD, GPI and the Hiroshima process which was the first global framework on responsible

artificial intelligence because we must learn from each other. Simply but hard enough. We must continue to build and share knowledge about the implication of the technology. Together, we must

develop technologies and governance models that build trust in public authorities, in public and private services, and that support democratic values and foster trust in society.

Together, I believe we must contribute to and not least ensure the practical implementation of an international frameworks for responsible AI. So, I'm really happy for this opportunity to get

together and discuss from our different perspective and also I am really happy and impressed by being here in India and Norway as a country as well with the FFA India trade agreement. I can see great

opportunities uh for the future for Norway and India also to work together on the green transition and the maritime industry with health tech and also of course with the digital technology and

artificial intelligence run across all of those sectors. So by that thank you so much for the attention. I'm happy to be here. [applause] Thank you. Thank you so much uh

Minister. Um now we're moving over to the panel discussion as promised to bring some more global perspectives to this session and I will just do a quick introduction. Uh from that I'll start

from that side. We have Lana Ronarate from Brazil and you can see the details of course on the screen. Um we have from our host country Amlan Mahanti and Sindu Gangadaran. And from Japan we have Mr.

Yukio Termura and of course our minister here. Um I have uh challenged you all for a quick lightning round and um since our minister you're going to leave us a

little bit earlier. I heard [laughter] we'll get a signal I'm sure um from where you sit. What does trustworthy AI means to you? So that's supposed to be short but sweet.

&gt;&gt; I I can be really short. It means that you should trust the technology and then buy trust society, trust businesses, trust politician, trust authorities, trust your friends.

&gt;&gt; Sounds good. &gt;&gt; Yeah, Mr. Termon. &gt;&gt; Okay. uh trust AI is fundamental to the AI governance policy of the Japanese government and the Japanese Japan is

committed to the balancing and the promotion of innovation with risk management and Japan launched the AI basic plan last December and uh it's also stipulated that by the pursuing the

transport AI and Japan aims to become the most AI friendly country in the world. &gt;&gt; Wonderful and we will hear more about that AI plan later on. Yes. Then we'll

move on. Oh, you I don't have a microphone. Oh, sorry. We have to share these. Mala, I think I'll keep it short. For me, I I I reflect back on what what I heard earlier on. And for me

personally, it just can't uh trust in AI just can't be about accuracy. That's one important piece. But it has to be also about uh reliability. I mean, you need to be able to rely on the outcomes,

right? And it's also about uh transparency. very important is uh fairness and finally I think it's also about accountability having somebody who was like okay that's the decision uh the

algorithm took but still I stand by that decision right so these are five important aspects for me &gt;&gt; very important and then yes we have to share these microphones

&gt;&gt; no problem at all two things for me um to trust something I need to understand how it works and two is I want agency so I want choice choice in the matter in case I don't trust something I want to

have an option. So that's the two things. &gt;&gt; Thank you. Well, uh thank you for the question. Uh in my point of view, I think uh to be trustworthy, it needs to

be inclusive, sustainable and also respects human rights and national jurisdictions. Sounds very good. um to reflect a bit on the values

concerning us all. Yesterday, Prime Minister Modi spoke about the importance of protecting children and young uh people from the risks of AI. And you've also been Minister very clear

that safeguarding children online is a priority for you and for Norway. Could you shed some light on what are you doing to uh protect Norwegian children and youth?

&gt;&gt; Of course. I really believe that children and young people have the right to be as protected in the digital world as in the physical world. Uh and as by now they are not. Uh when we leave our

children at schools or they play with friends, there's always adults there looking after them like looking over in the digital world. No one is there to take care of them. Um the big tech

companies today, they have a lot of power. They gather a lot of data. uh we can see examples uh which is not very nice uh uh on what children are being exposed of. Uh it leads to pressure uh

bullying even examples of suicide as we have seen. So there is a real need to protect children and young people online. Um that's why the Norwegian government now are proposing a age limit

on social media on 15 years old. We are working together with partners in the uh in the European Union also and I'm really happy that I heard both President MRO and and Prime Minister Modi

yesterday. That was great news. Uh I I feel that more and more countries are coming aboard because we are starting to see the real consequences. Uh but also we have to regulate the the tech

companies uh as well or the social medias when it comes to uh dark patterns uh dependencies algorithms and so forth. uh we have uh launched or we we had we are we are right now having a white

paper at the parliament in Norway as well and at the end I have to say it's right to find the right balance because we want to bring up children in this world that have digital competence as

well they have to learn to to use the technology and to understand the technology and to do critical thinking as well so to find the right balance uh is about giving the teachers and and the

adults the right competence to teach the the children the right things as well. So we have to be able to have two thoughts in our heads at the same time. &gt;&gt; Absolutely. And having um a safe

society. It's also about social stability which brings me over to you Mr. Turkamura. Japan is known for bing balancing innovation and and social stability. So how is this um uh this

philosophy so to speak reflected in the new national AI strategy? &gt;&gt; Okay. uh the utilization of AI is directly linked to the industrial competitiveness and uh national security

[snorts] and it's ideal to uh actively utilize AI to address social challenges uh accumulate experience as data and share it across organizations thereby aggress accelerating innovation and

creating a vious uh cycle uh that further promoted its utilization. And Japan is facing the declining the birth rate and an aging population and leading to the uh gradually shrinking

society and [snorts] but making utilization of AI leading the increasingly important. Nevertheless uh unfortunately AI has not yet been actively utilized in the um daily life.

Uh so um because it is recognized that the utilization of AI involves the various risks for example uh the technical risks such as misjudgment harshations and inappropriate

inappropriate output and uh social risks such as discrimination and bias and criminal use uh infringement of the privacy and intellectual properties and uh another one is uh the national

security risk including uh cyber attacks. Yeah. So these risks cause public anxiety. Yeah. So um in the AI basic plan uh sorry the the therefore the pursuit the

trust AI is not only essential for the dis disparing public concern on risks and but also crucial factor in actively utilizing AI and promoting innovation. Yeah. So in the AI basic plan, Japan

pursue uh further promoting innovation while mitigating risks and we will deepen the balance to ensure a human- centered AI society where individual dignity is respected so that people AI

can work together continuously and uh pursue trust AI to realize the most AI friendly country in the world. &gt;&gt; Thank you. Uh building on that you mentioned AI friendly. I will move on to

you Am Gangadaran. You're often described as a technology humanist. We have I just have to ask you about that. What does that mean? &gt;&gt; Well I think it's very simple Mala

because um technology cannot be there for technologies sake right I mean we have technology to make the lives of people better and life of and communities better. And probably it

reflects back also on the whole theme of this AI impact summit that we are having here right it's really about how do we take tech take it forward how do we bring bring people forward I love what

uh the minister was saying I mean it's finally about how do we make it real for people to consume right so for me it has always been not about hey what's the latest and greatest technology but

really how do we use that technology to shape and change uh uh I can just give We I know we are all talking about AI at this point but uh if I just also reflect a few years back right I mean we had a

massive pandemic right and if I just take that example um you know the second wave of the pandemic was quite uh tough for India at least many of you here in this uh audience would still remember

that um uh but but at the same time I I still remember how all of us kind of leveraged technology and um back then the the biggest need of the R in India was to track the the oxygen supply chain

along the length and breadth of the country. And I if I put on my SAP hat, I I work for SAP and back then it was really about how do we identify the top oxygen manufacturers in the country and

use technology to be able to help the government of India have this digital dashboard that helped them to very quickly track um the oxygen supply chain right and um it was almost leveraging

technology over the weekend uh right because 80% of the oxygen manufacturers in the country run on SAP but that's besides the fact but we were it's about usage of technology for people and to

save lives right for so that possibly goes back to the tech humanist what you're talking about [laughter] &gt;&gt; no excuse me we'll do the questions later please sit down please thank you

uh we &gt;&gt; was it a pandemic or a boware please sir please sir thank you um well actually uh following in India through the pandemic was quite impressive from

Norway. I remember my uncle asking me for if I had the vaccine and uh he had had it like a year ago and I we didn't have the vaccine. So um okay, we're going to move on uh to Emlan. Um when we

had our like u prepare preparatory chat there were so many things you could talk about but I'm going to stick to the fact that you're a tech lawyer and adviser to the Indian government on the AI

guidelines. Um I was wondering how would you describe the values that the policy it is um uh is built upon? &gt;&gt; Yeah look values you know I'm going to interpret values slightly holistically

here. So I'm going to talk about values in the sense of what's the spirit driving this uh the guidelines the governance framework its approach to trust and I'll just start with optimism.

I think India and you could hear this in Prime Minister Modi's speech yesterday is it's driven by a sense of optimism and so even when we're talking about governance it's an expansive view of

governance. It's not about containment. It's not about you know regulation or risk mitigation only. It's also about driving adoption and the importance of capacity building and all of the things

that Minister said early on right um so I think that's the largest spirit in which we're talking about it when it comes to you know value specifically I think it's uh you know embodied in what

the theme for this summit is which is inclusivity equality you know access so that's actually driving a lot of what the spirit of or the values of the governance guidelines are so you'll see

these referenced in the OECD you'll see this referenced in the GP GPA conversations and what the UN is doing and I think that's what India has also internalized in its governance

frameworks. So you know that's about spirit the optimistic spirit clearly on display here at the summit thematically value based I think in uh terms of what the core values are um in the summit but

I'll say in terms of actually implementing it I think the approach that we're taking in India is that we don't know need to reinvent the wheel these values are embedded in our

constitution these principles of fairness and equality are constitutional rights that Indian citizens have and there's no reason to believe this doesn't apply to AI, right? So, it's

really about ensuring that these same values trickle down across from the constitution to how laws are enforced through how guidelines are implemented by all stakeholders including companies

including how public officials enforce these laws. So, I think that's the light touch kind of uh regulatory agile approach that we're bringing to our governance framework in India.

&gt;&gt; Thank you Amlan. Um you mentioned the optimism and I'm just um sensing that the same might be the case in uh Brazil. Uh Lana uh Brazil and India are both uh part of the bricks

grouping. Large democracies with fast growing economies and increasingly influential uh both countries in shaping global the global technology debate. Um and you have also in Brazil launched the

national artificial intelligence plan. Um what values are uh upheld by that plan? &gt;&gt; Thank you for your question and for having me. Well, I think it's important

to say that for Brazil and specifically the ministry which I represent here, the ministry of management and public services understand that AI is not a matter of technology alone. there's a

lot about uh an understanding of and the need for behavior that is responsible, ethical, transparent that promote inclusion as well. So the the plan that we recently launched bring all these

values brings the value of sovereignty as well to work with this this important uh topic and uh you know that Brazil has uh for the last two decades at least worked a lot with concepts related to

digital public infrastructure and it has been very important for us to to promote better services to our population and we understand that AI I can help us to go to a next step and provide more

personalized and more proactive uh public services to our population. But we also understand that we need to mitigate uh the risk the challenges and to do that in a very responsible and

ethical manner. And we have been working a lot to promote that especially related to to data governance, data infrastructure and to to to safeguard all the human rights and dem democratic

values in this uh uh great endeavor that we are dedicated to. Thank you, Lanna. Um, I just got a signal that with five minutes left, I don't know where time went. [laughter]

So, back to the minister here. Um, Norway often speaks about digital serenity or digital agency. Uh, minister, what does that mean in practice for us? Very, I mean, we're

sitting here to next to quite big countries. What does it mean to a small country? &gt;&gt; It means everything. uh talking about digital serenity which is really the big

topic of all discussions I would say today. Um first of all uh Norway is a small country 5.5 million citizens. Uh we can't be self-sufficient in in in the digital world. We need cooperation. We

need to work together with like-minded countries. Uh digital serenity is not about one thing. Digital serenity is about a lot of things. It's many layers. It's a a whole value change. It is about

everything from regulation, guidelines, framework, but also about critical minerals, semiconductors, data centers, fibers, connectivity, software, hardware. The list is very long. That's

then that's why you understand Norway can't be self-sufficient because it is about lot of things. Uh but um it's important for us to have the ability to act, to have alternatives. Um I think to

have control uh we can have control through regulation uh ownership uh collaboration uh working together and that's the strategy that Norway has chosen because a lot of different things

can happen. Uh we have climate change fibers networks can go down. Uh we need to work on the robustness of that one. Uh cyber attacks already mentioned we have political risk which is also uh now

uh important for us. So having the ability to act uh and work together with like-minded countries is uh is the important thing for Norway to do and and that's why also I'm happy to be here and

feel the spirit from from India as well and I'm really impressed by the work that has been done here when it comes to inclusiveness and scaling. I think we have a lot of things to learn in Norway

from that one. &gt;&gt; Thank you. Um I would very hard would you like to add something? &gt;&gt; [laughter] &gt;&gt; All [gasps] right. Um, we have to we're

moving towards the end here, but just a quick uh question for you. Um, Sindu, India being a complex nation with quite the opposite kind of like large population uh in terms of size and

demographics. Um, for business AI represents a competitive advantage. At the same time, one has to sort out what's the hype, what's the uh what what will bring actually value to the

business or the country um as a whole. So I would just like a short remark from you. Um what do you think India is doing in terms of like making the right choices at this very moment?

Well, I think most of you have probably experienced it firsthand over the last days at the summit in terms of the right choices India is making, right? If you uh you talked about digital public

infrastructures earlier on, I mean, think about bringing together a nation of 1.48 billion, right? Uh so we've done that, right? And leveraging the power of technology and that is a little bit of

the foundational work also when we talk about AI. How are we bringing in AI to solve the needs of the the country? Right? Bringing it into education, into health care, into um agriculture, right?

All of these very pertinent needs of the R is what we are focusing on and making it inclusive right for the people for the um um various states and according to across the length and breadth. So

that's a little bit uh and at the same time what you're also seeing from a tech perspective mala for all the business community here in the room we have a phenomenal tech ecosystem at play a

consumption ecosystem at play. So the market is phenomenally growing. We're talking about a 7.8 7.5% GDP growth and poised to become the third largest economy in the world very soon. So in

that sense the time is right. So I can only say uh we are all about partnerships. It's all about inclusion and we want to leverage tech for driving forward some of those uh large topics

that I touched upon. &gt;&gt; Thank you Zindu. And um it's obvious that regulation alone will not uh build trustworthy AI uh nor by innovation alone. I think um it will be built I

from this summit that's my what I gather that it will be built in the intersection of uh values uh maybe power and also perspectives that you've shared today. Um this summit has really opened

its uh opened its doors to the world and and perhaps that is the real takeaway that no nation can build trustworthy AI uh all by themselves. We have to cooperate.

So thank you to our wonderful panel and thank you to our wonderful audience. Thank you and and [applause] please if you want to learn more uh

about trust there is a QR code on the screen appearing soon. Please just find out more. Thank you.
