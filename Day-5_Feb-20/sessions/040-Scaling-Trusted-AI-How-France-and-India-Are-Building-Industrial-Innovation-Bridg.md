# Scaling Trusted AI: How France and India Are Building Industrial & Innovation Bridges

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 18 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/48AFNBB9_tU?feature=share) |

## üé§ Speakers

- Arthur Mensch, Mistral AI
- Arun Sadheesh, TNP Consultants
- Frederic Lelong, Atos Group
- Naila Giovanni, Technip Energies
- Sandeep Kumar Saxena, HCL Tech
- Valerian GIESZ, Quandela

## ü§ù Knowledge Partners

- Business France (French Trade & Investment Commission)

## üìù Summary

This flagship Indo-French session brings together government and industry leaders to advance trusted, responsible, and scalable AI. Featuring keynote visions from India and France, moderated dialogues, and a high-level panel, the event focuses on AI infrastructure, industrial deployment, deep tech, and sovereign data systems. It strengthens bilateral policy alignment, catalyses industry partnerships, and accelerates joint R&D, positioning the India AI Summit as a premier global platform for AI cooperation and innovation.

## üîë Key Takeaways

1. This flagship Indo-French session brings together government and industry leaders to advance trusted, responsible, and scalable AI.
2. Featuring keynote visions from India and France, moderated dialogues, and a high-level panel, the event focuses on AI infrastructure, industrial deployment, deep tech, and sovereign data systems.
3. It strengthens bilateral policy alignment, catalyses industry partnerships, and accelerates joint R&D, positioning the India AI Summit as a premier global platform for AI cooperation and innovation.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/48AFNBB9_tU/maxresdefault.jpg)](https://youtube.com/live/48AFNBB9_tU?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

We were also very proud yesterday to uh to welcome um the different leaders uh who came for the summit and especially uh uh Prime Minister Modi and President Mran uh to come on the pavilion and

discover the companies and uh and speak with uh our companies. So as you see uh through this uh week uh the the French AI delegation was uh actually uh more than uh what you are

seeing on the pavilion altogether it was about 100 French companies uh who came and uh actually you can uh when you will u meet them uh you can find in different sectors like quantum ready photonix

secure hai mobility system cyber security, digital twin and green techch and actually all of them brought uh and they are all convinced and trust that uh AI is the next uh frontier. So now just

to share with you what is making this week uh very special. Um actually it's uh as you with what I uh said you can see that it was very intense that's for sure. But uh it's not

only intensity actually as you will see it's uh also a lot of results achieved and result with real partnerships real signature and real commitment between our two

countries I will just name a few uh for the the AI um just maybe the first with Zasia technology and uh GT solved uh where they signed a strategic partnership on Monday evening in

Bangalore at the French consulates during the French AI night and that really shows uh strengthening of Franco Indian cooperation and engineering automation in intelligent design. A

second one in a different sector between Exot Trail uh and uh DUVA space where they signed a major major contract in the space industry uh to deliver 14 satellite propulsion system along uh

sorry with which is also a very strong symbol of uh the cooperation between France and India in terms of space. Another signature between H company and St. James Hospital and uh a final one

that I can mention is actually u a partnership with between the North Friends Invest and the TAB that are uh actually uh uniting al together which uh will create new bridges uh between

actually one of the most Europe uh most dynamic industrial region and uh one of India most powerful innovation ecosystem. So as you can see when we see all these

signatures and I'm not just talking about AI uh the you can see that the dynamism between France and India is very strong but now actually when you see all this

it wouldn't have been possible without the strength of our collective network and uh business friends the trade and investment agency is really proud uh to collaborate and we have collaborated

very closely with different partners with definitely uh La French Tech and thank you uh Julie uh for the long-standing partnership supporting the French startup and uh for bringing all

these startups here in India with Num the leading French digital and tech association helping the structure and mobilize the presence of French AI champions in India

also So uh some other partners UA advisory aros but also the co-organizer of this event this panel at uh the main summit the Francoai Chamber of Commerce Indrrench Chamber of Commerce if

I'm I'm still in my so thank you thank you to to all of you. Uh now we are actually uh arriving to the today's session. Uh we're uh we are gathering today most influential leaders

shaping the future of AI. So I won't be long but um we are really honored to welcome Judy Yug director of the mission French tech also Arun Sadesh associate partner and country director for TNP

consultants uh nilakan veta karam vice president and global business head uh cloud AI and age from Tata communication valerian giz co-founder and CEO of Candela Dr. Dr. David Sadek, BP research

technology and innovation global CTUI and quantube computing from Tales. Sandep Kumar Sand Sakenna, Chief Growth Officer from HCL Technologies. And finally, uh, Tanoj Bal, senior

director customer solution experience from Daso Systems. So we'll be uh really happy to uh to hear your experience and um and before I conclude just uh to thanks also our

partners uh because you know this event has been also been possible thanks to them our uh platinum sponsors CMSGM total our gold sponsors BNP Pariba uh Capge Gemini Schneider Electric and the

silver sponsor MBD again thank you very much uh all of you uh thank Thank you to our co-organizer ifki and I wish you um a fruitful uh se session sorry um maybe just before I end also a big thanks to

um the teams the different teams uh business friends teams but all the French team all together who worked like crazy uh to make this week possible. So thank you so much and have a great

session. [applause] Thank you very much Estelle. We now move forward to our keynote address. It is my pleasure to invite Miss Julie Eujay

director La French Tech. Julie leads one of the world's most dynamic innovation ecosystems. La French Tech representing thousands of deep tech companies and scaleups shaping Europe's techni

technological leadership. Julie, over to you. &gt;&gt; Thank you. Good morning everyone. I'm Ascara. I'm Judy. I'm director of the French tech mission. So, we support the

growth of French startup uh in France and abroad. I'm truly delighted uh to discover the tech ecosystem here in India, a countries that trains around 1.5 million engineers every year. I

think it's the highest numbers in the world. So I'm very impressed. Um the AI impact summit is an opportunity an opportunity to create more bridges between France and India. Uh and exactly

one year ago actually we hosted the AI summit uh in Paris. That moment helped us uh helped our ecosystem to uh structure itself. It was the opportunity to attract investment to unlock talent

to accelerate um the creation of our French startups. Today the French tech ecosystem is uh strong and uh ambitious. Uh according to the room the top free AI ecosystem

globally are now San Francisco, New York and Paris. We are very proud of it and we are really sure that the AI summit helped us to build this strong ecosystem across France. Uh AI is becoming a

pillar of our industrial transformation. We already have major European leaders such such as Mistral AI or H company and I'm convinced that the AI impact summit here in Delhi would be as valuable for

India as it was for us. for the French tech. This week in India was of course a great opportunity to showcase French innovation but it was also an opportunity to deepen our

partnership with India beyond business. Uh I I'm truly convinced that we share common values trustworthy low environmental footprint positive impact for humanity. We support

innovation when it reinforce our economies of course but also when it brings real progress for humanity. Innovation only makes sense when it serves the greatest numbers number. And

to give you a concrete example, uh the French president MR announced yesterday that H company Sanjun's hospital in Bangalore have started a collaboration to make offic hospital more efficient

and to contribute to save thousands of lives in healthcare, in agriculture, climate and many other sectors. Franco Indian partnerships are key for innovation with real impact. This is why

I was really happy the all week to be here with outstanding French startups, companies already work working with India like I said told us a bit earlier and other ready to build strong and

strategic partnerships here and maybe I will introduce a few of them. Agrico is transforming agriculture through digital tools that connect farmers directly to markets. Watlab genomics uses artificial

intelligence to accelerate gene therapy development. Condela is building scalable quantum technologies that will shape the future of computing and each company develops advanced AI agents

capable of computer use to perform complex task autonomously just like a human would. For these innovations to become global leader international develop development uh is key.

And we all know that uh the world is changing. Economic alliances are evolving. We see it with Canada, Latin America, Gulf countries and obviously here in India.

Today India represents scale. 1.4 billion people, two f 200,000 startups. It's huge. France represent deep tech excellence, scientific force, industrial

capability and I think this complimentary is powerful. In France we like to schedule meetings weeks in advance. In India we learn to be a bit more flexible and honestly

innovation also requires agility and perhaps a bit of Indian wisdom. That's what we learn as well this week and it was like Estel said a very important week for the startups who came with with

us. So I wish you all a good session and a great day and uh thank you for being here with us this morning and Daniel thank you so much Julie. We will now move to our high level panel discussion

where leaders from telecom, quantum, industrial AI, cloud infrastructure and enterprise digital transformation will reflect on how our two countries can jointly accelerate trusted AI across

sectors. I am pleased to introduce our moderator for this session, Mr. Arun Sardesh, associate partner and country director, TN consultants.

Joining Arun on the panel are an exceptional group of leaders. Nilakantan Wenataman, vice president and global business head cloud AI and edge Tara Communications

Valerian GZ co-founder and COOW Candela [applause and cheering] Dr. David Sadi, Vice President Research, Technology and Innovation, Global CTO, AI and Quantum Computing, Tales.

Mr. Sepkumar Sakenna, Chief Growth Officer, HCL Technologies. Tanoj Mittal, Senior Director, Customer Solution Experience, DAO system. &gt;&gt; [applause]

&gt;&gt; With that ladies and gentlemen, it is my pleasure to hand over the session to our moderator Aron. &gt;&gt; Thank you. Uh thank you Salonyi. Uh good morning everyone. Uh it's actually a

pleasure and uh a privilege to be part of uh uh this summit and uh being a moderator to such an esteemed panel. I would like to start by thanking business France if key and uh um the AI impact

summit organizers to giving us the opportunity to discuss something that is very important about uh trusted AI. So maybe I'll start with uh actually what happened here yesterday. Um the u uh our

prime minister talk about uh human uh uh manav is the concept that he uh he introduced. uh our French uh our president uh talk about uh scaling and uh he used uh UPI uh the Indian uh

payment uh system uh as uh a good example of scale and if you really think about it there is uh a large element of trust involved in it. The way that uh in India we uh accepted u uh UPI means we

trust it and when we trust things scale is possible. So usually when people talk about uh topics such as scale or uh sorry so trust or safety uh there's a bit of u uh pessimism at times uh

talking about challenges uh but in this particular session I'd like to be more optimistic and uh present trust as the only way to scale um we if you want the large corporations the banks the

governments to adopt AI I uh they need to trust us and only when these organization adopt AI we can really achieve uh scale. So so that's that's the um you know I'd like to set the tone

uh with that comment. Um and maybe uh you know in the last 5 years especially after covid uh we have facing changes uh quite rapidly right I mean uh things are moving from one thing to another. uh we

all started our career uh and today we are talking about uh AI. So a lot of evolution uh in our lives as well. So I want to start uh from that point uh uh to introduce yourself but also uh tell

us u uh the evolutions that you have gone through and how do you define trust. Maybe we'll start with you Neil. &gt;&gt; Thank you. Um a very warm uh good morning to all of you and thank you

business France uh for having me here. Uh it's a pleasure to be here and talking to all of you and hopefully we'll have a nice interaction. Um uh so personally uh you know

we've been uh uh so just to introduce myself I head uh b cloud business for Tataccom which includes your general purpose cloud now AI cloud uh edge uh and uh dedicated private clouds for our

enterprise customers uh we are an international company 80% still comes from India and 20% comes from outside of India uh so Uh so we were uh as part of our cloud business we did have

uh a large a IML offering and uh about four years back uh when suddenly the transformer architecture came into the scene uh we were uh uh you know we didn't know about it at all actually we

were I would reckon that we were like uh we were we didn't know about it at all and uh so when it came up uh you you know we thought uh what is this new architecture which has come up and how

it's going to impact and openai and chat GPT came up and then we started thinking how we going to apply this to our businesses internally and also how we going to offer it as a service to our

customers uh so our journey has been a journey of learning a lot in the last 3 years I would I would say all of us are learning and and uh it's been uh pretty fastpace uh it's been pretty steep in

terms of uh technical We had to uh uh you know through the organizational levels right from the CEO to the bottommost we had to do learning of what will it take uh for this new

world to adopt Genai and how do we adopt Genai within the company and outside and offer it to our customers. So uh tremendous uh you know scale of uh uh changes and the potential for innovation

for our uh customers and for the company. So now we have uh we established an AI COE within the company about three and a half years back. Uh we had lot of uh pilots which were going on

within the company and now they are into production and uh similarly for the uh our customers and enterprise world and beyond enterprise government and uh uh you know institutions which work very

closely with government who work on citizen scale projects all of us have seen that right so truly in the last 5 years it's moved from um I would say PC's and pilots to now production and uh

production at an entry level. I would say scale is yet to be achieved. uh it's production uh to say that okay there is a uh return on investment uh in the enterprise context and there is uh

reasonable outcome for citizen scale projects and therefore we should start uh putting it into production and then of course scale it and scaling means that trust has to be put on steroids. So

let me talk about trust now. uh so I would uh you know describe trust as something which is uh in a very simple word I have your back and I will not fail you right that's trust uh you know

beyond that there's nothing so uh when we deploy these systems the the stack and then we when we deploy the use cases and the applications uh you know inherently trust has to be

foundational element uh it cannot be a bolt-on on top of what we have built. So it has to be built at every layer and u uh trust has also evolved within AI system in the last 5 years. You know it

started off by you know because it was an PC pilot so you're not really exposing it uh to the end users in a big way. It was in a closed group user group and therefore it was more of good to

have but now it's moved to foundational. more architectural in nature, right? Every element of the architecture needs to have trust built in. Um and u and from a regulatory point of view also

trust has also evolved, right? So earlier uh it was all about okay uh a soft guidance on trust saying that you need to be uh you know ethical you need to have transparency but now it's in the

baked in into the regulatory policies and requirements uh whether it is the DPDP which has been operationalized in India or the EU AI act which is already operational. So now it is you know it is

in black and white. Uh and uh from a technology point of view as I said uh trust is foundational. It is architectural. Uh whether you have explanability built in in terms of the

outcomes whether the behavior of the systems is predictable. It is explainable. You should be able to explain. It should be auditable. uh the data which is fed into the models and

trained and the inferencing happens and the data and the outcomes which happen you need to have a very clear data lineage you need to have end to-end governance and we talked about edge

computing I think uh we talked about edge so you need to have governance end to-end governance uh we talked about billions of devices which could be inferencing at scale and therefore

whatever happens in the cloud and what happens at the edge you need to be able to uh you know the entire workflow and the process has to have end to end visibility in terms of uh uh the uh

governance and finally resiliency is also trust uh it should not be broken. So from data communications point of view when we talk about it trust being the bedrock and foundational element of

AI and therefore it will scale while you put it to production we meant at every scale at the infra infra level we build in some of the trust components uh including uh you know zero trust

networking because you know networking is is the invisible layer which carries data across AI platforms to the you know the software layer and the platform layer we have uh advanced guard railing

technology, data lineage, uh data governance models, uh and and the entire end to- end data pipelining and management. So I'll I'll just get hand it back to you. Long answer. Sorry for

that. &gt;&gt; No, no, not at all. Uh it's very important and uh you know for us uh Tata is uh synonymous to trust. So I have to mention that. Um so well uh being a

French company uh uh I know about uh Quandela um but what do you like to uh talk about quant your evolution and um how do you um define trust in a quantum uh computing perspective?

&gt;&gt; Thank you very much. Yeah. So maybe you know I will just introduce a little bit Condella. It's a it's a startup coming from the CNS lab. We use a sen technology to build photonic quantum

computers. Uh actually we are full stack company developing software and hardware. And now actually we partners with industries like like Talis uh to move quantum from the lab to industry to

the real world and to deploy systems. Uh and basically as a CEO trust uh is a key is a pillar in in our road map because actually we need to build reliable systems. We need to demonstrate

compliance security in order to demonstrate scaling. That's very important for us. So for me when you asked about what means trust uh with my vision and I'm an engineer basically uh

it's it's easy. First trust it's trustability. Trustability because we need to uh trace uh the systems the models the data that we use for AI. uh the event for quantum we use quantum

artificial intelligence we develop quantum machine learning and for all of this it's important to trace trace uh the results and to get reproducible runs. Second thing will be

predictability. Predictability it's uh you need to know basically where are the limits of of the of the models and um where are the failures as well

and this is also why it's important to to investigate this verifiability the third one uh because we need to benchmark the performance actually now we at this step at condela we released a

framework which is called Merlin Merlin for machine learning um it's used to benchmark applications and performance on quantum computers and using using AI technique and and run stress tests on

the on the applications. Uh fourth security and the fifth pillar which is accountability as well. Uh how to make sure that we have a clear ownership along the full along the value chain of

AI on quantum computing between hardware provider, software provider, uh certificate providers. Uh we need to have clear ownership about everything and with this all together we will be

able to work in trust. we will be able to build the trust for the end users and we will be able to scale. That's for me. &gt;&gt; Thank you. Thank you Valeria. And Dr. David uh you you are in charge of AI and

quantum computing at Talis both evolving topics. Uh how do you how do you see this and uh what is trust for you? You have multiple uh uh topics in hand. Okay. So, um um hello everyone and thank

you very much for having me uh with you today. Uh I should say that when when I started my uh career, my research career in AI, it was like 35 years ago now. uh the what was important at that time is

just build systems that are able to understand the humans and AI was a kind of discipline at that time and uh so the the measure we had for the success of an algorithms is whether it's brilliant or

not u and at the time I I I was with a company called France Telecom which is telecommunication uh company uh which became became orange since then. Big uh

international company also and uh now and we were very I would say uh uh forwardlooking because we demonstrated at that time the first conversional agents uh interacting in natural way and

in in uh with a speech with the human beings. uh to uh uh some point that uh I remember I had a a whole page of uh the Wall Street Journal at that time because it was something which was just very new

and uh but nothing you know nothing uh uh in the in the ecosystem saying that it would generalize as as as fast as possible. uh one system today I I work for a company uh called Talis uh where

uh uh which enables uh at least one aircraft out of out of two I would say in the world to land or to take off. It's a company which uh also empower and and augment soldiers on on the

battlefield. It's a company which secures uh hundred of millions of uh identities of people. So uh uh the notion of stress is really at the core of what we uh what we are doing. You

cannot say usually you say you know when Netflix recommends you a movie you don't like so you just pick up another one and life continues. Now if you have AI on board an aircraft you cannot say okay

the aircraft will approximately land. It has to land. Okay. The the question I ask today is uh whether I can put my family in an aircraft which is running AI. If the answer is not immediately

yes, so I go back to work. Okay. And to make this very tangible and very rigorous at Tales, we uh actually uh set up a very uh clear strategy on trustworthy AI uh several years ago,

which relies on four major pillars. The first pillar is the validity of the systems which means that we need to prove that a system will did what is meant to do no more, no less. Okay. So

this is the very basis of safety. Maybe you know this but in in in aonautics for example to be able to embark uh a software or hardware component you should prove that the probability of

incident per hour of flight is less than 10 power minus 9 which means 0801. It's very small very small and you have to prove this formally. Okay this is the very basis of safety. The second pillar

is security of the system. Security is the is the the guarantee of resilience to any kind of malvolent behavior and especially to cyber attacks. And at Talis we have a team doing what we call

friendly hacking which actually friendly attacks our own algorithms to identify their breaches, their vulnerabilities and to propose counter measures. And by the way, this team uh won uh uh a

challenge from our mod French mod two years ago because the team succeeded in retrieving sensitive data which were used to train the the system. The third pillar is explainability of our system.

So if you have a digital co-pilot uh in in a cockpit recommending to a pilot to make a left in 45 miles for example. So the pilot should be entitled to ask the question why should I do that especially

if she or he has had in mind to do something different and the system should be able to answer because there is threat there is a thunderstorm and not because the layer number three of

the neural net was activated at 30%. Okay. And finally the fourth pillar which is last but not least is what we call responsibility and responsibility actually is twofold.

There is one stream uh which is the uh uh uh compliance of uh ethics principles of laws of regulation principles. As you know in Europe we have this AI act and Talis also issued

a digital ethics charter a few years ago which comes in 10 commitments actually we are really working to achieve it's on our strategic road map and business road map now and the second stream is about

the uh uh uh carbon footprint and energy consuming. So we have teams working on frugal AI uh to minimize the volume of data which are used to train systems for example. This is minimizing the the the

footprint of the technology itself AI technology and uh we have also the the the complement of this is what we call AI for green. how to use AI to minimize the footprint of applications like

working on optimizing the trajectories of aircraft for example to minimize the what we call the condensation trades which are generated by the aircrafts. So just to to to conclude this this first

part uh I would say that trust actually is is not a label it's not a promise it's a proof things have to be proved in our in our in our business &gt;&gt; thank you uh thank you David uh Sep

coming to you uh we are in the service industry uh uh our whole operation is built on relationship and trust so how are you coping up with these new challenges is uh of new technologies

coming up. What what's your uh take on this? &gt;&gt; Thank you. Thank you for inviting me here. So uh it's a very valid question and I will not answer it in a very

technical way because I'm sure all of you have covered all the aspects around technology, architecture, governance. So my name is Sep. Uh been in London for the last 24 years and I'm moving to

India next month to accelerate the India business. And uh of course when I was in I was managing the European business for HCL Tech. We're just about a $15 billion

company providing services and I took this job of growth markets too which is India, Middle East, Africa, France. It gave me a very different perspective because I'm managing about one and a

half billion dollars business and now here I come in a completely different world and uh I started like a startup. So I built my own systems

uh which was based on AI like we say before you preach anybody you learn yourself. So I built all my systems today for growth markets too which is what I lead

is built on AI. So my inside sales engine uh my business analytics my forecasting everything is based on AI. So we've I've reached from analytics to reasoning. I

am hoping I will reach to predictability in some way because the agents are still not predictive. There's still a reasoning but that's where I started. So if you look at

my business and every person in my sales team or my delivery teams is certified on AI. I myself started it. See if you have to embrace AI it starts from the top starts from the leader

and we talked about trust it starts from you. If you as a leader in BE there is no Excel sheet in my world, there is no PowerPoint in my world. You ask a question using voice, you

[snorts] get an answer on a dashboard. I can show you right here. Of course, I'll not tell you what is my forecast for this quarter. Uh but you ask a question, you have it. You ask a question about a

company, you get it in 2 and 1/2 minutes. And that is the power of AI. We were having you know earlier lot of people trying to dig data from here from there. It doesn't exist.

It is 2 and a half minutes. You ask for you know the market approach or anything that you want to do. So in my view embibe yourself. It is an iterative process. You do not

build trust just like that. You build it over a period of time. You have to be patient. You have to learn. You have to make somebody learn. And that is the learning

process that continues over a period of time and then you build trust. So my advice to anybody and the reason I moved to India is very exciting. It's a land of opportunity saying coming home and

you are in NCR which is we call it Delhi. It is the home of HCL Tech. So we have a very unique uh proposition or advantage in India or globally which is uh we have what we call as AI

products. Uh very proudly it is made in India for India and for the world which is HCL software. Uh we have expertise of our global services working with lot of customers across the globe. So what

it gave me an opportunity is to bring AI products, services together into what I call as AI solutions. So in this AI impact summit, we've launched seven solutions which is

not just for enterprises. It is for citizens, it is for the governments as well. Uh more than welcome hall 4 4.5 please if you have not visited go and visit what we are talking about. So

these are the solutions which will make uh you know it will help us protect ourselves fraud detection system compliance system training system skilling system not just enterprises. So

to me AI is about people progress and planet. Thank you. &gt;&gt; Thank you. Thank you Sep. And coming to you uh uh Tanoja uh do is such a flag

bearer of uh French uh innovation. um how do you um how do you see this uh whole evolution and uh what is trust means at the &gt;&gt; Thank you Arun and uh good morning

everyone. I represent uh Desos systems which champions the cause of industrial AI platforms. Now to this point of trust, the definition the expectation itself has

evolved I would say over the last uh several years. Uh five years back for example uh AI was still in silos uh and the definition of trust was mostly centered

around the accuracy of the output. So you have a model, you feed data, you put a query, if the results are near to your expectation, you are happy but that is no more the situation uh

because of widespread understanding of AI as a topic and adoption as well. Now there are new dimensions which got added to make it trustworthy and quite a few points which I wanted to

highlight is already covered my with my fellow panelists but for the sake of clarity and uh at the cost of repetition I will say it again. Uh the first one is of course the lineage of the data.

So the AI platform, the industrial AI platform needs to ensure by design that the data which is being leveraged to solve a problem uh is ethical. Uh it has traceability.

Uh there is no mischievous uh data which is being leveraged that done when the output comes. Uh it is credible and it is uh trustworthy by the people who are going to use it.

The second point which I wanted to highlight is about uh people in the loop. We still have to go a long way where we trust a totally automated system without human intervention.

uh we still uh like to have at least at the governance level uh people in the loop who will ensure that the processing the output given by the machines is indeed in line with the

objective which for which it was created. 100% trust only on machines is still a little far. So people in the loop is definitely uh which build trust for all of us.

Another aspect and particularly uh in an industrial AI perspective uh is to uh simulate the result of a AI model in a real world uh environment. Uh for example, when you uh design a car uh

you design a car in context. The car has to run on roads and the condition of roads changes from place to place. And if you really need to trust a car which was for example developed uh elsewhere

in the world but being used in India, people will trust if that car at least uh is tested in the real world environment of India as a context. Uh you have virtual twins of not only the

product now uh for system you also have virtual twins of the environment. So you can simulate how that car will behave when it actually uh gets on road in Indian conditions that builds uh trust.

Another uh example is what kind of checks and balances which are there in the model itself that it does not let you make mistake whether the mistake is unintentional or whether it is

deliberate. what kind of uh compliance you have already built in the model. If that is robust, the chances of uh getting a wrong output or a broken system is far lesser and that builds uh

uh trust. And the last one uh point which I wanted to highlight AI applications uh unless it is end to end from conceptualization to decommissioning

if it is still in silos the overall output is less trustworthy as compared to imagine a situation where right from conception up to decommissioning you have you have been

able to simulate the whole process multiple times again prove it uh streamline it and then launch it. That builds lot of trust for the people who are actually going to build that system

in the physical world and the consequent people who are going to use it. So these are some of my views. Aron, back to you. &gt;&gt; Thank you. Thank you, Tanoj. I think we we are uh we have some more time. Uh but

I'm glad that uh a lot of you guys um all of you in fact went through the use case examples as well which is very important. Uh so if you look at this panel itself we have um the the deep uh

strength of French innovation, French technology and two star walls of Indian scale and uh uh speed in a way. So I I just maybe quickly uh uh want everybody's point of view on what is the

mindset change that you are looking for um to build trust uh and the um you know the democratization of AI at scale. So what is the mindset uh that you're looking for a change of mindset? Uh

Niler quickly &gt;&gt; I think um uh I would say that uh the mindset change which we have to move towards is uh a mindset of uh an &gt;&gt; Uh because we can't do it all. Uh for

example, we partner with Talis on many of the security components which we provide as part of a solution. So it's an ecosystem play &gt;&gt; and uh we need to work very closely to

make sure the trust is not broken and the architecture is the trust architecture is maintained across the &gt;&gt; Yeah. I think it's on my side uh priority

should be to break the walls between quantum and AI and build a huge community and also this is why at at Condela we released Merlin which is a framework which aims to do that because

that's the point trust comes from benchmarking and reproducibility not from oneoff chart &gt;&gt; and Merlin um has been released with one very pragmatic first mission

establish trust between AI community, AI developers using quantum computers that are brand new technology which is now available and and we actually published some reproductions of papers. We we are

here to um show quantum machine learning results in a control environment and we are turning scattered claims into shared baseline and to build up community and invite people to use them. So yeah the

main my main topic is let's break the walls and let's share about what we learn in order to establish trust all together and and build a common baseline especially between France and India in

France we develop the we can develop the technologies in India we can scale the technologies &gt;&gt; so we have a ecosystem and uh community what's your take uh David

&gt;&gt; um um well I would say that You know in France we have spent like decades to build something which is you know really which is uh which is supposed to work in

context where uh failure is forbidden. I mean with companies as tales as do so as uh it it has taken us you know decades to do this &gt;&gt; and so we are living in a world uh of

certification of regulation of mathematics proofs. Okay. So trust has to be proved. This is very important. uh we cannot afford as I said earlier that you know just a declared trust say okay

please trust us when when you deal with critical systems you have to prove the trust and uh I used to say that trust is gained by drop and is lost by by bucket so this is this is very important and in

India I mean India has been doing something equally extraordinary I would say uh in record time uh with this uh digital infrastructure

uh for billion human scale which is really extraordinary and I think that the the combination between depth and scale between France and India is really uh uh uh the very challenge here and to

keep trust within this challenge is probably the way to go to make people adopt uh AI at at or scale. &gt;&gt; Okay. &gt;&gt; Thank you. Uh Sep for you.

&gt;&gt; I just say one word. &gt;&gt; Just have be open-minded and learn to adopt change &gt;&gt; adaptability. &gt;&gt; Very simple. There is nothing else.

&gt;&gt; And you uh t &gt;&gt; yeah quickly uh the scale is directly proportional to the trust we built in the system for sure. &gt;&gt; Yeah. And I'll build on the example you

gave initially and our prime minister also quoted &gt;&gt; UPI when it was launched in 2016. &gt;&gt; Last year in December it clocked some 21 billion transactions translating to some

30 lakh cr worth of uh money transacted with each other and today UPI is being used even by the most digitally illiterate person in India. He doesn't hesitate you know to put his trust in a

system with his money. So if you build the trust then the scale comes automatically is what I'm saying. &gt;&gt; Thank you. Thank you gentlemen. I think we are [laughter]

um almost uh finished our time. Thank you very much. I encourage you to uh come meet with the speakers and uh thank you very much for your time. &gt;&gt; Thank you once again to our moderator

and to all our distinguished panelists. Uh I would now invite all the speakers to please remain on stage for a brief momentum presented by Mr. Mark Mopilier uh and for a group photo.

Ladies and gentlemen, please join me in applauding our speakers as we take this moment together. [applause] years. He was the founding director of the robotics institute at the Kanagi

Melon University and he was instrumental in helping to create the Rajiv Gandhi University of knowledge technologies in India to cater to the educational needs of the low-income gifted rural youth.

He and Edward Foningham won the 1994 Turing Award sometimes known as the Nobel Prize of Computer Science for their exemplary work in the field of artificial intelligence.

Now I now request Professor Raj Ready to take the stage to deliver his keynote. Thank you so much. &gt;&gt; Good morning. I don't want to hold up the panel which

is more interesting and important. I just want to share some thoughts about the role of AI in India primarily. It looks like the world will spend over a trillion dollars this year on AI

creating what is being called AGI, artificial general. I don't think we should spend even a penny on that because it'll get done by somebody else.

What we should do is what I call multilingual AGI. We have 22 languages in this country. We don't speak the same language to each other. Whenever you go to someone else

and then I come to Delhi, I can't speak any language. When they speak to me in Hindi, I I kind of go blank. But we we are at a point that we can create a multilingual

artificial general intelligence and that's where we should put in our investments and the issue is what is multilingual artificial

intelligence. I'll give you one slogan that probably is the most important part of this talk. In the future,

anyone in India should be able to read any book, watch any movie and talk to anyone in any language independent of the producer and

consumer. How will that happen? What does that have to happen? I I don't know if you saw the movie her where there was a a smartphone in your pocket. It was

listening to you and using it to guide your your discussion. I'm hoping we'll create user friendly interfaces so that when I speak in Telugu, you can hear in Hindi

and when you speak in English, I can hear in my my preferred language. And I think we are there. We can get there very quickly and uh it's being done already. There there are

two startups in India called Saram and Bar Jen. Uh both are trying to do it. My request is that we create a quantitative measurable

metrics that we have achieved this goal. What that means to me is it's not enough you know already you know people will say we already have multilingual intelligence we have

systems that will speak in you can speak in one language but it is not usable it is not especially if you're a person in a in a village and uh you don't even know where to

begin. So the the first issue is how do we create a multilingual AGI and how do we make sure that we have measurable progress. There's a statement if you

can't measure it you can't improve it. We need to improve the existing models and they will probably need more computation, more memory and more bandwidth.

In the 50 years ago we created a thing called 3M computers myth megabyte and megapixel. Today we should create a 3T computers a terabyte of pro

process memory and teraflop of computational power and terabit bandwidth that's where we should aim for that means every one of us should have in our

pocket an AI companion that actually has what we call foundation edge models and they require not right now the many models that are on the edge are like

three billion bytes or 9 billion bytes. We're off by a factor of a hundred and we need to get there and India can you know kind of uh uh where am I how am I doing for time

anyway somebody it used to be that there'll be a time thing here but whenever it is time tell me I'll stop okay so that's one the second important point I want to make is

people at the bottom of the pyramid. Most of the talks I've heard, most of the expectations assume you are AI enabled and you can actually

make you effective use of AI. I come from a little village. I guarantee you not one of them knows anything about computers or AI and they

simply you know are not going to be benefit from the this whole technology. So what we need to do is just like the agricultural revolution of

Swami Nadan we need to figure out a way of how to get this technology to the Again, I'm sure you'll find uh I'd be happy to talk about any of these for much longer, but we only have a short

time. Then the what in order to do both of these things I said we need a teraflop terabyte systems and

what we need are personal so sovereign edge models and currently if you talk to anyone they'll say already we can have access to AI it is not private it is not you know

personal and secure. We need systems because they're always going to the cloud to access the AI models. As soon as you do that, you have no privacy. In the future, we want systems which are

personal, autonomic, cognitive assistance that are always on, always working, always learning. And that is the challenge of how to get

there without we have to cut it off from the grid. We cannot let it go to the grid because then it's no longer private. And uh so anyway there's a whole set of

issues of that kind. How how much time do we have? Anyway, somebody tell me [clears throat] there are three or four other topics we can talk about. One is I

I had a a child come and say if AI is going to teach me and knows everything why should I go to school? Yeah. And so uh the answer to that will take longer than two minutes but I only

have two minutes but you can figure it out. But basically what we need to do is essentially teach the kid learning to learn using AI

have a dialogue learning to think you have to teach them critical thinking right now most kids in India don't even open their mouth in classrooms they're afraid so we need to

kind of get over that barrier let them talk and think and go through critical thinking and learning to do you have to learn how to execute

with that I'm going to stop but I have want to leave with you leave you with one other thing which you can figure out one of the things I remember from Vedas is om shanti shanti shanti

peace at all costs And uh if you listen to uh one of our keynote speakers, they said autonomous weapons are going to AI based autonomous weapons are going to destroy

the world or something. That's a risk. Why don't we have humane weapons? When a missile is going to hit a hospital or a school, it is easy with AI to discover that and deflect the missile.

Why should we even kill the soldiers? They're innocent. They're just somebody recruited and they're being bombed and killed. We should build weapons, humane weapons that will disable them rather

than destroy them. There are lots of very interesting issues of this kind. We we need to think about how Thank you. &gt;&gt; [clears throat] &gt;&gt; A very good morning ladies and

gentlemen. Our uh next session is a panel discussion on AI for science. The panel will be moderated by professor Abh Karandikar, Secretary Department of Science and Technology and he's also the

chair for the AI for science working group. I would now uh request the panelists to please uh uh come on the dis uh professor Karandikar. The other panelists for the session are uh Mr.

Iraqi Berids, head of center of AI and robotics, UNICRI. Professor Entoin Pettit, CEO and chairman, CNRS France. We have Miss Joel Pino, Chief AI officer. Uh and uh we

also have Mr. Amit Shet, founder uh Indian AI research organization. A very warm welcome again to the panelists. Uh I will right group photograph. Okay. I request

uh all on the dice to please come forward for a group photograph. We'll have the photograph for you on your momentos. Thank you panelists. Thank you professor

Karandikar. I now hand it over to uh our moderator professor Ah Karandikar, Secretary Department of Science and Technology to carry forward the panel discussion. Sir, over to you.

&gt;&gt; Thank you. Uh uh thank you Ekta. Uh so distinguished panelist we have a um very distinguished panelist today uh on the panel uh colleagues and all the members of the global scientific community. Uh

it is my pleasure to welcome you uh to this panel on uh AI for science and we consider it to be a very core pillar of our vision for this India AI impact summit.

And as today we stand at the threshold of a new research paradigm uh our uh goal is not just to witness uh the AI revolution uh but to steer it uh towards a more equitable inclusive and

transparent future. uh you know uh in the today's AI world we are moving beyond uh traditional methods uh where you know AIdriven models and automated experimentations

have a potential uh to compress uh the decades of research uh into months and the rapid advances of these technologies however uh has not been so far equitably distributed and that is uh one challenge

uh many regions still face the significant uh barriers uh but still uh the realm of possibility for using AI for scientific discovery uh

continues uh to have uh uh you know lot of excitements. Uh today we are joined by leaders uh who represent uh the uh entire spectrum of uh scientific innovations, policy makers, institution

builders uh and from the governance uh and national research ecosystem. uh I look forward to the panelist insights on uh you know how uh what are the exciting possibilities in AI for

science and how we can bridge uh the digital divide and build a genuinely reciprocal global scientific ecosystem. Uh so with this I think uh I will begin with uh you know first uh few questions

and I will request the panelists to answer. Of course they are free to uh elaborate on any other things and then I think we will open this floor uh to the audience uh for the introduction. So let

me begin with uh you know Dr. Amit on the far end. uh uh so Amit you have been building I think uh IRO as a national style institution in India. Uh if you can just uh tell uh you know how uh can

this model help overcome the specific barriers uh that we have identified uh in this uh region you know such as inadequate compute and fragmented uh data sets.

uh and also you know I would like you to elaborate how can we ensure uh that AI research which conducts uh which gets conducted in our center of excellence actually can reach the translational

stage uh addressing the real world challenges. So if you can just uh you know take uh five to seven minutes on this and &gt;&gt; I think you can just uh

&gt;&gt; Hello. Yeah, thank you very much. Uh, Professor Karandiker, this is a perfect question for me to talk about. This is why I'm here. Um, I moved from USA 40 after 44 years here

to uh address exactly the question you answer uh asked. I was on um two days ago I was on another panel and I asked the this question to the audience.

How uh if I were to be the founder of DeepShik had all the funding that he had and has, can I find those 200 250 uh engineers, AI engineers and um

researchers that he had access to to build DeepSc. Out of around 100 people in the audience, three people raised their hand saying, "Yeah, we might, we may." Of

those three, two were students. So only one uh you know um mature person uh basically thought that we can have that and and I think uh that gives an answer of what we need to do. So um India

is well on its way I mean to grow many people who know something about the AI and they will certainly have the ability the skills necessary say India has been big in um IT services and if what

whatever IT services uh need um they will be able to supply the skill AI skill skill set that people would have here we will have that will be adequate But we have noticed that um uh you know

two members very important members of IRO's board are Ajay Chri and Sharat Sharma and they have extensively talked about uh or limited that India has not been a product nation. We have not made

any global products virtually I mean hardly uh you know any global brands exist have been developed in India and for that we need more than skills. We need people at high end of expertise.

That means our own uh in indigenous research capability, our own ability to train innovators. A very good model has been uh that um uh you know we do bachelors here. Take an example of Arvin

Sinasan. He did I madras then you go uh for outside. He did his PhD in um Berkeley. I did mine in Oha state and then he worked for companies uh three companies deep mind open AI and

Google and then he did his company but that also in US we want that to be done here right so the same um ecosystem that in which he got trained after leaving India we want to provide

that in India right so and and there are I think lot of things happening as you know uh there is a 40% uh decrease in Indians going to United States uh for studies. So and that will continue for a

while now right with uh uh most of you know of the reasons. So first and foremost IRO is developing an environment to create high-end talent of innovators.

Secondly uh at this and by the way if you see IRO's founders are professors who have graduated nearly 200 topend PhDs right so we know how to create that secondly we have created broad variety

of uh collaborations with uh various universities uh and we are starting to do that with industry and we are creating a significant infrastructure to to support IP creation to um uh

licensing that or to work with the corporates and startups to uh who will make the products. So the idea would be that um we'll co-inovate jointly work at IRO with the companies with the startups

with entrepreneurs um angels seed as well as growth stage they they are all hungry for deep tech AI startups and that we will provide comprehensive environment for us to take

now some of us also founders have also done companies four three of my four companies that I have done are AI companies licensing the research I did my in my university um

Romesh Jin has done more companies than I have and he's uh also a co-founder so we have the understanding of that entire pipeline it takes from lab to global products and so this is what we are

going to do for uh you know India and this um answer &gt;&gt; okay thank you uh thank you now let me Let's switch the gears and go to professor Antony. Uh he has been the

chairman and CEO of uh CNRS France. Uh uh so uh Antony I think CNRS as you know operates at a scale uh you know that most research organizations can only imagine. Uh so two questions. uh what do

you think what structural shift the national research and funding agency need to make to support the interoperable scientific ecosystem that can sustain uh AI research beyond just

short-term pilots and so the added question is that is there a need to build an AI uh AI for science platform like as a mega science uh facility So thank thanks for this invitation. Uh

yes two words about sen sen in French means national scientific and probably you don't need a translator to understand that it mean national center for scientific research and it's true

that we're a big institution we we employ more than 35,000 people among which 30 30,000 scientists and we cover all fields of science and and clearly uh uh AI opened a new era in

science in some sense because AI is not only an accelerator of existing techniques it's force us to to imagine new ways to do science just just to illustrate this if you look at material

sciences what I will see roughly before you define a new materials and then you studied the properties of these materials Now you you you say I would

like to have a material with such properties and then thanks to AI you will build the material with high probability that he will verify these properties. So in some sense you see

it's not upload an acceleration it's a reverse in some sense of of way to do science and this opens new new era in which you you you need really to have talents of

course but you have also to lead cooperations between different sciences and that's probably a challenge for for an old institution if I may like celeres we were organized classically in in

science we cover all sciences including humanity and social sciences. But you see that with AI you you need really new ways to cooperate between scientists and this means that as usual the key

point is talents and it means that we we we have to build ways to to push people to interact and that's why we we created some years ago a virtual center called AI for science science for AI and and we

have to create some kind of a virtual loop between in some sense producer of AI, mathematicians, computer scientists and consumers of AI which can come from every discipline. But the the trick that

this producer will not produce tools uh or software that will be simply used by consumers but consumers will have new in some sense new new attempts for for new new ways to do research. And that's

clearly something we we we try we try to do. And of course in addition we need absolutely to have computer facility of the highest level even if we also try as as a lot of

people try to work to have more frugal AI and in order to to to not have a carbon footprint which will stop to to develop this AI and so so that's clearly a challenge for for for a center like

but I I know that it is a challenge all over the world and probably a key point is to to really start from scientific use cases in order to as I said to to to rethink the way to to do science.

So do do we need to have a platform for that? I don't know. We clearly need to have cooperations. That's that's absolutely key. uh sen we have a long tradition of cooperation with India and

and with with DST in particular and clearly uh from my point of view the the way I feel India approach AI in a very very pragmatic way can be an example for us I you you really try to

apply AI for for your citizens and in some sense for science I think that the the the process should be the same. We should start from very pragmatic scientific questions in different fields

and to see thanks once again to cooperation between between data scientists, computer scientists, mathematicians and colleagues from the other fields how we can apply AI but

also and for science AI for science has also some some risk. uh in particular you you can produce a lot of of papers thanks to AI and it's not clear whether these these papers were were right or

not and in some sense we can lose all our time by producing false paper by AI and then referring these papers also by by AI and that's that's a difficulty we all face

I think that none of us has a solution right today uh uh be But but it's clearly clearly also an issue. But be be optimistic and and let us think that AI for science once again will will allow

us to make to make progress and to to to discover also new results but also new ways to access to these results and in particular there are right now

fascinating applications of AI to mathematics. uh a bit frightened in some sense because the new new results have been obtained in mathematics without uh the

help of any human and uh does it mean that AI will replace scientists? I don't think so. &gt;&gt; Okay. So, so do you think AI will replace scientists or it will act as a

co-scientist or a hybrid scientist? &gt;&gt; That for me? &gt;&gt; Yeah. So uh let me just introduce I think uh professor Zu Pino uh so you have an academic background and as well

as you are now a chief AI officer so you have worked in the industry as well. So just your take &gt;&gt; happy to share some thoughts and and happy to be on this this panel to

discuss this this topic. Um a few things about my background. I I I am an academic member um at Mila the Kibik Institute of Artificial Intelligence at Miguel University. I also spent a number

of years um supporting the AI research teams at Meta, the fundamental AI research teams. Uh and most recently chief AI officer at Coher. Um this question of you know are we going

to create an AI scientist, a co-scientist and so on. I would propose a different framing of that and I really do see AI as a new scientific instrument. And so if you look back to

some to some number of years, you know, when suddenly we had computation and the ability to produce numerical computation, it completely changed what you could do not in one field of science

but across all of the sciences. And so what we are seeing today is a change of that magnitude where we have this new fantastic instrument that is going to change the trajectory not of one

discipline of science but of the sciences as a whole. Why do I call it an instrument rather than a scientist is because what years of being an adviser to early career researchers has taught

me is that the hardest thing in science often is asking the right question. the right question at the right time in the right way. And so as much as there's been some impressive results in terms of

mathematics recently and as well as other fields, it starts with a question and we can use AI to ideiate around a topic and to explore and do discovery all of these things. But there's usually

an intent that starts the process of science and at this stage um it's hard to imagine where that where that intent comes from though the AI is able to carry more and more of the steps

together. So I think to me that's the right framing at least for this for the next few years. Um both the sciences as well as AI is changing rapidly. So we may need to redo

this panel on a regular basis and the and the model might evolve. But I would say for for this period of time for me that's really the most productive way to do it. As with any instrument some

instruments are extremely powerful. Um and some instruments when used poorly can pose risk. They can pose risk to the integrity of our scientific knowledge. they can pose risk in terms of carrying

false information and so on and so forth. And so that also gives us a framing for how to think about that without falling prey to unmaterialized fears about this technology but actually

using it from the point of view of how do we make the most of this to accelerate our scientific discovery process while making it uh you using it uh judiciously in light of some of those

risks. I'll make this very concrete for you. I'll give you some examples. you know, we've done some projects um while I was at Meta on the field of uh AI chemistry, the ability to use AI to

essentially produce new uh in this case new crystals. Um and when when I talked to the research team uh doing the work, um the feedback I got from them, many of which were experts in this field, was

that in about one year of research, they were able to accomplish the equivalent of what would previously take them 20 years of research. So it's not that the research process completely dissolved.

You still needed time. You need some investment. But the acceleration of the discovery process was phenomenal. And the way that this is done very concretely usually it involves taking an

initial data set. So in this case a number of existing crystals for which we know the properties. feeding this into a model, a generative model that then you can use to rank the properties of new

crystals. And in this particular case, once you've done the ranking, you take your top rank candidates and you still need to run them through a wet lab to verify the properties. Your mathematical

model has some imperfections, some approximations, some errors. But by having the ability to rank the candidate solutions, you cut down the search times drastically. In the old days, you had to

list the list of possible solutions and you had to test them one by one in the lab using your intuition of the order in which to test them. But now you have a ranking algorithm that tells you in what

order to rank them. So for those of you who remember the web pre you know page rank algorithm where you know the search tree to find a website of interest was incredibly long and all of a sudden you

had a good ranking algorithm. It was a complete gamecher in order to retrieve information and now it's a complete gamecher in terms of finding candidate solutions to problems in AI. And so this

process that I described for this one case applies across all sorts of other areas whether it's biology whether it's mathematical theorems and so on and so forth. So this is not like magic. There

is like an organization to how you take the data, how you use it in a generative models, how you do the ranking and then how you verify your solutions and the verification process changes depending

on what what the what the domain is. In some cases, the better your model of the data and we hear a lot about world models, the ability to predict the properties of the system means that you

can accelerate further the discovery. you get better ranking and you have to take fewer solutions to the lab. &gt;&gt; So that's just to give you a sense of how to use it in practice um to make

this a little bit more concrete for people. &gt;&gt; Thank you. Uh now let me come to uh Dr. Iraqi Paris. uh Iraqi leads the United Nations inter uh regionals uh crime and

justice research institute center for AI uh where he manages one of the first uh sort of UN programs uh dedicated to AI. So um uh so what is your take on uh uh the uh you know this uh risk versus

benefits uh you know if you see that in your experience uh this AI for science can potentially pose and what you know even other speakers had raised. &gt;&gt; Um thank you very much. Thank you for

the question and thanks the organizers for putting this together and invite me inviting me to the panel. It's a really pleasure to share the panel with the distinguished speakers uh who spoke

before me. Uh I'll give some reflections what we are doing and how we're looking at uh the discoveries of the science including the social science and other things how it translates into the policy

developments at some of the United Nations uh streams and how we are working with that. So I'm leading a center for artificial intelligence and robotics for one of the UN agencies

called Uniquely and our mandate is anything related to uh crime prevention, criminal justice, rule of law, human rights, uh AI literacy. Now the center itself opened in 2017

um in the HEG uh in the Netherlands and uh we have a global mandate supporting law enforcement agencies all over the world to use AI and in a responsible way. We develop specialized toolkits and

policy frameworks for that. We also support uh uh investigators to use AI to solve concrete crimes and at the same time we are assessing risks how criminals and malicious actors can use

artificial intelligence and how we can support sort of a global frameworks to ensure that AI is used in a beneficial way and risks are mitigated properly. So this is the type of framework what we're

doing. Couple of questions now sort of starting from the broad side from the United Nations. Obviously UN just uh approved a scientific advisory board. This is a extremely positive development

and uh and just an hour ago there was a panel about science related to the AI governance and how it is so crucial to understand and and especially for the policy makers

and sort of broader audience what we are trying to actually govern and uh and what we are hoping is that scientific advisory board is going to do just that and quoting secretary general of the

United Nations who said that policy should be as smart as the technology it aims to guide and it is so true uh and and right now there's quite a lot of sort of misconceptions and and and uh

miscon misconnects in that sense. Now a little bit about the law enforcement and how uh uh sort of how we are looking at it. There are number of things and then there's a lot of uh aspects it could be

touched upon. Um several years ago when I started the center itself and we started sort of our programs especially on the responsible use of AI by law enforcement most of the law enforcement

agencies were not using AI we're talking about back in what 201819 or they did not even know what were the tools and uh and we had sort of a really handful of examples here and there and now uh last

summer we conducted a uh we conduct regular global meetings AI for law enforcement and this one was uh hosted in Brazil and we had so many use cases that we didn't know actually sort of

what to showcase right on the one hand this is a really good development so we have a um law enforcement needs to use AI and it needs to solve problems and right now without AI tools the vast

amount of data which exists there it's uh cannot be interpreted and cannot be put in put put in place but at the same time it has to be done in a in a responsible way so what we are doing is

that we're developing specialized toolkits for responsible use of AI and that involves the multistakeholder dialogues and we bring scientists there we bring law enforcement agencies,

governments and academia to put together those findings and frameworks so that uh this could be applied directly in the policy translation. So India is one of the uh pilot countries right now. We

have five countries where this uh toolkit is being implemented and uh uh this is India, Kazan, Nigeria, Oman and Brazil. Um a couple of days ago we had a meeting at the central bureau

of investigation and uh and we understood that there's a lot of progress already made in the implementation of this particular uh project. At the same time uh we are uh

we have launched a rather sort of a scientific project on how to ensure that public trusts use of AI by law enforcement and in few weeks we're going to issue a policy recommendations and

the report which comes out of it which is uh again uh very crucial form of the governance of AI in that particular field where uh AI has been used by law enforcement

but but public has a uh fear to it and has a misunderstanding perhaps or or right understanding on how it is being used and applied in in in reality. So all of this stuff is being

kept happening. &gt;&gt; Uh thank you uh thank you all the panelists. I think uh uh before we just open I just had some one quick questions to not in any order but uh uh just to um

uh Dr. Pino I had this uh question to you since you made a very important point of uh AI to be looked as an instrument. uh now uh you know one question I had is that there is this

reproducibility crisis in science you know so what do you think uh do you need any standard or any methodology uh so that you know AI generated discoveries are considered you know as

real or as reliable as you know &gt;&gt; yeah I I I do appreciate the question I've been um quite concerned about the reproducibility more generally uh in the

field of AI for a number of years studying in around 2018 and have published quite a few papers specifically on this topic of reproducibility. I'll keep it very very

short. Um I do think this is an issue. I do think AI can be an instrument to accelerate the reproducibility of scientific findings because specifically in those cases the question is already

there often there's a candidate methodology and so that means we can apply the the wheels of AI um in using reasoning methods and generative methods to to accelerate reproducibility. Um

we've looked at doing that and running reproducibility challenges. I've run an annual reproducibility challenge around some of the AI conferences and so I think there's a lot of opportunity there

um to do that. I would emphasize there's two ingredients that are necessary which often are associated with discussions of responsible use of AI. One of that is transparency. So to facilitate

reproducibility, it helps to have the artifacts of the scientific process be publicly available. And um the the second one is evaluations. And so just to reproduce a method without being very

specific about how you're going to specify the criteria um can be difficult. So I think by by spending some time on uh transparency and evaluation we can we can really

facilitate this process. &gt;&gt; Okay. Amit your &gt;&gt; Yeah. So um I uh I think we've gotten great um things out like productivity and other things that colleague from

Kohir mentioned uh about using very large models trained on arbitrary data. Um we are bringing we plan to bring to India something very unique. uh uh from the very beginning. In fact, when I had

a chance to uh talk talk to the prime minister, we said that we need to have uh you know India make its mark in the particular in a new form of AI and in this case I get the chance to perfectly

explain what we are doing. uh we want to solve instead of using a big model and um use it as instrument uh or uh you know partner we we are developing models that are very specific I we call it

compact custom neuros symbolic models uh such that we solve specific problem deeply IRO has taken the topics of healthcare uh sustainability and environmental science and pharma as

initial domains and um uh recently in pharma uh there was a there's a company called benevant AI and they had a uh you know uh FD approval of a new drug remoted arthosis drug where it was

developed be by use of knowledge graph and deep learning right so the can I just wind up in &gt;&gt; yeah so um in our case we want to create specific

model for specific problem solving and trained neuros symbolic means that uh we can we can make the models explainable, safe uh uh aligned, grounded with uh deeper reasoning options and planning

and so on so forth and so I think this is an alternative model for AI that is uh likely to come up and would solve the problems deeply very specifically with high value. Okay, just quickly I just

wanted to ask you this question that what do you think that AI for science can act as a bridge to solve uh problems in some of the priority sectors uh like climate resilience or agriculture or

energy particularly for countries which have a limited experimental facility. &gt;&gt; I have two hours right? &gt;&gt; Yes. [laughter]

No, no, clearly as I said before AI will play a key role in particular because by this ability to treat a huge amount of data. I said before that scenario who are also a consumer of of AI. If we I

look at the domains who produce the most amount of data, it's it's it's not at all mathematics, it's computer science, it's particle physics and and astronomy and they need new techniques

based on on on AI for to treat properly this this data. But but to coming back to to north south relation as as you said I'm convinced that we need cooperations. uh uh we we live at a

period where sovereignty becomes a buzz word but sovereignty does not mean from my point of view isolation. We we need we need to collaborate. Uh we we need to share we need to develop open science

and open software. Uh and and clearly this not in a in opposition with with the the will of sovereignty. And clearly uh to to be brief, I think that we need to to start from use case

either use case coming from civil society or or use case coming from from science and and we we as as developed countries. We we do not have as you know France has a history with Africa which

is particular and and during a long time we we try to explain to African people what what they need and now we have understood at least I hope that the main point is to understand what are their

needs and to try to develop cooperation in order to to to to fill these needs. So thank you at le you made an important point of uh the responsible AI uh what do you think uh you know that's uh about

the the shared global ethics you know uh for the AI that AIdriven scientific breakthroughs are governed by some kind of a shared ethical framework. &gt;&gt; Yes. Okay. Yes. Thanks a lot. So there

are not I mean many many many things happening at the moment uh in the world. On the one hand we have the global digital divide where a lot of countries are investing in the technology and

advancing and including in education in scientific breakthroughs and then you have quite a large portion of the world which is uh uh staying either behind or uh or may have a potential to stay

behind. For example, right now only half of the world has either AI or digital strategies and and have governmental spendings or allocations to that. Another half doesn't. So that digital

divide is very dangerous and uh there are numerous calls how to minimize that and on the level of the United 10 nations there are many type of streams there but I don't think it's enough and

I think that a lot more has to be done and hopefully the scientific breakthroughs through the AI and some shared platforms and some some shared collaboration that can be bridged and

this could be uh benefited and uh when you see the uh uh title of this AI impact summit I cannot not share share it more or or cannot resonate more that welfare of all, happiness for all. AI

should certainly benefit all and not uh selected few and uh I think that summits like this and hosting a summit in global south uh uh should give a a renewed impetus for doing all of that thing.

&gt;&gt; Thank you. Uh thank you very much. Now since you know we are running out of time, we just have a time for two quick questions. So we can take from here just yeah please go ahead.

&gt;&gt; Right. So it's very interesting that the fundamental model in fundamental science was released in public domain but the one which has commercial applications in drug discovery Google has chosen to keep

private. Um my question is do you see this as a trend where the scientific foundation models as far as they relate to fundamental science will be released in open source but if they are

fine-tuned for commercial applications they will be kept private. Is do you see this as a trend and what do we do about that professor in India? Of course, I can't speak to Deep Mind

strategy that belongs to them. I've been in deep disagreement about their open sourcing strategy for many years, respectfully. So, I do think that the circulation of scientific assets and

ideas is absolutely for the benefit of all. Um, I will say it is possible to go against that trend. I was uh in 2023 responsible for a language model called Llama. At the time, all of the industry

was against open sourcing large language models. We went against that. We open source the llama 1 model, llama 2, llama 3. Today we're looking at over three billion downloads of these family of

models. Um it's possible to see disturbances to those trends. And I think specifically in the field of scientific research, there's so much more to be gained by sharing assets and

sharing ideas than keeping it closed. But that takes courage that it's going against the grain and it takes vision. Uh I want &gt;&gt; I mean just brief I think just

&gt;&gt; yeah I want to express deep admiration for that um uh effort uh and and and trend that you started in uh making open source model. India has to develop its own model. Uh so uh we just had a whole

day yesterday with the pharma industry. They are partners and uh with the access to information they can provide guidance they can provide data they can provide we will develop our own model for drug

discovery we'll we are ourselves developing a very large pharma knowledge graph we have already developed a good one decent one now and we will be training our own model with deep uh

pharma drug related uh uh you know knowledge and uh create our version &gt;&gt; thank you So just one last question we'll have in the end. Just be brief. I think 30 seconds and then we'll have one

of the panelists to answer another 40 seconds. &gt;&gt; My question is &gt;&gt; Yeah. Go ahead. &gt;&gt; Yeah. My question is is there uh any

government guidelines for responsible global AI? &gt;&gt; Uh any you want to answer this? Uh &gt;&gt; all right. uh so there are numerous guidelines on the responsible use of AI

in many different domains from our side the the the sort of angle of the UN where I'm working we did develop uh guidelines and not only guidelines but practical framework on the responsible

use of AI in law enforcement and law enforcement is one of the probably most sensitive applications of artificial intelligence and that guidelines or that toolkit that practical framework is now

unveiled and it's working and it's been tested in many countries And as I mentioned it, India is one of the first country which is implementing it and it's very admirable. Thank you. So thank

you very much. With this I think we are time up and we have to close the session. I would like to thank all the panelists. Thank you. &gt;&gt; Uh thank you all. I just uh would like

to give away the momentos for the panel discussion.
