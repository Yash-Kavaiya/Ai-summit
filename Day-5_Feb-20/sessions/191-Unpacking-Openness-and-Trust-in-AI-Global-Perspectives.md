# Unpacking Openness and Trust in AI: Global Perspectives

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 17:30 ‚Äì 18:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 18 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/VFor0DKpaRI?feature=share) |

## üé§ Speakers

- Alondra Nelson, Princeton University
- Amba Kak, AI Now
- Anne Bouvert, Government of France
- Astha Kapoor, Aapti Institute
- Karen Hao, 
- Ravneet Kaur, Competition Commission of India

## ü§ù Knowledge Partners

- AI Now

## üìù Summary

This high-level panel explores a central tension in AI governance: openness can enable collaboration, innovation, and trust, yet may be constrained by commercial, state, and security considerations. The session examines how openness can function across the AI stack - compute, data, models, APIs, and applications and how to prevent misleading claims of openness. The panel also aims to highlight meaningful openness for emerging economies, balancing innovation, intellectual property, and national security.

## üîë Key Takeaways

1. This high-level panel explores a central tension in AI governance: openness can enable collaboration, innovation, and trust, yet may be constrained by commercial, state, and security considerations.
2. The session examines how openness can function across the AI stack - compute, data, models, APIs, and applications and how to prevent misleading claims of openness.
3. The panel also aims to highlight meaningful openness for emerging economies, balancing innovation, intellectual property, and national security.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/VFor0DKpaRI/maxresdefault.jpg)](https://youtube.com/live/VFor0DKpaRI?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

So, welcome. My name is uh Amba Kak. I'm from the AI Now Institute. Um the AI Now Institute and the API Institute. We are honored and delighted to be co-hosting this panel at the close of what has been

an extremely stimulating, some would say overstimulating uh week. Uh what brings uh API and AI now together despite the many kinds of distance between New York and Bangalore is our focus on the

political economy of AI and our insistence that questions of technology are always questions of power. So we have a formidable panel by every standards leaders in their field

advocating for AI in the public interest. Uh traversing several fields of of government service, academia and journalism sometimes in the in the same person as uh you will know if you read

their uh bios which I'm going to skip for reasons of expediency but I'm going to talk through some of their specific advantages um kind of in the conversation. uh you know it it's always

pains me a little bit to to even bring it up but I'm going to do it anyway which is it is uh exceptional that this is also uh the only female only panel at this uh symposium.

[cheering and applause] Uh hopefully that's not something we have to say a lot or something that uh we have to wear as a badge of honor but more more um something to work on for

future iterations. So um before we begin, I don't think he's in the room, but uh I want to also thank Amlan Muanti who's been a partner in conceptualizing and helping to bring this panel to light

and to our wonderful uh summit organizing team uh Sanja Mishra and Iksho Virat for their tireless efforts. Uh I hope you all get good sleep tonight after a very long week. Hope you are. Um

okay, so let's get into it. I'm going to moderate this panel. So I'll take a seat. &gt;&gt; [applause] &gt;&gt; So, let's get into it. Let's put on our

mics. Okay, let's let's get into it. Um, there have been many discussions about openness at this summit. You've probably been um in at least one of them. Uh, for the most part, these discussions have

focused on the kind of technical affordances of open source, open sort of open weighted models, open hardware. Um but what's clear is that the word open is doing a lot in these uh a lot of work

in these conversations. It's a standin for many much uh broader values of uh democratization of participation agency even sovereignity. So in today's panel we're going to kind of widen our

understanding of what openness could mean in this conversation about AI. And I'm going to uh start with um Alandre. Alandre has been the deputy director of the White House Office of Science and

Technology um under President Biden. Uh and Alandra, at the time there was a very heated debate um you know about the geopolitical but al also safety implications of open source and what US

government policy would be on these issues. And it seems like under this current administration, we've landed on a pro-opensource overall orientation. But at the same

time it feels as if in many senses AI AI governance in the United States is more closed than it has ever been. Um so I guess I wanted to ask uh what do you see as the broader challenges to openness in

AI governance today? &gt;&gt; Yeah. &gt;&gt; Thank you for organizing this colleagues and good to be here and good to close out this exciting um summit with you

all. So um a couple things I mean I would say the Biden administration I think took the question of openw weight models as as a gradient right so it was a spectrum so that open was not a binary

it's either open or not open and I think this the new administration the current admin administration takes it much more as a binary that like open is a thing that you sort of have achieved and it is

now open is closed to as opposed to being closed. I think the difference is um is that to your point uh um from the opening is that uh I think part of what we were trying to do in the Biden

administration was really go go back to um you know a kind of foundational sense of openness that comes out of an open-source movement that really thinks about openness as a kind of tech

sociotechnical characteristic and not just a technical characteristic. So certainly the questions around um open models AI models are are often around technical things like model weights are

the model weight shared only the model weight shared is it also the case that the training data shared um you know is the API open to a certain extent or closed to a certain extent so the

technical things are certainly there but I think if we go back to a sort of broader understanding of openness that comes out of sort of open s open source software it was about shifting power. It

was about forms of accountability. It was about um sort of openness as a kind of practice um and openness as shared infrastructure, openness as resources that could be used by lots of different

communities, things that could be you could modify the technology that you could sort of just use the technology for the the sort of purposes of your community or the purposes that you had.

And so that meant that that older I think broader definition of open was much more about democracy and transparency and accountability um in a way that if you take even you know a

so-called open-source model like Llama 2 or Llama 3 um which isn't really open source and that we're we're um being asked to be content with um model weights as open. So I think the you know

why we want to really push back on that is because um you know that that that we are often I think using geopolitical states as a justification for not doing the socio part of the sociotechnical for

not doing the accountability and the transparency and the democracy part because you know too dangerous because in the UNESC context China you know these things just sort of sit in as

signs for um explanations for you know why things can't be different and uh I think it's the case that um to go you know to be reminded of a kind of broader sense of of open reminds us that um you

know it's not this binary and that one can have you know there obviously may be places where you don't want open source like do you want open- source like nuclear deploy AI like probably not

right um but but the debate gets carried forward as if like every open- source use or open weight use is that use as opposed to the sort of gradient of uses um that are you know much safer and and

moreover are beneficial to communities to helping people achieve their goals and sort of certainly much better for public transparency and accountability about what these systems do in the

world. Can I ask a quick followup and then I want to u move to an which is that um the other sort of defining feature of of certainly of US government policy today is that it's happening less

through traditional you know the traditional forms of regulation that we're used to and much more through industrial policy through trade policy through immigration but these are also

spheres that have um been I would say relatively even more immunized from public accountability or harder to um you know harder for the broader publics to to to weigh in on. So just wanted to

get your thoughts on on how we &gt;&gt; Yes, I've been writing and thinking about this. Thank you for that question. So, you know, we we've spoken a lot about the new administration and gets

talked about as being deregulatory regards to AI and being very light and being quote unquote light touch. And I think if we actually pose that as a question as opposed to accepting it as a

statement and and actually look at what the current administration in the US is doing around AI, it's actually taking a quite very heavy hand to ste to sort of steer AI. So uh you mentioned some of

the levers that they're using tariffs, trade policy, export controls of semiconductor trips um in the US context even immigration. So, you know, there are um you know, uh I think companies

are getting out of it and around it depending on their relationship to Washington, but we're told that an H-1B visa for a high-tech worker is $100,000 per worker, right? And so that's, you

know, 10x, 20x or whatever times a company, that's quite a lot of money. Um and also just the way that science was being funded, um to the extent that, you know, the federal government plays a

large role in driving uh the sort of research tech e techos ecosystem for technology. So all of those things are being um very heavily shaped in the current administration in the US and so

it may not be regulatory in the sense of formal rule making as it happens in the United States context. Um but it is certainly um hyper regulatory I think in a lot of other ways. So, and let me just

and I'll go back to the, you know, my keyword of the day, the democracy piece, which is the upside of formal rulemaking, even though it can be clunky, it can take a long time,

sometimes the pace is too slow for the pace of the technology, all of those things can be true, is that it it has democratic input, right? So, if you're doing a rule making in the context of

the US federal government, there will be a public call. There'll be a public notice that you're doing the rulemaking. There'll be a public call for input. So even if you don't agree with the

outcome, there are sort of moments of sort of democratic input when we are doing AI policy by fiat and through executive authority only those inputs even if th those limited inputs are even

gone. So it's not only I think quite heavy-handed, it's it's um unfortunately I think anti-democratic relative to the status quo. &gt;&gt; Yeah, exactly. Um and I want to move to

you as the French president's special envoy for the AI action summit. you've been at the heart of um you know a lot of global coordination um on AI governance and there was a time I would

say the last 10 years have been characterized by open versus closed as a kind of binary or a way of um organizing uh the world into particular camps when it comes to AI that the democratic open

world and the rest of the rest of the world um but it's interesting how much that has you know the ground beneath us has shifted in the last few years and it has been particularly interesting to

note at this summit that it is middle powers as a frame that is coming through as a kind of new organizing principle. So I guess I want to say I mean do you see that openness still has value in

forging um multilateral solidarities and and where especially in this brave new world we're in? Um yes absolutely. I mean clearly the geopolitical landscape has um um really

[clears throat] shifted um at the AI action summit in Paris. It was exactly a year ago in February. Uh it was just after the inauguration in the US. It was the first international trip for um uh

Vice President Vance and and and what a speech that was uh uh just before uh Munich the Munich Security Conference. Uh it was a moment where uh the US announced at the White House the

Stargate um project. So it was a very uh strong and loud message from the US saying uh uh we're here, we're investing, we're the world leaders. Um and at the [clears throat] summit JD

Vance said very clearly, we want all of you to be customers uh of of um our technologies. uh and at the same time this is the moment when deepseek emerged on the world um uh map and and everybody

realized that actually uh China using opensource which is why I want to come to that um was really saying we have uh a seat at the table and we're actually playing that game um and and China using

open source is actually very interesting uh because open source has a number of uh benefits and and also risks I don't think it's the answer to everything. Uh but clearly it's a way uh for

challengers to uh catch up. Uh this is um uh how uh Android came uh to the world of uh smartphones. There there's many examples and and this is what uh China has taken as a lever uh to be in

that race. Uh but then on to what does it mean for other countries than um uh the US and and China. It also means that this is a tool that can be used by other countries. Uh which is why in France and

in Europe, we're very much in favor of open source uh as a competitive tool and as a way to leverage the um uh uh the knowledge and the findings of others to then um just stand on their shoulders

and continue to uh develop technology. Uh it doesn't mean that everything should be open source. There are cases where you do want to be uh careful depending on the use case. But as a way

to uh uh develop and stimulate competition, it is very powerful. Um it's not the only tool. You mentioned um u middle economies, middle powers. Um there was this fantastic um uh speech by

uh uh Mark Carney uh at um uh at Davos and u uh and there was a speech by uh by Macron as well that maybe that I'll conclude um uh with but but but this idea that um middle economies that have

um some resources not not the resources to build their own stack top to bottom and to fund um uh frontier level AI but together together by building coalitions of the willing. These middle economies

can do a lot of things. I I believe that that Canada, France, uh Germany, um uh Switzerland, uh uh India, Japan, uh Australia, I can name uh a few of them. And it doesn't

have to be one big block of these middle powers, but um ad hoc coalitions of the willing. Um so that I believe this is really something that can be useful in in the evolution of of um governance.

&gt;&gt; So that was that was a fascinating account and I think what it also highlights is that actually whether you're China or the US or the middle powers or France there's a level at

which everyone as we discussed can in some limited way be is pro- opensource. So do you think then that the differentiation will be at the layer of of governance and our approaches to how

we govern these technologies? &gt;&gt; Huh? I don't know is really the answer. Um governance is such a a broad word. Um uh there's a lot of for example um uh open

source is is really being uh taken as a tool by uh startups and scaleups um in in Europe and in other countries I mean by mistral by kohir uh by um sakayi in Japan by by a number of is that

governance um I don't know uh uh but clearly governance and and um uh countries and institutions have a role to play in saying How do we shape those coalitions of the willing? How do we put

public funding or access to publicly funded compute or or access to data sets that that um uh uh countries can can help to put together? How do we put that at use and in which ways? So what are

the governance levers uh that we you use to um strengthen uh uh digital sovereignty and and resilience? &gt;&gt; Precisely. Yeah, that that's sort of what I was getting at. Um okay as I

quickly move to you middle powers as we just discussed it's a very broad term and what it conceals is that there are a many different economic and political aspirations of the countries that are

bundled in that mix and uh especially for countries like India or other countries in the global south uh what are uh the unique kind of forms of both leverage and dependence uh in this

current environment &gt;&gt; yeah thanks so much am I I mean I think that what we've been wrestling with over the last few days is that uh we went from global south to middle powers very

quickly in a matter of days. Um which changes our form a little bit uh and our aspirations. Um and I think that that is what we have to grapple with which is that as global south our needs are very

different in terms of we have structural issues around health around education that need to be addressed. We also have you know you things that we need to do in terms of moving the country forward

beyond what is just technologically mediated progress and I think that what we've been hearing around over the last five days is that things like well open data or multilingual data sets is what

is going to be that push. So you know our languages will now be online but then at the same time we also have to realize that without having openness or control or agency or frictions across

that entire AI stack we we are basically risking you know our populations in the global south big doing the labor to bring people online. So openness as a driver of adoption is actually quite a

dangerous uh frame for global south countries because it moves attention from where we might need to invest our resources to then thinking that the only way to our you know historical problems

is via adoption and we've also seen that in you know in the absence of governance India is not new to the openness openness discourse right we have had a history over the last 12 years or 15

years about on digital public infrastructure but we've also seen the limits of once adoption occurs and when you have innovation people with the deepest pockets come to innovate there

because this is an enormous market so I think that you mentioned Carney like if we are a middle power we're definitely on the menu uh as a market uh if we are a global south country I think that

there's value in thinking about what that solidarity is because you're right, there's no homogeneity and I think we've missed some of those questions around what we as large markets diversify. We

are not here to do the labor to you know test bed models that are built elsewhere. So I think openness as dialogue as distribution of value is what we need to think about. So many uh

sound bites that I want to clip out of what you just said that was uh incredible. Thank you chairperson Cory. Thank you so much for being here. Uh I think what what Asa said actually leads

in well to the question I wanted to ask you which is how does one combat this dependence and as the chair of the competition commission of India you uh you know you're a regulator that has

been kind of ahead of the curve of looking at anti-competitive uh trends in this market. So from your perspective, can you say a little bit uh you know both about the key implications of uh uh

uh you know competition in the AI market and also if you see competition as a lever in the so-called sovereignity toolkit. &gt;&gt; Uh thank you. So uh for us at the

competition commission of India we've been looking at uh lot of developments happening in the internet economy and these uh developments have changed the way businesses work how consumers

interact with the markets and how value is being created. So uh things are moving very rapidly on the digital front and uh as the commission we have looked at what can be the practices which can

be anti-competitive. You know apart from the benefits which are coming from a digital economy we have numerous benefits when it comes to economies of scale uh the network effects uh the

efficiencies which are coming from that. But then there are also these uh risks which are there and uh some of these have already been observed by the commission. So uh the key ones which uh

we found in the case of digital markets uh is uh the uh self-preferencing which is happening tying and bundling is uh occurring in numerous cases. leveraging is being done and uh there are these

exclusive agreements where unfair terms are being also uh sought and uh you know parity agreements parity arrangements are being put in place. So in the competition commission we have

looked at this conduct when it comes to search engines. Uh we've looked at it mobile ecosystems uh online intermediation services whether it is hotel bookings uh food

ordering uh e-commerce or it is uh social media platforms. So we've across the entire spectrum the commission has been looking at it and very interestingly when uh we started looking

at AI and what could be the impact of AI so we did a market study on AI and competition and the report has been uh released recently October 25 it's available on our website and uh we found

lot of similarities in the way AI can function as well so AI can bring lot of benefits we are seeing a lot of benefits when it comes comes to healthcare, education, logistics, supply chain

management and there are a lot of uh agriculture and we seeing a lot of good things happening on that front but uh also there are these potential uh possibilities or risks where you could

see concentration in the entire AI value chain. Uh there could be ecosystem lock in which might happen. Then there could be targeted price discrimination of uh people based on location uh economic

means etc. So the uh and then exclusive partnerships you know and the systems being opaque. So those were the things identified in the market study and as a first step we thought we need to make

everybody aware because you know the important issue is one of access. Who has the access? that is a person who will determine what will happen in future. So it is access to data, it's

access to compute infrastructure, it is access to even skill sets. So whether we are able to build up uh the required skill sets uh within the country to be able to compete effectively. So those uh

issues have brought us to work towards a framework where we are saying in the entire life cycle of the AI system, how can we bring in transparency? How can we bring in accountability?

&gt;&gt; Yeah, I think that's so important too because we focus a lot on you know big tech control over infrastructure or you know people are familiar inputs but I think what you're pointing to is that

it's access to the consumer the pathways to monetization are happening at the distribution layer. So really paying close attention to making sure that we have free and open competition in that

layer and you know uh firms can't sort of take uh dominance from one market into another seems seems really important. My second maybe more provocative question was around do you

see competition as a tool uh for particularly global majority countries to retain and and exercise sovereignity in in the kind of AI age. You know when we uh look at AI we are looking at where

how far we can develop and deploy monitor our AI systems that we are putting in place and that's where uh the issue comes up that we need to have the autonomy to be able to deploy the

systems as per our economic strategic and societal priorities and that's where we see the very critical thing that uh how we can ensure that AI does that and The competition is a very important

aspect of it. We just can't forget about it because competition is what is going to ensure that there are no entry entry barriers that players who are already there are not using their dominance to

foreclose competition to foreclose the market and also that the consumers are not left locked in into a particular system because they can't move their data and their various benefits that

they are deriving from the AI systems to some other applications. So really competition is at the heart of it and I don't see any way where we can forget about markets. Markets would need to be

uh contestable, fair, competitive and for that you know that is where uh I would like to point out about our study that we have clearly brought out that people who are deploying the technology

they have to have technical transparency. The stakeholders have to be able to understand what's happening. What is this technology or this application being used for? And then

there has to be governance transparency that is that how you are governing that system that also needs to be transparent. So once we are able to ensure that the people who are deploying

these systems are in looking at all these aspects then uh the self audit is happening then maybe uh we would be able to safeguard competition because at the at the you know really crux of it all is

maintaining competition. &gt;&gt; Thank you so much. Um Karen, I'm going to move to you and just by the uh you know the fact that there was so many a line of people trying to take a selfie

with you before we started uh I'm going to assume that many people in the audience are uh familiar with Karen's incredible book empire of AI. Her work has really delved into the global

inequities that are embedded in the AI sort of global supply chain. I want to ask you where I mean your book is full of rich examples but where do you see uh that open approaches to developing AI um

in some ways pose a challenge to this empire model of AI? &gt;&gt; Yeah, thank you so much Ama and I feel a little bit intimidated by my amazing panelists. So I'm feeling kind of

nervous which is unusual for me. Um [laughter] uh I wanted to build on this the point of access that you brought up because I think when I in my book I argue that

these companies need to be thought of as empires and one of the key characteristics of them being empires is the fact that they monopolize knowledge and knowledge production. And what I

mean by that is they often say that they're the only ones building frontier models. Therefore they're the only ones that are able to investigate and interrogate these frontier models. and

therefore they're the only ones that can that can advise policy makers or inform the public about how these technologies work in the first place. So it's really this question of access to knowledge

like who gets to actually know what's happening beneath the surface of these models and um one of the examples that I really love from my reporting over the years in 2022 there was this project

called the Bloom large language model um and it was big science project. It was this project that brought together over a thousand researchers from 70 countries, 250 institutions to try and

create an open-source large language model that not only would allow many different um researchers to then interrogate what is actually happening beneath the surface of a large language

model, but also to completely rethink what it would take to develop these technologies in a fundamentally more beneficial way where for example there's better data governance practices where

you're actually curating and cleaning the data, making it transparent for for people. Um, being able to track which data owners are then contributing to what aspect of value generation within

the model. Um, and this this kind of goes back to Aljo's point as well where you were saying that we really need to understand openness with a much broader conception of what openness means. It's

not just technical openness and this project really embodied that where they were working together with lots of different cultural institutions with libraries um historical institutions to

try and figure out better ways of capturing the rich data that they had but with respect to that institution and with a way to then deliver value back to that institution so the value chain

wasn't going just to the model creators themselves. Um, another project that I really loved is one that I highlighted in my book in the epilogue, which is the um, Tahiku Media um, uh, AI speech

recognition model. So, Tahiku Media, they are a nonprofit radio station in New Zealand and they broadcast ino Mai or the Mai language, the language of the indigenous peoples in New Zealand. And

when uh a couple years ago they there's been this big movement within New Zealand to try and revitalize the Maui language because it has almost been lost um through the process of colonization.

And Tahhiku Media thought they had a very unique opportunity with this rich archival audio of Toro Maui to open this up to the community and help facilitate more language learning. They wanted to

make it more accessible than simply just allowing people to listen to it though. They wanted to create an application where you listen to the audio while you see a transcription of the audio. You

can click on the transcription to get um automatic translation, figure out how the language actually works. But they realized they didn't have enough capability to transcribe this because

there simply were not enough proficient mauy speakers. So this was a perfect use case where they could leverage building an AI speech recognition tool to do that work for them. But they went about this

project in a totally different way. They made it extremely open and participatory to the community also not in a technical way but al in a social way where they engaged immediately with the community

to ask them do you want this AI tool? And once the community said yes, they then had a public education campaign where they taught everyone what is AI in the first place? What do we actually

need? We need a model. We need data. This is the kind of data that we need. this is the data that we would need from you. Um, and then once they actually engaged in that process and they

developed so much trust with the community, they were able to collect enough data from the community with full consent in just a few days to train a speech recognition model. And then they

continued to go back to the community and they said, now that we have this model, what do you what kinds of applications you actually want us to develop with this? What kinds of new AI

models do you want to develop with this? And all of this was built on another open- source project which was the Misilla Foundation's deep speech model which was similarly um with that kind of

broader definition of openness. You it was a model developed purely with also consentful data donations. And so the entire stack was with this spirit of collaboration with participation from

everyone in the community with uh equal um exchange of value where the people who are giving the data have a vote have a say in then how the model ultimately can help support their journey in

language learning. Um so both of those examples I always hold in my head when I'm thinking of what are the visions of AI that we actually want to support. what are the visions of open space AI

that we actually want to support? Um I so I have a a as you were speaking I was just thinking apart from being open and participatory in all the ways you said um these examples also provide a

contrast to the idea that there is one model to rule them all these this very sort of large language we're taking a single bet on a single technology type of um approach but similarly one of the

I guess common retorts to these these experiments in some sense is that we can't do that at scale and so I'm just curious what do you see as the tension between um the these kinds of governance

structures and and scale and is there a trade-off? So I would reframe what we mean by scale because what we are taught by Silicon Valley is that scale means they distribute to everyone but they are

the sole distributor and to me that's not scale that's a monopoly. Um and what really we would want from scale is different communities all around the world different industries different

companies each developing models by and for them at scale like that. That's to to me like a much more appropriate way of thinking about scale. And in fact, what's so interesting is like because of

the data imperative for large language models and the compute imperative for large language models as they are currently being trained by the main companies, there is not a there isn't a

good ability to diffuse this technology across many different industries or many different communities. Most industries are data poor industries. They're not like the internet industries. they don't

sit on vast amounts of data. And so if we actually want to diffuse AI to more um more people around the world and for more use cases around the world in fact we need to think of scale from like a

small AI perspective, a communitydriven perspective, application specific perspective and that's how we're going to get scale. Okay, we've heard uh I guess a range of rich perspectives and

I'm going to take it as a good sign that all our panelists seem to be actively taking notes and sort of engaging what with what each other was saying. So, I was going to propose as a sort of round

two that I might ask just based on the conversation we've just had, Alandre, what is something that's sort of sticking with you or that you're you're working through um in response?

&gt;&gt; Yeah, I think community. So Karen um queued that up for me and the note that I was just writing here was about that and I was thinking about um how the stack that we are building now is is

like explicitly closed to community and I was thinking in particular about the data center and cloud layer. So in the US context you know there's a lot of contestation there's growing

contestation in communities about data centers. Um what folks might not know is that part of the contestation is because elected officials are asked to sign NDAs and contracts are being signed to to um

stand up data centers in the dark of night and communities don't even know. So it's you know so the the sort of lack of um openness around the infrastructure that infrastructural piece of the AI

stack is actually quite profound. And then I was thinking the opposite. So my reflection on the time here which I'm still going to be processing for quite a long time. It was my it's my first time

in New Delhi, my first time in India. It's been an incredible experience. &gt;&gt; But I've been to a lot of AI conferences like you know Nurups and everything you know like professional ones, not

professional ones a lot. &gt;&gt; This is the first one I've ever been to that has included the community in any considerable way. And it just is I mean I think it's a revolutionary thing. And

um and if we're really serious about having democracy and community and voice, AI conferences need to look much more like this one than the ones that we spend a lot of our time going to. So um

I you know so who knows what will be the outcome of this week together. But it has been extraordinary and distinctive in the inclusion of lots of you knows aunties uh college students and lots in

between. Yeah. &gt;&gt; Aa closing reflections. Um yeah um first of all thank you for that reframe as somebody who was here on the 16th I was feeling so overwhelmed

and my instinct was like there are too many people but [laughter] like um but but I do appreciate that reframe on the fact that this is the community that is going to build and question and and and

do the work I think that we all keep talking about and I think from that is also my word is also community but I think friction. How do we enable some of that both the coalescing but also the

the dialogue the questions the where is the value for me part of it and um I know uh an example that was presented yesterday by on on the AMU co-op we've been doing a lot of work with

cooperatives uh to me which is a is a nice space because it is the governance question of one member one vote you can pull things um so how do they become recipients but co-designers in some of

the things that we've heard over the last few days. So yeah, &gt;&gt; person just closing reflections and and maybe even just a takeaway that you're sitting with after after this week.

&gt;&gt; Yeah, sure. So uh for me I think uh the very important thing which came out from this uh AI impact summit is that uh the governments need to be very active about uh how they are ensuring that the

deployment of AI is happening and for that I am very happy with the way uh we are going in terms of you know we did a great job when it came to digital identity and digital payments. So uh now

we are looking at uh a digital public infrastructure how you're going to be able to provide uh compute platforms for startups for people who don't have the resources uh make available data and uh

then the focus which is there on small language models everything doesn't need to be large especially when we look at uh things which are very language specific very uh related to our country

and to our solutions. So that's one of uh the key takeaways that I have and the other of course is that uh we be going all of us uh at the competition commission are now you know going back

with this that one needs to be very alert as to what are the kind of systems which are being put in place and uh are is there transparency is there accountability so those are the key

things because at the end of the day it is trust if you can build up trust if your systems are not opaque uh then uh you would be able to get the people on board onto your uh applications and to

your systems and uh that's that's where success lies. That's where value is. &gt;&gt; I'll say ma'am that my one of my key takeaways and I hopefully the someone from the Swiss government is listening

for next year is that we also need to see much more voices from uh the enforcers those that are going to make sure that uh the players in this space are accountable to the public and uh not

above the law. And so I'm very grateful that you're here and I hope uh that uh future summits see see more more enforcers at the table. Um okay Karen you you get the the last word and I

would I'm going to open up for questions. So start start thinking of them. I think my my biggest reflection from the summit which I also shared at an

event last night is that um it's so interesting to observe corporate speak in these spaces and the thing that struck me the most about this summit is that this corporate speak has gotten

very sophisticated in that they have adopted the language of inclusion diversity um empowering marginalized communities um to talk about ultimately selling their technology and and making

sure that you kind of buy into helping them lock in their their their closed platforms. And I hope that because we have more community engagement and there's more openness in a lot of the

discussions that are happening um kind of alongside the this very sophisticated corporate speak that all of you will take away from the summit. This ex this um broader idea of what it really means

to ultimately build a future where AI can empower people. It does not actually mean the democracy that the companies offer us. It in fact means that we should all be thinking very deeply about

what are the problems that we really need to solve in um as individuals within our families, our communities, our companies, our context and then whether or not AI is even the right

solution for that problem. and then how to design and develop from the ground up AI solutions that truly are uh are empowering and enabling and help tackle those problems and bring everyone along

together. &gt;&gt; That was yeah, let's what a what a great note to end on and and honestly a note of optimism um and and a note to build towards the futures we want to see. Um,

okay. So, does anyone have any questions? Okay. I I saw you first. Go ahead. &gt;&gt; Um, hi everyone and um, yeah, I was one of the people in line u [laughter]

looking for the uh, signature on the on the book. So, I've read uh, Karen's book and my question is uh, addressed to you. Um so all of this um it makes sense but it makes sense in a more macro way uh

from a micro perspective where an individual um is exposed to AI and uh you know at at their workplaces and we're expected to use it and you know that there's no getting away from it. um

how do we reconcile the the fact that you know probably there is a whole lot of exploitation behind the models that we're using but at the same time you can't not use it because it's just it's

everyday &gt;&gt; I don't use it. &gt;&gt; Yeah. [laughter] Yeah. So I'd like to know a little bit more about that. How &gt;&gt; um Yeah. No, I I actually I think it's

totally possible to not use these tools, but also I would say that oftentimes our conversations around adopting AI are are posed as a binary. Like either you go completely allin or you go none at all.

And there's actually a million possibilities in between, right? There are so many different ways that you could refrain from using a in certain context, but maybe there are other ways

that it helps you. um being more intentional about what kinds of AI tools you adopt from which kinds of companies like we've been talking a lot about openness. So maybe you choose to use

more open AI technologies rather than the closed ones. Um, one of the things that I feel is missing right now within the AI ecosystem that makes the burden very very high on consumers is that we

don't really have thirdparty organizations doing analysis to make clear like clear and easy labels for consumers to determine what values and what degree of resources are being used

to develop different types of AI models so that they're they can actually make informed decisions. But we have lots of precedent of this happening in other industries like the fashion supply

chain, in food, in coffee. And so I hope that someone out there listening will start working on this like develop some kind of third party third party labeling system so that consumers can actually

start um making more informed choices. The other thing that I would say is I also don't think individuals um like we aren't just consumers. That's not the only way that individuals can push

against the inevitability narratives of AI. We've seen amazing protests that have broken out all around the world to push against data centers. We've seen protests from parents who feel that

their children are being harmed and this um rapid escalation of AI advancement is getting out of control. We've seen artists and writers using the tools of litigation to counter when these

companies are infringing on their intellectual property in ways that they don't stand for. Um, and so there are many different ways I think within your life. AI is everywhere. And also that

means you as an individual and within your community have a thousand different touch points for how you can interact with the AI supply chain. And in each of those touch points, you can choose

whether to resist or adopt or be neutral. And so there's yeah like I hope that people actually feel significantly more agency than I think people generally feel today.

&gt;&gt; Thank you. &gt;&gt; Okay. I think we should do a couple of questions. So you you and you. Okay. Let's go in that order. So we'll take those three questions and then

&gt;&gt; Hello. Um thank you so much. This was I think my favorite panel of the whole summit. So and also like an all female panel. I think it's it's nice. Um, it's also kind of connected to a reflection.

You know, my question is like I feel like at this space I've realized there's not as many women by far as men. Uh, and again, as you said, it's the only female panel and we are here with a group of 15

people from Germany and like half of us is male and half of female. often just um our male counterparts get addressed and somebody's just speaking to them and you know not like asking them for money

or other like in terms of like pitching their their business idea whatever um but I've also noticed other things like the the theme is right AI um all-incclusive right uh but I'm

wondering like who does this include in the specific context and which vision like do you understand like from this summit who you think is included in this vision for all inclusive um and also

I've realized I don't know if anybody else has realized but I feel like China is quite an important power in the AI governance space but the amount of Chinese people have here I've seen is is

very low and it's just something I realized I noticed so I feel like it's still just some reflection I wonder how you see this like what what does yeah this notion of all-inclusive mean for

for you or how you perceived it here &gt;&gt; thank you that was many important and provocative questions you just asked uh could yeah &gt;&gt; uh I was curious kind of as a our

colleague here, your role on the open source Chinese models which are clearly the most intelligent but uh in the open source space but clearly have a deep CCP perspective and so I'm curious like how

does that come together in this ecosystem and how can we leverage it appropriately? &gt;&gt; Great. and &gt;&gt; hello. Thank you panel for the wonderful

discussion. Uh I'm an intellectual property and business lawyer. So I will my question is related to intellectual property specific to Ravnitma. Just I wanted to know uh how you see the

openness of AI in context of the intellectual property as uh openness is somewhere giving the restriction with with in context of the intellectual property.

&gt;&gt; Okay. Why don't we start with that question? Okay. Sure. So uh when you look at intellectual property because you know there's a lot of uh research development and innovation which has

gone into the development of that technology and uh whatever is put in place there and there are these copyrights there are these uh patent acts which are protecting that when it

comes to the competition commission we come into the picture only if we find that there is an abuse wherever uh whatever innovation has been done it is being used to ensure that no other

people can come into the into into the same market and it is being used to enforce conditions which are unfair. So that is uh the only space where we come in otherwise the purpose of the

commission is not to stifle innovation. We are to in fact protect innovation because that's the way to grow. That's the way markets will grow further. Competition will increase. New players

will keep coming in. Better technologies better value for the customer. So consumer welfare is one of the very critical things we look at. that's how we address these issues.

&gt;&gt; I wonder if Aasta you can talk to the gender and that broader question on inclusion. &gt;&gt; Yeah. Uh thank you so much for that question. I think it's a it's what we've

all been feeling as well. Um I think that bases what I have understood and so very early overwhelmed sense is that there is a inclusion as Karen was saying is also being troenhaused as a word for

adoption. Um and I think that that is the primary framing that I'm taking away from the inclusion for all because as you'll see that uh democratization is about market access the working group

also says so so and I think that the gender perspective will also and we've seen this again in previous iterations of the tech will save us financial inclusion digital financial inclusion

variety which is like get people online and and then what ends up happening is that when you realize that you're not able to make money of these like you know the bottom 80% then you start to

get drop offs there. So it is at the moment of that hype cycle of getting everybody online and then whether we're able to extract value from these people will decide who it's for if that makes

sense. &gt;&gt; Um Alon maybe you could take the question on Chinese open source AI and how we feel about it. &gt;&gt; I'll try. I mean, one thing I would say

about there's been some news reporting on um uh you know, about the fact that this week took place during the lunar new year um and that that probably had some um impact on participation Ramadan

as well. I mean, you know, so I think um that's not lost I shouldn't be lost on any of us for this question of inclusion. Um I I think I mean I haven't worked with the Chinese models so I

don't know but if they're open source models you should be able to tune them so that they don't have um you know at least as much kind of um you know CCP kind of ideological control. I don't

know if you do that in the training data or inference level or where you do it but um and it seems that they are there are a lot of companies that are building on the Chinese models and so it it it

seems like even in the enterprise space and so um that is clearly not a um a hurdle to some of the enterprise kind of uses and applications that people want to build on them. So

&gt;&gt; I think we can take two more questions. Okay. Okay. So, your hand and I just want to take someone from the middle. You can go. &gt;&gt; Okay. We we the alarm just went off. Um

so, if you could also make sure that it's a crisp question that would allow there to also be answers. &gt;&gt; Yeah. Yeah. So, I am really interested in how AI is going to impact labor. And

one of the biggest concerns in this area is the fact that you know AI can train on the intellectual labor of so many people without giving credit without giving compensation. So there are

obviously regulatory approaches to this but I'm more interested in like an so new research that's happening about protecting publicly available data be it images be it uh websites be it written

content in a way that that data if it's used directly by AI it's either useless to it or it's harmful to it I think there's some research happening in University of Chicago around that and

some other places so my question here is twofold first is this like a good approach to sort of protect intellectual property or data by creating protection by design and two how does it

tackle how does it go with the idea of openness right because on the one hand it seems &gt;&gt; can that that let's thank you for the question I just want to make sure we

have time for the others they're going to kick us out of this room um &gt;&gt; that's the final question and then maybe Karen you can address the labor question &gt;&gt; hi I wanted to um ask about open

washing. We've been hearing the term in previous discussions about um openness and competition and I just wanted to ask um in terms of enforcement, how should competition authorities assess whether

this openness is genuinely lowering entry barriers or or whether underlying um dependencies still exist essentially. Do we need new analytical tools? Does there need to be

an reworking of the frameworks around competition? That's essentially the question I wanted to ask. Thank you. &gt;&gt; Okay, Karen. And then chairperson Co, you will have the last word.

&gt;&gt; Sorry, can you remind me the very last part of your question? You you were talking about um &gt;&gt; I agree with everything that you said basically that yes, this is a huge

problem. [laughter] Um yeah, like labor exploitation is absolutely happening both with the exploitation of the the labor that is being used to produce the data and also

labor exploitation of like data workers that are cleaning the data. Um and I think that just shows given that the labor exploitation is happening all through the supply chain that that is

kind of inherent in the logic of how these models are being created and we need to fundamentally rethink that from the ground up. &gt;&gt; Thank you. Uh so when we come do a comp

uh competition assessment uh we are looking at a numerous economic factors are also taken into consideration. It is not based on you know what is being submitted to us and a very detailed

analysis is done to understand whether there is any competition harm and uh the other aspect which is looked into is what are the effects which are there is there an appreciable adverse effect on

competition. So we have to establish both the things and this is done on a case-toase basis after doing a very rigorous analysis of uh both uh the data which is available in the public domain

and the analysis done by our internal teams only then we are able to determine whether there's a harm to competition. &gt;&gt; Okay. Thank you all so much for being here. This was such a rich conversation

and thank you all for being [applause] part of it. &gt;&gt; I think we You heard the bell.
