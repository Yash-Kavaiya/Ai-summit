# Standards as Strategy: Accelerating AI Market Growth

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Shakuntalam Banquet |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/l9q_fVpbQUo?feature=share) |

## üé§ Speakers

- Amanda Craig, Microsoft
- Balaraman Ravindran, IIT Madras
- Chris Meserole, Frontier Model Forum
- Esther Tetruashvily, OpenAI
- Owen Larter, Google DeepMind
- Rebecca Weiss, MLCommons
- Rohit Israni, Chair AI Standards US (INCITS)

## ü§ù Knowledge Partners

- MLCommons

## üìù Summary

This discussion examines how AI standards simultaneously reduce risk and create business value. As AI capabilities advance, many markets face deployment barriers not from technical limitations but from reliability concerns and broader trust deficits. Robust standards, backed by rigorous evaluation, can unlock market potential. This panel convenes leaders from AI standards and governance organizations alongside industry and policy executives to examine how effective standards enable economic growth, market confidence, and responsible governance.

## üîë Key Takeaways

1. This discussion examines how AI standards simultaneously reduce risk and create business value.
2. As AI capabilities advance, many markets face deployment barriers not from technical limitations but from reliability concerns and broader trust deficits.
3. Robust standards, backed by rigorous evaluation, can unlock market potential.
4. This panel convenes leaders from AI standards and governance organizations alongside industry and policy executives to examine how effective standards enable economic growth, market confidence, and responsible governance.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/l9q_fVpbQUo/maxresdefault.jpg)](https://youtube.com/live/l9q_fVpbQUo?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

My name is Buchanan Sati. I'm a partner at PWC in the US. I'm also an adjunct professor at NYU Stern. I'm going to provide a brief introduction and then I'll have my panelists introduce

themselves and we'll get into the discussion. So I'm a consultant around AI transformation. I help companies implement AI, drive the return on investment in a responsible way with AI.

What's really important about this discussion is we need to demystify what we mean by standard setting. There's been a whole lot of discussion at this week's summit around the importance of

global cooperation that the importance of inclusion around AI driving solutions that meet everybody's needs. The tech CEO spoke about it yesterday. World leaders have spoken about it. We're here

in India where it's about planet and people and prosperity. So that's what the discussion is going to be about and we are going to have time for Q&amp;A at the end. But I'm going to have my panelists

introduce themselves first in the order that they're sitting to introduce themselves and also talk about what standards mean for them, what lens they're looking at from a standards

perspective around AI. &gt;&gt; And we're going to get the mics to work. Hello, my name is Rebecca Weiss. I'm the executive director of ML Commons. We are an AI benchmarking organization. We are

an engineering consortium that focuses on that problem. And so for us as a technical standards organization around benchmarking, what that means for us is two things. One, we want to define the

methodology for measurement. And two, we want to create the technical artifacts that allow for engineers to integrate this methodology into their development life cycle. So for us when we see what's

happening in the world today, the ability to measure risk is a big barrier to adoption and that ability to understand and estimate the uncertainty around the behavior of an AI system is

something where we think benchmarking can help. So I will actually because we have a large panel so I'm going to let everyone else have a chance to talk and I'm sure more will come out in our

dialogue. &gt;&gt; Thank you. &gt;&gt; Great. Thanks Rebecca. My name is Eten Shapony. I work for Qualcomm. I'm a vice president of technical standards and so

what we do within that role is effectively we have team going to technical standards for AI and we actually try to coordinate where is it that we need to go how is it that we

need to make sure that we understand what it means to be compliant. I come from a world of telecom as Qualcomm can uh can evoke to some folks. Um and for us it's a very different thing right for

the telecom world you cannot ship a product unless you comply to a standard because you need it for inter interoperability. In the world of AI standards is a bit different. So we're

talking more about safety standards and those typically tend to trail the products. The products are out there and then they're going to comply to standards at some point when the

standards are available. Um what matters however what is common in all of this is that the standards need to be available at scale for everyone and in a way that engineering teams can do it easily u at

least from the product side. So I think I leave it at that and yeah pass it on. &gt;&gt; Hi everyone I'm 1 from Singapore government. Uh I work in AI governance and policy. Um so many things but

specifically for standards uh what it means to us is um setting norms um that means alignment globally um on um what good looks like um and specifically in the area of uh AI

governance then a lot of it has to do at this stage um in terms of uh common methodologies and processes that we have to follow uh but it's still technical it's not a checkbox but um hopefully

that helps us all align into what good looks like. Thanks. &gt;&gt; And maybe before the next introduction, just so you can get a flavor, we have standard setters and measurers. We have

people in industry and we have people who play in the the policy and the regulatory environment. And that's that's the importance around this topic. &gt;&gt; Thank you. Hi everyone. I'm Amanda uh

from Microsoft. I am uh I lead the public policy team within the office of responsible AI at Microsoft. I think Wansy said it well um when she described standards as really like aligning around

what good looks like. And I would offer you know we actually at Microsoft in our office we define something called our responsible AI standard that applies to all of our internal kind of product

groups our engineering function our sales function. And you think about like the the role of that internal standard is to align all of the internal stakeholders we have around what good

looks like externally we need the same sort of u mechanism right and that's the role that standards can play in the broader ecosystem. So we want to partner with our industry colleagues um and we

want to partner with governments and others around the world to be able to define what goods what good looks like so we can all have that common language and set of expectations.

Hello Jocelyn Google deep mind where I also work on issues of AI standards governance and policy. Um building on what's been said. So I think that was an interesting point that often technical

standards come first and process and safety standards often come later in the space of AI at the moment actually regulation has gone ahead and jumped to you know we've regulated uh and

essentially made reference to standards that do not yet exist. So for places like Google Deepmind who have not invested heavily in the standard space in the past, this is now of an utmost

priority because we actually need this to assist with implementation and compliance. That is a a primary goal on our side. I'm uh Chris Muzel. I'm the executive

director of the Frontier Model Forum. Um our mission is to advance Frontier safety and security and we work with many of the the leading Frontier AI developers and deployers including

several colleagues uh on the stage today um to advance you know best practices for risk management. There's a for Frontier AI in particular there's a kind of unique and a set of unique and novel

risks that over the last couple of years the community has really started to develop and and converge around you know a set of best practices that now I think need to start to graduate into actual

formal standards. And I think that's that's kind of why we're here and that's why we're very interested in the the standard setting space. &gt;&gt; Hi everyone, my name is Esther Tetroilli

and I'm the AI standards lead at OpenAI. Um echoing many of the things that have already been said. Um I think standards for us especially as an an a frontier AI lab is about translating some of our

practices for risk management into the language of risk management for customers across the supply chain. And it's also about creating a language for consumer trust and assurance. It's also

about um in the age of agents thinking about interoperability and helping everyone benefit from this ecosystem that we're developing here. So I'm really excited to be here and to talk

about these issues with you all. &gt;&gt; Thank you. Hello everyone. Uh I'm Chhat Chhat Bartla from Bureau of Indian Standards the National Standards Body of India and here representing ISOICJTC1

SC42 because BIS Bureau of India standards is a part of the SC42 and for us I would say standards are the tools which enables consumers trust in the whatever ecosystem for which they

are developed as well as enablers for the industry to get it done to ensure the quality and the consumer trust. I would say that's the main focus areas for us.

&gt;&gt; So let's start with like why we need standards like why are we even here because there's a lot of confusion between standards, regulation, legislation, are we going to get global

cooperation around these things? Maybe should just from a a a standard setting perspective and then maybe from a regulatory perspective, why are we here? What are we what's the problem we're

solving and and for whom? So I would say uh the problems there were multiples in the standards domain specifically it's always starts with what we are tackling with what is AI

that's was the primary focus of the JTC1 SC42 when it started so it defined what is AI what is generative AI now they're talking about what is agentic AI as of now talking about so I think the most of

the specific points that needs to be tackled here is what is coming next and to keep pace with that and apart from once it comes to that one we have kind of

mentioned that what it is all about then how do we verify and validate whatever is being said that this is a system which is having AI for example I

would say uh someone says they have then equipment call it washing machine or refrigerators is equipped with the AI but is it actually equipped with the AI or it's just a normal logic system. So

this is something that we're trying to through the standardization. &gt;&gt; So it's about it's about trust. It's about verifying that the tech firms here represented are moving very fast with

the model development. So it's like we need standards there. Just from a regulatory perspective, what would you add there? I wouldn't say from a regulatory

perspective um maybe in terms of why from a AI policy perspective we think standards are helpful it's like I said it's about um defining alignment in what should be in let's say transparency

right so I think the if you if you say what would be the top three things today that we want to think about testing sorry setting for standards will be one testing how do you do um testing

um for AI whether it's AI models or AI applications I think that's one area because then it defines what good testing can look like right two um perhaps in transparency what would uh

disclosure look like right um everyone is sort of have their own way of sharing the information that they want to share um one way is to standardize it so it's easier for the readers people who are

consuming this information to understand and I'm saying this in very very broad terms I mean it depends on which reader you're talking about who's going to consume but just in broad terms perhaps

some one way of standardizing it. Maybe the third way could be in how you're reporting or monitoring um incidents. Um but it's we're still very very early days but that's where standards again in

terms of alignment that might be one be useful to find some alignment in these areas &gt;&gt; right so how do we report how do we disclose how do we make it credible um

and so it's not a subjective tick the box exercise etc from a standard setting Chris and Rebecca from a standard setting perspective what would you add to that before we have kind of the

industry view &gt;&gt; um I'm happy to add to this so I think there's been a theme that has come across in this panel a couple of times which is what is good enough and I I

think in order to define that a standard represents a consensus about what is good enough. The problem that we have is who contributes to that consensus. It shouldn't probably be exclusively an

industry perspective. You need to have more stakeholders or more constituencies that need to be represented in that definition. And then on top of that, what is good enough? As I think Joselyn

mentioned earlier when we were talking before this panel, there's a scientific element to that. How do you define the characteristics of a system such that you can actually create the kind of

uncertainty estimation that lives up to a statistical guarantee? But then there's also the political element to that which represents a whole set of issues that I'm actually not qualified

to talk about. So I will pass it to Chris. &gt;&gt; One of the original questions &gt;&gt; is Chris's mic working. &gt;&gt; Sorry. I was just saying one of the

things we should uh maybe do is back up a little bit to this question of what are standards for and I think a big part of what standards are for is to try and solve this collective action problem of

there is a there's a kind of unique set of risks that we are worried about. Um uh we want to make sure everyone's on the same page so that no one kind of actor is you know disadvantaged or

advantaged compared to others. Having standards for how we're going to manage risks uh across an ecosystem are extremely useful for that. Um, so there's a there's a policy dimension to

it. Um, there's also an adoption dimension to it, right? Because people want to know that there's kind of a a common way across industry of handling a certain class of risk. Um, and I think

being able to set standards and have have a formal standard setting body to one of the points that was made earlier, they are by definition a standard setting body is open, right? So there's

a legitimacy and a credibility to standard setting bodies that you don't have if it's just industry or just government in many cases. is and I think you know all of those kind of factors

coming together are exactly why we're so keen on kind of pushing forward the standards discussions around risk management for for AI. &gt;&gt; Y so maybe from a from a hyperscala

perspective maybe Esther then then Jocelyn and we can kind of like play the different how is this showing up kind of at your firms and how are you thinking about this? Yeah. No, that's a great

question. I think from sort of a market adoption perspective, a lot of our technology like general purpose AI models or foundation models are being integrated into existing ecosystems or

on top of uh stacks and there's a lot of confusion in terms of risk controls and risk management about what that means. We have our own risk management processes. They have their own

riskmanagement processes and one of the barriers to adoption is having a common language to talk about how do you map those controls onto one another. There's a separate challenge I think of like who

is best positioned to control a particular risk. What are the risks? Um what are the net new risks? What are the risks that are already existing? Um where we don't need to create something

net new. And so for us, it's both an an important an imperative in some ways to kind of translate what we're doing in terms of managing [clears throat] risks into the language of upstream downstream

customers so that they can understand and map those same practices onto their controls. Um and then we kind of can create a universal language um that can ease trust and assurance in an easy

groable way across the market. Um there's also just space for I think several people have talked about regulations moving ahead of the standards uh where we are still

developing methodologies what is standardizable in what we're doing um recognizing where the science is not caught up yet um and where and where we maybe are in a place of more maturity

&gt;&gt; and maybe just to to bring it to life for the audience given given the the huge amount of subscri subscribers you have in India around the world growing every day is what's changed in the

standard vernacular at open AI &gt;&gt; what in terms of our adoption or in terms of how we're just &gt;&gt; the prominence of it how people are thinking about it the importance of the

topic &gt;&gt; so I think there's both an aspect of it that's like what does already exist that we can use that can reassure customers that we are following the best practices

for the industry say for privacy or cyber security there's a existing risk management standard ISO 420001 that open AAI just got certified And that's definitely signals something to the

market and to customers. Then there's also uh sort of a transparency element, right? We have our safety frameworks. We update them. We disclose information about in our model cards performance on

a variety of metrics. Um and then there's uh certain things we do uh to kind of elevate and help stakeholders across the spectrum in terms of how to build evaluations. So we currently

published a safety hub that gets updated regularly that kind of tell us how we're performing in a variety of metrics and what are the best methodologies and how to work with us.

&gt;&gt; Great. So Josie, can you bring to life how Google deep minds are thinking about standard setting in that context? &gt;&gt; Yes, I'll take it back to what Chris was talking about in terms of collective

action problems. So some of the mitigations we're talking about associated with some of the more extreme risks uh that frontier AI poses can be quite costly. And so I do think that

there is just a strong industry incentive to work together to resolve this collective action problem. Again, as Chris said, doing this through standards through an open legitimate

process seems to be incredibly impactful. Again, like the the worst thing for adoption would be a safety incident. So again, we have a collective incentive as an industry to make sure

that we raise the floor to avoid that on all of our behalfs. So I do think that that is seen you know I think standards at this point are seen as a very clear and important strategic play for making

uh you know essentially clearing the path for rapid adoption &gt;&gt; and Amanda how do they show up at Microsoft right now &gt;&gt; so couldn't hear the question

&gt;&gt; how do they how do these standards show up at Microsoft Amanda's going to speak about Microsoft experience &gt;&gt; thank you yeah I I was going to start by just you know thinking about

at Microsoft oft at at Google at other places. It's not a totally new kind of process that we're going through, right? In terms of thinking about standards and the importance of standards for uh

adoption of this technology, sufficient trust in order to uh have adoption and in order to to really enable compliance. I mean I think Esther made a really good point and and sort of acknowledging that

you know especially as we are deploying this technology we are um working with customers that have their own set of standards and and regulation and part of the challenge that we find ourselves

like facing right now in AI governance is we have a lot of highle norms and expectations that again are not so different from the patterns we've seen before basically we want to know how AI

providers are managing risk but um we are in the early days of defining really what that means in practice in a really detailed way especially like across the AI value chain. So what are model

developers really responsible for doing for risk management? What are application developers really responsible for doing? How does that dock in to what deployers of those

applications that are oftentimes uh implementing existing standards and meeting existing regulatory requirements? How does all of that fit together? Um and again you know we've

done this with other digital technologies as well like software like cloud services where we're ultimately trying to define in practice what is everyone responsible for doing? How do

we have a common language to be able to talk to each other among sort of providers or the or the supply chain of technology and those that are ultimately deploying it. Um but we actually really

do need the standards to to support that right because you know otherwise we we are we are stuck at the sort of like highlevel um conversation about norms around we we want to evaluate risk. we

want to figure out what the kind of right transparency practices are or we can find ourselves in this sort of deep technical weeds. But like sort of having that a place in between that is um

really at the level of of standards of technical standards really helps drive that kind of common set of expectations so that you can have trusted adoption and then also you can have clarity for

compliance. &gt;&gt; Yeah. So we need them. They're important. We got to drive adoption. There's a collective action agreement here. from a Qualcomm perspective, STN,

bring to life the business model, how you use this in engineering your products. &gt;&gt; Yeah. So, I think there's there's one thing that I'd like to to note here as

as Qualcomm, we're basically provide chipsets, right? We're not building big models. Um what matters to us still is the fact and the reason why we're engaged in those standards whether it's

in ISO sens for Europe ML comments when it's other type of standards is effectively the fact that it provides scale in the sense of providing scale not only across the globe but also

allows any different type of companies to benefit from it. I mean, let's be clear, right? If you look at the companies who have the type of resources to either set up their own standards and

risk management systems internally, there are typically pretty big companies. Now, the thing with AI is that there's a huge amount of companies who are being created every day and they

don't have the resources to put this together. And so, there's two conditions for making sure that the type of standards are being put together are one inclusive is that they're open as

Rebecca you were alluding to before. And so whether it's ML comments which has a very open governance model or ISO or Senelch in in Europe it need there needs to be an opportunity for everyone to

participate right so that's the first step however we know and that's the reality that not everyone has the means to participate because they're like super focused they need to bring up

their own LM for that particular use case or maybe very general use case and they just don't have the resources to do this so from that standpoint having the standard as a effectively a mechanism

for them to go directly to product and know that they're going to comply with what the effectively world or the community has set up is really important. So from Qualcomm the reason

why we want to participate is to enable this type of accessibility to companies which are not always the biggest one. &gt;&gt; Yep. So be so agreement that we need them before we go into how we set

standards, how we measure and benchmark them and Rebecca will bring that to life. A wildcard question is there could be a lot of people listening to this to say the world is not connected and

cooperating around this. We don't have global regulations on AI but yet we have industry leaders standard setters vehemently agreeing. How should the audience think about that? Is there a

disconnect there or anyone would anyone like to comment on that? I would actually put so part of one of the you know reasons why I think we're also interested in standards is one of

the things you're have one of the things you're seeing is multiple jurisdictions saying some version of we think that there are new risks with frontier AI um we as the government are concerned on

behalf of our citizens that we are kind of attending to those risks across industry those risks and how to manage those risks are probably best left you know uh

to be developed or kind of managed through the standard setting process but they aren't always setting the standards right so in the United States in uh there's a couple of different states for

example within uh the United States that have passed requirements for you know Frontier AI developers to have a Frontier AI framework but they don't specify what should actually be in the

framework they kind of spe they they kind of offload some of that to the standards process um which is why I think it's so important to have these these standards in place like there's a

clear kind of policy and regulatory interest in there being um mechanisms by which some of the risks uh uh that may come with frontier are managed but that we need to kind of color in the lines a

little bit exactly like you know how we're all going to do this as a community. &gt;&gt; Yeah. And before we go to Rebecca just from an India perspective PM modg talked

about manav yesterday and the AI vision through there that there was a lot of focus on validity and governance so standards were implied there. Do you want to just bring to life kind of how

India thinks about this before we go to Rebecca and talk about measurement? So I would say [clears throat] the man of mission you it's welfare humanentric and all those aspects are there and from the

governance perspective also what is going on is that we as of now the India AI governance guidelines are there this is providing you a framework that these are the things that you should look into

just providing a reference to so in this direction the Indian government as of now is moving into coming into the from the perspective of standardization and the at the national level as well as

the ISO level. Uh I'm adding to the question that you asked previously that standards bodies are interconnected with each other. The ISO

there is a license mechanisms the we have the ML commons as the license there the IT are there all bodies are there so they are all interconnected there and then way whatever is coming as of out of

the these bodies is an outcome which is based on the studies and out but done by various forums it's not only the one I would say just the ISO body or not So in this direction the Indian standards that

we are working on we are developing are also in the direction because AI is something which is global we can't have them specifically for India there could be the risks there could be specific use

cases that are India specific for that those we need to have some specific guidance but more or less the everything is the the global thing that we are trying to look into and then adapt those

with the specific use cases that we need them, &gt;&gt; right? So, we need global. We need to adapt that to kind of local kind of conditions and use cases. So, let's get

a bit more technical, Rebecca. Like, why is this hard? How do we measure it? Like, how does it compare to benchmarking maybe Rebecca? And then, and then from a regulatory perspective,

um, &gt;&gt; did you want to make a quick comment? Yes. Do you want to make a response there and then we'll get into SorryC please.

&gt;&gt; No, I just want to respond to Chris uh comment and your question about, you know, if there's no regulations, then why do we care about standards, right? I mean um sure I think there will be

regulators who will say yes you turn to the technical standards to define the expectations which I think is a fair point that Chris made um but even when there's no regulations I think the

standards still are useful I mean um Esther just mentioned that open AI certified for 421 you didn't need to do that but why did you do it right and um entropy has done that as well and I

think the the idea is that perhaps there's also a way to differentiate iate for organizations for enterprises and it doesn't have to be the frontier model labs only it could be app developers and

so on the way to differentiate themselves and say that look I'm I'm adhering to a global standard um I'm demonstrating that I have actually implemented something that's good enough

I've addressed a risk in this way I think that's one good um um reason um for standards even if I if they have if there's no regulatory cover so the certification the assurance part is

helpful um yeah I just wanted to add that as a as a little bit of color just to give some benefits to the standards community that &gt;&gt; you're still kind of very very

&gt;&gt; Thank you bringing the regulatory perspective and kind of the Singapore experience. So let's get into measure and the fellow panelists if you want to respond to anything just give me the

signal. We're going to make this an interactive conversation. So Rebecca, how do we measure this? &gt;&gt; Um well solve all the problems in one definition. No, I'm kidding. But um the

as I said earlier uh benchmarking consists of two things. It consists of a methodology at least from our perspective the way that we do benchmarking consists of a measurement

methodology and it consists of reference builds implementations of that methodology so that engineers can use that and the definition of a benchmark as we've been um trying to

operationalize this in places like ISO and others uh is a taxonomy um a data set and an evaluator system and the point of all of that construct is as Etienne pointed out this allows for you

to scale this kind of approach towards you know the type of deployment ments that we're expecting to see in these types of AI settings. Uh the challenge behind all of this is that what you're

really trying to do is estimate uncertainty. Um you're trying to provide a sense of I'm not going to tell you that your system is quote unquote safe or not. What I'm going to tell you is

under these considerations, under these conditions, under these assumptions, the estimated likelihood of a particular risky behavior is X. And then it is up to you as a riskmanagement professional,

a um a deployer, a developer. It's up for you to decide is that is is that enough is that good enough for your needs and I don't think it's going to be the same for different sectors. I think

some sectors will have a much higher bar for the amount of uncertainty that needs to be estimated and then other sectors will probably like that's good enough for me. I don't necessarily need to get

uh much further than what you are offering right off the uh we can go into all of the different questions that remain open but those particular areas related to developing that taxonomy um

developing those data sets and developing those evaluators the best practices and the standards to make it clear that this is the best in the industry this is the way that it is

that's what we need to get better at &gt;&gt; yeah so what I'm hearing is we need clarity clarity of the taxonomy clarity of what we're measuring and it needs to be you know verifiable and credible from

from an industry perspective. Would anyone like to pick up like how's that going to work? You know, what are what you know what's in place now? What some of some of the challenges might be? How

do you get organizational buying? Anything to add from Ninja and Man, you want to start us off? &gt;&gt; Sure. I I mean, I think there's work to do across all the elements that Rebecca

just laid out. Um, and it's really an reason why we are really invested in and working with ML Commons because I think we need places that are bringing industry and civil society and

stakeholders together to actually work through these problems and resolve these hard questions um, in ways that, you know, are really going to be sort of valid and reliable broadly. Um, and and

so I I think that's that's really the the work still ahead, but I think we are also making good progress, right? Um and thanks to ML comments for um helping to facilitate that. Y

&gt;&gt; uh my thought on this is that we've been talking for years now about how nent this field is and that actually to rel judge if we are actually making progress this too could be standardized right

like we don't have common ways of assessing are we still in a nent stage what levels of uncertainty do we have so to Rebecca's point I think this is absolutely essential so we can all align

exactly on have we made suffic efficient progress to start relying on these things. To what degree can we rely on them for important decision-m around deployments?

&gt;&gt; Yeah, I think I'll just add, you know, if we take this back down to like the basics, I I think whether you're an enterprise customer or you're a consumer of our products, you just want to know

like, is this thing going to be accurate? Can I rely on this thing? Um, is this going to get me into trouble? If I incorporate this in my workflows, am I going to carry some sort of liability?

And at the core of standards is figuring out a way to have a common mechanism to provide an answer of reassurance. You can trust us. Here's a measurement by certified by somebody else of that this

thing is reliable, that this thing is accurate, that I can rely on this thing and I can use this thing. And I think we're in this moment where we're still trying to figure out as an industry and

as a community about what that's going to look like. And so whether it's advancing the measurement science, right, because we currently don't have enough of that in order to make sure

that we can give an estimate of what is accurate, what is reliable, what is safe for specific risks or on the other side, what are the risks that we care about? Um I think some risks are might be some

countries, some jurisdictions might have one list of risks, other countries might have a different list of risks and and then there's going to be a question of like how do you control for that, right?

And and that's kind of what Rebecca Neil Commons and many others are working on is how do you how do you provide some sort of mechanism of credibility that says we've measured this this thing is

safe that can then be certified could be could be you know understood in the same way for everyone. Um so at the end of the day in order for us to really unlock the value of this new technology that is

transformative. I think many of us who are here today for the Indian uh impact summit recognize that that potential. We all also need to kind of answer those questions and standards are the way you

facilitate it. &gt;&gt; Yeah. And so there's a theme of trust that's going through this. So maybe Chris add to that and then add to comment from a Qualcomm perspective.

&gt;&gt; Yeah. Just briefly, I think I also just want to situate how kind of benchmarking standards and some of the scientific questions we've been talking about fit in. Like there's I think we've we've

been talking a lot about different types of standards. I just want to clarify that there's like a kind of broader highle set of process standards where you kind of say all right for this class

of risk what we're going to do is we're going to identify what the risk is. We're then going to evaluate what that risk might actually be and then we're going to put in place certain kinds of

mitigations and controls. Those are kind of it's a process for how you're going to walk through risk management for something that absolutely needs to be standardized. But then even within that

once we get to all right once we have agreed on what the risk is that we're trying to evaluate how do we actually do that and that's where the standards come in for the benchmarks that we want to

see developed and that's where some of these scientific questions I think really come into play because we need to have you know those kind of credible scientific uh evaluations and tests for

the whole kind of broader risk management effort to to hang together. Um and I it's you know again critical I think for this this whole process. &gt;&gt; Yes. This has got to live next to the

risk management identification mitigation strategy in any company. Go ahead, Justin. &gt;&gt; I just add briefly. I think the possibility for comparison across models

is also something that's super important here. I think there's an important safety dimension there. If we actually are all measuring the same thing and can give consumers some relative assessment

of safety of quality, this is actually going to potentially contribute to a race to the top as opposed to the bottom. &gt;&gt; Yep. And so we're solving. So that's the

question on who we solving for. Two of the panelists have mentioned consumers. It's not just about enterprise. It's not just about governments. It's all about consumer trust. Etsium, what would you

add? &gt;&gt; What what I wanted to add is the the fact that here when we're talking in general, you know, about trying to res create standard to resolve the type of

safety risk that we're going to see. It is just also to reassure the audience that it's not that we're trying to solve every single risk that happen. There is a huge amount of existing standard

bodies whether it's in ISO and sens and other places where they already have identified risk for their particular verticals or their particular not silos but the particular industries those are

already at work right so how they're going to use AI how AI is going to be uh effectively the AI safety is going to be translated to their own processes th those things are already happening right

so it's not only the people on this panel who are working on this that the entire community of standards whether it's in automotive radio equipment directive everything is

is already um everybody's already looking at that right in the end the difficult part is going to be to make sure that uh there's a commonality in terms of the type of techniques that

we're using whenever there's an automated technique that we can use because from an industry standpoint what is really useful in particular if you're a smaller company is to make sure that

you can run something efficiently and it addresses as much as the use cases that you run as possible. So that is an important thing that we need to uh to keep in mind when doing when we're doing

this. So it's it's why I mean from from Qualcomm obviously we we don't address every single thing but we want to make sure that at least in the areas where we're involved there's going to be as

much as a commonality in terms of the measurement techniques that we're going to use. So consensus around the need to do it, consensus in the fact that it's hard but it's important for consumers

and business and investors. But Joselyn made a point that we've been talking about how this is a nent topic etc. I want to look forward what over the next two years does this look like? What have

we got to get right? What the models are changing you know there could be regulation that changes. There could be changes around you know China US operating in different ways. What does

this topic look like? How do we make sure we stay the course on this topic? Anyone want to offer a perspective as we look forward and then we'll we'll start wrapping up and thinking thinking about

questions and we can get questions from the audience. &gt;&gt; I'll take a I'll take a crack at it. Um so at least from my perspective there are a couple of things that I hope to

see over the next couple of years. Um, one is that I think this idea of benchmarks and other standards representing consensus, we should be seeing more things like certification

that represent more types of consensus. If benchmarking represents consensus around how to estimate and measure a thing, certification could end up representing an agreement, a definition

of like what is good enough deserves some form of certification. I don't know necessarily what that's going to look like today, but I have to imagine that those sort of represent truses, the

temporary um of of agreements about this is this is good enough for my industry, this is good enough for my deployment, this is good enough for my use case. Um so that's what I'm hoping we start to

see over the next two years. &gt;&gt; Anyone else want to add to that? Because I mean Chris, jump in. But we've seen some of these disclosures in the past and people commit to environmental goals

or DEI goals or other set of standards or disclosures. Stakeholder capitalism was a was a big deal and now it's more about shareholders. So I'd love to understand like our perspective on like

how do we stay the course. &gt;&gt; Yeah. I might distinguish a little bit between how do we future proof these standards and then how do we kind of ensure that they're implemented over

time. And I think um the way that we future proof them is to some extent to go back to the point I was making earlier about process standards right the the process is somewhat agnostic to

the actual kind of you know uh uh AI system itself and the capabilities it has. If you have a good process for identifying risks evaluating risks that process can kind of be a bit futurep

proofed the specific eval you run are probably going to have to be updated over time to account for the greater capabilities of models as they advance. Right? And I think similar with some of

the controls that might need to be kind of used to manage some of the risks. Um if there's certain thresholds or kind of if the evaluations kind of indicate a certain level of risk, right? So that

the subcomponents of it might need to be evaluated. The overarching framework hopefully can kind of have some uh some legs behind it over time in terms of future proofing it.

&gt;&gt; So we must commit to a process. We can't future proof because we can't predict the future, but the process is so important. Even a good example of this would be something like the um I think

40,0001 has come up a few times like the there's a certain class of AI that 40,0001 is very kind of um tailored to and but even that AI has changed over time but 40,0001 is still a very good

kind of standard for managing those kinds of of risks for those uh uh kind of applications of AI across a broad array of machine learning algorithms. But the the other point that I would

make in terms of you know you you alluded to some of the kind of implementation of standards over times and making sure that they have the same currency to them and there I you know I

think we can rely on some of the incentives and the need again for there to be collective action on this that we've talked about before. um uh some of the incentive to to make sure that

there's a collective action problem is going to rest with policy makers which is why you've seen some you know regulatory activity even in areas where there's not to to Wan's point there's a

clear market need for these standards to be developed and implemented over time because consumers want to see you know they want to trust that the the the um you know whether it's you know

individual consumers or enterprise they want to trust that the model is actually safe and secure to use and so I I don't see kind of the standards um uh the importance of standards diminishing over

time. In fact, if anything, as the capabilities advance, consumers and enterprises are going to be more and more interested in making sure that they know for sure these things are safe.

Yes, it's going to be consumerdriven. Once you just from a regulatory perspective, any thoughts on Chris mentioned implementation, which is the hard stuff of where lots of this stuff

gets stuck. Any perspective on implementation or from your experience as a regulator to add here? &gt;&gt; Implementation of standards. Yes, &gt;&gt; I mean Chris put it very well, right?

One, um, regulators could say, I expect you to comply with certain requirements and this is how you do it and that's where the standard set how you do it. Um, or regulators can don't um provide

um certain requirements or certain expectations and the market um sets out these requirements and these expectations. This is how we we if you do it then we will buy your product for

example. Um so I think from an implementation point of view um there's sufficient I think there there will be some momentum either from the market or from regulations to move um standards

but I think the I think where I think I hope if you back to your original question what's going to happen in two years I hope we can actually move faster on standards in terms of the definition

of standards I think that would be super useful we're leading some work on testing u well benchmarking and rate teaming um primary methodology

um definition but um we we hope that in the next one year that can be done and sorted and um and and and um accepted within the ISO um process. Um but the experience has shown us that it takes a

while right so in in the next few years hopefully we have find a way in which we can move to standards faster. &gt;&gt; So we need to move with speed from a regulatory perspective. Amanda's going

to have the last word and then we're going to go to questions. So please prepare them. Amanda &gt;&gt; I didn't realize that. Um, no, the one thing I wanted to add in terms of a like

a a goal for where we can find ourselves two years from now is thinking about um like a system of standards that are interoperable where we have a sort of modular approach, right? where across

like general purpose technology and for example in different sort of deployment scenarios, different use cases, different sectors, we actually can get some efficiency from, you know, these

standards are all going to need to continuously evolve and improve and we're going to learn from the science and we're going to keep evolving the benchmarks and the kind of methodology

around the evaluations. Um, but we don't want to like keep starting from scratch with every piece of that, you know, puzzle. And so we need to figure out a way to actually ensure that like where

we are making progress on the evaluation science and how we are doing this in the context of like evaluating AI models or systems and then how we are evaluating AI and deployment and like critical

sectors for example we actually have some synergy built into the standards ecosystem so that we are making kind of more dynamic progress across everything at the same time.

&gt;&gt; Yeah. So it needs to be interoperable and we can't keep reinventing the wheel. So audience um questions. I'm going to collect questions maybe three to five. So the gentleman at the front, the

gentleman at the back, and then um the the lady with a hand up. &gt;&gt; Hi there. Uh thanks for taking my question. Uh maybe I have a bit of a tricky question for you. You know, on

the panel, obviously we have a lot of commercial interests. My question is this. How do we know in your assurance program or whatever you're proposing that it's going to be done since it's

driven primarily by industry? How do we know that you're not just going to create something that cheaply satisfies the industry in front of us versus what the public actually needs? And assuming

you do have a a program that you're going to talk about, uh how does a government or external agency audit such a program given the skill gap to create such a very sophisticated compliance

program? How can world governments come? Because I've been on a lot of panels this week. The fear, uncertainty, and doubt is not only just the policy gap. It's actually the technical gap. the

inability of world governments to audit properly whatever you have. Thank you. &gt;&gt; Thank you. So, keep the questions brief. Thank you for that. So, that's about like how do we make it real? How do we

make it not performative? I'm going to collect two other questions and then we'll throw them to the panelists. So, keep your hands raised. Whoever gentleman at the back and I think there

was a lady or a gentleman with a tie. &gt;&gt; Uh yeah. Hi. So um as a recent computer science uh student I am interested in building AI for India specifically with

such a distinguished panel I thought I'd shoot my shot. I'm a little nervous so I apologize about that. Um I want to talk specifically about language bias. uh being in India there are 22 official

languages and you know I'm constantly thinking in two to three different languages and when I utilize tools such amazing tools built by um everybody here I'm wondering how you guys would go

about um tackling language bias and building guard rails around that to ensure that you know a small model like a student like me is making does not go haywire.

&gt;&gt; Yeah, great question about language. Thank you sir. And then gentlemen with a tie, which doesn't mean like they more gentlemen wear ties, but yes, please.

&gt;&gt; Hi, Jules Pollynetsky at the future of privacy forum and our AI governance center. The standards always seem to be uh an easier path when they are more technical than challenging social policy

and AI governance seems to capture the most broad potential collections of social policy. And given that there's a lot of disagreement and some debate over whether one should even measure certain

areas, do you imagine that we're talking about minimum viable consensus with the broadest number of stakeholders or are they or is there a path to in some way address some issues that some

stakeholders see as absolutely necessary and others don't want on the table? &gt;&gt; Yeah. All right. Sound bite responses panel. Like how do we make it real? How do we deal with the skills gap? How do

we deal with the MVP? Anyone? &gt;&gt; Go on Jocelyn. on on the performative question. I think now that standards have been referred to within actual regulation, I think to the

extent that we want to use these standards as evidence of conformity with those particular regulations that sets a kind of minimum bar at the very least because I think if we make these things

too high level, too abstract or too essentially lowest common denominator, I don't think regulators are going to look at those standards as evidence of conformity. So I think there is that

kind of interlocking pressure created by the regulation itself for some sort of degree of of uh quality. &gt;&gt; Thank you. And Essa, do you want to comment on the language perspective and

how you're thinking about that open AI? &gt;&gt; Thank you. Yes. Um we do a a series of of evaluations um like MMLU for determining how well our uh models perform on a variety of languages. We

also have a specific test actually in QA. Okay, you &gt;&gt; um there's also a specific tech uh test in QA that uh that we also kind of uh test our models on that has a variety of

dialects within India though I think the short answer is that this is an area where we need more participants and I believe ML Commons is an active uh uh playing an active role in helping

further um our capaci capacity building um and I think working with local ecosystems um to help clean and collect good data so that we can do this appropriately. This is another area

right just like we've been saying where we need to work in partnership to figure out how do we both collect the type of information how do we measure this stuff um how do we build the evaluations and

then how do we build an industry standard where all of the actors are kind of held to that to that standard and it's going to have to be a collective effort.

&gt;&gt; Yeah. Go ahead. &gt;&gt; Okay. Um ju just to add a little bit on the the question regarding the language in the end I I don't think there's like a there's no silver bullet solution

right there's there's going to be a need to have this type of um either safety test or safety prompt which are required for different type of languages and you're not going to be able to address

every single thing because there's just a huge amount of diversity. I mean you take me I I'm I'm French from from cultural background. I speak English and think in French and English all the

time. there's weird stuff that I say that will not be captured by a model that's only for American English, right? So there's going to be a need for more than one language which are captured and

probably a lot of them. But this is where the community of basically everybody needs to come and say, "Hey, this is what I want to capture for my type of language." what matters to make

sure that there is scale and that it still remains efficient is that hopefully the tool and the software framework around it can be reused and that that's really a big advantage for

that. Thank you. &gt;&gt; So so in summary and thank you de dear panelist for the for the great discussion. So you heard today that standards are important. This is a

fastmoving world. We've got to be designing for consumers for for business people. There's a commitment here around measurement. It's both art and science. We need to have the process that's

consistent but across regulators, across standard setters, around policy makers, you know, and the business and the and the tech community, there's a consistent understanding. So, it's going to be an

emerging topic which I know we'll continue to to discuss. Thank you um panelists and thank you to the audience. [applause] Thank you.

&gt;&gt; Is it okay?
