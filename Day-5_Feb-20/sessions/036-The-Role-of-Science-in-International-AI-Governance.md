# The Role of Science in International AI Governance

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 2 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/xPYSLh7W6zY?feature=share) |

## üé§ Speakers

- Ajay Kumar Sood, GoI
- Amandeep Gill, UN ODET
- Anil Ananthaswamy, Science journalist and Author
- Anne Bouverot, Government of France
- Ant√≥nio Guterres, United Nations
- Balaraman Ravindran, Wadhwani School of Data Science & AI, IIT Madras
- Brad Smith, Microsoft Corporation
- Josephine Teo, Government of Singapore
- Soumya Swaminathan, World Health Organization
- Yoshua Bengio, Mila Institute

## ü§ù Knowledge Partners

- United Nations Office for Digital and Emerging Technologies

## üìù Summary

Scientific knowledge is an essential foundation for effective governance of Artificial
Intelligence. As AI systems evolve, there is a growing need for transparent and evidence-
based assessments to guide international standards and ensure inclusive innovation.
This session will explore how the science-policy interface can inform international AI
governance and strengthen cooperation between stakeholders.

## üîë Key Takeaways

1. Scientific knowledge is an essential foundation for effective governance of Artificial
Intelligence.
2. As AI systems evolve, there is a growing need for transparent and evidence-
based assessments to guide international standards and ensure inclusive innovation.
This session will explore how the science-policy interface can inform international AI
governance and strengthen cooperation between stakeholders.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/xPYSLh7W6zY/maxresdefault.jpg)](https://youtube.com/live/xPYSLh7W6zY?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Today's session begins from a simple but powerful premise. We cannot govern what we do not understand. It is my honor to open this session with a special address by the Secretary

General of the United Nations whose leadership has placed science and multilateral cooperation at the forefront of global AI governance. So please join me in welcoming his

excellency Antonio Gutesh. There is a computer here. I don't know to whom it belongs. Excellencies, ladies and gentlemen, thank you for joining this discussion on

the role of science in international AI governance. We are barreling into the unknown. AI innovation is moving at the speed of light, outpacing our collective ability

to fully understand it, let alone govern it. AI does not stop at borders and no nation can fully grasp its implications on its own.

If we want AI to serve humanity, policy cannot be built on guesswork. It cannot be built on hype or disinformation. We need facts we can trust and share across countries and across sectors.

Less noise, more knowledge. That is why the United Nations is building a practical architecture that puts science at the center of international cooperation on AI and it starts with

independent international scientific panel on artificial intelligence. This panel is designed to help close the AI knowledge gap and assess the real impacts of AI across economies and

societies. So countries at every level of AI capacity can act with the same clarity. It is fully independent. It is globally diverse and it is

multiddisciplinary because AI touches every area of every society. And I'm delighted that the general assembly of the United Nations confirmed the 40 experts I proposed to member

states. Now the real work begins on a fast track to deliver a first report ahead of the global dialogue on AI governance in July.

The panel will provide a shared baseline of analysis helping member states move from philosophical debates to technical coordination and anchor choices in evidence. So

policy is neither a blunt instrument that stiffens progress nor a bystander to harm. That is how science strengthens decision making.

When we understand what systems can do and what they cannot, we can move from rough measures to smarter riskbased guard rails. Guard rails that protect people, uphold

human rights, and preserve human agency. Guard rails that build confidence and give business clarity so innovation can move faster in the right direction. Science-led governance is not a break on

progress. It is an accelerator for solutions, a way to make progress safer, fairer, and more widely shared. It helps us identify where AI can do the most good the fastest and it helps us

anticipate impacts early from risks for children to labor markets to manipulation at scale so countries can prepare protect and invest in people. Today, international cooperation is

difficult. Trust is strained and technological rivalry is growing. Without a common baseline, fragmentation wins with different regions and different countries operating under

incompatibly incompatible policies and technical standards. A patchwork of rules will raise costs, weaken safety, and widen divides. Science is a universal language

guided by the independent panel and the global dialogue on AI governance. We can align our technical baselines. When we agree on how to test systems and measure risk, we create

interoperability. So a startup in New Delhi can scale globally with confidence because the benchmarks are shared and safety can travel with the technology.

Finally, let us be clear. Science informs but humans decide. Our goal is to make human control a technical reality, not a slogan. And that requires meaningful human oversight in every high

stakes decision, injustice, healthcare, credit. And it requires clear accountability. So responsibility is never outsourced to an algorithm. People must understand how decisions are

made, challenge them and get answers. the message is simple. Less hype, less fear, more facts and evidence. Guided by science, we can transform AI from a source of uncertainty into a reliable

engine for the sustainable development goals. Let us build a future where where policy is as smart as the technology it seeks to guide. Thank you.

Thank you, Secretary General, for those inspiring opening remarks. Ladies and gentlemen, we were going to have uh Mr. Brad Smith, uh vice chair and president of Microsoft Corporation as our next uh

speaker, but he's running a bit late. So, we will move to the next item in the agenda. Uh I would like to uh welcome professor Yoshua Benjio to the stage uh scientific director of MIA and one of

the world's leading uh AI researchers. Uh he and I will be uh in a fireside chat and uh we'll uh hoping that Mr. Brad Smith will be able to join us very soon. Thank you.

Um, so welcome, Professor Benju. &gt;&gt; Thank you for having me. &gt;&gt; My uh our pleasure. Uh, so you are the most cited computer scientist and I looked it up. you're actually the most

cited living scientist um today and have played a unique role at the global science policy interface including through the UN scientific advisory board and your leadership of the international

AI safety report. So from your perspective how do these science policy interfaces actually work in practice and where do they add the most value?

So it's it's tricky right because um there are many different views especially uh different interests uh in in business in different governments

and the role of uh science the role of the kind of synthesis of science that we want for the UN panel uh that we have see uh for the uh AI safety report is to to try to make it uh to provide a

um shared understanding as a basis for those political discussions and uh not uh be influenced by as much as you know is humanly possible uh by by by those tensions that exist in our societies.

And I think it's particularly important because maybe unlike in the case of climate u the scientists themselves don't always agree on what to expect for the future or even how to interpret the

you know the science that exists. &gt;&gt; Yeah. &gt;&gt; Um and &gt;&gt; I just want to add something. So something that's a little bit subtle

about this kind of exercise is to be able to recognize the uncertainty and the divergences that exist and you know where is it that scientists agree where is it that the

evidence is strong where is it that uh we have clues uh that matter like even if we're not certain about a particular risk we might have clues about it but if the risk um has huge severity in other

words if it does unfold then then it could be catastrophic. Um then policy makers need to make attention and and it's it's always difficult when we don't have proof that something you know

terrible is going to happen. Maybe like a good analogy is tipping points in in climate, right? Um because uh there's no not enough past uh evidence to be sure that a particular tipping point is going

to happen. But the situation is is similar in AI in the sense that we don't have the experience of say machines that that are like really smart and can change uh society and be even

potentially smarter than us. So how can we deal with you know the right policy decisions? But uh it that's why it is so important to have uh as uh neutral and as like fact-based

uh uh evaluation of what is going on available to everyone and in a language that is accessible to everyone and of course for policy makers which by the way is difficult for scientists to

achieve. They need help. They need iterations. They need feedback from people who are used to the interface between science and policy. Is there anything in particular about

the highly technical nature of AI and also the pace of change that makes this interface particularly difficult? &gt;&gt; Yes. Yes. Um the

facts shown in the scientific benchmarks across labs, companies and academia uh on AI show very rapid growth of the capabilities of these systems. Um and that growth is uneven. So we see AIs

even surpassing most people on some uh measurements of capability and being kind of uh stupid or like a six-year-old on some other things. So it's very difficult to grasp what that means. Um

but because it's moving so fast, there's always going to be a lag between even like the scientific papers take time to be written. uh if there are studies so think about studies that involve people

you know that they're going to take months and so by the time we start seeing clues that that there's a potential problem so you can think of something recent that was not expected

that like the psychological effects on people of these chat bots uh we now have lots of anecdotal evidence and we only starting to see the the the you know the scientific studies

&gt;&gt; and of course on the policy side it's going to be even later because those discussions are going to happen after we see stronger scientific evidence. So there is going to be a lag uh and that's

a real problem because things could move too fast for policy to catch up. &gt;&gt; So maybe that leads uh well into our next question. We often hear that AI governance moving too slowly. Uh and

from your experience like what kinds of scientific assessments or benchmarks could realistically keep pace with this rapid change? &gt;&gt; Yeah, that's a great question. Um

my opinion on this is that we should be thinking about not just policy in the usual sense of like coming up with principles but um we should try to strive for high level principles that

can be applied uh you know without having to go into the details because the details are going to change and the second thing is I think we should strive for technology

that are going to help to implement those guard rails. in the field in the deployment of AI uh because you know otherwise there's not enough time to react.

&gt;&gt; Well, thank you for those insights and also congratulations on your recent appointment to the independent international scientific panel on AI. &gt;&gt; Um in a few words, how do you see this

new panel helping to strengthen the link between science and global AI policym? Well, I think there's something really important about this panel and it's g it is its global aspect and being rooted in

the UN and and the reason I'm saying this is that AI is going to be transforming our world very clearly uh and it's going to have global effects whether it is on the good side the

benefits are on the risks um but also the kind of power relationships that are going to be changing in the future and I'm personally very concerned about how this will unfold for developing

countries in the global south and and we need to work uh in a multi-disiplinary way so that uh we can foresee those effects and we can start discussions uh to make sure that everyone is at the

table and no one is on the menu. Well, um, well said, Professor Benju. Well, thank you very much for kickstarting our discussion. We will now turn turn to our panel. Um, so

u ladies and gentlemen, it is essential that discussions about AI policy include the voices of key industry actors. And I am pleased to invite Mr. Brad Smith, vice chair and president, Microsoft

Corporation for his keynote address. Well, good morning everyone. It's a pleasure to be here. My apologies for being a few minutes late. Um, I want to offer a couple of thoughts this morning.

The first thing I think we should come to together to think about is that in my opinion this is a moment in time when we need to reflect on and reinvest in the importance of the United Nations.

There is there is a wellknown economic theory that says that humanity is in many ways almost destined to repeat its great economic mistakes

every 80 years. The reason it's 80 years is because that is basically the lifespan of human beings. And so every 80 years almost everyone who had any living memory of a

prior financial calamity has left the planet. If you look at the great recession that started in 2008, what you realize is that it happened 79 years after the stock market crash that

led to the great depression in 1929. And you can follow this series of financial mistakes all the way back to the bursting of the tulip ble bubble in the Netherlands

hundreds of years ago. I think there is a correlary worth thinking about. Just as there is a risk that humanity forgets the mistakes it made 80 years ago, humanity runs the

risk of forgetting the great successes it created 80 years ago. It was just over 80 years ago that the world came together to create the United Nations.

It was, in my opinion, one of humanity's greatest accomplishments of the 20th century. It is a unique organization in a very imperfect world.

And so, of course, on any day in any year, it is possible for anyone to blame the United Nations for the imperfections that we see all around us. But the truth is this,

those imperfections are fewer and their consequences are less disastriable in in my view because of the United Nations. And one of the great things about working at Microsoft in a job like mine

is that I get to work in a global organization. We have subsidiaries in 120 countries. We do work in 190 countries. We see the world. It turns out that

everywhere we go, we see the United Sometimes it's the United Nations Development Program working to foster economic development. Sometimes it is UNHCR helping refugees. Sometimes it is

the UN Office of Human Rights seeking to protect human rights. But the truth is, if there's a problem, the United Nations is almost always part of the solution. We need to remember this. And we need to

remember that however challenging the last 80 years have been, we have managed as humanity, as a species to live with the ever constant presence of nuclear weapons

without using them or destroying ourselves. The United Nations has in fact in my view been indispensable to the not just the protection of people but the preservation of our species.

Why does that matter now? Why should we talk about it today and this week in Delhi? Because here we are on the cusp of the future. A technology that we all know will likely change the future. Here

we are in the second month of the second quarter of the 21st century and we need to focus on how we bring the institutions on which we rely into that future.

So then let me talk about a second aspect that I think is so important to think about this morning. One of the things I'm constantly struck by leading a global organization

is how often everyone disagrees with each other about almost everything. But one of the things I've learned along the way is that I think one of the reasons people so quickly disagree is

that we rush so quickly debate to debate competing solutions. This happens in domestic politics. It happens in international diplomacy. It frankly happens in a global company. It

actually happens everywhere, even in families. As soon as there's a problem, people want to talk about the solution. And then people have different solutions and

then they debate and they disagree and they argue and sometimes it's even worse than that. One of the things I've learned is the reason people so often disagree about

the solution is they don't have a common understanding of the problem. They don't spend enough time talking about the problem. They don't have a shared contextual understanding

of the problem they're trying to solve. They're too quick to want to blame someone for the problem and then that spirals into a discussion that becomes completely unconstructive.

Why does that matter today? Because what we're here to talk about today is all about creating a more common understanding together based on science of where artificial intelligence is

going. This is an indispensable tool. Indeed, it's a critical service for humanity so we can all learn together. We can all think together. We can all understand together what is going on in

the world. I think it's especially critical to be honest when it comes to artificial intelligence because I think if you even consider most of the conversations you have about this

technology, I would argue that it has two flaws. The first flaw is it usually involves people making very grandiose predictions about the future. You know what? I've worked in the tech sector for

32 years. I have listened for more than three decades to my colleagues in my industry around the world make bold predictions about the future. No one ever holds them accountable a decade

later for whether they were right or wrong. I used the researcher agent in Microsoft co-pilot a couple weekends ago and I loaded a lot of names. I won't say whom

but you can guess. And I said, look at all the predictions they made about all the technologies and look at the predictions they made about when these technologies would come to do something

or another and give them a grade. The average grade was 25%. You couldn't even get close to the top of failing. You were at the bottom. So let's just understand one thing

together. There is no such thing as a crystal ball. No one has one. But what we do have is the ability to understand where we are today. And what we do have is a better

understanding to de under to just appreciate what is happening each and every year. There's a second flaw in my view in many of the conversations that take place including at this AI summit.

Everybody wants to talk about how they're going to make machines smarter. That's interesting. I think it's interesting to imagine living in a world where a data center is like a country of

geniuses. But as I mentioned yesterday, compared to the people who lived in the Bronze Age, we're all geniuses already. What that should remind us is that human

capability is neither fixed nor finite. And so what really matters is in my opinion is not whether we are going to build machines that are smarter than humans. Yes, in some ways we will. But

how will we use those machines to make people smarter to help us do what we need to do? That is what this effort is all about. Let's harness the power of science

to build a common understanding of what is changing each year. And then let's connect it with the global dialogue on governance so we can pursue policies that will ensure that this technology

serves people. There's no better place to get started than here. There's no better time than now. And let's face it, there is no better institution on the planet that can do more to serve

humanity and protect the world than the United Nations. And on behalf of Microsoft, I just want you to know we are putting our full energy and resources to do everything that we can

to help. Thank you very much. Thank you Mr. Smith for those insights on responsibility, accountability and the role of industry. Uh we now turn to our panel.

Our panel brings together scientific leadership, public policy expertise and international coordination. Please welcome to our to the stage our speakers uh professor Balaraman Raindran IAT

Madras uh Swamya Sam Swaminafan former chief scientist WH Ajay Kumar Sud principal scientific adviser to the government of India and Anne Bubbero France's special

envoy for AI. I am also pleased to introduce our moderator Amandep Singh Gil under secretary general and special envoy for digital and emerging technologies. I invite him to guide the

discussion. &gt;&gt; Thank you very much. Oh yes, &gt;&gt; thank you very much. Thank you Anil for uh leading us and for

those who've not read his book the elegant math behind machine learning please do um have a go at it we cannot govern something that we don't understand so

something as simple as like if 90% of AI is matrix multiplication a 01% as he was explaining uh in improvement in efficiency of matrix multiplication has huge energy

implications. So I want to welcome our esteemed panelists. The stage has been set by very inspiring keynotes and a fireside chat. Uh so we will dive straight in and since we are running a

little short of time, I'm going to compress the two rounds into one rapid fire round. Okay. Uh so all of you work have worked on or are working on the science policy interface and

my sense is that there is a loop here that there is a loop between science and evidence and evidence and policy. And we want to explore that loop today in the context of the significant development

of the setting up of the international independent scientific panel at uh the United Nation. So I want to start with you Somia. were the first chief scientist, first woman chief scientist

at the WHO and worked at a very difficult time during the co uh when evidence trusted evidence was so critical. So in your view what makes this evidence that comes from science

trusted and actionable for policy makers? &gt;&gt; Thank you. I I think that's quite a difficult question because I uh I I don't know if we know the answer but we

did learn a lot of lessons uh during covid and it was very clear that uh on the one hand trust in science and in we saw countries where there were leadership was led by science led by

scientists and good public health policies were made based on data and evidence and these were iteratively improved or changed based bas on the evolving evidence because I think in a

way AI is like co the uh the evidence is is very rapid the field is moving so rapidly in covid we had to review a couple of hundred publications every day to understand what was happening on

different aspects on the virus on the imunology on how vaccines were working and drugs and we had to make recommendations based on the best available evidence that day I think we

may be in a similar situation with AI and it's wonderful that the UN has now set up this body which I see as something like the IPCC. I think we do need global governance. We need

something like uh you know the we're talking uh now about preventing future pandemics by sharing data on pathogens u making sure that we have protocols in place where countries are willing to

share that data and also of course to share the uh the tools the vaccines or drugs when they become available when or in case there is another pandemic. Similarly, I hope that this scientific

body that's been set up by the UN would also establish systems that would link to national bodies and systems and that would ensure the voices of all are heard. So one of the things during COVID

was some of our recommendations were relevant in high-income countries but not in low-income countries because the context is very different and the WHO was criticized for this I think

rightfully so and we need to learn from those mistakes. So it's a voices for example of women a low-income woman a farmer in a remote place is going to use technology very differently from a a

large farmer with access to lots of machines uh in Europe or or or North America. So if AI has to work for everyone then we need to make sure that those voices are heard and ultimately I

think that loop you talked about sometimes policy is made in advance of evidence. You have to you can't wait but the policy must change. It must ask for the relevant evidence and be able to

adapt when that is clear. &gt;&gt; Thank you very much Somia. I'm going to come to you uh Ravi Professor Balaraman Raindran. Now as AI policies begin to take shape and you've been involved in

some policym yourself, what signals from regulators or public sector users should most urgently guide future AI research priorities? So in a sense, you know, the loop coming back into research.

So thank you for that question. So I mean AI right now right especially in the global south so we don't completely understand the implications

of adopting AI and how is it going to affect uh uh uh you know the society the people livelihood and everything right in fact uh I I also feel that we don't have enough evidence about how AI is

even affecting the social fabric because how how are our our children getting increasingly isolated with the adoption of AI and whether the effect is uniform between cities and in rural India

because the cultural setup is very different and so on so forth. So if the government as we heard our honorable prime minister say yesterday should focus more on youth right and the impact

of AI on youth what is the evidence do we have about what is happening in India right so we hear stories about you know how uh there is dependence of uh on on on AI models of children and also of

people who are you know mentally challenged and so on so forth who are under stress uh but all of these stories are coming to us from the west right so what is it that's happening in India So

when we have these kinds of policy decisions that have to be made, the government says that AI should be pushing uh you know uh efficiency in agriculture right so do we have a

benchmark in India that can evaluate the efficiency of or effectiveness of these AI models in agriculture what are the kinds of flaws right that happens when I for example build a bot that can act as

a co-pilot for a farmer right so these are these are bigger challenges so we have a lot of questions that we have &gt;&gt; if I can quickly follow Where do you actually see evidence for impact in the

sustainable development goals space? But just a quick example or two. that was not in the notes he gave us earlier. So I have to think on on on my feet here. Now you have our

&gt;&gt; so uh so let let me take one thing that we are very familiar with we are working on right now is on the education space right so so for example so we don't know we don't have evidence of AI

interventions how likely is it to change student learning behavior so we have done some preliminary studies so so the author of the study is somewhere in the audience I know because he has been

sending me pictures of the stage uh but uh So what we have found out is the effectiveness of AI adoption is a direct function of habit. So if the students are using AI more then they tend to but

now I don't know what is the causal factor there the I don't know if the causal factor is whether they are using AI more therefore they get better effect or do they use AI more because they are

getting better effect better impact from AI. So these are questions that we have to ask right even in something as simple as education. I'm saying simple because there's a lot of you know positive bus

around using AI in education but even there we need a lot more evidence to come in place. &gt;&gt; Thank you Ravi and we honored to have you on the new international independent

scientific panel. So I if I may jump to you uh an and you're an AI scientist yourself you know all of us know you as a special envoy President Mron who made the February summit happen last year in

in Paris uh but you're also an AI scientist. So from your perspective you you kind of lived in these two worlds. So what works best for the interface? you know, what kind of scientific

evidence would take would you take to President MRO if you were to convince him to change the policy? &gt;&gt; Well, thank you for the question. I I studied uh uh AI a long time ago, but

I'm not uh really a scientist, but I I try to understand, of course, uh understanding I think is is probably the very first thing. And before we move to policy makers, I think it's for

citizens, for us as human beings, the things that we don't understand, we tend to be more afraid of. Uh I I often quote um uh scientist Maricuri. Uh she wasn't an AI scientist, but she's um one of the

brightest scientists um uh that that we've had, two times uh Noel laurate. Uh and there's a wonderful quote by her. She says um uh now is not what she says nothing in life is to be feared.

Everything is to be understood. Uh and now is the time to understand more because of course there are more things we can be afraid of uh at the time when she was living and and now as well. So

trying to understand things having scientific panels is definitely uh the right thing to do and and we're uh fully supportive in France of the scientific panel. We're very proud that um Joel

Bahal is our nominee. She's a scientist in AI and health and and a member of the panel. Uh this is absolutely um uh excellent. So yes, understanding things is absolutely key. And then maybe um

just a second point in to give an example of how understanding something or not can lead to very different uh policy decisions in the field of AI and work. uh we've had predictions I

remember in 2013 that was the previous AI um uh uh uh revolution but uh scientists I believe at Oxford said within 10 years half of the jobs will disappear um uh we haven't seen that um

at the uh AI summit in Bletchley Park for very good reasons we had um uh frontier AI leaders in particular Elon Musk saying within two years half of the jobs will disappear. So, of course, the

fact that this didn't happen doesn't mean that there isn't a risk for for work. Of course, there's a risk for work. But if your potential or probable outcome is the end of jobs, then you

need to think about universal basic income. What are we going to do with all the people who don't have jobs? If um what economists are saying is that 80% of the jobs will be transformed then the

policy outcome is training skilling reskilling uh and and helping to educate people. That's why listening to economists and having the International Labor Organization and and other

institutions really follow closely what is happening in which countries for younger people, for older people, for women, for men, for different types of jobs. That's super important.

&gt;&gt; Merci Kuwan. Merci. And I'm going to turn to you, Professor Sud. you know you you occupy an important position within the Indian uh system and you look at science broadly and India has deployed

some of these technologies at societal scale India uh stack uh the digital public infrastructure. So how do you look at the AI opportunity and importantly how do you look at AI risks

and how are you prioritizing R&amp;D allocations to harness the opportunities manage the risks. Uh thank you very for uh for having me on the panel. As you know that uh all the aspects which you

asked. We have uh had very extensive consultations across all stakeholders and we came out with the national AI governance framework. not the regulatory framework but how do we really handle AI

all aspects and there uh we have looked at how do we enable the compute facility compute resources to our people uh because we are not at the scale when few trillions of dollars are being uh

invested. So we came out with some framework which we think with public private partnership we could enable it and we could see the results of that within a year as demonstrated in AI

summit uh the release of uh AI sovereign uh models and so on. Other aspect which is very important as you rightly said the risk assessment. So this is where as it been mentioned our uh experience with

the digital public infrastructure which has been rolled on a very public scale with the safety and security which is as difficult as in AI. AI of course it's more difficult. But we still do not know

the risks. But when we were dealing with the digital public infrastructure either for the financial transactions or for identity identity uh verification and so on. It was a challenge and that was done

by embedding governance through technical design and this what we call technolal which honorable prime minister said in the Paris summit and also mentioned here. So this is where we are

uh suggesting that this could be one way to look at it's not that everything is laid out. We will need uh framework for that. We will need technologies for that. But this is one way which will

have a smooth uh uh interaction if we can bring this technological framework. &gt;&gt; Thank you so much for those insights. And now that since we are running out of time and I'm going to discriminate

against the men on the panel so my apologies in advance. So I'm going to turn back to you s and an for like 40 second 30cond reflection. What do you think in terms of the pace and direction

of technology opportunities including for accelerating scientific discovery and risk? What would be your advice for the international independent scientific panel? Mickey maybe an you can go first

40 seconds. &gt;&gt; Yes, I think AI has a strong potential for helping uh science. Uh we've seen that with the two um uh Nobel prizes in physics and chemistry uh a year back. Uh

there's many more areas in science where AI can help. It can only be possible if we have um databases of uh scientific data uh that are available uh to the world and that are constructed by

scientists and funded by governments and international institutions around the world. So um this is a very important topic for research. &gt;&gt; Thank you. An Somia you have the last

word. &gt;&gt; Yes, I agree very much with an and I think that the scientific panel could actually help network many more groups of scientists from around the world

perhaps sectorally for example what's happening in health what's happening in education what's happening in agriculture. looking at the evidences as they emerge, encouraging research,

setting priorities, but also looking at safety and risks because I think that's going to be very important. There may be unanticipated risks and harms that we have not considered and of course equity

being a UNled panel ensuring that equity is at the heart of AI and it's being done for public good. &gt;&gt; Fantastic. Thank you. That's a great closing. Ladies and gentlemen, please

join me in thanking our outstanding panel and we are going to move straight to uh the closing. Over to you and um thank you to the panel for a rich and forward-looking discussion. Uh to close

this session, it is my honor to invite Josephine Tio, Minister for Digital Development and Information of Singapore to deliver the closing remarks. Minister Joseph.

&gt;&gt; Good morning everyone. First allow me to thank the secretary general for his remarks and uh it serves as a very useful guidance to all of us working in this important technology. Uh for the

closing this morning I thought that it would perhaps be useful to offer a perspective from a small state. Um Singapore has a population of just six million people. Uh and uh more than 30

years ago at the UN uh we became the convenor of the forum of small states which still has about 108 members. Um I will just make three points on how we look at developments on this front. Uh

the first point is that um we believe in AI being used as a force for the public good. But to do so uh it is important that we continue to invest in the science that underpins it and ground

trust in evidence. Um this certainly requires sustained investment in research and is also the reason why we set aside a billion dollars in a national AI R&amp;D plan which will include

foundational and applied research into responsible AI. We believe in it and we have to put money behind this effort. Uh there are of course other investments uh such as in building up a digital trust

center. Uh it's our designated AI safety institute that has been participating in important conversations on this topic as well as setting up a center for advanced technologies in online safety. So those

are just some of the efforts that we can dedicate resources to doing as a small state. The second point I want to make is that there is almost always going to be a tension between moving quickly um

given the pace of AI development and moving carefully giving the latest evidence that presents themselves on what we should be paying attention to. Both impulses are necessary and we

believe it is not impossible to try and balance them through integration of science and policy. It is not easy but it is not an effort that we must give up on. Um I should just add that on this

score it will be much better if we can cooperate internationally to develop sound approaches that can also be interoperable across different jurisdictions and this is one effort

that we believe underpins the work that is being carried out by the UN and this brings me to my third point. I want to highlight the important role that an organization like the United Nations

plays in facilitating global discourse to bridge science and policy. I cannot overemphasize the importance of this effort. We must recognize that global AI governance landscape is becoming

increasingly fragmented. There are multiple initiatives, frameworks, and institutions. The UN's unique value lies in your legitimacy and inclusiveness to encourage interoperability across

efforts. The sector talked about this too. We therefore welcome the establishment of the independent international scientific panel on AI building on the work of the UN high

level advisory body on AI which published its report on governing AI for humanity at the end of 2024. We note that the panel's multidisciplinary approach covering machine learning,

applied AI, social science, ethics, all of these are necessary to address the complexity of AI governance challenges. Finally, um I would just like to acknowledge that we now have substantial

convergence on the high level AI principles. Joshua talked about this um transparency, accountability, fairness, safety, but the challenge is in operationalizing them. We need to find

standardized evaluation methodologies that work across different regulatory contexts. We need capacity building so that all countries can meaningfully engage with the technical evidence and

not just with the large AI research ecosystems. I would encourage all stakeholders to view scientific input not as a constraint on policy flexibility but as a foundation for more

durable effective governance that can maintain public trust. We need to keep the conversations going one where science informs governance and governance sharpens science. Um I would

just perhaps end by highlighting Singapore's continued commitment to contribute to advancing these discussions. Uh we were very fortunate to host the international scientific

exchange on AI safety and to bring about the Singapore consensus on global AI safety research priorities. Joshua was in Singapore for this very momentous event. We will continue to participate

in joint testing efforts of the international network for advanced AI measurement evaluation and science. We have organized two additions of the Singapore AI safety red teaming

challenge. The first multicultural and multilingual AI safety red teaming exercise focused on the Asia-Pacific region. And as chair of the Azan work group on AI governance, we have actively

spearheaded efforts to foster a trusted environment in ASEAN by adapting global norms and best practices for ASEAN and in bringing about regional harmonization through the ASEAN guide on AI governance

and ethics as well as expanding it to address the risk in generative AI. We are now working within Azan to explore practical tools for AI safety testing and aim to collectively develop a set of

AI safety benchmarks that reflect our region's concerns. And finally, I'd like to welcome all colleagues to join us in Singapore for the second edition of the International Scientific Exchange, which

we expect to take place on the 17th and 18th of May. and uh we look forward to furthering our discussions in this area. Thank you very much once again. Thank you Minister Tio for your closing

remarks. Uh this session is now concluded. Thank you very much.
