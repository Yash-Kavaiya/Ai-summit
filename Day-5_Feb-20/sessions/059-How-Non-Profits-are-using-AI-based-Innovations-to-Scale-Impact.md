# How Non-Profits are using AI-based Innovations to Scale Impact

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/GP4PQ6t_gmE?feature=share) |

## üé§ Speakers

- Erica Arya, Project Tech4Dev
- Mainak Roy, Simple Education Foundation
- Manohar Sreekanth, Sattva Consulting
- Pritam Sukumar, Avanti Fellows
- Steven Suting, QUEST Alliance
- Temina Madon, The Agency Fund

## ü§ù Knowledge Partners

- Sattva Consulting Pvt Ltd

## üìù Summary

Join social sector leaders for a grounded look at a six-month AI Cohort Program. Featuring insights from seven NGOs, this session explores the transition from initial ideas to piloted solutions. Speakers will share reflections on strategic objectives, approaches, challenges, and learnings. Gain a practical framework for implementing responsible, use-case-driven AI in the social sector, backed by real-world outcomes and lessons learned during the journey from concept to impact.

## üîë Key Takeaways

1. Join social sector leaders for a grounded look at a six-month AI Cohort Program.
2. Featuring insights from seven NGOs, this session explores the transition from initial ideas to piloted solutions.
3. Speakers will share reflections on strategic objectives, approaches, challenges, and learnings.
4. Gain a practical framework for implementing responsible, use-case-driven AI in the social sector, backed by real-world outcomes and lessons learned during the journey from concept to impact.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/GP4PQ6t_gmE/maxresdefault.jpg)](https://youtube.com/live/GP4PQ6t_gmE?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Not sure why exactly you came here but but I'm glad you're here. We'll make it worthwhile. Um so my name is Manohar and I'll be moderating the session. Now usually what

happens is in the beginning of such a panel discussion you know we tend to introduce the panelists and uh since we are at an AI summit so I thought uh and we are all in the habit of delegating

things to AI these days. I thought why not let the AI itself introduce some of the panelists. Right. &gt;&gt; We don't know what they're going to say. &gt;&gt; Hello, Elizabeth. How are you doing

today? &gt;&gt; Hi, Minoa. I'm doing great and ready to help. What's on your mind today? &gt;&gt; You couldn't hear that, right? Uh, one second.

Or can you speak a little louder, Elizabeth? &gt;&gt; Of course, I can definitely speak up for you. Just let me know what you need and I'll match your pace. What's next?

&gt;&gt; No. Right. &gt;&gt; Can't hear. &gt;&gt; Let's try again. &gt;&gt; And I can hear you. &gt;&gt; Usually this should work.

&gt;&gt; Yes, absolutely. This works just fine. If there's anything specific you want to try again or clarify, just let me &gt;&gt; Right. Okay, Elizabeth, I am sitting in

front of a panel right now and I need your help to introduce the panel members. Can you help me do that? &gt;&gt; Absolutely. I've got their profiles right here. Just let me know how you

want to frame it and I can help you introduce them smoothly. &gt;&gt; Okay, let's start with Tina. &gt;&gt; So, introducing Tina Madon. She's the co-founder of the agency fund. Tina

works right where technology, philanthropy, and economic mobility meet. She invests in services that empower human agency and create social impact at scale.

&gt;&gt; All right, thank you. Next up is Erica. &gt;&gt; Next, we have Erica Arya. She's the CEO of Project Tech for Dev, which collaborates across the global south to help nonprofits use tech and data at

scale. Under her leadership, they've supported over 200 NOS's with open-source platforms and advisory expertise. &gt;&gt; Very nice. Thank you. Next, we have

Minuk. Now, we have Min Roy. He's the co-founder and CEO of Simple Education Foundation. Min partners with state governments across India to enhance

teaching and learning at scale. He's also exploring how AI can responsibly support teachers and public education. &gt;&gt; Thank you. Next up is Steven. &gt;&gt; Up next is Steven Sutting. He's the

director of technology and product at Quest Alliance. Steven leads AI powered digital learning platforms that reach youth across India using datadriven innovation to improve learning outcomes.

&gt;&gt; Thank you. And then we have Priam Sukumar. &gt;&gt; And here's Priam Sukumar. He's the technology and research leader of anti fellows. Pretter drives tech and

research efforts to use data and digital platforms to uplift public school students life outcomes across India. &gt;&gt; Excellent. And now finally we have this chap moderating this session. His name

is Manohar. Can you tell me something about him? &gt;&gt; And finally [clears throat] our moderator Manoharas Sri Kantth. He's partner and CTO at Sata Consulting.

Manoha works at the intersection of tech, data, and AI, creating solutions that help social sector organizations scale their impact. Excellent, Elizabeth. I think you did a

stellar job. Thank you so much. You wanted to do the panel for us. [laughter] &gt;&gt; Next year, I'm sure we'll have some digital assistants sitting here. But

anyway, uh I hope that was interesting. and you know it did a good job as well right so the main theme for this discussion is a AI cohort program that was run in from September to uh December

about a 4-month program um which was actually anchored by project tech for dev and about seven nonprofits built their AI use cases in the course of these four months right so we're going

to talk about the genesis of the program why it was uh structured that way and also some of the learnings and experiences and finally depending on you know I'm not sure how many NGOs are

there but if you want some takeaways on how a nonprofit can also take away approaches towards AI uh that's also something which we'll cover right okay I'm going to begin with uh Erica because

you know project tech forev was the entity which you know came up with the idea for such a program can you give us a brief overview of maybe start a little bit about tech for dev itself right and

then Why did you think about such a program in a cohort model right and what are the genesis what are the motivation for this and something about the structure also

&gt;&gt; sure thanks so um good morning everyone um so they did &gt;&gt; hello &gt;&gt; so good morning everyone uh the AI did a bit of introduction for me uh and I'll

just add a little human element to it. So yes, we at project tech for dev, we develop open-source tech platforms for the social sector. Uh that's one part of our work and in addition, we do a lot of

tech advisory for the nonprofits. Um and as we had been working with uh you know more than 200 nonprofits in India mostly what we realized was yes we have these open-source platforms which nonprofits

come they they can use it as a uh as a SAS platform and we also provide consulting and through our tech advisory what we learned was that there are times when you know you really need to

handhold nonprofits in taking that first step towards technology or those who have already taken that step to help them move to that next level and there have we have in past you know run a data

catalyst program also um which was in collaboration with Dasra and I'm just assuming uh you all would know this name in the social sector um and they've been running these cohort-based programs and

we we felt that you know when we do these deep rooted rooted programs with a small set of NOS's we're able to learn a lot from them and that actually feeds into you know the platforms that we

built because the way we design our platforms is not like a top down but it is always listening from the ground what the nonprofits need and I feel these cohort-based programs at least for tech

for dev enables us to get those learnings in addition to that you know even this small cohort that comes together. There is lot of peer learning and sharing that happens. It helps us

see the commonalities across the use cases the NOS's are working on and it helps them to further collaborate on them. So why do you rebuild things or if we are building new things can we make

it for the sector? Can we reuse the intellectual property that we have you know working with one or two other partners in the cohort? how can we leverage that and make it available more

for the sector. So learning from our data catalyst program which was a cohort-based programs and a program that agency fund was also running on AI uh and it was called AI for global

development. We felt that maybe while agency fund program was working more with the nonprofits who were much ahead in their journey in technology and in using AI, we felt that can we come down

a level and work with those nonprofits who were wanting to take that step of you know integrating AI into their work. So they had a good use case but maybe you know funding was a challenge or

maybe it was the resources were a challenge because in the sector especially in the NGO space we know that having engineering resources uh is a very big challenge and many nonprofits

do not have that. So is that a barrier for them to take that step towards you know adopting AI? So we wanted to you know bring down those barriers by introducing mentors into this program.

So just I'll quickly tell you about the structure of the program. It was like we got seven NOS's together. It was an open application. Screening was done. Uh we had calls with the NGOs to really

understand that their their use case was really fitting the program. It was a free program for the NOS's because as tech for dev what we believe it was a pilot for us. So when we are running a

pilot there is we are learning together in it and if we have the funds to you know encourage these NOS's to come together then then you know we should play that role. So there was a proper

evaluation of the use case also ensuring that the nonprofit has a resource who can you know devote time to running this for the period of the four months so who could anchor it within the organization.

there was leadership buyin into onboarding onto the program because for technology to get integrated it is very important that the leadership buying is there because there is investment that

tech needs. So I think that was the reason why we felt that can we you know just unlock these these couple of barriers that these nonprofits have and today we have three of such nonprofits

uh on this panel who are going to share with you you know what this this cohort enabled for them. So I think yeah &gt;&gt; right thank you Erica I mean you talked a lot about the goals and the intent we

will hear from the nonprofits how much of that intent also was realized I think and you can be candid I'm sure all of you right we'll move on to Tina now Tina from um the agency fund do give a brief

overview of agency fund itself but also talk to us about the motivation of funding such a cohort model because you know typically funding you can give to specific nonprofits themselves for the

AI use cases but this is a different model what was motivation for that. Maybe we can start with that. &gt;&gt; Sure. Thank you everyone. Um I live in Silicon Valley and I started life as an

engineer. I've never pursued that career uh over the last 20 years. But um one thing I saw in Silicon Valley is that a lot of new ventures are started in cohorts. Why combinator is a quite

famous incubator for uh profitable companies. I was working before we started the agency fund in South Park Commons which is a venture capital fund and tech community. There's one in

Bangalore, one in San Francisco, one in New York City. And the way SPC operates is to bring founders together at the earliest stages in their journeys as they're trying to figure out what to

build and how to build it and who the user will be. And that's a very lonely journey. It is filled with frustrations and failures and it helps to have a cohort of colleagues in the same stage

of life or in the same stage of product development. And so we brought that philosophy into the agency fund when we started that um we bring together cohorts for accelerators and these we

have participated in a lot of accelerators including the data catalyst program that tech forev had done. We run uh the AI for global development accelerator as well. Um, the AI one is a

year-long for us and we bring established companies, nonprofit companies together, but they're all building AI for the first time. So, it's that same experience of needing to

understand your user, figuring out what to build and going through the practice of putting together pipelines, experimenting, experimenting, iterating, refining. Uh, it's a journey and it's

difficult. And so, I do think that the cohort support helps a lot. The other thing is as a funer our perspective has been that while we don't know everything there are certain resources that are

hard for nonprofits to pay for themselves and if we can create those resources in a pool format and make them available we can perhaps be more efficient. For example, not every engine

NGO is ready to hire two full-time AI engineers. Maybe they only need a part-time person right now as they're building out the pipeline. So we've put together a pool of of 10 technical staff

uh who sit alongside the organizations that we fund uh in the accelerator. We include product management in that as well. We've just added some additional people in product management because um

the AI technology is actually easy especially you know there are a lot of talented engineers in India and else elsewhere. What is difficult is to fit the technology to the pain points we all

experience in life and build a product that achieves social impact. That's that's really difficult. Um it's so much further from what the typical Silicon Valley startup has to deal with. They

just need to make money from people who already have money, right? We are trying to do something much more difficult with a population that's much more excluded. And so, uh you know, there aren't a lot

of product managers in nonprofits. If you're in a nonprofit, raise your hand if you have a product manager. Oh, I'm surprised. Okay, there's there's a decent number. Um, but it's not a role

that commonly has been found in nonprofits. This is probably a like a special group. &gt;&gt; Some of them are from the organizations in the panel. So,

&gt;&gt; okay, fair enough. [laughter] There you go. &gt;&gt; Not counted. Okay. &gt;&gt; Anyway, thank you, Tamina. All right. So, that set the stage. So now you got a

sense of you know why the organization actually both these organizations thought of a cohort model why they set it up and so on. Now let's get into the trenches in terms of the experience of

the nonprofits themselves. Right? So um would be good to start with the problem space right so what problems were you trying to solve in the context of this particular program and at a high level

how did AI you know come into the picture and overview we'll get to the experiences and learnings a little later but just to set the context of what problems because again we should

remember that AI is a means to an end right so understanding the problem that we're trying to solve and was it scale was it inclusion was it reach right in the context of your program would be

good to understand uh let's start with you minor croy. Thanks. Uh I'm audible right? Yeah. Okay. Uh so I'll also add a bit to the

intro that the AI did. So I'm also a teacher. Uh and that's how I started my journey into this space. And uh one of the things that as a teacher I'd always struggled with is figuring out what is

the right classroom pedagogical strategy that I need to use for a certain sort of class. Uh and that often changed with the topics or the objectives that I was covering on the day. Right? And for a

teacher, it's often difficult when I'm doing eight lessons a day to sharpen my sort of focus and ensure that I get the perfect strategy. And that really was our sort of problem statement in many

ways that can we build a platform or a tool which enables teachers to actually say that this is the class I'm teaching today. This is the kind of classroom that I have. and then can the AI throw

out something which is evidence-based and has worked in other similar classes before uh and support the teacher. So that's what we wanted to do and uh in India I think if I asked how many of you

use WhatsApp probably all of you will put your hands up and that's the case for teachers in some of the most remote areas of the country as well. So we chose WhatsApp as a platform and we used

a chatbot kind of a mechanism to solve that problem for uh our teachers. &gt;&gt; Okay. Thank you man for that intro. So that's simple education foundation. So they built this simple teacher buddy.

We'll come back to you a little later. Steven Quest alliance. So what was the problem you were trying to solve and uh high level overview the solution? Yeah &gt;&gt; thank you. Um it's happening. No I'm not

sure if I can. Yeah it's happening. Um so we work Yeah. So we we work with young people from grade 8 to uh to class 12 and then younger people who work uh in the TVET who study in the TVET

ecosystem who are between about 16 to 25, right? Um and what we realized in the work that we did and this wasn't necessarily revolutionary was that no two learners are the same, right? uh and

they're different in the way they think, in the way they learn, in the confidence levels that they have. Um and that's one dimension of difference. Then when you think about the demographic difference,

their opportunity of access, the gender inequalities, and if you put all of this together, you you have a system that's a classroom that's fairly heterogeneous. These are not homogeneous systems,

right? And but unfortunately, the educational structure around this is a chalk and talk mechanism. it's it largely treats all the students in the same way, right? Um and as a result of

that, you're not really meeting the learner where they are. Um and if so, that's one dimension. The other the other side of this problem is also that uh there's a lot of stress with the

availability of teachers in general. there's about a 1 is to30 ratio between student uh and teacher and that's a that's in in in a good scenario right so what tends to happen is these students

don't necessarily have access to the information that they need you're not really meeting the learners at where they are and so what we try to do or what we're trying to do is really try

and place a system uh that is able to hear the learners problems with respect to the area of career development &gt;&gt; okay so you're directly targeting the learners Right. Whereas my next use case

was targeting the teachers. Right. So we have yet another education use case from Avanti fellows. Priam tell us about it. So hi, I'm Prriam from Aanti Fellows and what Tamina said and what Steven said

kind of resonated because we struggled a lot to find uh a good use case for AI because we have a lot of pain points like our teachers have pain points, our students have pain points, our program

managers have pain points and they're all spread across the country in remote locations. So we started with a use case to improve student reports so that because a lot of I mean we [snorts]

reach about 200,000 students and 98% of those are online learners and they don't get useful feedback from their test report they just get score and this and that but whereas in our physical schools

there is a teacher talking to them there is a mentor talking to them so we thought we'll improve the student report first but that didn't work out so well so we we our mentor actually helped us a

lot from tech for dev uh and we we iterated through a few use cases till we landed up on actually replacing the teacher student mentor conversation with an AI summary that can

be useful for our uh low touch I mean our our online students so it kind of collects all the data of the students performance in the tests about how they're doing what what how their

attendance is what they what chapters they're weak in what chapters they're strong in and generates kind of a script and for the teachers the script is used to guide their conversations and for the

online learners the script can be used to like just give them a uh proper mentor sort of mentorship guidance so that they have actionable things to do for their next test or whatever they're

doing. Yeah. &gt;&gt; Right now let's dig a little deeper. So now where are we on this journey pri and uh you know how was the solution deployed? How many people are using it?

Is it being in the pilot phase? Can you tell us more? &gt;&gt; It's uh I think it's somewhere between the pilot and a rollout. So we uh around around 15 teachers I think have had uh

57 or 75 57 to 75 conversations with students with these scripts and we are uh working on feedback because uh there are hallucinations as LLMs do but the hallucin hallucinations in this case are

a little weird. The numbers are correct but instead of saying increased it says decreased. So we are like there's a lot of prompt engineering that we are doing to get this uh sort of fixed and in the

low touch in the online program it is being uh once the the the roll out is kind of ready and we just waiting to fix this uh these kind these small issues before rolling out.

&gt;&gt; Okay. And what's been the response from the teachers themselves who are getting these reports? &gt;&gt; The teachers are very happy. I mean it saves them a lot of time like uh in one

of the main feedbacks one of the main uh points of feedback that we got from the teacher is that it saves them really a lot of time because before we before before such a conversation they would

have to look at the last four reports of the student they would ask I don't know what are what is happening at home like are you getting device access and all this now all this they kind the students

fill a form before the mentorship conversation and the teacher we have the test data and we give this all in the script to the teacher. So that has been the positive side. On the negative side,

the hallucinations really bothered the teachers because they there isn't 100% trust yet in what we've given them and that we are still working through. We I mean the solution is not clear because

to me maybe I we need more AI engineers like Tamina said but because it's not clear exactly what to do with these hallucinations because to me the to me and us the LLMs are like a black box.

You just put something, you get something out and you don't know what change will bring the change that you want. Yeah, that's where we are now,

&gt;&gt; right? Yeah. I guess the error rate that the hit ratio um and what kind of an impact it has depends on the use case and if the teachers can be trained to address some of this might be one way

out. Um Mina, you talked about WhatsApp being the channel, right? So that's probably something which you know eases adoption because they don't have to learn something new. It's there. It's

part of the conversation. So now they're getting some additional feedback and advice. But at the same time, and by the way, I know this because I was mentoring, you

know, some of the folks you are. So by the way, this this whole program had a mentorship model where each of these nonprofits are hooked up with one or two mentors and those mentors guided the

teams, right? So I happen to be one of the mentors for simple education and we did face some interesting challenges also even if it was you know simplified from the WhatsApp point of view. So what

were some of those challenges on the ground right because when the rubber meets the road that's when you see what I mean we would have imagined something every product person imagines and starts

with a hypothesis but then needs to be validated right so what were some of those things which we learned yeah I think uh there are a bunch of challenges but you know my favorite challenge is

actually um we wanted teachers to start the conversation with the bot with a simple hi but the moment teachers would get the QR code and the scan it, they would start putting their problems in,

right? And then the bot would glitch because the bot did not get that first high. Uh, and then the whole process of the data that we needed to collect to give the teacher very specific guidance

was not happening. Uh, so we ended up saying that whatever is the first conversation that the teacher does, the bot sort of recognizes it as a high and then starts the conversation. So it

although we've kept telling the teachers that started with a high but it does not happen. So we've sort of worked around it. Uh but yeah that's been one of the challenges and then I think uh we've

seen a bit of also teachers figuring out what kind of questions they can ask. So sometimes there's been some straying away from the kind of questions we want the teachers to ask and because it's AI

they would still throw out some response right. Uh so over there also we've had to put some guardrails around what kind of conversations the chatbot will entertain. What are the conversations

that we would completely sort of say no to. So yeah right thank you Stephen. Um in your case I think you had this slightly more ambitious plan for behavior change right you're looking at

nudging these learners towards a different kind of behavior and you had a certain approach to that. Can you tell us a little bit about it and how how successful has it been really?

Um yeah, I think we're still largely pie in the sky thinking right now. So we still hope to be ambitious through the entire course of the project and not be deterred by how many users and you know

do we have how many sessions do we have. So we're trying to be steadfast with that. I think um for us the the fundamental premise was that we didn't want to create a system that was really

an information dissemination system, right? Um cuz there's enough and more of that. We wanted to create something that emulated a human being or emulated a teacher. Uh and the intent over there

was really to be able to pick up signals. If you imagine a conversation between a teacher and a student, uh there are multiple signals that a human being is able to pick up when they're

having a conversation, right? It can it sometimes it can just be the tonality. It can be the it can be the speed at which they're speaking. You can gauge confidence levels, right? Um, so but

when you're working with an interface like uh like a bot for example, you have limited access to the kind of signals that you can pick up. So then how do you decrypt conversation to be able to pick

up these different signals and then how do you use those signals to then create a response that intends to or is intended to emulate a human being, right? Um and and and interestingly so

when we started thinking like that, it stopped becoming a software problem. it started becoming a behavior science problem, right? And so for us that was really the elevation of that situation.

And so right now we've got a plethora of like people who are specialists in that space. We've got, you know, the engineering and software folks to help us with the scaffolding, but the heart

of the problem is really in understanding that human being. &gt;&gt; Right. No, it's taking it really to the next level. That's so nice. Um so Tina you've now heard some of these

challenges experiences and so on and I think you've worked with previous um cohorts as well. I want to get a sense of also how these Indian nonprofits you've been working with and engaging

with. How does this differ from the others probably you've engaged with you know in the US and abroad in terms of adoption in terms of maturity in terms of the kind of use cases they're looking

at? Can you just give us a lay of the land comparing the two? Sure. There's definitely more complexity in the problems being solved in by in the social sector and by engineers and and

behavioral scientists uh working in NOS's. Um maybe I can talk a little bit about uh a framework we put together coming out of the most recent accelerator that maybe shows some of

this complexity. We think [snorts] of product development as requiring evaluation throughout. But there are many kinds of evaluation and [snorts] it's not just the pilot with some data

collection. We like to think of the evaluation as four levels. They're similar to motors you switch on as you're developing a product. The first level focuses on getting the AI system

to be reliable and safe. And we call that AI system or AI model evaluation. And you [snorts] heard about some of those activities from the NOS's here. um you're testing to uh and and then making

changes to remove or reduce hallucinations uh to remove uh words that might be abusive and to kind of filter uh and you're changing things. You're changing

your prompt. You're changing the knowledge base that you're if it's a rag chatbot [snorts] or a rag uh LLM system. The second motor you switch on is once you start deploying to actual people.

Now you've got something in a prototyped form. You'll maybe deliver it to 15 teachers and you'll see uh whether those teachers use it. We call this the uh product evaluation. And often for an

NGO, the product is not just the bot, it's also a bit of coaching to the teacher for onboarding or a bit of training for the student, a set of prompts that get them to experiment and

get used to the product. And you want to be able to evaluate user activation rates, user engagement rates, user retention. So those are very similar to Silicon Valley or other startups, right?

You you all of those um two first stages you'll see in any AI product [snorts] where it totally breaks out is in level three. The third motor you switch on. That's when you get to a sizable number

of users, say 300, 500 users. You want to understand how users change their beliefs, their behaviors, their mood, their ambitions as a result of interacting with this AI. And companies

in in the profitable sector are just looking for the behavior change to be a purchase. You buy something. That's a simplification, but it's the general idea. All of us are looking for a

behavior change that is much more complex. It's around my uh building a belief that I can learn a new skill and then going to learn it. It's about my belief, my confidence in myself as a new

mom to take care of my baby and know what uh caregiving I need to provide. Uh it's about um my role as a farmer feeling that I'm going to be uh able to experiment with a new input and feeling

more confident or thinking maybe I'll try livestock because now I have better information and support. So [snorts] we call that the user evaluation that requires survey data collection. Most

companies don't do many surveys. Maybe they buy some survey data from a a firm. But all of these orgs once they're deploying to enough people will have monitoring and evaluation systems that

really try to understand the user. And then the four fourth motor we switch on uh we call impact evaluation. And that's when you have tens of thousands, hundreds of thousands of users and you

want to understand whether the um the product that they're using is helping them make a change in their health outcomes, in their education or livelihood outcomes. and and so we

almost never see that fourth stage of evaluation in the private sector. That's something we do in the social sector. But we think that it's a nice way, this kind of four-level framework to think

about how to continuously learn from the product you're deploying and then prove its impact uh to to society and hopefully bring in more funding to to scale.

&gt;&gt; Right. No, thank you um Tamina. In fact, if those of you who are interested in that framework, it's a very powerful interesting framework. the search for agency fund evaluation framework and I'm

sure you'll find that uh it's a very useful resource um right um so in fact so this is one such topic evaluation is one such orthogonal topic but there were a couple of others as well so Erica also

from a program structure point of view right you people had some knowledge partners come in right so it was not just these nonprofits hooked up with mentors but you also had some others can

you tell us a little bit more about those knowledge partners their role and so on and then we'll get into some how they impacted the work they were doing. &gt;&gt; Absolutely. So thanks Manohar. I think

this is a very critical part of the entire program design. said Tech for Dev while we are like a bunch of you know engineers uh CTO's in the organization but again we know that the problem that

we are trying to solve is not something that we can do alone and what we try to do is in whatever we do um we don't want to reinvent the wheel and that's where and we know we don't know it all so we

always work in our programs through collaborations and partnerships ship with people who have expertise in those areas so that we can get the best to the cohort. And so as part of this AI cohort

2, we wanted what was the overall goal of the program? It was that the nonprofits could unlock those barriers which was keeping them away from building and deploying AI solutions uh

to help them bring in more efficiency, help them scale and create more impact on the ground. But we wanted as a technologist we could say that okay we're just building something but are we

building it in the right way? That's what we wanted to do. And so we collaborated with two knowledge partners. One was digital future labs who brought in expertise around building

you know of on integrating responsible AI principles as you are into your design as you are working on a use case and the second knowledge partner was Tattletal which was which works in AI

safety. So we actually wanted that when the nonprofits are working as part of this cohort, they have that thinking of responsible AI and AI safety built into their design right from the get- go.

It's not something that you need to think later. Okay, let's me let me just build something and then I'll come to you know responsible AI practices or think about AI safety you know a couple

of after I've done my pilot or you know after a couple of months when actually I see things breaking. So we wanted to build that right from the get- go and that's why we collaborated with partners

because we knew we did not know this bit. We definitely contributed through you know what Manor said this was a mentorship program. So a lot of mentors came in from project tech for them

because we knew that is one piece that we we feel we do good at and collaborated with these partners and I hope that this uh helped the nonprofits in designing better solutions.

&gt;&gt; Right. No um that was a very unique part of this program actually. Right. because uh also anyone who's in software would know that quality KMA and all these things we look later let's build and get

the functionality out right that's the typical attitude and in the context of AI AI safety responsible AI seems to be an afterthought but here it was baked into it so now let's hear from some of

the nonprofits and how did this influence the way you approached uh you know the building out this and how did AI safety or responsible AI kind of thinking uh influence and how did Did it

actually help on the ground itself? Uh Steven, would you like to say something? &gt;&gt; Sure. Um I think for us it was supremely helpful just primarily because you know the artifacts that these organizations

help put together in some ways were like a blueprint for us, right? And when you have a blueprint in front of you, you you have a sense of what the different moving parts are. Um, and what that

allowed for us to do is to rapid prototype in in in a in a fairly modular way which which allowed us to fail fast, right? And and and if we were failing fast, we were learning faster, right?

Um, yeah, I think and I and I think what can typically happen in this space of human development, right, because the

dimension the dimensionality of like problems can be fairly large. Um and this phenomenon of analysis paralysis can happen and it can be overwhelming to decide what do you pick and choose

because they all seem like really important problems right. uh but having frameworks like uh you know what Tamina was talking about helps you sort of chunk things into you know where is this

problem best suited and where is it most relevant um and then you solve for that in that section and that helps influence what you're going to do in the next step and then you kind of shuttle back and

forth till you felt you've crossed a certain critical threshold of it making sense to the problem that you're solving &gt;&gt; right um one of the things I remember from the AI safety part was uh what

tattle came up with were these plugins right so where they have created a slur list uh right a list of words which the AI is not supposed to use and um that's something which they have crowdsourced

and so on and uh there are also some guard rails plugins from llama and so on right and uh the fact that those things can be plugged into your bot to make sure that it's behaving the right way

was I thought was an interesting thing did anyone of you use uh any of those things not yet right or &gt;&gt; right for the simple yes I mean I remember the guardrails so uh the the

bot which min was talking about so there you could ask any question and then we would the the whole thinking process behind making sure that even if a random question comes so let's say a teacher

asks what do I do it's not a question the bot supposed to answer right but how does it respond to that is something you know we started thinking about and baked into

the whole design itself and that was used for testing, right? Okay. Um now one of the unique um features of this program was also the whole collaboration piece, right? Because um they are not

working in isolation. So we had in-person workshops where each of them actually came and presented and they had sessions where you see all three of them are actually working on education use

cases and there were some others as well. So how could they learn from each other, right? That's one. The other thing is and I think I'm sure you'll recognize you probably are also looking

at uh similar problems in this space. So how do you not reinvent the wheel? How can you leverage some of the work which been done by others? Right? So this collaboration aspect also came in in a

very strong way. So I want to understand from some of you so whom else did you speak to? How did this play out as a part of the program? This how did this program structure influence the way you

know you went about it and how was it? I mean in comparison to let's say you were going about it by yourself right what was the difference anyone &gt;&gt; um

I think one thing that was nice about the program design was that by nature of like the conversations that we were having there was this sense of

porousness that we had that we weren't holding our cards too close to our chest know it was okay for me to learn from you know what you were doing well and what you weren't doing well and if I had

that conversation with you it would it would elevate like or it would it would sort of catalyze and expedite certain problems that we were trying to solve right like for example when we were

thinking about how do you um like if you have to do responsible if you have to do classification if you have to do behavior so these are all different parts of a fairly large problem and we

had a certain approach in mind but through the cohort we realized that people were trying to solve similar things but they did in a different way and like for example, we didn't think

about this through the agenetic way, right? And so then when people started saying that this is what worked for us in that you know model of deployment uh that in many ways kind of expedited the

way we solve for that problem and and and and I think there are multiple examples like that also the idea of responsible for example right like when you say responsible it can be a whole

gamut of what you mean by responsible but what does responsible mean for a 25-year-old versus say a say a grade 8 student is significantly different now if you're you know um if you're let's

say for example an avant and you're working with a certain cohort that is similar to your cohort right what are they doing with responsible that you want to do right and what is that

conversation that we want to have so I I feel that was certainly helpful &gt;&gt; interesting Erica &gt;&gt; uh yeah I'll just add in so while these were like seven NOS's out of which four

were from the education and three are sitting here uh there were two health NOS's also uh and they were both working on on building a predictive model to uh predict high-risk pregnancies and they

didn't know about like you know each one of them building something like that. So but when the cohort came together they discussed their use case and then we felt you know the mentors also got

together and then that's when they felt that we are building the same thing. So then are we happy to collaborate and that's when you know the future calls that happened was getting these two

NOS's together and you know building on at least sharing and building it together was one thing. Second while we were working with these seven NGOs's one of them which is not represented here

was working on an assessment model. How can we do assessments of say answers answer sheets which are coming from students because that takes in a lot of time of the teachers and then we also

since we've been working with 200 nonprofits we were also aware of two other nonprofits who were working in you know trying to uh work on similar solution. So just going beyond the

cohort we brought all three of them together and we just discussed on you know the assessment models that they were building the rubrics that they had and we were seeing that there is there

was a lot of commonality so could we build this together learn from each other's mistakes so I'm just trying to share here that the learning and sharing goes beyond the cohort also and that is

where you know platforms or organizations like us who are more eos ecosystem players have a role to play. So yeah, I think these are like two such examples where I could see collaboration

happening with just bringing a set of seven NGOs's together in a room. &gt;&gt; Right. No, thank you Erica. Those are very interesting and powerful examples. Also building on what Tminat said

earlier contrasting this and the corporate space. We spent a couple of decades in the corporate side and this kind of collaboration at an early stage of a technology is very very rare right

you don't see that on the forprofit side and so it's fascinating to see this kind of thing and know of course we are in a in a room where I'm sure we're working on similar kind of problems and to just

to exchange notes is is so so important. All right. Um just now wrapping up we have about 6 and 1/2 minutes. I'd like to understand how many of you in the audience are from nonprofits. Can you

raise your hands? Okay. Quite a few. All right. So now we have uh keen nonprofit listeners. So the question to the nonprofits and also probably others over here is what are some of the learnings

that you know um you came away with you know which surprised you or which you didn't know of before which could be useful for the nonprofits in the audience as well as they go about their

AI journeys right um if you could share some of your nuggets priam yes &gt;&gt; so I think one thing is that uh one thing we learned is to stop looking at use cases for AI

But look at like pain points and troubles we already have and see if AI is a good fit there. Like it doesn't have to be like AI is this new technology. Let's put it and build

something amazing and innovative. There's already a lot of trouble in the way our even our nonprofit runs. Like there's a lot of inefficiency. There's a lot of stuff. So you just there is a lot

of stuff that AI can do to help daily operations like our fundraising team write grants. our our programmers write code which of course is the number one use case right now but yeah that's that

is one thing we really believe at least I really believe now &gt;&gt; um you know when AI started becoming really popular it almost became like knee-jerk reactions for organizations to

you know jump on that bandwagon and if you weren't doing it then you couldn't get into the right rooms with the right kind of funders and then you would be lost in that race right not not always

but more often than not there is that pressure. Uh and I think and I think what has happened as a consequence of that is some part of our DNA was forgotten. Like I I feel like civil

society organizations have always been um you know a species that has really always asked questions sometimes overindexed on always asking questions. Um but then when software development

became so much more easier to do, AI became so much easier to do, we started leading with solutions and we started deploying solutions. And then uh and this is true for our space as well that

when we go to a classroom, there will be five different NOS's who are solving the same problem and there's that learner who we're all saying that we're trying to work for the learner. We're putting

the learner at the center of design. But there are f five not forp profofits who are all trying to solve the same problem for that learner without recognizing what we're doing to that learner. We and

we need to have that conversation. Right. So sometimes I think it's important to just take a moment and and and have that conversation or do that assessment before you start leading to

solutions. &gt;&gt; Yeah. It reminds me of multiple people building an app for Asha workers and they have to interface with you know multiple apps themselves, right? Um Yes,

Roy. &gt;&gt; Yeah. you know, I think uh just sort of definitely plus oneing to what both of them have mentioned. I think uh don't build what is sexy, build what is

needed. And I think we had a very different use case to start off with. And I think we ended up building something very different because we recognized that that was actually the

need of the R. So I think that's definitely one thing that I would I would say. And the second piece is um I feel like especially when we are building for the

nonprofit space in India scale becomes a very important metric that we want to reach out to like thousands and hundreds and thousands of teachers or students or whoever and I think in that whole uh

space we miss out on some fundamentals like responsibility that responsible AI that we were talking about. So I think how do we build that and that's something that I think I have learned

through the process. Uh there's something that we've been working on now called the golden set to ensure that the responses the AI is giving is actually more aligned to what we actually want

the AI to give. Uh and I think so those pieces are things that if we fix early on then I think it's just easier. Uh and that's something that I think we've uh learned through this process.

&gt;&gt; Right. Thank you man. I mean the golden data set he talked about is part of an evaluation framework also something which is uh very strongly emphasized in the context of the program we have a

couple of minutes we'd like to open up for questions but before that any last words Erica Tina &gt;&gt; yes so totally resonate with what you know

all my three panelists said uh so don't just get on to using technology you know because everyone else is doing it only if it really meets your needs. That is when you think about technology and when

you think about technology please look there might be already solutions existing so don't jump on to building custom solutions because I think what you are working on is also something

many others are working on and that will just help you save time effort and money so maybe just even if an existing solution I'm just saying like an open-source platform is meeting 60 70%

of your needs just start with that and then you can improvise it and then decide on whether I want to build a something which is custom. So yeah, those are like my thoughts.

&gt;&gt; It's a fantastic note to end on. Thank you. Thank you for the panel. A big hand to them. Thank you. [applause] We have 1 minute and 3 seconds questions. I have a few hands up. Uh the

person actually building off a losing thought when you said I'm actually from India. Uh so you said that don't build right away like there there might be existing solutions. I'm actually curious

to know for like some of the solutions that you just described would something like a existing Gemini gem or say a claude uh like a Gemini gem or a claude project.

Did you all evaluate that? Curious to know the journey of that build versus buy or just adopt for any one of them. Yeah. Yeah, I can just add and maybe you know as you are using it so like um like

when we were talking about say a chatbot right u so it's not it's like those models like why when we are using we built the glyphic chatbot uh so we've obviously integrated it with open AI so

it's not that you are reinventing anything but and even we're building an AI platform now even in that platform what what are we doing we are integrating different open-source

elements which are there. So we ourselves as an organization even if we're building something new we are picking up things which are already existing stitching it together and then

adding layers when we speak to our NOS's of you know what is missing in it and then just build that part of it. So, so it is always there in our working um that we integrate opensource solutions

that are existing and not building even if it is like for dashboards. We are like we have a data management platform but we've not been creating dashboards on it. We've integrated it with superset

which is another open source solution. I'm just I know you may not know these names but what I want to call out here is that even as a tech organization who's building platforms we're not

building things from scratch. we are integrating with other tools uh you know which are meeting the needs even when we are building our own platforms. Yeah. But

&gt;&gt; thank you actually it's 000 uh but we'll stay back if you have questions we'll love to you know have a conversation with you but thank you for your time. It was great to see a big audience also

engaged. Uh hope it was useful and do reach out to any one of us if you want to find out more about the program. There's a lot of documents which have been written and published as blogs as

well from project tech for dev and some of the nonprofits. So happy to be engaging with you also going forward in this journey. Thank you. Thank you so much and thank you to the panel.

&gt;&gt; Thank you.
