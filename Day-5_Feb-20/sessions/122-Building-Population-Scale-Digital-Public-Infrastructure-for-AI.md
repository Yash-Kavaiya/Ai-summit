# Building Population-Scale Digital Public Infrastructure for AI

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 14:30 ‚Äì 15:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/KTznEO5a5aM?feature=share) |

## üé§ Speakers

- Dario Amodei, Anthropic
- Doreen Bogdan-Martin, ITU
- Esther Dweck, Brazil
- Esther Dweck, Brazil
- Nandan Nilekani, Infosys
- Shankar Maruwada, EkStep Foundation
- Trevor Mundel, Gates Foundation

## ü§ù Knowledge Partners

- EkStep Foundation

## üìù Summary

This session brings together examples of AI solutions that have scaled from pilots to population-level systems, yielding measurable gains in service delivery, productivity, and inclusion. It will surface the governance, infrastructure, and partnership models that enable sustainable scale.

## üîë Key Takeaways

1. This session brings together examples of AI solutions that have scaled from pilots to population-level systems, yielding measurable gains in service delivery, productivity, and inclusion.
2. It will surface the governance, infrastructure, and partnership models that enable sustainable scale.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/KTznEO5a5aM/maxresdefault.jpg)](https://youtube.com/live/KTznEO5a5aM?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

by saying that you know let's set the context the context is have we overdone it right u when we talk about AI and cyber security these two areas how do they come together there's AI for cyber

security and there is cyber security for AI right so what we're going to do is we're going to discuss both aspects we're going to at least try um so I you know the first question and and I'd like

to actually point it to Miss Daisy you know what has changed you know if you were to look at the larger picture the big picture you know in terms of AI coming into cyber

security what has changed &gt;&gt; I think as with happens with all technologies and AI is no different in that sense it is of course u as we've been hearing over the last few days a

technology that will redefine humanity and how we live work play all of that but one thing that it has in common with all of the other technologies that have come before it is that it's both an

opportunity and a challenge and it's particularly true when it comes to the security uh space. So on one side there is the promise that you know for some time now with the with the advent of

technologies number of things getting connected all of our lives going digital uh cyber threats have become the landscape has of course expanded and threats have become more and more

complex and complicated and for some time now we've not been able to manage cyber security at human scale. So machine scale was uh you know lot of tooling was already in that space. So

there is the promise with AI that you can manage security better. So there is definitely that opportunity but at the same time there is a recognition like Daru Amadai said on the main stage

yesterday that his biggest concern and all of our concerns is that AI brings a set of risks which not all of them that we know of at this point in time today. So both of these so it's also like I

said that commonality is there with all technologies that came before it. It is both a challenge and an opportunity and a challenge because we've got to protect models from being jailbroke.

&gt;&gt; Yeah, &gt;&gt; we've got to pro make sure that the models don't uh leak our confidential information or poison our data. &gt;&gt; Uh we've got to make sure that most of

these are open-source models that we they come with inherent vulnerabilities. So, how do we detect them? So, we've got to think about securing AI as well. Absolutely and very rightly said. So

it's becoming fundamental part of the infrastructure that is being then used to build applications. So earlier I think the perspective it changed was that we we were looking at AI just at

the application layer but it's gone much below um in in the infrastructure. It's got embedded into the kind of systems which are now getting created and deployed u for citizen scale. So um and

that is where I'd like to bring in Narins you uh your perspectives on on on what are you seeing in terms of national security you know is is it is it something which is giving us a spike a

blip something which you can discuss disclose here &gt;&gt; yeah I mean it requires to be discussed that's one thing is definite no one you know I I take the points that uh you've

said one thing about all the other technological revolutions as you said is that you know there was a time frame over which that seeped into into the system okay and then we had time little

cat how do I use it beneficially and also to look at the adversarial effects of it and how do I mitigate those things case of is that it's really happening at a brene speed and there's also an

adoption willingness to adopt into enterprises of the different AI tools that are there so that is where the scary part is there and the other is the adversarial part of the is that

though you know we are uh you use AI for cyber security but the issue is that there are nation states or big enterprises uh which are adversarial enterprises which would be using AI as a

tool for doing it and they have got a lot of motivation to put in effort and thought process into how do I use it more effectively then the persons who are actually using AI for their own

benefit in terms of they're looking at you know how do I improve my productivity how do I improve my efficiency that's the focus area that they're in so this is where there's a

disconnect and this has to be really bridged and that's where the problem is this summit actually in one way it's helping you know people become conscious about some of the measures that you've

taken that is one part the other is the difference between other systems and this is you know and I got a little technical in the sense that you know in the other systems we have a separate

control plane and a separate data plane and and you know there we could actually control they provide access the limits to the control plane but here the data itself is the control. So you have that

poisoning of uh models happening through the inputs that are there. So you could have a drift and over a period of time you'll find that the model will not be behaving as you would expect it to

behave and it's not also not very deterministic. So there are challenges in uh you know how do I protect it now this this uh AI systems uh to see that it gives me consistent results you know

after a period of time then there is also lack of clarity about you know what is a cyber security issue there and what is the issue of malfunctioning or a poor design of an AI

system that lack of clarity also results in you know the challenges that are there I think these These are the preliminary thoughts that I have. So at a national scale the issue is that when

you have multiple entities at the enterprise scale and financial sector, the telecom sector and all of them and the power sector adopting AI, the effect on compromises on the critical

information infrastructure is something that you know would actually make us wake up and then see that what could be done. So those are issues that are there. Excellent pointers are excellent

pointers and I think uh since you brought in the private sector you know and the way they have evolved and uh they're also subjected to these risks which are evolving in nature. Uh I'd

like to bring in Laxmi Sar from Tata here. So um so a lot of infrastructure is is being built connected communicated using uh you know what you're building for the nation. So um how are you seeing

the paradigm shift from let's say how it used to be before AI was commoditized and an every everyday technology it used to be in the labs now it's out and in everybody's hands so what is the change

that you are seeing and the impact you're seeing on critical infrastructure &gt;&gt; I don't think people have woken up to the fact that they are fast running towards the cliff

because I I genuinely think that the digital infrastructure in enterprises today are already fragile and we know that from a enterprise security point of view there is there are so many attacks

that are happening and we know that there are u huge issues when it comes to for example you know now we more talk about IT security the you know operational technology in factories were

never in the purview of um uh IT security and there are you know security today and digital infrastructure in general is still very fragile. It's islands of different OEM technologies

and many many things and uh and you know I don't want to you know um it is it is a major issue. Now on top of this fragility you add AI and this fragility is going to be

multiplied a 100 times over right on many many counts um because AI um is going to increase the the network traffic you know

especially the east west traffic uh by again uh you know multiffold uh the number of API calls that uh somebody and we all are saying oh I'll embed AI at the edge of the device and

if I have a banking application I will do that but nobody has thought through if I put a you know uh an inference there or if you put an inferencing at the edge the number of API calls these

have to do is tremendous and these API calls are long lived sessions they're not traditional API calls so the edge infrastructure is going to come under tremendous strain so That's why I'm

saying that in in all our excitement of AI, I'm I'm I'm very passionate and excited about AI but I genuinely feel that people are not looking at the foundations properly. Right? So that is

very fragile and that is one point I want to make. The second point about this is I would like to expand the scope of this discussion. It's not about AI and cyber security alone. It's also

about a broader trust question. Right? I think with uh we all know u you know whether fake the messages you you don't know apply that in the enterprise context and I know there was a talk

about you know model drifts and so on and so forth. So what we at Tatakom are doing one is to pro protect the digital infrastructure uh through many many things that we can do and and the

unfortunate part is I don't think enterprises have woken up to the fact that they have to do it. So I tell them that you can't build a a skyscraper with a a foundation of a bungalow, which is

what they're trying to do. But when it when it comes to the the the the drift and the trust part of it, um I do believe that enterprises require an AI operating

system, right? And and what we mean by that AI operating system is something that brings the context together because LLMs will provide the knowledge to make that

knowledge into actionable intelligence. You need the context layer. You need the agentic layer and more importantly you need to have a trust and governance layer which will control what an agent

will do or will not do. Right? And if I take that control on on in my hands and say that I will configure and ensure this agent will do something or not do something, I can make use of the models

underneath a lot more intelligently. Right? So I think rather than focusing on whether this LLM is good or that LLM is good and and so on, this AI operating system is what is required for people to

build an application which will ensure that all of these are governed properly. So that's a great point. In fact, I I was having a conversation a few days back and I was saying that from the time

of corporate social responsibility, it's time to evolve to corporate AI responsibility where corporates start talking about how they're controlling and owning the actions of the AI that

they're that they're building and and deploying. Um a great perspective, sir. Thank you very much. Uh at this point I'd like to bring in Richard uh to sort of continue the talk about um uh digital

infrastructure and resilience. So how has resilience in your in your perspective evolved when we talk about AI risks to cyber security and and vice versa?

&gt;&gt; Well the the question of resilience is is a complex question. So I will bring few aspects that I think are very important. So um it is well understood that um that people are

are typically the weakest link in cyber security. Uh the reason is that uh we as human beings we are not we were not evolved to deal with machines computers and so on and most of us don't have

really deep technical knowledge about how systems work and so on. So we are to a big extent dependent on relatively superficial understanding and and uh so we are more easy to be tricked

by different social engineering tricks and so on. Now with with AI, this is becoming a big issue because how you can distinguish a a scam from a real communication when the scam

communication looks exactly like the real communication. Uh I'm talking about deep fakes and so on. So this is this is one aspect of of the risk connected directly with people. The other aspect

is that we want AI to empower people to do things more things and and make them uh in an easier way. So we have those agents and we give them some or we want to give them some commands like do this

for me or that for me but we don't understand all the steps that the agent will take on our behalf when performing those tasks. And uh and each of those tasks can be a there can be a risk

factors involved without us knowing like okay if you want to perform this action you will need to have uh those additional tools to achieve that and where you get those additional tools

okay if AI decides on your behalf these are the tools you need software packages whatever it is and they get to your computer without this being supervised uh then this is a problem. So where

where I'm heading like resilience here is really protecting or paying attention to details. What is actually happening? What is running in the background? How are your commands transferred to to the

agents? Is is there a possibility for them to be intercepted to be modified? So, so it's even it was difficult and complex even before advent of the new AI identic approach. Now it's becoming even

more important to really go into all the details and we just heard from Lakshmi that that he sees that we are moving towards a cliff. Um well depends on us of course we want to

go fast we want to employ we are all excited uh about AI but we maybe sometimes we need to slow down a little bit and make sure that the pieces are in the place and cyber security is not

overlooked. Excellent, excellent perspectives and and you know I think uh and an an offshoot to that question can be to Miss Daisy which is you know what are you

seeing as as changing you know when you're talking about digital infra and and especially the connectivity which it which it needs um you know because you're at Cisco right and here is

something which is connecting a lot of things to a lot of other things. So how are how are you seeing changes happening especially when you talk about resilience and and what's going inside

digital infra. &gt;&gt; So I think um Lakshmi touched on a very important point of the underlying the fragility of the underlying infrastructure and that is something

that I want to reiterate. You know for the past few years we've been publishing an AI readiness index and the good news is that we are as ready as everybody else. The bad news is maybe we're not

that as ready as we think we are which is the point Lakshmi is making right 90% of just under thousand large enterprises that we spoke to in India want to deploy a agents this year 40% want that agent

to work alongside a human being uh but only about twothirds of those enterprises really have a data layer data strategy a data platform and a data governance uh strategy

only about 1/4 have the compute capacity they need only about onethird are able to um understand AI threats and deal with them and less than 1/5if have the innovation engine to think about

building and scaling and maintaining AI applications and use cases. So clearly there is this ambition versus reality gap which we have to solve for. That's not a problem as long as we all know

that that's where it is and they were acutely aware of this uh issue. The other thing is AI is essentially leading to what this is means is that we are rewiring and reststacking the

enterprise. It's not just networks, it's compute, it's silicon. I know you know at the national level silicon security is is is a is a conversation. So all this resiliency which we used to build

almost like a bolt-on at the top and particularly we used to think of it only as cyber resiliency it's a system resilience which is built into all layers of the infrastructure stack all

layers of the AI stack. &gt;&gt; Yeah. And that's why at Cisco since you asked me a network specific question we used to have you know we used to deal with connectivity largely as

connectivity and now we know the persona of that end port that connects to an end device that might be doing an inferencing or it's in the data center that persona has to be that it will be

on one side it will be a switch or a router &gt;&gt; but on the other side it will also be a security defense point. So this ability of building special grade of security

appliances and putting them in various parts of the network is fast becoming an outdated idea and the point we've got to do is we've got to break it into a number of virtual instances that can go

wherever you want the security policy to be uh so it becomes a very virtual distributed mesh rather than a hardware. Yes, there will be hardware. I'm not saying it'll go away but this ability to

infuse it into the fabric where and networks tend to be the all pervasive fabrics that's the way at least as Cisco we are thinking about it uh so this domains of networking and security are

crashing together uh so secure networking is like the conversation in in the network space particularly the other part about this is the performance requirement which also Lakshmi alluded

to AI will put pressure on the underlying infrastructure in a way it's an exponential technology. The demands it'll create on its underlying layers is also exponential.

&gt;&gt; Yeah. &gt;&gt; Right. So we've got to almost build a new category of technology silicon systems applications everything a new category uh has to be built and we have

to build it in new ways. You cannot build it in the ways of of how we built it in the past. Applications is an interesting one right? We used to give an input expect the same output on the

other side &gt;&gt; is easy. &gt;&gt; But now if you are going to deploy AI models this thing is probabilistic and &gt;&gt; you know sir refer to it. So you want to

get it to a degree of assessment so that you know you cannot expect in a financial application or a very important citizen service application you give an input and the output is has

to be deterministic but you're using at the core of it a probabilistic technology. So that refinement is also takes a whole lot of work. So it's it's rethinking in ways in all layers of the

uh from silicon to software to systems you have to rethink everything every rule we have to rethink. &gt;&gt; Excellent. Excellent. And and since you brought in that perspective of

rethinking reimagining and how we're using AI in the operating system of the company I'd like to bring in Dashan here. So Dashan you do a great work you do a lot of great work in creating uh

thought leadership content as well as doing consulting work for very large companies. Of course, there are CXOs and a very highly ranked official of the government sitting here. But then what

are the other six CSOs, CXOs thinking about when it comes to AI? Is it still a compliance thing or has it percolated to strategy? Uh first of all, thank you. Um I'll probably add some context to

whatever I've heard so far. So uh first of all, my views is any technology disruption brings in two emotions, right? So hope as well as fear. And I'm sure all the other panelists have

rightfully covered the fear construct of AI in cyber security and rightly so. No disputing that uh truth. But there is a huge hope component from a cyber security company right for us because we

are a hardcore deep tech cyber security company. I see a lot of opportunities u and we as a country India can also be uh we are at the sweet spot between intersection between AI and cyber

security and this topic is very aptly crafted because I think it's it's a huge opportunity for us to also uh utilize and I'll tell you why cyber security has so far been a very asymmetric uh you

know equation uh the intruders have always had an advantage right over the defenders or anyone who's actually defending a network because they just need to get one thing right and we need

to get everything right right so it's always been a symmetry but with AI now all of a sudden we are at a level playing field you know uh from a technology standpoint to identify a

needle in the haststack for example one classic use case can be an agentic uh security operation center right uh because at the end of the day if you have ever visited a security operation

center it is a 24 bar 7 someone analyst looking at a screen and almost an inhuman job so to speak but today with AI now you got a level playing field because we've seen those kinds of use

cases being deployed at our sock where even a shift handover is done by an agent so a lot of real use cases so I'm on the on the hope side there's a lot of opportunities that today we have and

second in terms of talent I mean we have a lot of youngsters sitting in this room who are looking to grow we've spoken so much about other services other areas evaporating in terms of job

opportunities. I think we can create the world's cyber security talent uh combination with AI because cyber security and AI are not two different speed uh you know fields. Uh they

actually cyber security needs AI and AI needs cyber security. So I think we are at a very very opportunistic uh opportune time for us to really ride this wave and create worldclass talent

which can address. So now on the second part which you just spoke about in terms of what we are hearing at the CXOs globally since we do deal with a lot of people in the payment ecosystem CXOs

obviously have the same construct of hope versus fear right so some are obviously being a CISO or a or a CIO uh there is amount of fear that is also coming in because this is these are real

problems right for example deep uh fakes or uh you know spear fishing attacks have become more robust with AI but one of the key things that we are trying to uh uh explain is that uh yes those are

things that you need to address no doubt but can you also look at how you can take advantage of those AI and uh Lakshmi rightly pointed out how do you have a AI operating system similarly we

talk about how you can have a AI security operating system right which you should have a playbook on how to leverage AI rather than being on the defense player yeah so those are the

those are my views uh sum yeah no &gt;&gt; excellent excellent views and thank you very much for those perspectives And I'm glad that I still see people coming in you know this is an interesting session

uh and some people standing as well. So um I would like to bring in Praep now. uh Praep you know as a follow on to um to what I just asked Darren here is something which is uh you know at the

top and we're saying you know while it is percolating into strategy a bit um do you think that we should have a dedicated function within an organization and what are you seeing

currently not just in India but elsewhere as well &gt;&gt; yeah thank you for that um so probably adding on to what Dashian said right um I I don't mind the hope and the fear

thing because uh being in cyber security space it both of them do add more to what we can do right for for the industry as a whole for the country as a whole if you would uh when we look at

strategically when we talk to let's say leaders in both at companies in India across the across the world uh predominantly when we when the conversation is about AI the topic goes

towards innovation competitiveness and ability to bring in let's say productivity gains right what often gets missed is that AI I is quietly reshaping the risk equation within the enterprise

right now um cyber security right so can no longer be just about protecting systems and the data now don't get me wrong right cyber security is still needed to be able to identify all the

systems within your enterprise beyond the extended enterprise as well as be able to protect the data that is on all of these systems but it is it it needs to evolve into something more given the

AI landscape which is I loved how LMI put it right. It's going to be about trust. So going forward can cyber security how can it evolve to start protecting decision- making and trust

because trust is starting to become measurable right through provenence through au authenticity as well as verification. Now all of these mechanisms are going to come in in a way

that we are able to identify measure rate risk rank and call out whether this particular transaction that you're doing whether it's a payment approval or let's say an executive communication is um

trustworthy or not and then accordingly the agent or the system that's allowing the transaction to go through allows it or not right so that's something that we are seeing and AI in this context is uh

is is a force multiplier right on both sides for us as defend ers we are seeing like a Tashan said how we are able to detect identify threats at scale and speed that we have never seen before

right um and definitely right bringing in again it's not going to so if you ask okay is it going to completely revamp how we do and run socks a little yes it's not going to replace all the

analysts but definitely in terms of certain tasks that we're doing we've already started seeing Microsoft with it security co-pilot how it can automate tasks right? Like different agents doing

different tasks of the sock life cycle. So we already starting to see that now but in addition to that it's also helping attackers on the other side of the equation which is it is

industrializing disruption at scale. Think fishing, think social engineering. Now all of these manipulation now it's happening at an unprecedented scale. Now that's that's going to continue and

we're going to see it continue for let's say the next few years because that's where we're headed in terms of air rated fishing. Um I would say yeah definitely manipulation and how this is going to

impact the industry as a whole. Now I would say that's that's pretty much how um all of these the shift is the tectonic shift is happening right across. So as I would say working with

leaders and board members we are looking at how to look at um how to look at these risks and how to frame these risks and here usually we see three three lenses. So one is a compliance risk

which is am I complying with the EU AI act right? Am I complying with let's say DBDP or other sectoral guidance. So it's more of a check in the box approach maybe helps with me in protecting

against regulatory exposure but not with systemic risk like what um Daisy was saying. The second angle which some companies have started to move towards is the operational risk right wherein

the boards are starting to ask the models am I using is it reliable is it safe is it trustworthy and what is the risk if this particular model or service provider who's providing that model goes

down so that's the operational risk angle that we seeing more of the third angle which I think it's very few companies doing today is probably the strategic risk angle right wherein being

able to call out if I'm using this particular If if there's an AI AIdriven attack um identity attack right that is reducing or impacting the reputation of my organization with my customers. What

is my exposure in financial terms? Now these are questions that boards would start to need to ask because we we are starting to ask those questions and get those questions from leaders in order to

how be how are you able to measure those in how how do you quantify risk in financial terms and be able to convey that to the board as well because that's what at the end of the day boards are

concerned in being able to uh penetate to the sha stakeholders and shareholders. &gt;&gt; No that's that's that's great and you know those are some interesting lenses

that you've put to the whole conversation. So sir, I'd like to bring you in now um you know from your vantage point. So when we seeing when we talk about India's DPI we we are implementing

AI into systems which cater to healthcare which cater to uh you know telecom you know across the across the citizen supply chain if if you will. So how do we make sure that the AI

deployments that we're doing and what capabilities do we have to make sure that these deployments are secure and they're taking care of the risks that uh the fellow panelists highlighted?

&gt;&gt; Yeah, you know even now we are really struggling with getting the cyber security maturity across all sectors. No, the financial sector for example is mature but let's say take the health

sector it's not as mature as others but if you look at the enthusiasm for example of the health sector to adopt AI you'll find that the level of enthusiasm is similar to what is there in the other

sectors so that is a big challenge you know we we've been engaging with uh health sector for example we've had meetings recent meetings also to see that how do I improve the cyber security

posture of that sector so that's a big challenge actually getting so we had this digital divide we have a cyber security divide that's there and now we are going to have this air divide uh

that's going to be there across uh enterprises in different sectors. So that is the challenge that is required to be addressed and there I think is the capacity

building part and also come up coming up with you know uh frameworks where people have access to that framework and understand what is really required to be done

and you know the talked of assessment when an enterprise is coming with the AI system is it secure is it doing the work it's supposed to do so we don't have those assessment frameworks now so if

you're aware you know uh the testing and assessment part is an important part and creating that infrastructure for so that people could go and then test and says that is important part uh the department

of DRD has come up with an ETI framework &gt;&gt; if you're aware of it similarly we from our office also we funded a project and still on it's around a year back it

started November of 2024 we funded that project for coming with an assessment framework for ES systems so that one is the security aspect of that and the other is of course the uh the functional

aspect you know that also in the sense that somebody claims that this a system does something how do you actually assess that is this so I think one is the capacity building part and the other

is the you know having the frameworks in place is good one thing good about this country is that we have an institutional framework that's been established especially because the cyber security

over the period of time like we got the cert India and CIPC or their institutional frameworks and also the sectoral regulators also come up with sandboxing regulations in the sense that

if you want to try out something new, you have these regulations that helps you to try out something new. So I think these uh like in the financial sector you have the RBI sandbox. In the telecom

sector also there's a mechanism. So I think people start using these sandboxes to prove technologies to prove applications prove use cases and that would help them to actually understand

how it really works before they deploy in production. that I think would help uh uh in you know going going forward. &gt;&gt; Awesome. Uh thank you sir and I think it's it's uh it's enlightening and

enriching for all of us here to know your perspective especially you know what the government is doing towards it. Um I'd like to bring in Lakmi sir from Tata um here for the next question. So

um sir if we reconvene five years from now here what are we going talking about? What did we do? What did we get right? I think this these discussions are very

healthy, right? Whether AI with a positive lens or with a with a with a fear lens, I think we need to I u on two comments. One is you know the the question on assessment we ourselves

in Tatakon then we asked ourselves the question where do we want to be five years from now and I made a statement that uh the next five years will determine the health of the company for

the next 50 years because the technologies are moving very fast so for an assessment framework we developed a framework ourselves we studied a lot of material we didn't find something good

so we developed a an assessment framework where on one axis we plotted the capability um you know it includes uh talent it includes the platform which is when I

said look you know no no point in doing individual use cases uh in an organization how many use cases will you do you need a platform approach which is where we said AI operating system is

required so that is maturing so one on one axis we are going to plot the capability right so it's talent even culture AI I don't know whether people have appreciated this is a very

different parad paradigm right even now in the discussions I see people talking about how AI can help automate things and do things faster no that's not what AI will do AI

um you know while the previous technologies of cloud and um internet have helped companies to scale transactions AI is going to scale decisions and when you're scaling

decisions you need to think of a different paradigm altogether right and we are still talking in the old paradigm of what task can be automated and how it can be done. So this is a new paradigm.

So in the capability axis the culture dimensions would have to be you know thought through carefully and talent appropriate. I find some of the younger talent are more easy to train on AI than

some of the older uh unfortunately u that so I think the whole talent and capability equation is one axis and we're going to plot ourselves and the other axis is on the outcomes. what

outcomes do you really want to deliver uh with with AI and there you know outcomes could be more on efficiency outcomes could be more on the revenue announcement outcomes could be more on

the trust and the customer satisfaction all those outcomes need to be plotted I must admit we ourselves are somewhere in the in the lower quadrant and I hope uh we as a company will move to the top

quadrant and um and and and that needs to be defined and that needs to be visualized and only then you can move towards that and that's what we're driving the company towards and all the

platform development that we're doing uh strengthening our infrastructure for enterprises and we've shared some of these assessments to our customers as well. So that is one. So we I hope that

most people would see themselves moving towards the top quadrant in in five years time. Um the second thing um that I worried about in in the context of uh strategy

is again you know when people talk about AI and strategy um I I believe that like in the previous technology when we had internet and cloud there were new business models

that came about right so we had intermediaries coming the booking.coms and others who disintermediated many many people or fintexs who came and did things better than the the larger banks

and only when you know the larger entities woke up to the fact that these people are going to eat their lunch and they have so and and that's what happened in the previous wave of

technology [snorts] in the AI I think similar disruption is waiting to happen um don't know where and when and what but if if a strategy does not think about that as to what disruptions are

going to happen they would have missed the bus so five years from now I would expect a new class of companies who are AI native who are out there going to disrupt the existing business

model. So those are the two things I would expect in five years to happen. &gt;&gt; Fabulous. And sir, one last question to you Narinsa. Um if if you were to give me a call 5 years from now and say

Samrad this is how this is how nation states have changed. What would that be? &gt;&gt; See one is you know AI and and I've talked somewhere else also. you know adoption of AI is a competitive

advantage. So that's why you know you have to adopt AI and you don't have any other because there are other nations who going to adopt the other enterprises going to adopt AI and they're going to

try to look at how do I do business better so that way you know so going down you'll find that nations we would adopt AI and actively and this is this conference is very good for that five

years down the line the other is protecting yourself from the adversary effects of because it's a very powerful tool it's a powerful tool and then u you It's a just a thought process now but I

think we as as you pointed out this just one year we have found that such a lot of development has happened. We do not know where this is really going to lead us. So the thing is for us to be on our

toes uh to actually look through that how is this technology going to affect the way we do business and how we run our countries and and then also and then you know this development of capacity

capability and and identify the dependencies that we have when this technology is adopted and try to see that how do I mitigate the dangers of [clears throat] those depend

dependencies. This is where I think uh the thought process would be and this is where I think the road map for the next five years for us. &gt;&gt; Thank you. Thank you very much sir. And

thank you all the panelists for taking time out and agreeing to do this uh for the audience. I see the room is full and a lot of people waiting uh on the sides as well. Thank you all for paying

attention. U please put your hands together for the esteemed panel that we have here together. We have to conclude this panel only for the posity of time otherwise we could have gone on. Uh

thank you very much.
