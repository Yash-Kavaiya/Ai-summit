# Enterprise-Grade Responsible AI for India and the Global South

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 17:30 ‚Äì 18:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Nalanda Banquet |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/RW9vl6Froqw?feature=share) |

## üé§ Speakers

- Anupam Chattopadhyay, College of Computing & Data Science, NTU Singapore
- Babak Hodjat, Cognizant
- Balaji Thiagarajan, Flipkart
- Hari Menon, Gates Foundation
- Mike Haley, Autodesk
- Raju Vegesna, Sify Technologies Ltd
- Shereen Bhan, CNBC-TV18

## ü§ù Knowledge Partners

- Primus Partners

## üìù Summary

For India and the Global South, as AI systems move from pilots to mission-critical deployment across enterprises and governments, this challenge is amplified by fragmented and heterogeneous data, legacy IT infrastructure, uneven regulatory maturity, multilingual and culturally diverse populations, and high-impact use cases in finance, healthcare, welfare delivery, and public services. This session will examine what enterprise-grade responsible AI looks like in such contexts, grounded in real deployments rather than abstract frameworks.

## üîë Key Takeaways

1. For India and the Global South, as AI systems move from pilots to mission-critical deployment across enterprises and governments, this challenge is amplified by fragmented and heterogeneous data, legacy IT infrastructure, uneven regulatory maturity, multilingual and culturally diverse populations, and high-impact use cases in finance, healthcare, welfare delivery, and public services.
2. This session will examine what enterprise-grade responsible AI looks like in such contexts, grounded in real deployments rather than abstract frameworks.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/RW9vl6Froqw/maxresdefault.jpg)](https://youtube.com/live/RW9vl6Froqw?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Uh, can you hear me clear? Yeah. Uh good evening everyone and uh thank you to our esteemed panelists and everyone who's come here braving the traffic. I know it's a end of the AI impact summit

and as people were saying they've heard so much of AI this week that they could decompress for the next one month and not here so but however we can't wish it out because it's a very significant part

of our life. Uh I'm Sunita Mi managing director at Primus Partners and it's a pleasure being here. We started with the inaugural session on the 16th and we are ending with a session today. So it's a

very significant moment for us to be uh here today. So I'm going to quickly ask we have a really good set of panelists here. So I'm going to start with you uh Babak. So um we've been talking a lot uh

we've been attending a lot of sessions. People are talking about what is real in AI and uh today's topic is about how do we connect India and the global south and what are some of the guardrails we

can build here and especially as the chief AI officer at Cognizant you're seeing how AI is really impacting real life and enterprises are really moving to delivery architectures and operating

models in AI in uh mission critical infrastructures like banking and healthcare. So from your point of view uh what are you seeing as the guardrails and the trust frameworks that

organizations are creating to make sure that these are safe and what would be your advice be for India and the global south. What kind of frameworks should we adopt?

Yeah. Um uh AI is real and uh both the promise and the risk is real and so guardrails are needed. Um we can't fall off either ledge of trusting AI either mistrusting it to the point where we

debilitate it by uh basically um uh having you know a human rubber stamp every single step. uh or the other way um basically thinking that it's you know some magic pixie dust

that you just uh pour over your organization and then turn it on and and it's AI enabled. Uh so guardrails are important um and there are different uh ways there's no panacea to uh to uh

ensure safety as well as reliability of these systems. Uh one of the biggest risks is the um uh this notion that because uh the AI systems respond and reason very well uh after one or two

reasoning steps that we can allow them to just continuously reason. They they do make mistakes um even very trivial mistakes after several hundred reasoning steps. So, um, we've been here before,

for example, with telecommunications where a bit might flip when a truck is driving down the road. Um, and so we know how to error correct uh through redundancy and through other uh means.

We know how to engineer systems that are reliable. And those engineered systems might require for example uh yes human in the loop or on the loop for sure but also agents in the loop and on the loop.

Uh checking other agents works. Um uh assessing uncertainty in an agent's output and uh deciding not to take its output at face value. basically taking the output as well as its own measure of

certainty and uh its output as uh as a measure of whether or not we bring a human in. Uh so these are just some techniques but u there are a multitude of techniques that can be used. There's

also increasingly this issue of um uh agentic identity. When you're building a system fully in-house for your own use, then you pretty much have control over the agents. you know which agent is

talking to which agent and and they're all built in in-house but increasingly we're moving into a world where you have agents from third parties maybe another business maybe your consumer represented

by an agent uh BTC may be an agent uh coming in and talking to your agents how do you assess how do you determine the identity of this agent we don't really have very wellestablished standards for

that just yet I know our friends at Google are are working on that in A2A uh and there are other standards coming out but it's it's still not well established um so there's risks external

to your agentic systems as well so I just listed a whole bunch of uh different areas when when it comes to India I I know that there's talk about for example building these systems in um

within India like sovereign uh LLMs to back the the agentic systems um regulation does play a part. Uh again, there's a risk of overregulating versus underregulating. I think that's it's

important again not to fall off the ledge from one side or the other. Um uh I have opinions on that too, but I realized I'm talking too long, so I I should pass it on to my colleagues here.

&gt;&gt; No, thank you Babak really good point. I know you have a very difficult job at uh Cognizant but the two things that you mentioned about keeping agents and human in the loop and we also heard in this uh

one week a lot of people talking about having humans at the center of everything that you build. So that's amazing. Uh morning we also heard about regulation versus innovation and US is

at the point of innovation, Europe is at the point of regulation and where does India and the global south start stand. So that's good. I'll move to the academician point of view anupam with

you next and much of the responsible AI research still assumes uh that data is clean and uh there is a stable infrastructure but that's not true about the global south because we do operate

here on very heterogeneous data intermittent compute access and multilingual environment so from a research perspective what are some of the new technical directions uh hardware

aware AI and robust arch architecture evaluation models that are needed to make uh AI really trustworthy. &gt;&gt; I think this is a very important question. Uh we do

&gt;&gt; uh can so we do see the scale of innovation and the pace this is going at so high rate. It's not always easy to just take a backseat and think

of the research as a standalone component that matures and goes to industry. People people are releasing tools and things are going out of hand very quickly and for that reason what we

figure out is it's always good to keep the research very grounded and try to test the waters with some real world scenario. And one of the examples that I pick up here is uh one of one spin-off

that we had from our research group that's on defake detection. &gt;&gt; Mhm. And there we are facing exactly the problems that the models that we begin

with. When we start training it, it is actually showing very poor results. When we are testing subjects from global south like for the images or for the audio or if we are putting the audio

under some circumstances where there is a lot of noise because it was tested on very much clean data and under noisy atmosphere the accuracy of the defect detection is failing. It's a huge

concern because people are also not always educated. There is already a digital barrier &gt;&gt; and on top of that there is a AI barrier that's coming up. So which is making

people fall prey to a lot of cyber scans very easily. So that's the bad side of the AI that we are observing. We're trying to defend it and for that the technologies that we are trying to bring

in is of course one is to create synthetic data sets. So we have a tunable noise addition on top of the data. then collecting as much as possible say data by scrapping the

internet. But for defect it brings a different problem. You see a video or an image and from a human point it's not even discernable that it's defake or not. It looks so original. Right? So we

had to create a separate automatic fact checker which is looking if there is a news that is linking that image with something and news is coming from a trustworthy source only when then we

call it's a original image or otherwise it's refake. So that is the data collection issue. But when it goes to the even the implementation aspects that of course not everyone is having access

to the uh high performance computing and we have to cuddle the data or the models back to the bare minimum and there we have to resort to techniques where we are doing say mixture of experts that

there are different models with different defect detection capabilities. We put them together and sometimes the models are proprietary and we want to take it from a particular vendor merge

them together or an organization they have their own contextual model but they don't want to share the models as it is and for that we have techniques like federated learning on how to merge the

models and still guarantee that their training data or their models will never be linked. So it's a privacy aware building up. So we do have all the technologies and tools just a short

glimpse of that it's going around. &gt;&gt; So thank you Anupam. I think one of the things that we are always discussing about there's not enough data to train the models and uh that's why there was a

lot of emphasis during this week around getting language models in so that there is enough indic language as well as across APAC. The other thing is about synthetic data which is very important

for us to keep the data clean. And one of the conversations we were also hap having is how do you enable creation of uh synthetic data in countries like India and the global south by creating

AI in a box which is a very modular infrastructure that is available to students researchers in a very small uh minimal environment for them to be able to create some of this data. So thank

you with that Amod uh I wanted to speak to you about uh AI infrastructure given that you are in that business with Sabur and that is now becoming central to the responsibility defense uh and debate as

well. So the IA estimates that data center electricity demand will double by 2030 and AI workloads are a key driver. uh how do enterprises and governments think about responsible AI not just from

a model creation perspective but generally at an infrastructure environment ecosystem perspective in terms of cooling energy transparency resilience.

&gt;&gt; So from our point of view uh the responsible AI starts from the design uh of the infrastructure. So if my design uh of the data center is sustainable that is where I'm going to

then uh be able to achieve my goals efficiently and sustainably. So to do that today we can leverage liquid cooling technologies which will uh minimize the overheads in terms of

cooling these infrastructure uh requirements and allow us to scale AI rapidly for betterment of people and the planet. We need to as government I would say we

need to get to a point where we can define KPIs around energy consumption per token or water consumption per token for these type of massive infrastructures and incentivize the

players who are actually achieving or crossing those KPIs. It is essentially it is all about making these data center designs sustainable from the

power consumption standpoint and achieving a much better outcome that we want to achieve in terms of AI and its scale. &gt;&gt; Yeah. So that's a good point because um

at least Tanvi and I and Babak you as well have all come from Davos. I think one of the main conversation there was around energy and how do you make it efficient and in one of the

conversations at Bloomberg we did hear about uh ROI and how do you measure the cost of query like what is it on the infrastructure so I hope that at least with renewable energy and efficient

cooling system we get better as well as optimized query capabilities so with that Tanvi I wanted to move on to you and uh especially because you're creating sovereign LLMs now uh with the

Vatican as well as with the New York City. So drawing from your experience of leading AI transformations uh how do you think that deep tech startups in critical sectors like BFSI can build

advanced functionality and uh across complex regulatory systems and also what's your sense about the definition of sovereignty from given it's a very loosely used terms across all and we

hearing a lot of it this week. Yeah. &gt;&gt; Yeah. Thank you Sita. Thank you everyone for having me here. I'm very happy, very excited to come back to my homeland in in Delhi again from Zurich and the

conversations were very enlightening. We call it divorce 2.0 of what India is hosting now with the AI impact summit. So, thank you for having me. I think the question is super loaded. I can go on

and on and on for multiple hours, but let's just pivot into the conversation on ROI. Um, I come in from a banking background, worked for more than a decade in Swiss banking. Um and the

conversation always around if you're putting in an investment what's the return off it. So whether we are calling the use of LLMs the frontier models we all know what the return of investment

for the consumer is. I think this is the first technology that touched consumers first enterprise and governments later. We always had technology touch enterprise and government first and

consumers later. But here since the equation has turned lopsided there are lots of factors that goes into ROI. So going back to sovereignity, um I think President Trump has uh really done the

marketing and sales for sovereignity and everybody tends for themselves whether it comes to defense or whether it comes to owning your own infrastructure, your data and your and your intelligence and

your cognition which we call as models. But one of the factors that always resonates coming in from banking, if you cannot control, if you're not accountable to what you present, you

would never pass the regulatory bars on using the technology. So we had this very famous team called the model risk management and we used it for a IML for the longest time. I think anybody in

banking would resonate with that. Similarly for healthcare, similarly for the regulated industry. So with the use of LLMs and I had the opportunity of working very closely with OpenAI during

my time at UBS being Microsoft's primary partners, we have the entire world's data in charge GPT and all the other LLMs. There's no way we can guarantee what

output the systems going to throw at you. So the control on cognition and intelligence is as important as the control on infrastructure is. And that is paramount um and which gives gave

birth to what we're now building at ECA is domain specific model. It doesn't get trained on an open source. It's not an American first or a Chinese first or a French first. We're talking a lot about

France and Mistral. It's your own model. And from a sovereignity perspective um it's important that we can build our own models where data is not a constraint. You could use the data of your own

content of your own organization of your own government in your native language and there's no translation required and you could use multiple use cases across that domain which is extremely

applicable and hopefully gives the ROI to the sovereign stacks that different governments and different organizations are building for themselves because if your model is in your control you could

put them into consumerf facing use cases and not the internal productivity use cases and the value of this whole technology for enterprise and government is only applicable when the end consumer

gets to use it the way the retail consumers are using open AI and anthropics and others. &gt;&gt; Great. Uh uh thank you so much for that because uh I think one of the other

things that I heard uh this week at the conference is also not only protection and guardrail at a model level but there was also a demo of a product where at a hardware level they're trying to put

some kind of controls so that there is a break. So we'll get to that topic. I wanted to move to you Balaja because Flipkart is right in the middle of consumers like user user consumer very

much like our LLM models. So how do you think you operate at a uh population scale like in India and global south and in a high velocity environment? Uh where does responsible AI collide uh with

business realities? for example, how do you manage personalization, data security, fairness, and marketplace trust? &gt;&gt; Yeah, Sunas, thank you for the question.

Um, you're right. Flipkart operates at um internet scale pretty much, right? So, we have 500 million users. See, when you talk about fairness, um, it's it's across multiple areas and we'll talk

about sovereignty separately. Pricing, we have to be fair. the quality of the things that we sell in our marketplace, it has got to be good quality so that when buyers buy something and and they

see the quality that they see in our applications and our marketplaces, they get exactly what they expect. Uh third uh around fairness and pricing is also quality of service. When when we deliver

something like it's it's okay to deliver milk or groceries, but if you're going to deliver some big equipment like an air conditioner, the quality of service is also not about just delivering. It's

also about helping them understand how to use the product, how to install it, how to do after sales service. And so we have companies in the Flipkart group like Jeeps that also does that. So for

us fairness um is across a broad spectrum of things starting from the beginning of the customer journey all the way through servicing the customer through the life of the product. Right

now if you think about how we achieve that you know it's it's not a uh it's not a formula that we know exactly how to kind of implement. There is a recipe what we

call standard operating procedures. It starts with data. We need to have good quality data right if you don't have good quality data then from there on everything get starts getting diluted

further and further and further. Now on top of that good quality of data the other thing that we do is the access controls on the data and who can access what data is is also very

important. So you know that's where we bring in security aspects of it from an access control perspective. Then when you're talking about interchanging data between organizations, between services

and so on so forth, it's not only data at rest, it's also data you know in motion. So how do you secure that data? So that is all about encryption and everything else that goes on. And then

when we go into the modeling layer, you know, at Flipkart, um you know, I think one of them talked about it, we use a mixture of experts. uh the concept of a world model being

able to serve our needs or for that matter anybody's needs to the specificity of fidelity of information or accuracy is something that I have not seen work

right so at a broad information level the LLM of the world the chat GPTs of the world you know cloud opus and everything works but when you get into very specifics for example I'll give you

example you know we work on image generating models A seller today can bring um uh you know a piece of u you know whatever you know skew or listings that they want to sell.

They can take a picture and based on that picture we can actually create a listings in a catalog and the seller can be in business in our marketplace in a matter of 20 minutes. Right? So how do

you do that? To do that we have to recognize what this picture is and based on that we also have to recognize all the things that we need from the picture to create a catalog listing and based on

that listing we also want to tell the seller what kind of price ranges you can actually sell this equipment for. So when you go through all these things when you talk to an LM it's going to

give you a range it's going to take some international data into account but you have to train the um what we call a domain specific models which is what Tani was talking about we call it SLMs

right for the specific domain for the specific region for the specific demography which is India in this case and then price it accordingly so that sellers are not selling to somebody in

sitting in US or England or whatever else they're selling to somebody in India and by the way we can also give them a price range that if you're selling it in Bombay or Mumbai versus

Delhi versus Kolkata versus some other place in Bihar this is the kind of price ranges we can have that's how we bring fairness into the system &gt;&gt; so that that's a good point but I again

Balai want to ask a quick question because uh when you use agents in services like yours for customer service which is a very important component of the job uh do you are you transparent

about this being a bot versus a human and that conversation has also come up. &gt;&gt; Yeah. So look um we today when we uh in customer service when we deploy our agents they are primarily co-pilots

right u the reason is we we have not mastered the technology yet in terms of actually using voice boards that can directly talk to somebody respond to somebody in a multilingual way also and

and when we say we have not mastered it we know how to do it conceptually But the models hallucinate right that's number one. Number two we do have a very very strong ethical and compliance um

you know system in house which says fair disclosure and transparency is by far the most important things to win customer trust. So if you are going to have a conversation with an agent

is going to talk to you for example our UX experience teams we actually look at it from how will the customer understand who we are talking to and we actually have what is called disclaimer

saying that you might be talking you know to a machine here and if you do not want to have that conversation you can always opt out. So there's an opt out position by default. You have to opt in

to actually have the conversation rather than opt out to have a conversation. If you see a lot of companies including the Apples of the world and the Google's of the world and everybody else, default is

opt in &gt;&gt; and you have to you have to very carefully think about it because if you're not conscious about it, you're just opted in,

&gt;&gt; right? That's not how we do it. We opt out and then we have folks opt in for us. &gt;&gt; That's uh very refreshing to hear. I would go back to Babak next, but before

I go back, I have a very unusual request. They want us to huddle together for another group photo in the middle of this before we get to you again. So, please can I request everyone

Okay, moving on after the picture. Uh Babak to you. I I mean one of the questions that uh a lot of the representatives from the government have been asked over the last one week is uh

what is a framework for building a government stack a viable government stack AI stack. So if you have to do scaled AI deployment in the global south which includes monitoring, human

oversight and vendor accountability uh what would be the framework that you would recommend we should or your advice to the government on how we should look at it?

&gt;&gt; Uh I would start off with processing capacity. uh that's the underpinning for building these systems in-house that uh and and

running inference on them. So you you know if you if you really want to um build something internally and I would actually create a public uh sort of um publicly available uh processing

capacity uh it's something that everybody's complaining about everywhere around the world. Uh most of the processing capacity is concentrated in uh private uh companies or or uh large

companies um and not available to for example students or the public to experiment and build stuff and then rely on uh academia and students and uh uh research and government entities in the

public domain to actually uh build on top of that. And uh so that's one thing I would suggest. Um it would attract talent. It will uh reinvigorate innovation outside of this like very

exclusive uh few big companies that can innovate in in AI. Um and uh uh then I would also create a sandbox sort of a sovereign sandbox in which to um uh invite both entrepreneurs, startups,

academia, the regulator to uh um in a safe environment, safe and controlled environment be able to um try out various different applications, various different interoperability between these

these agentic systems um and come up with the regulatory framework that is well suited for India specifically um I think these are I I don't know if the role of the government is to

actually build an AI stack uh I think I I would think that the role of the government is to actually create the ecosystem within which this stack can uh organically uh create and be uh

safely created. Um, you know, we talked briefly about regulation. Um, you you can't be frontr running regulation. You can't also be completely negligent of regulation. Uh, it's risky either way.

Um, and the best way to do that, I think, is in some form of a safe sort of sandbox environment where the regulator can try different things, can observe, and if something goes wrong within a

sandbox, you have control over it. The implications are limited. Um and then you gradually move that out to the more uh like general usage. That would be my recommendation.

&gt;&gt; Uh no that's uh music to our ears uh Babak because uh to be uh honest uh the Indian government has actually under the ages of the AI uh mission done exactly that. that they've created 60,000 GPUs

they've procured and provided to states and to institutions to create and uh we seeing a lot of innovation come out of this. We saw some of our sovereign LLM models that are now going to go open

source with everything that they have created which is amazing. Uh so we were in uh some of the announcements that were happening last week and Serb spoke about the models that they are creating.

So uh with that I'm going to uh you next Amod um so uh we spoke about infrastructure. Yeah. So you worked on enterprise and data center operations and you're now

moving from small AI pilots to sustained high density production environment. So based on sorry based on your experience across projects what patterns have you seen in organizations that are

successfully scaling their AI infrastructure and what are one or two cases in early design choices whether it's uh how you code or uh your cooling d cooling your density or your

deployment planning that has actually made a decisive impact on reliability and trust. So uh we are we are seeing uh some patterns here in terms of I would I

would call it a change uh not a big change but a change is happening wherein people are now understanding that the traditional approach of building uh data centers wherein you build a data center

with certain power capacity and then plug in IT equipments inside it is no more working. Now one needs to look at the chips which are going to use today and the chips which you have a future

road map of uh that that needs to be a core part of your design and build and even with that you still need that design to be modular, flexible and most importantly sustainable.

And why why we need that is because traditionally when you design and build data centers it takes anywhere between two to three years and it there are cases wherein it exceeds that also but

let's talk about on an average two to three years in that period u I mean and all those who are tracking all these activities from Nvidia within two years they would have launched three or four

generations of their new chips and suddenly what you plan for &gt;&gt; would have become redundant or obsolete. So whatever you plan for today needs to be flexible enough to accommodate all

those future road maps as well. And how do you do that is by designing your data centers in a modular fashion leveraging technologies which allow you to accommodate future chips which are

going to be all the more resource hungry. They are going to generate all the more heat. So we need to have those technologies in place so that your designs can sustain that over a long

period of time. So that is one pattern that is clearly coming out with people who are now moving from let's say pilot to production or uh from prototype to pilot people are understanding that

aspect and that making a key consideration around these areas. Coming to the uh cases or benefits I mean we we have uh seen cases wherein by using uh this sustainability focused technologies

in terms of cooling companies are getting benefits in upwards of 30% in terms of energy consumption costs &gt;&gt; we are seeing uh uh customers who are live more than 3 years with zero IT

failures which is which talks a lot about the reliability aspect. ect of the setup uh that gets designed here. So all of it uh if I if I have to put a summary of all of it, it is all about making

your design decision which keeps it flexible, modular and scalable. And I I would like to just leave a thought here that the way we see cars getting manufactured in factories today wherein

you source many components of the car certain components are manufactured by the manufacturers in their factory and everything gets assembled and rolled out as a car as a product. We see data

centers moving in that fashion wherein the electrical, mechanical, the IT will be manufactured, designed and manufactured as modules and then rolled out to the sides as modular, scalable,

sustainable uh infrastructure for these AI factories of future. Thank you. &gt;&gt; Great. And I really hope we get a great design playbook for building data centers that are accessing renewable

power, better cooling systems and better ROI. So with that again Anupam to your view from uh uh research, how do you think that and industry should jointly rethink model efficiency uh reliability

and assurance as a single design problem rather than treating ethics, performance and infrastructure as different layers? &gt;&gt; Yeah. So okay so I I'll I'll take a little bit step back from this problem

to highlight that for any technology we do have the good side and the bad side and before it being it's rolled out to the industry and masses in general there needs to be enough say safeguards in

place and in academics or university we do have that liberty to take pot shots saying this is wrong like we do feel right now there is a lot of gaps in the cyber security of AI and we are trying

to raise as much attention to that as possible. So we are doing that as part of the research that the models are not properly trained that there are possible loopholes in hallucinations and there

could be alignment issues and without these things properly being regulated when it rolls out to industry there will be uh repercussions there will be setbacks. So we draw caution to this and

to address that problem what needs to be done particularly in global south because I spent a lot of time in research in Europe. So I have seen that and I can make a comparison is a very

very strong industry academia partnership that the industry brings up a problem and tells okay this is what needs to be solved and we want your students to actually learn this before

they come to the industry and we try to say align with that kind of philosophy. So one of the things that I like very much from uh my perspective in Singapore and NU that they started this AI.sg SG

as a single window consortium sort of stuff which has multiple steps like starting from the research that they're giving funding then there is a technology and innovation then there is

a technology transfer and commercialization there is a dissemination and there is a regulation so no matter who is a researcher or university or the company they can

participate at any level of this so the problems can be very different because university is like a melting pot so we are making some model with little bit of training and little amount of data. But

when it goes out then we see the problem is now becoming AI for automotive or AI for perception module, AI for agents. This is not what we can control because every industry have their own regulation

their requirements moves at different pace right. So this is what we try to address by having the single point window and clearly define the parameters and benchmarks. For example, fairness

and ethical thing is what is a recurring theme in the discussion here is often underrepresented. We highlight the performance but not the ethical lapses and the hallucination and the alignment

lapses as much as possible. jailbreaking or getting data out of a model. It's so easy that we are really scared before someone says okay start rolling out this claw bot or motor but we know from

academic point of view it's weak but we cannot control this unless enterprises and the policy makers steps in and say this must be regulated. U that's a good point and I think uh the example that

you took both out of Europe and uh Singapore is critical but at least uh that way I have seen with artificial intelligence there's been a lot of collaboration that's happening between

industry and academia throughout the world so we hope that continues. So to you Tanvi um given your work with platforms like Palanteer and OpenAI, how should AI applications balance broad

interoperability with deep scalable domain integration and also we'd love to hear your experience of what you've done with uh in New York City as well as Vikin and what are some of the learnings

that we can take from there. &gt;&gt; Thank you Sita. Um I think when you when you ask about learnings from Palunteer and OpenAI and I fortunate to be a design partner in both the cases in my

work at the bank. So Palunteer this was way behind when when they were more a government um technology provider for the US uh defense services and they wanted to make an enterprise play. So my

bank back then was a design partner from financial services. So see the transition from being um a defense services company to a platform company um in the space of AI and ML and that

has been very interesting because to uh to Bali's point right there is no one word model that can fix everything and baler obviously is one of the best software out there when it comes to a

IML. So they developed a stack that you could do the customized a IML at scale for a IML and that was a huge learning um being in a bank you know one size doesn't fit all and you can't think of a

domain as a financial domain and a healthcare domain because the way we do finance in Switzerland is very different than the way we do it in the UK and where regulators are different our

retail use cases are very different from the wealth use cases so one size does not fit all especially in the regulated industry so that was a very important learning with open AAI this was know now

all the data the 80% of the enterprise data still remains within somewhere that we keep on storing and archiving in Switzerland you have to have 10 years worth of every single conversation that

has happened with the clients every single information that has been manufactured in terms of data while doing any regulatory work so we have that data we never used it not even with

palenteer it's very a IML with open AI you get this whole unbound data that you could use for a lot of interesting things to manage your regulatory and compliance requirements which is the

biggest cost in technology for a bank but also for engaging with your clients better right so but then it's an API right it's an so from platform is what what I got to experience with talent

here and with an API access we could got it into the early 23 24 sort of time frame so with those two learnings what if you could create a scalable customizable platform platform like

Palunteer but for generative AI which is what we started building at ECA. Um and the idea here is very much you build in the guardrails, you build in the security as part of your four layers

that we have at ECA and use your domain knowledge, your domain corpus of information to train it on. So it's very much yours. There's no translation required. It's very language oriented.

It's very deeply culturally oriented. And that's why the work with the Vatican was very significant to say if the church is going to trust you with their literature, with their information as a

benchmark against some of the hardest questions that get asked to the church, then we have a fair chance to get introduced to the enterprise and to the governments. And from a New York

perspective, there's a lot of work we're doing starting with AI and education, which is what we're also hoping to do more of in India. The challenge remains at least 50 students to every teacher,

lots of languages, lots of cultural aspects and the infrastructure is yet not there to match what the students really need. But now with AI, you could hyperpersonalize the experience based on

every student. So you do not have to learn English to learn maths. You could very much do maths in your local language in Marathi, Bihari or any other state language and that that sort of

barrier could go away. And I think proof is always in the pudding. So we get to see how these domain models get to work in enterprise as well as in the governments.

&gt;&gt; Wonderful. And you have a lot of insights on what's being asked to the church. So we'll have to catch you on that someday. But thank you. Uh so coming back to you Balaji. uh from

Flipkart's perspective, how do you decide what do you build internally using AI and what to adapt, what to rely internally for, where do you use an external model, and how do these choices

affect your long-term decisions with business and customers? &gt;&gt; Yeah, you know, I think um we talked about this. As far as I can tell, unless we decide to build our own foundational

model from ground up, we will always use a mixture of experts where at different layers will use different kind of you know parameterized models. Usually if you look at you know a a workflow that

is getting executed like I'm trying to buy something a shopping journey or I'm trying to you know decide in a discovery funnel or whatever else the top of the funnel usually is a very generic

statement that that's where the trillion parameter LLMs actually help and for us it works because at that point in time all you're talking about is an intent and trying to get understanding of what

the user is trying to say but as you start getting in into the further details and the intent becomes more and more clearer where we want to provide the right recommendations or

hyperpersonalize the information or adapt to what the customer is doing. That's where the smaller what we call SLM uh the you know smaller language models come in and for that you know

what the way we think about this is we have an agentic orchestration framework each agent actually decides what is a task at on hand and based on the task on hand we have SLMs that have been trained

for a specific task domain or a specific task even and the agent knows at that point in time I got to go to this particular you know infrastructure of an LLM or an SLM them and then get the

answers from there. So we have an agent techic orchestration framework that is a very dynamically learning framework that understands what's going on adapts to what is happening in the ecosystem makes

decisions off online um and then it depends uh on what is happening it redirects the traffic to the right SLM. For example, if we if the if the consumer is asking

for, you know, show me the best price for these categories of products in a specific region. Um, that's usually a pricing and promotion, you know, domain. And that domain might be uh uh a domain

of data that we have trained on a specific SLM on a specific catalog of items for that particular area, if you will. Now, if somebody comes and says, I'm just looking for running shoes,

right? That's a very very different um uh that's a very very different query and in that query what you do is you actually look at the whole catalog and then you marry that catalog results with

you as a person of your of your interest and then we kind of filter that out and give it so that's the way it usually works. &gt;&gt; Uh so today uh like Nand Deakani was

telling that uh people who use UPI everybody uses UPI in India but nobody knows what is the technology behind it. So hopefully we'll get to a point where we don't know what's the technology

behind but it makes every user's life so easy and contextual that uh it is actually then had an impact. So with that one last question for all of you. Uh so um Babang I'll start with you and

we'll go from left to right. Uh what's your uh feeling about the last one week? What is your key takeaway from this? what are you taking back outside of the traffic and the crowd and uh any piece

of advice that you would give? &gt;&gt; You know, I was at uh AI everything summit um Africa last week in Egypt and they said it's huge. It's one of the biggest summits uh 23,000 people and I

came here and they told me it's 300,000 people. So just the scale the scope um and uh you know uh India is in a unique position that it's its starting point is a starting point of technology and it so

I think it's a it's a it's much better prepared to understand uh AI its implications how uh it can be used um very strong startup scene I was very impressed by that Um and uh yeah so uh

to me um it's one of the largest and most interesting and I go to a lot of these conferences that that I've been so very very impressive. Yeah, that's good because when we started uh a lot of the

planning started in October or even before that I think we never thought about the size of the event and when we saw the footfall and there was government, there were researchers,

there were students, there was business, it's just amazing that we could really run that scale. So thank you so much uh Amodore. I think it has been a fantastic uh week

here in Delhi participating in the AI impact summit and uh I I'll just go back to the three sutras uh people, planet and progress. I would only say that it is our responsibility to build AI

infrastructure or the entire ecosystem around AI which is planet friend planet friendly and uh focusing on the real use cases which address the last pile uh the last uh uh citizen of the country

and progress is something that is bound to follow. Thank you. &gt;&gt; Okay. I can articulate the journey from Paris where the AI impact summit started

which I was in last year to just being a dialogue between the political leaders to the earlier this year in January where sovereignity and building AI for everyone and not just the big frontier

models that we see coming out of America or the competition from Deep Seek and other major players from China and global south building the technology and the sovereignity becomes the main theme

in divorce uh as a conversation to actually seeing it implemented here across the halls of Parat Bandapa. Um it's fascinating. I feel very proud to be of Indian origin and also like taking

what India has done to Geneva as part of the organizing committee in Switzerland where I come from. I think there would be very hard shoes to fill. Um and coming in from an ecta perspective, my

company I think sky's the limit to the opportunity. Hearing from biology and many many other practitioners including service now and others it just seems like um the opportunity is there. People

are ready to experiment. People are looking towards not piloting but actual return of investments. We see that with infrastructure. We see that with what really works and without customization.

This is the deepest and the most uh important part of every organization of every government with what we do with our data and how we use the cognition where we have control over that

cognition and I like what Mr. Fernavi said he said like we don't want the American and the Chinese babies. I like what Eka is doing. It's bringing in a lot of Indian babies to the world which

is what domain models do. So very much looking forward to hosting many of you also in in Geneva next year and uh a very big learning and a very impactful week that India has organized for the

world. &gt;&gt; Thank you Anupam. &gt;&gt; Okay. So in in one word summaries is fantastic like I have not seen scales like this because in academics you know

we go to technical conferences ranging from very small 100 to 100 people. The largest one I attended was having 9,000 attendees. That's triple AI, also an AI conference. But here it's like a

complete order of magnitude more. And this is very much essential that we have the dialogue between researchers, uh, entrepreneurs, policy makers, ministers all in a single stage. That's

really really wonderful. One thing I was curious about maybe as part of organization team you can throw some lights into is how much AI was actually used to arrange this and to maybe defend

against cyber attack in all the systems to detect if there are people passing through. So that I'm curious about that would be like AI in action in hosting an AI summit. We we did use a significant

amount of AI uh but obviously not everything but one of the most uh uh really amazing things I don't know how many of you saw the prime minister's address uh but one of the real things

was uh we had a AI agent that was actually doing realtime translations which was more for accessibility purpose. So I think those are examples of where we have really used and of

course in the planning uh uh although this is not just uh with the government I think a lot of uh people from business from academia have all come together so it's primarily a win across India I

haven't seen that scale of partnership that has happened uh we have a team that sits in the ministry and for the last six seven months the amount of people that have been just coming in

volunteering supporting it's Just amazing to see how it's come together. &gt;&gt; Look, I I've been to the first AI impact summit. I've not been to other places, but the way I look at it is the

government of India decided to do this. It's a master stroke for multiple reasons. Once it it brings the government, it brings the industries, it brings the academia, it brings the

students and it brings the imagination of the whole country together that this is doable. the art of the possible is absolutely there right and more importantly when I think about this um

India's um technology underpinnings was from a service-based industry right and if you um hearken back to the world of telecommunication where we leaprog landlines to mobile

&gt;&gt; I think this is the opportunity for India and India based companies and any com any company that wants to operate in India to kind of leap Frog this whole SASbased technologies, web-based

technologies, what have you and directly leaprog and India can take that opportunity and become the number one software provider, not of services of systems and products that are at a world

scale. We do not have a brand, we do not have a software brand in India that sells on a worldwide scale. Service is not a software brand. This opportunity provides India to kind of leaprog

because we have the scale, we have the people, we have the intelligence, we have the ability to actually you know think very very differently at a price point that nobody can imagine to be

honest. Um and then now the government is behind this and with the public AI infrastructure it's also reinforcing all the research that needs to happen. So this is an opportunity for India to take

or lose as the case might be but I think India is going to take it and win. No, thank you so much. And on that optimistic note, thank you all of you for being here. And we started uh the

conference with uh talking about the theme which is Sarvajana, Sarvajana Sukai, welfare for all and happiness for all and I hope we carry this message across the global south into Geneva and

bring in Europe and US into this as well. Thank you so much. We have a small moment for &gt;&gt; Yes. I mean before we conclude may I please request Suna to give everyone

their momentos. Thank you so much. &gt;&gt; Thank you. &gt;&gt; Thank you so much.
