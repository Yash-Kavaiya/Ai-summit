# AI and Children's Safety and Wellbeing

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 19 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/P3ciuXOc4z0?feature=share) |

## üé§ Speakers

- Amandeep Singh Gill, UN ODET
- Chris Lehane, OpenAI
- Joanna Shields, RAIIF
- Maria Bielikova, Kempelen Institute for Intelligent Technologies
- Megan Garcia
- Nikita Lakkaraju, Digital Empowerment Foundation
- Raul John Aju, (AIRealm Technologies Pvt Ltd) AI Kid of INDIA
- Thomas Davin, UNICEF
- Tom Hall, International LEGO Education
- Urvashi Aneja, Digital Futures Lab

## ü§ù Knowledge Partners

- United Nations Office for Digital and Emerging Technologies

## üìù Summary

Children are becoming among the earliest and most intensive users of AI, often before safeguards and regulations are fully in place. This session asks a direct question: how can AI be shaped to strengthen children's safety and wellbeing rather than undermine them? Drawing on technology leaders, child-rights experts, and a young AI innovator, the discussion examines advancing innovation, where risks demand firm limits, and how trust in AI can be built for the next generation.

## üîë Key Takeaways

1. Children are becoming among the earliest and most intensive users of AI, often before safeguards and regulations are fully in place.
2. This session asks a direct question: how can AI be shaped to strengthen children's safety and wellbeing rather than undermine them? Drawing on technology leaders, child-rights experts, and a young AI innovator, the discussion examines advancing innovation, where risks demand firm limits, and how trust in AI can be built for the next generation.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/P3ciuXOc4z0/maxresdefault.jpg)](https://youtube.com/live/P3ciuXOc4z0?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

governance. How we manage AI on behalf of children will be the clearest test yet on whether we are governing this governing this technology responsibly and for the public good. AI's rapid

adoption has been driven by extraordinary capabilities. But its continued place in society will depend on trust and trust is built through responsible design.

The posttharm regulatory model that we've seen with social media reacting after damage is not fit for purpose in the AI world. AI is fundamentally different. It is not a platform. It is

increasingly a onetoone adaptive interaction embedded in how children learn, communicate, create, and form their own sense of self. Inadvertently, AI is engineering

simulated intimacy and humanlike interaction at a scale that is hard to imagine. When a model says to a child, I care. I understand. That's not conscience.

That's code. But for a child, it can feel very real. And children are not miniature adults. They cannot reliably distinguish between authentic human connection and

artificial intimacy, especially when systems are so persuasive, emotionally responsive, and always available. That difference has implications not

only for safety, but for mental health, identity formation, and long-term well-being. We have already seen what happens when the line blurs. emotional dependency,

manipulation, deep fake abuse, and in some cases, devastating loss. Children must not be the beta testers for our AI enabled world. We need to age appropriate experiences by default with

guard rails around systems that simulate intimacy without accountability. The question is not whether AI will continue to advance. Of course, it will. The question is whether we shape it in a

way that safeguards the dignity and the development of children and accountability begins with protection. And I'm excited to join this distinguished panel to have this

important conversation um even though it's day five of the summit. [laughter] Thank you very much. [applause]

I'm going to have to move this back up. I'm sorry. Uh thank you so much Baroness Joanna Shields for setting the stakes so clearly.

Too often discussions about children and technology speak about children rather than with them. This s this session is intentional in doing otherwise. Therefore I am very pleased to introduce

Rahul John Aju widely recognized as the AI kid of India. He is our featured young AI innovator who has built and deployed real world AI tools, founded his own AI startup and advised public

institutions on using AI. Um Rahul would like to invite you on stage. &gt;&gt; Thank you so much. &gt;&gt; Thank you. Thank you guys. Thank you so much for the lovely introduction. I know

safety is a bit boring topic but it's a very crucial topic and I think if I stand there no one is going to see me. So I'm using a hand mic. So hopefully everyone can see me. Yes.

&gt;&gt; Can I get more energy? Hi guys. &gt;&gt; Is this all you guys have? Hi. [cheering] &gt;&gt; Perfect. So, let's get started. Starting with uh you know when I was young my

father used to tell me. Okay. I'm still young. I'm still young. Younger. Younger. That's what I bet. He still tells me that Rahul question everything. Be critical about

everything. The slide changer is not working. Okay. Without the slides changer also it will work. Okay. be critical about everything. Ask questions. So I did. Why

does the chair have four legs? Why is the sky blue? And also, why do birds fly? Why can't humans fly? Then I bombarded him with a lot of questions. So he just took the phone and he's like,

"Raul, this is Google. Go search it." And so I did. But you know, while I was using Google, my parents also taught me one thing, how to figure out what is the correct information and the fake

information. And that helped me a lot. But this age of AI, how do you expect me to do it? I don't think even parents can figure out what is the right information and fake information. We all agree upon

that. &gt;&gt; Yes. So how do we do that? Because curiosity is there in every child. I think I have enough curiosity. But it only becomes powerful if it's guided the

right way. So how do we guide the right way? Because right now we are just teaching kids how to talk to machines. Before we teach them how to question it. Now I'm just saying a random co quotes

now. But let's dive deeper and see why. I'll give an example. Everyone remembers the Gibli trend. &gt;&gt; Everyone did it. I did it too. Guilty. But Gib, it was very fun to be honest.

But what happened there was we were all just taking pictures, uploading our pictures to the cloud. But we don't even know what's happening with it. We all agree, right? But right now kids are

also doing the same thing taking their pictures uploading it to the crowd but we tell children don't be on social media don't upload your pictures to social media don't share your pictures

to strangers and all right but what about the AI world we are miss the parallel is missing we need to translate real world safety into the digital world because right now even most okay I have

a question how many you guys read the 25page terms and conditions. I don't right you don't know what's happening behind the scenes right most of these pictures were taken and

obviously made for the model to be better for all of us right right now a lot of companies are making sure children are safe but we don't know about it are they safe there are a lot

of unknown AI companies as well what do we do then that's why also I created an AI software where you can upload a full terms and conditions or any contract and it'll tell you the high risk losses raw

lower risk losses and it will thank you and it will literally tell them what to do if you should use the product or not right so be careful anyway so that tool was known as rescue AI I've been working

on that for the past 3 years for emergency for law people a lot of things I don't want to promote myself too much but I'm trying to do that but what about when things like that are not there what

about if I didn't do something like that is why AI awareness and safety is necessary obviously it is that's why you're called here R But how do you do that education right? How do you teach

about AI? You know, recently I got calculator in my school school and I'm so happy because I don't have to do maths by multiplying, dividing manually. I can do it through calculators in my

exam. By the way, I bunked my exam and came today. Anyway, very happy for that. But I had you have to do all this calculation. But because I have a calculator, it's way easier. But I only

got access to it once I learned the basics of maths. Right? I believe AI should be same. We should learn how to write essays. We should learn how to sing. Maybe then you should I know I

don't know how to sing. Everyone will run away if I start singing. But you should know the basics and the foundations before you start using AI. I feel that's when you teach about AI.

That's when you say okay AI can help you do the essay. AI can help you do the song. You should use the natural intelligence first then start using artificial intelligence. I believe it's

about using the combination of both right yes how many of you guys use natural intelligence everyone does right I mostly reliant on artificial so I got to switch to but

that's what matters but it's not just about that it's also about how we teach deliver topics starting with personalized content you know reading for me is kind of boring I'm so sorry

but everyone learns differently it might be through reading It might be through listening. It might be through watching videos which I prefer the most. That's how I learn most of the things that

happening from geopolitics to cricket which I love. All of these things I've learned because I watch the video. I'm a more visual person. It's not one sizefits-all but sadly I feel

educationist and I believe AI can generate content for wait. It's not believe it's already happening. You guys know about notebook LM right? It can generate videos. It can generate

podcasts with one textbook content. That's how I passed all my exams to be honest. Even not just that, there is this tool study fetch where you can upload a chapter content and it will

convert it into games. It's not just about that. Everyone's interest is different, right? Take a wild guess. What do you think my interests are? Wild guess.

&gt;&gt; AI. &gt;&gt; AI. Exactly. I'm here to talk about AI, guys. Cricket on the side, but AI, right? What if you connected E is equal to MC¬≤ and thought that through AI? You

can do that too in this AI world. How do you do that? See, right now schools teach us what to think. I'm repeating that schools teach us what to think. But I believe schools should teach us how to

think. How to think and how to think critical. How to think critically and how to face failures. How to communicate. These are basic things trust me to stand here I had to face a

lot of failures but I learned how to do that because of my father giving you some credit but so thank you

see now he's recording the audience clapping for him okay so that is what matters and here's one proof of demand okay I started something under my company ARM technologies think academy

yes a bit of promoting at Thinkcraft Academy where I taught what is AI to building your own AI LLM fine-tuning and all that in 30 days and more than 7 lakh people learned from that and that course

was completely free and even there was another course going from what is AI to building your own AI as a startup founder as a student and that course was also completely free but do you know how

many people joined and learned from that Again, seven lakh people did combined. That shows that people want to learn about AI. It just has to be delivered the right way. The name of this course,

I know everyone is searching right now. Ra, it's on my YouTube channel. I'm a content creator too. Raul the Rockstar. Yes, you might be thinking, what does he not do, right? I'm joking. But a lot of

things goes on. See, I am not saying a lot of big things. I believe we all should be open mind. We should be open to learning more things. We should be curious because AI will not take your

job but someone using AI can. But at the same time, the most important thing in the world of AI is also to be as human as possible. My name is Rahul. Thank you so much.

&gt;&gt; [applause] &gt;&gt; Is it okay if I take a small video &gt;&gt; influencer? So, &gt;&gt; thank you so much. Have to do this too, guys. So, it's very simple. Like I said,

I have to do this. Totally forced to. Okay. I'm just going to say AI IMPACT SUMMIT. HOW was the session? And you guys can be if you guys didn't like it, just say no. Okay. Hated it. You guys

can say that. Be fully honest. Okay. Oh, I should say you also, right? Okay. I'm totally joking. I'm very grateful for this opportunity. You know in last November I was wanting to come here. I

was like register for this and the fact that they called me to speak here. I'm very grateful for this opportunity and we have to thank them. Thank you. Shall we DO IT?

&gt;&gt; AI IMPACT SUMMIT DELHI by UN. Okay. Not by Okay. Once more. It's a part right. Okay. Uh okay. This is how many times I have to record a normal video.

Thank you so much UN for calling me and AI impact summit the audience. How was the session? [cheering and applause] &gt;&gt; Was it boring? Was it boring? You guys are agreeing

it's boring. [cheering] No. THANK YOU GUYS. Thank you. I'll not take too much time. Thank you Rahul for that very thoughtful and energizing address. Your perspective

underscores a key message for today. The question is whether or is not whether children will engage with AI but whether adults institutions and systems are prepared to guide that engagement

responsibly. We will now turn to our panel discussion. The discussion will be guided by two co-odderators with deep expertise at the intersection of innovation, policy, and child

well-being. I am pleased to introduce our moderators, Thomas David, director of the office of innovation at UNICEF, as well as Urvashi and Asia, director of the digital futures lab. And I invite

them to guide the discussion. Thank you. &gt;&gt; Can you hear me? &gt;&gt; Yes. All right. So, delighted to be here with you all. I'm one of the two

co-odderators and I'm delighted to invite four leaders in the industry who are going to have the high bar of keeping you all as entertained and on substance as Raul just did over now. So,

please warm welcome to Baroness Joanna Shields please. Maria Bikova, director of the Campellan Institute for Intelligent Technologies.

I took the liberty of not reintroducing Baroness because I think she was already known to you. Chris Lehan, welcome. Chief global affair officers for Open AI.

Tom Hull, welcome. Vice President and General Manager, International Legal Foundation. [applause] Over to you, Oisha. Thank you and thank you to the UNICEF

team and thank you for that very energizing uh opening. Yeah, I I I hope we can live up to that uh level of uh dynamism. Oh yes, can we invest? Baroness wants to know if we can invest

in your company. [laughter] &gt;&gt; Okay, great. So on on that very cheerful note um thank you all for being here and I'm delighted to be able to moderate this discussion at the India AI impact

summit. Um as someone who studies the governance choices that shape how technologies land in society. I'm interested in a very simple test whether AI expands children's agency and

learning or does it quietly narrow it through design incentives and design choices. So let's begin with what we want AI to enable for children at scale and in practice. Tom, so perhaps I can

start with you first. Um, LEGO education has recently pushed into computer science and AI learning in young classrooms. So what does AI literacy that supports well-being look like in

real classrooms? And what should we do if we want AI to deepen creativity rather than replace it? Well, first of all, thank you for having me and uh very tough shoes to fill after

Rahul's spot there. Um I agree with so much of what he just had to say and yeah, I' I'd love him to come and uh guide some more conversations. Being at this conference, I think we can all see

that um the the rate of technological advancement is breathtaking. And I think often we stand whether we're deeply involved in it or on the sidelines. Um there can be a feeling of incredible

excitement. There can also be a feeling of um kind of frankly doom that this uh change is happening so fast. Um and I think that we kind of underestimate what the role of children is going to be in

this journey. um they might look at what's happening in the world of AI and simply see it as a magic box that they can interrogate at the click of a button and ask simple

questions and get really quite deep um answers back. It might be a funny video they want to produce. It might be the ex the answer to a history exam that they have to submit on Monday morning. And

what we think AI literacy is is ultimately handing children a screwdriver and saying here is um a fairly complex uh box but let's take it apart and let's understand what's under

the hood and let's understand all the components. So for us, AI literacy is allowing children and empowering them to really kind of interrogate the fundamental basis of computer science

and artificial intelligence and that's teaching them that you know how the world sees so how computers see the world as data, what is sensing, uh how to think about kind of uh

predictability, uh how to think about bias and force conversations in a classroom. So we want to empower children to to have uh deep thoughts about this. We also want to empower

teachers and I think right now again this this pace is happening so fast. We asked some um primary and and middle school teachers in the United States what they thought about the pace of

artificial intelligence in classrooms and they're all hugely excited about the or a very high number of them are very excited about the pace about what's happening. uh they agree that artificial

intelligence literacy needs to be a foundational skill in school but that's 80% of them see that only 41% of them feel remotely ready to go and teach AI literacy in a classroom so I think we

have to provide teachers with the tools that are going to allow them to bring real world learning to life &gt;&gt; thanks uh thanks Tom and I would love to maybe at a later stage in the panel come

back to you on the how because we do a lot of work with policy makers trying to uh do kind of capacity support with policy makers and we really struggle uh in terms of you know how do you actually

embed AI literacy. So I imagine children we really have to think about the pedagogy quite carefully to make sure that we are imparting that um that learning. So I'd love to kind of come

back to you on on that. Um Chris, if I can bring you in next. Um, OpenAI has emphasized that AI systems will increasingly support learning, creativity, and problem solving for

young people. From your perspective, where do you see the most promising opportunities for AI to positively shape children's experiences, particularly in ways that strengthen agency, curiosity,

or access to knowledge? And you're not allowed to say what uh Raul already said. [laughter] I was just going to say you got a great explanation of that. First of all, thanks for having me. Uh,

awesome panel Baroness. Always good to be with you. Um, my, uh, my son would be very jealous that I'm sitting next to the Lego guy. That's a pretty cool thing. Um, uh, so, um, thank you. And

I'll just also, uh, share I may have to exit a little bit early because I have a bilat I'm supposed to be at that double scheduled. So, if so, my apologies in advance. I'll try to answer your

question at a at a macro level and then maybe a more specific level that I think picks up on your pedagogy question that you were just asking. First of all, this technology has enormous

uh capabilities to basically individualize teaching uh individualize I mean you're at a place where uh you know every kid in the world could in effect have their own AI tutor um that

would be able to help them um to learn at the pace that they learn and in ways that they learn. I think amongst u you know sort of insights in education is kids just learn in very different ways.

Um and this technology could be incredibly liberating in terms of answering that. You mentioned uh the teachers we do work with the largest teachers union in the United States

400,000 teachers to actually train them to develop the AI to in fact do some of that individualized teaching. But I think there's a maybe a level down from that which I think you

were sort of picking up on uh at when you were setting up this question and that's the agency question. Um I know the US public education system better than I know others around the world. So

part of what I'll say is really based on my US experience. But the US K through2 I see the sign yesterday telling me to shut up. K through 12 uh public education system was designed for the

industrial age. It was basically designed to take kids who were coming from rural environments into into urban environments and teach them to be able to work in factories. That was both the

bells, different classrooms that you would go to, the time that the day started, how long the school day lasted. Um, but sort of at its core was not just literacy in terms of teaching people to

read, write, do arithmetic. It was actually creating an ethos about how you should work and participate in an industrial age economy. I do think one of the big issues that we're going to

need to think about with this particular technology which is going to really reward people like Rahul who take agency is how do we actually teach people agency. This technology is an incredibly

leveling technology. It scales the ability of anyone to think, to learn, to create, to build, to produce. And the question is, do you actually encourage people to be able to use it that way?

Because if so, the way we think about the social contract, the relationship between capital and labor and how that is calibrated, um this technology has a huge can have a huge impact on actually

giving individuals the ability to control their own labor as owners of it. Thanks. Thanks Chris and I appreciate particularly the point around agency and you know how can we teach people agency

and I though I also wonder that you know sitting here in India in the global south uh one of the things that we can see very clearly is that agency in some sense is not only a factor of individual

capacity but has so much to do with with the broader socioeconomic institutional context in which you're in and so I wonder how we think about agency across across different contexts. Um back to

you. &gt;&gt; Thank you so much. Let's get into the next segment which is really about what happens when it fails, what happens when there's harm that is being done. Um from

a UNICEF lens, of course, when we think of the education in the world today, seven out of 10 children in classrooms cannot explain to us a text that they read at 10 years of age. Seven out of

10. So clearly the technology potential is immense in really realizing huge bounds in learning outcomes. But what happens if actually we go the other way and we suddenly have an overdependency

on that technology for children when we maybe frame the children's creativity in ways that we actually constrain it or or make it one one fits all. So let's go into that segment of risks and harms and

what is the accountability frameworks and how do we protect against this. For those of you who are following carefully, I would say that the organizers of the panel have done a

beautiful work on gender. I don't know if you noticed, but it's boys on one side, girls on the other. Woman asking question to the men, the men asking question to the women.

&gt;&gt; They're by definition much smarter. That's pretty clear. &gt;&gt; And that's exactly where I was going. And the next question to the women are going to be harder than before as they

should be. &gt;&gt; So, let's curve. Yes. &gt;&gt; But to be fair, it continues to be harder and harder as as the panel continues. Let's start with Boness. Uh

Joanna, you've held UK government roles focused on internet safety and harms and you have helped build major child online safety coalitions internationally. From that experience, what is one key

lesson from the UK internet safety agenda that you believe is worthwhile surfacing today? And maybe one area where you think or you should say, "We've tried this. Please don't do this.

If I could convey one thing, um, after 15 years of looking at how do we regulate technology, um, to prevent harm, this postarm paradigm that we're operating in is not going to work in the

AI future. So, we have had to adapt very quickly as governments as harms have emerged using AI. For instance, the deep fake crisis that we've experienced recently. Um I know six, seven

jurisdictions of, you know, countries that have implemented very quickly, you know, laws that are specific and targeted to that particular harm. But what we need to do is we need to step

back and we need to think about that how do we how do we um build and design safety from the ground up? And my personal view is that this has to come through consultation with the companies.

I see a very different type of reaction from the AI models developers. They're much more receptive to the idea of safety by design and building in guard rails that protect children from the

outset. And I'm actually um an optimist at the moment because I'm starting to see companies like OpenAI just recently announced that they have an agegate um age assurance technology to ensure that

children under age in you know whatever the jurisdiction is I think it's it's 18 okay um are not able to engage with the model and to experience you know that and I think that's really important

because you know we've been battling this age on the internet for 15 years and now the technology whether it's cryptography or biometrics all kinds of technologies have emerged

to where you can preserve privacy and ensure that you can protect privacy. So there's no excuses anymore for companies not to build in robust age assurance that's privacy preserving and that can

ensure that the design experience that you get is appropriate for the age you are. &gt;&gt; Thank you so much. So I love the point that social media we talk a lot about

social media these days right rightfully so but indeed it's been a late awakening worldwide about well the potential of that but also the potential for what happens to children in many ways um and

we cannot make that same mistake with AI it's just so much deeper and broader we need to look at this a lot more systematically Maria if I can come to you your your work spans user modeling

personalization as far as I understand it and trustworthy AI I and you've also spoken publicly about disinformation risks. In your view, where do AI system create the highest risk failure modes

for children specifically and and what kind of technical evaluation should be required before deployment? Thank you for having me. Uh really we are here to um because we care about

children. Do you? &gt;&gt; Yeah. Yeah. &gt;&gt; Great. But not just in physical world but in online world where AI is and nobody doesn't want children to be

harmed. Yes. Yes. Hopefully. But they are actually one example is profiling on social media and even though we saw uh role as almost adult the the brains of uh children are not uh fully developed

actually and and they they cannot um uh fight against this uh properly. This is uh this is true. Even we adults cannot do this. And by me the highest risk is that we exposure our children to

something that we don't understand because current AI is not transparent but this is not a bug. This is a feature. So it it it works in this way. Of course researchers uh work on it but

first we has to know what is going on and that is the reason why we at Campalan Institute of Intelligent Technology started with uh trying to understand behavior because having just

uh data from uh social media providers and analyze them this is definitely not enough. So we have to provide behavioral studies. So what we are doing we are sending bots on social media. They are

simulating users like uh our recent study was that we had a 16 years old and adults in three areas. One was uh beauty, the second was fitness and the third one was gaming. Everything the

same except of age. And they they they they were collecting data, liking, watching videos on Tik Tok for 10 days in Germany actually. And then we found out what happened and

maybe I can tell it in second uh um in second my entry that it was really shocked for us. Thank you so much. So in essence really having very clear impact focused

research continuously so that can inform potential query mechanism and potential redress mechanism as a as a as a way to safeguard against those potential risks. &gt;&gt; Yeah. And and how they are exposed to

commercial content and this is the most critical. &gt;&gt; Thank you. &gt;&gt; Even though we have digital service act in Europe.

&gt;&gt; Thank you. Let's move to the third segment. Thanks. Um yeah and I think that brings us really nicely to this question of what next? What do we do? Um I think we

often agree on what needs to be done at the level of principles um safety, transparency, accountability. I think you've added another dimension to it. uh when you talk about in some sense

evaluations that we need to be doing kind of real world evaluations in real world deployment context of these systems not just testing these systems in a lab setting but uh testing

evaluating them in a real world context and regularly. Um I think the hard part at least when we talk about the principles with things like safety, transparency and accountability is how

we operationalize them across jurisdictions and also across business models which I think also speaks to the point you were making around it being a feature and uh and not not a bug. So

this segment is really about the how. What becomes enforcable, what becomes measurable and what changes um incentives. Um Tom, if I can start with you again. Um, as AI becomes more

embedded in classrooms and in learning platforms, what governance or design choices are essential to ensure that these tools support children's well-being at scale, particularly around

diverse education systems and cultural contexts. &gt;&gt; Thank you. Clearly, this is a really uh exciting and uh high, you know, the potential of this moment in time is

enormous. So I think everyone should be ambitious uh but at the same time be measured. Um go in ambitious with your design plans for bringing AI into classrooms and see it as an as an

opportunity to maybe make exponential gains in in many different markets where you may have been very challenged before. I think there are tremendous opportunities for many markets in the

global south right now. So see the introduction of AI and AI literacy as something of a a reset, but you know, don't jump in blindfolded. This is a a once-in-a-lifetime

opportunity to establish essential foundational skills for young people and it's going to need really careful thought. These governance and design choices, they've got to be built on no

regret moves. So I would say put data privacy, data sovereignty um and inclusion and respect for the student at the top of any plan when you sort of teach about um I don't know systemic

bias and um large language models in classrooms. Make sure that all kids of all types of diversity and and inclusions are represented and can see themselves coming back in the products

that they're um experiencing. Children have a lot to say in this space. So involve them. We've published a free um AI policy toolkit for classrooms. Have children think about what kind of things

they think need to be considered here. It's going to be a really meaningful conversation between teacher and student. And talking of teachers, I I think give them exciting but also

relevant curriculum. We have computer science um uh qualifications in the UK. The entry levels for that are critically low and uh very low for girls. uh we introduced that 10 years ago. We gave

very insufficient training for children and the curriculum is frankly very dry. I think we have to really think about realworld curriculum that is going to excite students and so let them see

themselves with real world problems in the types of uh learning experiences that we're putting out there. I'm speaking on behalf of the LEGO group. So, you know, children are our role

models. I think when you're designing AI policies for children, this has to be sort of child- centered and child-led and so just involve them in in the plans as you roll them out and I hope that

will lead to some really exciting changes. &gt;&gt; Thanks. Thanks. Thanks, Tom. Um Chris, um earlier this year, OpenAI's policy engagement has included calls for common

sense youth safety approaches and more parental control. So what what in your view should be the baseline governance package for child-f facing AI and what should be globally interoperable versus

what is locally set? &gt;&gt; Sure. Thank you for the question. Let me just give two points and then I'll answer that question specifically. First of all think and I think this is a

really smart room so I'm sure we're all thinking about it this way but really important to understand and recognize that this is not social media and we should not make the classic mistake of

fighting the last war with the next war. There are certainly lessons that are important that you take from it, but understanding that this is going to be a technology that is not just on your

device, but is going to be around you in all sorts of different ways, physical world, non-physical world. So, understanding understanding that component um I think secondly

interesting lessons from what we've seen on the catastrophic harm side. You've seen the emergence of these so of AI safety institutes around the world. um where the leading frontier labs for the

most part work with those safety institutes to to basically be creating safety standards UK, US, Europe, Japan, Australia seen an early version of that here in India and I do wonder whether

there's some version of that that you actually do specifically for kids safety. The third point really goes to your question which is yeah we have put forth um and we're really the only AI

company that has done this thus far. We do hope others will join us. Basically a multi sort of prronged approach. The first and the baroness mentioned this is we do do age assurance. Um we try to use

signals to identify whether you're under 18 uh or not. Uh if we identify you as under 18 and if we are unable to identify you, we then default you to an under 18 model. So even if we're not

sure of your age, we do default you to an under 18 model which has all sorts of restrictions around violence and sexual conversations and mental health type of issues. Three, we build it in with a ton

of parental controls. Parents can control whether it has memory or not about your child. Uh parents can get real-time feedback. Uh parents can control how long you're spending on it.

Um you can get uh warnings and alerts around stuff if your child is asking stuff that would be in the mental health types of space. Um uh four um we prohibit any targeted advertising of

kids using the technology. I think that's one that's a clear lesson from the social um media age. Uh fifth, we have um an outside review process that we've called for. uh in the US that

would be done by like a state attorney general but someone who's a uh you know part of government to actually review that what you're saying you are in fact are doing and then finally um you know

prohibit the targeting of specific kids bots. Um you know there may come a time and place when we actually have really good guardrails around this and they can really serve really helpful positive

productive purposes but until we have those guardrails uh we think we need to be really really really mindful of that. So, it is a complete package. We are pushing this in California and a number

of states. We want to take it around the world. We're working with some of the leading children's advocacy organizations. And, you know, anyone here who'd want to work with us on it,

we really welcome that. And we don't pretend to have all the answers. Like, we're super humble about this. We do think this is what we've seen from our data. This makes a lot of sense. It goes

farther than what others have done, but we also know that this is going to be a constant learning process and this is a beginning, not even the middle and certainly not the end.

Sorry, just just to ask a follow-up question on the bit around how you make this locally relevant. So, you have this kind of package, you're rolling it out in the US. How do you then cater it to

different contexts? &gt;&gt; You know, it's a great question. Like there are some parts of the world um you know, Europe is an example of this where uh there are some privacy limitations

that actually impact your ability to do the age assurance at the level that you would like to be able to do it at. So, we're in the process of some of these jurisdictions of trying to work through

some of those types of issues. Um, I think there's other dynamics that potentially come into play, which maybe is what you're asking about, you know, cultural context, um, uh, societal

context. Um, and I think those are things that you do have to work through with individual countries because individual countries are going to have their own norms on those.

&gt;&gt; And I think we'll also see different levels of vulnerability or different types of vulnerabilities in those in those different um, contexts. Um Baroness, if I can bring you in. Um how

how should global norms for children's safety handle cultural and regulatory diversity without creating in some sense loopholes that allow companies then to opt for the weakest protection?

&gt;&gt; So I I wanted to take that question in two different directions. First of all, um in terms of a global regulatory framework, there are certain standards that are um required across every

jurisdiction. I mean, you know, a every country is has an age where, you know, children can participate in the digital world and it it unfortunately it's a blunt instrument in many cases. It

applies across the board at a certain age like we've been seeing a lot of social media bans recently. Um, and you know, I think that has come out of exasperation on the part of governments,

the fact that they just have given up trying to regulate this technology and they've decided they're going to just use that blend instrument as a as a guide. And unfortunately, um, you know,

there are benefits then that the children can't participate in. But the reality is that, um, this this Oh, there's a little bit of movement here. [laughter]

&gt;&gt; [gasps] &gt;&gt; As the, you know, as the age of assurance technology grows and becomes much more capable, we can custom design experiences for young people that

accommodate their level of maturity and capability and ensure that we can meet these requirements in a much more sophisticated and better way. It's about time we solve for age online once and

for all. And I believe we're getting close to that. There's an organization called um the o open age alliance and it's a very important organization that's looking to harmonize standards

across all of um age assurance technology. So whatever age assurance you think on your platform is reliable um open age will enable you to um generate an age key and then that age

key travels with the child everywhere they go online. So we've got a you know a very um absolutely verifiable way to for companies to deliver an age appropriate experience.

And you you asked me about something else that I think is really important in this context about culture. And if we have a world where we are accepting models from just the global north, I I

really believe we will lose so much of our cultural diversity, our uniqueness as um people, whatever, wherever we come from, whatever our background is. We have to be very, you know, mindful of

the fact that we don't want to develop a monoculture that is based on, you know, a handful of models that everybody uses around the world. and we lose that that richness of who we are, what makes us

human. I think that, you know, that wasn't really the aim of the question, but I couldn't let it go without bringing that to to bear because this is an absolutely critical question we need

to solve as society. &gt;&gt; No, thank Thank you. I couldn't I couldn't agree more on both those points on how we have to get the age ver we have to solve for age verification and

then the the risk of kind of flattening flattening culture and what that means for children and what that means for how they develop and grow. Um Maria, last but not least, um you've helped elevate

trustworthy AI as a public agenda in Slovakia and in Europe um through initiatives through initiatives spotlighting responsible practices. Um so if a regulator askked you for key

measures or measurable indicators that an AI system is acting in a child's best interests um what would those be? Actually I already mentioned it somehow that um it's something that that AI at

this moment is um so um complex meaning I I I mean the uh neural networks that that we have that uh we cannot uh actually measure something that we don't know we can observe it and this is this

is quite important uh to do a lot of studies as as as we do not just taking uh analytics from uh companies that provide it. Even though they they they they seem the best uh because even

though um they tell that uh children are not um profiled but they are because we we we see it and sometimes it's uh out of their control uh because because this so we should really make uh such studies

as I mentioned because for example one of the result of uh study I mentioned before is that uh children see less uh formal ad advertisement uh on Tik Tok. This is this is uh fine but actually

they are exposed five times more uh to um u profiling for to to to the topics uh with influencers and so on uh that are not uh formal advant advertisements. So we definitely should do a lot of uh

such studies and and the children should be there because if we uh prohibit everything for them until some age then they will not be able to explore it. It's is the same as we will prohibit ch

children to go to the city. But we should know what is going on and and we should uh travel with them through this uh environment. then this is probably the most important to doing uh such

studies uh to to really understand what is going on on the platform where they are because they will be there. I think that's such a powerful u that's such a powerful analogy the city one and

I think while you're speaking what struck me is that you know we have some tools already this we don't have to kind of approach this aresh so we have actually tools around data protection

and privacy if we actually enforce them some of that profiling that you're talking about need not happen uh we have tools that allow us to get data from the platforms to actually understand what is

happening um on these systems so again we have things in our kind of regulatory toolbox that we can exercise and then of course I think in addition to that really this point around contextually

approp contextual evaluations that involve children um is so that we can understand what these systems are actually doing. Um Thomas maybe I can hand it back to you to or did you want

to add something? &gt;&gt; Thomas is my formal name so I thought you were talking &gt;&gt; Oh right [laughter] if you would [clears throat] like to add

something and then you can hand to the other &gt;&gt; would you want would you want to something &gt;&gt; other Thomas? No, I a lady said

something I thought was very wise to me this morning and and said um you know, you've got to think about what kind of ancestor you want to be. And I guess we're at this really interesting moment

where we've we've we've had social media, we've had sugar, we've had tobacco. Um surely now this is our chance to make some really sharp decisions um and and pay it forward for

the next generation. So credit to uh the lady who said that to me this morning. Yeah, &gt;&gt; thank you so much, Tom. So um it's going to be very hard to close. So maybe I'll

just I'll just try to um to see at least the points that that I took from the panel and and hopefully they will resonate. I I come away with a sense of I would say it's going to sound terribly

UN but measured optimism. Um one because the potential is tremendous. We we are all aware of that the potential at least from a UNICEF lens on

on really changing outcomes for children in ways we have never been able to do before is is huge and the risks are equally tremendously important and potentially um

will be there for decades if we don't craft design it right to my mind there may be three directions where that that I heard that we are going in the right direction one is safety by design has to

be a must that's about age appropriateness It's about data privacy. It's about child rights at the heart. It's about appropriate content for the right age. It's about systematic impact

measurement. I was struck, Tom, in your session this morning when you were talking about, you know, if we have a model that actually gives the right answer or an answer to children all the

time, they might actually lose their sense of curiosity. And I never thought about it like this. What huge loss would that be for humanity if we suddenly have children who are just no more curious

because they just ask whatever question? Can we design a model that actually gives the wrong answer on purpose so that the child actually struggles because we know that grit is going to be

one of the huge skills of tomorrow. Um so those things are going to be massively important. Redress mechanism we don't talk about this and how we enforce those redress mechanism when

things go wrong is also there. The second layer in my mind would be inclusion by default. Coming back to Baroness's point about having a monoculture on the risk of this and we

know that some of that is already playing out and hopefully having a summit in India is one of the turning points where we can see actually this turning around a little bit where we

really have so many more countries beyond the global north creating shaping what those solutions are having representation of regions of language um of of different dialects but also

children with disabilities um which are quite often left uh as we know out of those I'm out of time and maybe one thing that we haven't really talked about is having solutions that work for

the unconnected having solutions that work offline. We are at risk of just focusing on urban centered uh people and that will be terrible if we don't do it right to those who are already kind of

struggling by the w line. And last but not least is children at the heart. And children at the heart because that's who we want to create that world for the ancestors. We want to be for them. But

also because Raul demonstrated that for us. They are the most effective users of that and the ones that have the ability to tell us this works for me. This doesn't work for me. And they should be

not just a voice but they should be part of the governance of those mechanism. That starts with AI literacy in schools. It starts with also helping parents having the ability to help their

children know where to get that literacy. And hopefully if we hit all of these right, we have a chance. Thank you all for joining us. I just want to give the floor back to the MC.

&gt;&gt; Thank you so much to the panelists as well as the moderators and the audience. Um also on behalf of Under Secretary General Amandib Gil, United Nations special envoy for digital and emerging

technologies who regrets missing the session as he is stranded with the secretary general's program. Even the United Nations motorcade cannot make it through Delhi traffic. Um but could we

please welcome Raul back up to the stage for a very brief reflection on the discussion? &gt;&gt; I'll make sure it's brief. First of all guys, can we have a big claps for them?

That was not enough. If you don't realize these are the main people who designed the future for us kids and the fact that I got an opportunity here to speak. Thank you

again UN for that. Thank you AI summit for that. And whatever they said is very true. You know why? Because at this age specifically us kids the policies that are designed when we are building these

AI tools that should be the first thought of keeping kids in mind not an afterthought right and the fact that that's happening is good right because from Lego to open AI to all these big

places to ma'am everyone here they're designing the next world and I just want to say a big big big thank you and I also want to add one last thing. Thank you so much for always talking about me

also in between but more than that for listening to us kids you know for not just having thinking what we need for putting our opinion in mind also while building this. So a big thank you from

all the children out there. Thank you so much [applause] &gt;&gt; excellencies and distinguished guests. Thank you for your participation and engagement. We appreciate the insights

shared today and look forward to continued discussion on the responsible advancement of AI. The session is now concluded. Thank you. &gt;&gt; Thank you audience. May I request the

session officers to please come to the stage. Si, excuse me. May I request the audience to exit from the door behind us?
