# Artificial General Intelligence: A New Paradigm of Safety, Security, Privacy, Ethics, and Governance

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 16:30 ‚Äì 17:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Nalanda Banquet |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/cWifdwhp6ko?feature=share) |

## üé§ Speakers

- Mr. Atul Kumar, Government Initiatives & Global Trade . DSCI
- Mr. Avneesh Pandey, SEBI
- Mr. Hendrikus G.J. (Harry) Verweij, Netherland
- Mr. Kenny Kesar, Wipro
- Mr. Simonas, INFOBALT
- Mr. Vinayak Godse, Data Security Council of India
- Ms. Alexandra Bech Gj√∏rv, SINTEF
- Ms. Aradhana Gupta, Data Security Council of India
- Ms. Nicole Foster, Amazon

## ü§ù Knowledge Partners

- Data Security Council of India (DSCI)

## üìù Summary

Artificial general intelligence will intensify existing challenges around safety, security, privacy, ethics, and governance. This session will examine how current trajectories in advanced AI raise near-term governance questions, particularly for developing economies. It will explore institutional readiness, policy gaps, and risk pathways across data, compute, markets, and deployment contexts, and will surface practical considerations for anticipatory governance that can inform responsible decision-making before irreversible dependencies take hold.

## üîë Key Takeaways

1. Artificial general intelligence will intensify existing challenges around safety, security, privacy, ethics, and governance.
2. This session will examine how current trajectories in advanced AI raise near-term governance questions, particularly for developing economies.
3. It will explore institutional readiness, policy gaps, and risk pathways across data, compute, markets, and deployment contexts, and will surface practical considerations for anticipatory governance that can inform responsible decision-making before irreversible dependencies take hold.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/cWifdwhp6ko/maxresdefault.jpg)](https://youtube.com/live/cWifdwhp6ko?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

impact summit and u the basic idea and intent behind setting up this session is uh while uh all the things were happening in AI in in the period of 2020 to 20 lot of development happening and

somehow uh all that is now uh leading to kind of acceleration that we are seeing in last 3 years of time and uh especially this year uh since January all the new launches that breakthroughs

that we see we're getting the first sign of a powerful AI right and now because of that there's a discussion about AGI seems to be gaining quite a significant uh ground right and um although people

still have lot of doubt and skepticism about whether it is really reality or possibility in coming future or what that means many people are still struggling to define what that means

physically right so as a overall society uh and I I can tell about India. So probably we didn't pay much attention when AI was coming. uh if you don't pay attention now what is coming in next two

three five years of time uh or 10 years of time for that that is a probably the timeline for AGI then probably we'll miss on again uh thinking talking discussing governing better basically

right so this discussion is about one is to help understand uh for us and for the audience here basically what do you mean by AGI can we really think about that right now uh what are different

components that will lead to thank you Kenny welcome to uh the panel and uh try to then find the meaning uh possible meaning for security privacy and ethics

basically right so I'll like to talk with someone with you so how do you see this concept of AGI and foundationally how that will be different that we would see what is your understanding about the

concept of artificial general intelligence this is a mic I think &gt;&gt; yeah so yeah thank you very much for uh having us here and uh yeah like you said it's a

really uh nice topic to wrap up maybe the conference so well so you know uh of course there are kind of different definitions of AGI and uh on the same time most of them agree that uh it's you

know it's about uh smarter AI when we have right now we were joking a bit that you know on the way uh the traffic uh uh is you're really you know exceptional And uh yeah that's a sign that maybe we

we are still not here today. So uh so but yeah but basically uh kind of uh among those uh common agreements uh that uh let's say the smarter AI uh should uh reason uh it should learn uh it should

adapt uh also it should transfer knowledge and also it shouldn't be you know very narrow uh like you know of course right now we have great let's say uh areas where AI is really helping a

lot like uh code development uh customer service and etc. But you know it should be much broader so uh and you know well don't think that any of us maybe the colleagues will be

able to to answer when we will have you know and send what timing but uh definitely you know that said that's that's one of the big big topics. Let me come to name to you and uh you look at

the digital initiative as one of the important research area. So we are grappling with understanding what is right now but can we think about what would happen in next three five years of

time and that seems to be timeline for AG. &gt;&gt; So so I'm the one with the date. I I'll do my best. Okay. Um so first of all my definition of AGI is very simplistic.

&gt;&gt; Yeah. And I think that we need some simple explanation in in this field. And my my very simple explanation is AGI will be something that can perform every human task at the level of accuracy and

professionality of a human professional. Now this is not an optimal definition because people can ask every task. Can can if a baby is crying will the AGI help him stop crying? And people can ask

what is the level of professionality? But I think that this is something that we can digest &gt;&gt; and I think that for me I understood that we are getting closer there not

from a technology perspective but from the perspective of talking with real Israelis about their problems and five years ago when I was telling this definition of AGI people were like oh

it'll never happen not in our lifetime and right now when I'm speaking with Israelis and I'm telling them this is AGI they're saying oh aren't we there yet. Oh, because I thought that Chachi

can help me like a lawyer. Isn't it true? Now, I think that we are not there yet. Okay, there is a a very sharp line between the AI that we are experiencing today and true AGI. But the fact that

the audience is already confusing, the fact that people give trust to Gen AI tools, uh 50% of Israelis trust them more than they trust their friends. Many trust them more than they trust human

professional. this puts us closer to AGI. So I would say that it's a matter of 3 years to 7 years until we reach that uh milestone. &gt;&gt; Yeah. So coming to you Alexandra. So how

do you see uh this as a concept but what is leading to this uh Asia? I mean what would we do uh that will bring this age of Asia in three or seven years of time frame? Well, I'm not sub necessarily

subscribing to the time frame. I think that depends on how much money we throw at it. &gt;&gt; Yeah. &gt;&gt; And then there are other things to throw

money at at as well. And some of this, for example, we had a discussion with my team, you know, &gt;&gt; are machines able to make complex decisions as fast as humans? And in some

areas like uh you know, many operations demand millisecond response and reflex level. You know, you you can see that machines are quite good at detecting fire or doing very sort of instinctive

things as fast as we are. But the ability to interpret context, emotions, ambiguity, surroundings, body language, etc., that's that's still quite far away. They

take too long. And um in a dynamic environment, uh uh you know, a wrong decision or a late decision is really a wrong decision. So, so in order to get there I you know

there's both low latency energy efficient hardware neuromorphic and edge computing and architectures &gt;&gt; beyond auto regression uh but um I think my you know the researchers in Cintf I

head up the largest research institute in Norway they you know they point to promising like hierarchical reflex reasoning systems embodied multimodal learning etc. etc., etc. And there's

there's really no real doubt that you will you will get there, but there's in order to have the situational awareness like a human, you have to study a lot of data that would be considered private

personal. So there's really limits on privacy and then it triggers a lot of other questions that I'm sure we'll get into. &gt;&gt; Yeah, we'll we'll come to that. So Mr.

Kenny you you must be serving many of the client right now on AI right &gt;&gt; and every of us are getting stunned by the progress and acceleration of the capability that is happening week by

week basically right and that also scares us key what is coming next &gt;&gt; right and when it comes to that level where there is a there is a two words uh somebody defines AGI right so one is the

consistency across the domain uh that it will be so general in a way that it will be consistently performing across the domain and second part is uh it will be reliable as well. So currently probably

sometimes it doesn't have anything and it throws output and that's why hallucination happens basically. So consistency and reliability that's what the AJ will bring to the table

basically. So it will solve lot of problems that we see uh uh right now we have been also getting stunned by the things that it can do basically. So, so there are routes to achieve the AGI or

which will lead us to AGI basically. So, how do you think uh uh from your perspective the the journey that probably take us there? &gt;&gt; So, um you know I've u you know I agree

with the panel that a couple of things we we talked about in terms of uh where we getting to models evolving but you bring up another uh component of accuracy. I'll talk about accuracy first

and I'll come back to uh the disruption which is happening in the market. Now the epidem of accuracy is 59s. So for AI to get from 90 to 99% it took 5 to 10 years. Now every nine that you add is

another year or two years to the point where you get to 99.99 and 9. So every nine that you're adding has a time frame to it. and the number of nines that you add, you get closer to general

intelligence because that's what is going to look at the human brain. I I'll take the topic of photographic regression that you've talked about. Any regression AI is right now built on

regression. It's built on learnings uh of the neural network maturing on information that it's seen. But the human brain is also inventing. It's researching. So when AI really gets to

the point of being able to research and bring new ideas to life that a human brain does, you're you're getting closer to intelligence. Now the disruptions in the market that you've seen uh with

announcements across the different players uh which dominate the AI market is creating a disruption in the industry and I think it's the right disruption. It's the disruption that word processor

did to typewriter. what type what word proc computers did to word processor and what cloud did to data center. This is another thing but it's much faster because it's more pervasive and it

impacts everybody in life. So the fact is people are talking about how does it translate to me when I say translates to me it's about how do we structure processes everybody and I agree accuracy

is work in process and since accuracy is work in process we have to be really mature about the use cases that we put onto it uh we have to look at the human pyramid what components of the pyramid

that you're going to look at. So the way we are advising our clients and what we're doing ours is maker jobs which is basically repetitive jobs with little context. AI does very well but create a

controller for these autonomous. So the combination of probabilistic and deterministic is what's going to be the near future as we get to more and more deterministic when we get to uh general

intelligence because from a human perspective it's mostly deterministic right yeah so these are and thank you all for putting some level of clarity in terms of what this means and so at the

end of day Asia is like uh so they say attention right ability to give attention to all possible thing that people millions and billions of people asking questions to

but as you rightly say the context matters. So it's not only attention the it should be contextual to your requirement and your uh things that you do right and third important part which

they are doing and last 6 months had been a great months for reasoning that bring to the table basically. So my question is and anybody of you can answer this then for achieving all of

these things. So why compute becomes very important? So why you need this much of compete? Why there are trillions of dollar that is invested to make sure that it it gives attention to each and

every problem better and it is contextual and give reasoning and at the same time latency as talk about. So the role of compute uh what is the role of compute to achieve this any of you?

&gt;&gt; Yeah. So you know of course if I may start and of course please accompany. So u currently we at super high cycle let's say of uh those investments and you know

most of us most likely also wondering uh you know is it a bubble or when it will you know blow a bit and etc. So because is it really uh in some cases sustainable? Well, everyone of us most

likely has our own opinion. uh but you know but still uh this race uh to be number let's say one uh this uh believe that if you are number one you will remain number one and you know this

momentum uh I think uh plus huge sheep title this hype definitely brings much much more money to the table than we could ever imagine. uh and you know and on the same time it depends a lot of

course on the algorithms you know how efficient they will be. So we saw you know all of us remember most likely last year uh this deepseat moment uh and there are also other models which are

much more efficient. So you know at some point we might understand that we a bit overestimate that you know o overinvested at the same time I remember uh in Sukenberg's uh quotes that you

know said okay and the worst case scenario I will you know have over capacity for couple more years and then any I will use &gt;&gt; anybody yeah

&gt;&gt; so um my humble opinion is that compute is one element in a chain of elements and that sometimes we treat this element as the only on let's uh &gt;&gt; explore a metaphor. Let's imagine that

we are in the 19th century and a prophet arrives and he tells us okay in 5 years a new technology will emerge that will enable you to arrive from Delhi to Bangkok in less than an hour. But I

don't know what the technology is. Maybe it's a ship. Maybe it's it's a car. Maybe it's a train. Maybe it's an airplane. But we must be prepared. So everyone is trying to be prepared and to

build the right infrastructure. The problem is everyone thinks about it as something else. So one will build an airport and the other one will build rails and the other one will build

boats. I think that we are in this moment. We know that AGI will arrive. We know that it is soon and we know that we must be prepared. Compute is one of the elements that is necessary but energy is

also important and heating and cold is also important. data is extremely important, implementation is important, language is important in India as well. Uh I think that one of the elements that

we are not investing enough is the human element. Think about critical thinking for example. I don't know what AGI will arrive but I know that already now for us it is very important to raise

critical thinking among the public when you hear something in the news when you see something was it made by by AI what is the manipulation that is being uh forced upon me so I think that investing

in education is not less critical than investing in computing &gt;&gt; yeah and then another Alexander I want to come to you on this that you talked about

u there is very interesting discussion about this system one and system two thinking human is more intuitive in terms of response and system two is more logical mathematical and AI probably

helping with that basically right but there's a latency that is an important area right and that's why they're putting lot of effort on improving the comput such a way that the latency of

system to thinking is also less so that your intuitive thinking can improve with that basically right but it's not only the compute right the the the perception the amb the senses, the emotions. So all

that also matters a lot and that's where the limitation of language based models are getting exposed basically and you did talk about that in your initial remark. Can you just throw light on that

like &gt;&gt; on the language &gt;&gt; on the different type of the models right ambient compute for that matter world model that people talk about. So

uh &gt;&gt; well I I just wanted to first agree with uh uh &gt;&gt; Mir near sorry &gt;&gt; that that uh you know if if you are a

government and this democratic access to compute is a big topic I think you can really get lost in just invent investing in in comput power so investing in in skills and uh

&gt;&gt; leading edge technology uh understanding in in in your own country and participating in the regulatory approach. Because some of the things that I care about is that everybody says

that there should be human oversight. But you know that once you get into these dilemma situations like what should happen in a car accident, humans are not very good at understanding risks

and humans are not very good at uh really making ethical discussions. They tend to go as far you know do your best and then let moral luck decide who gets lost. But you have to in in uh

machine-driven systems you you actually have to make decisions about those things. So I think becoming you know educating also our politicians to to know that you have to make the hard

choices what because otherwise the machines will make them for you and they will continue our biases and they will uh you know it it will not end well. Uh but then I I

just wanted to share a little story that I heard and you know Michael Lewis, the guy with the money ball and everything. He has this uh anecdote that in the basketball um association in the states

they started video surveillance and the coaches were all uh making racist decisions and home home uh team decisions and by showing the videos and by showing the statistics next season

they couldn't find any bias at all. So I think that's a good example of how the machines make people better uh whereas we're not able to better ourselves over time. So I think I just thought this was

a nice anecdote for this panel. &gt;&gt; Yeah. Thank you. When I come to Kenny, so as we are trying to solve problems of security, privacy in current big capability of AI and we are struggling

to understand what it means for safety, what does it mean for security, what it means for privacy and suddenly there's a significant acceleration is happening this right. So, so what we are doing

right now for security privacy which could help us to graduate to more and more powerful model comes in be it AG or any other things basically. So Kenny can you just help us?

Yeah, I think u security as we uh evolve when and we talked about compute, compute gets bigger, contexts get bigger, we get smarter in terms of what AI can do and definitely the same AI

that can generate can pose more sophisticated and as we uh attacks and when we get to AGI right the biggest thing is I could be emulating a human let's say in a company I could emulate a

CEO and take a decision because I'm getting so close to being natural. Uh the threat is real. Now even today, let's say without AI, you need to be just a step ahead of the uh uh you know

the bad actors or the persons who are uh into cyber crime. You just have to be a step ahead. And similarly, we talked about u you know mentioning about the human quotient, right? that the human

portion needs to get more educated where there are going to be set of humans that are going to use the same AI to build better agents to fight them. So now it's a question of the tooling that you have

at hand. Even today it's the tools. It's a human who's building tools to fight your cyber threats. Imagine in the in the next era the only thing is it'll become nearly close to science fiction

when agents try locking humans out. But that's I would say still science fiction but but the fact is as we evolve uh we need to rightsize the solutions and that's how we will manage comput you

don't use a i7 computer or to do a simple calculator task of adding two numbers right you use a calculator so in the context of the world we're going to have SLMs which is small language models

that do smaller things so that we can manage compute you'll have the bigger models that will solve world hunger in terms of how we do with different levels of machines and processing that we do.

&gt;&gt; I think there will be tearing. Right now we were talking about it's a fight to who's first. So been the fight to first bigger better elaborate but now as it evolves you'll get the right size

fitting to them then only it'll be commercially viable. AI is not commercially viable today. It the costs outweigh the ROI. &gt;&gt; Yeah. current cost is quite

significantly higher. You can do P but &gt;&gt; once you put in production environment the token cost is too much high to yeah &gt;&gt; so so N um want to come to you there is

a established understanding of security privacy safety or ethics right and that's what the paradigm that we at least try to understand right now but would the Asia altogether different

paradigm and the concepts of security privacy will be foundationally very different than what we discuss right now. &gt;&gt; So as I see it uh when we try to deal

with the uh risks that AI pose, we distinguish between four different levels. The first level is the classical risks like privacy, security, cyber, um um fraud, every technology that we have

since the '9s. We need to explain how does it meet the current risk in that matter. And AI is much more powerful and it poses a lot of more risks. But these are the kinds of risks that we uh when

we design products, we know how to deal with them. Above it there is a level of of human health and mental health and we find out that AI solutions can be quite problematic for mental health can cause

a lot of uh uh damage in some cases and this is something that is not yet well understood and investigated. Above that there is a social level. What does it does to the empathy between people? What

does it does? Normally people say oh I see that it's bad for my kids. They are experiencing bullying or addiction. Usually what's bad for your kids is also bad for you. And we understand that this

is these are complications that we didn't think about when we code. And the higher level is a macro level. What does it does? What does it do to society? What does it do to democracy?

&gt;&gt; I think that several countries are now experiencing foreign manipulation and it is very easy to run uh campaigns that are uh built of fake news and we see that manipulation can be become very

problematic. So I think that a a strategy a national strategy and an international strategy should access should address all these levels and all these levels have mitigations but they

are costly and they need collaboration. So we need to be in close collaboration in order to mitig mitigate these risks and &gt;&gt; good that the way you put the structure

right uh things it will do to the us our brain and the thing that will impact us as individual and we discussed that in one of the session that we hosted on neuroscience and AI. So what this means

to the brain development process if you are using AI for every small thing that we want to do what that means to society uh brain development process plateaus for that matter what will be to society

and then what is the macro uh uh kind of impact it you want to add something on that &gt;&gt; yeah I just sorry I I just want to build on that how it's not just targeted

manipulation or or you know the the things that we see in our kids and and you you know, somebody walking around with a button called friend and that's your only friend that you need. Uh, but

also the um well ststructured um in the geopolitical context the ability to create completely different information universes. You don't need to be neurologically

strange. You just see a completely different view. We just published a paper in science on these uh agent swarms. Uh and just reading a book about the the Ukraine and Russia war going on

now and how large populations are overpowered by uh totally different images of the world from what we are. And at least obviously your defense systems need to be hardened against

those kinds of manipulations. But it's also actually a an offensive strategy to find good bots that enter those universes that it's an actual battleground in and of itself. And it's

very strange to think about the world in that way. But I think you're very naive if you if you don't start systematically working on how you make your conviction of what the world is like also part of

the people that you need to somehow hopefully not defeat but relate to and convince that things can be better. So this uh it's not just a technological challenge it's um I would say it's a

huge mental leap for most of us. &gt;&gt; So Simon the question and both of you Dr. But I question is like more we use more we become dependent on AI system right and more acceleration of the uh

people's ability to think critically uh that will go down basically right the speed will increase the more dependency and more AI become powerful for that matter right so what we see in terms of

this misinformation disinformation and defect so probably there'll be different kind of cognitive warfare that may happen. So how do you see such kind of challenges the society talked about

society or individual for that matter. So what kind of implication it will have for individual society and overall the way the world is organized. &gt;&gt; Yeah. So absolutely. So basically um all

those layers and all the dependencies like you uh rightly stated uh they also you know critical thinking of course as one but also u awareness education and you know the skills abilities for people

to to understand the things and you know here I think this audience is you know uh text and uh for us it's more or less everything self obvious but you know but uh when you start talking to people in

the streets or you know or or a bit different backgrounds then you certainly realize that you know what is so obvious for you uh for another person might be completely completely different. So, so

to find those you know ways uh I would say to educate to to you know to basically help them identify the threats that one of the key

uh priorities and also uh obligation I would say uh from our uh side. &gt;&gt; Yeah. So one of the important challenge of this critical thinking which which I

come across is uh critical thinking is nothing but your ability to give attention to various different dimensions, nuances, different perspective, different views basically

right where uh it is tremendous amount of effort that I would have to become a critical thinker and AI solves that for quite easily for me. It can make me to bring all the attention, all the

dimensions, all the nuances, all the viewpoints, you can quickly get access to me. Right? So even for critical thinking, Kenny for you this question is you will be depending too much on AI as

well. Right? So we need to know distinction between what do critical thinking? Critical thinking is not just getting information, giving attention but critical thinking is what? So that

that question probably is a very important questions to ask. &gt;&gt; No actually it's a very very uh important question to ask from two aspects.

&gt;&gt; One critical thinking uh today yes you can give AI a persona be a critical thinker give me uh input and gives an input which is pretty precise but the fact is if everybody starts doing it

what is AI learning on it's learning on the critical thinking that it is doing. So I feel that it's a huge risk to society as we start consuming critical thinking from AI and we're kind of

diminishing our ability of the brain to develop that critical thinking uh that is very necessary for us to innovate further. So the biggest issue that the AI world is facing 30% of the content

it's consuming is AI generated already. So basically you're feeding back and it's learning on the same model. when originally it was learning on artifacts that were built through different

thinking processes. So I would say uh one of the it's a risk. It's a boon because it gets work done but in over time it's a risk that we will stop evolving because if we don't exercise

the brain as a muscle if we don't exercise it uh and don't build those neurons which really uh influence critical thinking um it would be actually a very big loss to society. So

I would say general intelligence everybody's asking for it now. How do we make sure as computers get general intelligence we're not losing our intelligence to create that general

intelligence again. So it's a it's a it's a vicious cycle it's a question uh which we're debating we're trying to answer ourselves everybody has perspectives but it's a it's something

that I think about do I have an answer to it? No. But I feel that critical thinking on both sides is something that we really really need to critically think

about. &gt;&gt; Yeah. So that's what may every thing that you think as a solution and kind of thing. So there is always this challenge of what it means right in this

new paradigm is an important. So now little bit concluding part of this discussion is can we this is question to each of you briefly we can uh discuss about it. Can we still think about I

know we know we have been doing security privacy in a particular safety privacy particular way right but as this paradigm is a new can we think about some anchor control right now that we

should be mindful of right that when it comes uh it happened right when AI was getting built after 3 years we are talking about AI governance and all these things so is there a way for us to

think about some kind of a anchor control or some idea some concepts basically that could help us to browse through challenges the AGI could throw. I can start with you briefly and each of

you can comment on this s. &gt;&gt; Yeah. So uh well of course you know what are some technical things like you know uh the same uh water marks or something you know labeling and uh other technical

features um that could help us a bit um to identify at least some uh threats. uh then uh also we can talk about regulator measures but you know maybe

that's a broader topic for the uh further discussion but uh especially here we in Europe we tend to regulate and overregulate everything so so yeah but in a way I think also at least some

measures here also can be really viable and really reasonable &gt;&gt; yeah well I come from a very small country Israel is so small that you can put it.

It's like a pin on the map and therefore our uh regulative approach is that we we are unable to determine the global regulation and in this AI race I think that what is more important is the

global regulation. So since we are a very tiny country, we must work with positive tools. Say okay, we cannot affect the regulation, but how can we work together with the AI developers in

order to make the personality of the AI um more moral, more ethic? How can we put egalitarian and and equality into the uh consideration? How can we avoid bias? And I think that it makes us work

together with the industry and together with the academia in order to find out about new consequences. I think that in many cases the giants the big tech doesn't um point towards unethical

conclusions but they work towards financial incentives that make AI behave in a very immoral way. If I'll take for example the conflict in Myanmar in Burma,

&gt;&gt; we saw that Meta was not actively promoting violence in Myanmar. But the algorithm of Meta was designed to attract attention in a way that make the more violent post much more viral and

make violence flourish. So if we will be able to promote a dialogue and if we will be able to be together with the industry in development of new AI sometimes we will be able to make AI

more ethical. &gt;&gt; Yeah. So Alexandra your views. So one is the anchor control idea concept but second part is how do you get into early because we are

&gt;&gt; how do you get it to &gt;&gt; early in the game right? So when AI happened now we are discussing in 25 26 about the responsibility and alignment and adoption and governance basically

right so in Asia discussion is the anchor control ways ideas and way for us to get into early discussion of it actually &gt;&gt; well I think at least you need to you

need to work on resilience and robust roll back mechanisms a little bit like what what we're experiencing now in Europe where we all have to practice on living without electricity.

&gt;&gt; You know that it's a realistic option that somebody &gt;&gt; sabotages your electricity and then looking at well how dependent are we really and what are the alternative you

know and and planning from a point of view where you not only work to reduce risk but you really work to reduce consequences of those risks occurring. So if you work on the traditional risk

matrix, it's always, you know, avoiding bad outcomes but then making the bad outcomes less bad. That's something that at least we think uh is uh well the new realities are propelling that kind of

thinking and I think that's important. &gt;&gt; Yeah. Can your words on this? &gt;&gt; Sure. Actually the way we look at it u in terms of AI from e ethical AI to biases to data privacy uh it's very

similar akin to what a human would do even today uh what today we have a standard operating procedure that we review for biases we review for uh content you know in our organizations we

have organizations that manage this now and the The other thing is we train people uh on ethical practices on uh uh non-bias and things like that. So ultimately it's AI is very similar to

that where we will have you know in today's world for the lack of a better word I call it AOP instead of SOP agent operating procedure or AI operating procedure where we have to train AI in

terms not to be uh not to be biased. So I feel that there is a big industry which is in the offing which is going to manage and create models LLMs to manage or to to validate that the responses

from uh you know your common models are ethically right nonbiased because today as organizations we invite experts from outside to come and see our practices whether we we're following ethical we

are transparent a number of those things very similarly as we mature towards more general intelligence and the more ways of working I feel that these control structures will come in cyber security

will come in uh um you know ethical use of AI unbiased use of AI so ultimately it'll be a checks and balances system and we will see innovation in these areas at least that's how we feel it

it's an evolving area let's see how it happens &gt;&gt; yeah and thank you all of you to really help us understand the meaning of this concept of PG and how that will pan out

from now and what kind of uh challenges it will throw to us. There are definitely opportunities that we don't have time to discuss about what it will bring to us. But then what could we

start doing right now and uh this was definitely one of the important conversation help you understand what we are talking about the AGI today. Please uh help join me to give big to my co-

panelist for helping us understanding. Thank you. Thank you Simon. Thank you N. Thank you. We have some uh photo shoot uh uh Alexandra and we we need to come here for photo shoot and yeah

&gt;&gt; uh I also request our fireside panels Hrikas and Alenat to please join us for the photo shoot. We continue here. We'll take some time for transition.

&gt;&gt; Just another minute. Okay. Okay. &gt;&gt; Before we commence the session uh for the fires, I would like to announce the launch. I would like to announce the launch of AI cyber security terminal.

This is published today.
