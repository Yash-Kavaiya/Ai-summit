# Trustworthy AI for All: Democratizing AI Resources Across the Stack

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 16 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/oEHclkecnlE?feature=share) |

## üé§ Speakers

- Carsten Maple, The Alan Turing Institute
- Dame Professor Wendy Hall, University of Southampton
- Dr Peter Mattson, ML Commons
- Dr Saurabh Garg, GoI
- Harish Iyer, Gates Foundation
- Natasha Crampton, Microsoft

## ü§ù Knowledge Partners

- The Alan Turing Institute

## üìù Summary

Many countries are developing strategies for sovereign AI capabilities. Not all nations, especially LMICs, can have total control of the supply chain for their own AI stack. Such nations need the ability to have agency and control of their own AI. This panel will discuss the requirements for sovereign AI, the role private and public organisations play in delivering this, and the mechanisms that can be deployed to ensure a trustworthy and responsible AI stack.

## üîë Key Takeaways

1. Many countries are developing strategies for sovereign AI capabilities.
2. Not all nations, especially LMICs, can have total control of the supply chain for their own AI stack.
3. Such nations need the ability to have agency and control of their own AI.
4. This panel will discuss the requirements for sovereign AI, the role private and public organisations play in delivering this, and the mechanisms that can be deployed to ensure a trustworthy and responsible AI stack.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/oEHclkecnlE/maxresdefault.jpg)](https://youtube.com/live/oEHclkecnlE?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Thank you. Thank you so much, Dr. Gog. Um, really highlights one of the things about collaboration and I'll be talking to a number of the panelists about about that

and I've been so impressed this week at how much people are are really coming together for the community. you know this is a much bigger summit than we've had previously many more people really

opening it up to everyone but if I can just ask you one thing on on because the working group that you're doing I think is is is excellent it's going to be really important um what do you see as

the biggest challenge around that what do you think you know your vast experience that you've got of coming together do you think um there's any particular challenges in in coordinating

that international effort &gt;&gt; u of course uh see uh there would a number of uh challenges but I think as I mentioned that uh uh one doesn't need to really control every layer of the

resources uh that is there and while foundational resources the foundational computer resources sharing would be a a major challenge but I think a bigger challenge might be to manage the

interdependence of the AI ecosystem uh because it spans hardware software and uh and the and the protocol so to say or the ethics around that. So I think one of the biggest challenges

would be the governance around uh this uh sharing mechanism sharing uh protocols and managing the framework and the other would be uh what would be the uh talent and the con and the and the

institutional capability uh which is in a way uh required while see infrastructure can be acquired but expertise would has to be developed and I think uh that It's critical to ensure

that if you want to democratize and ensure that global soft is integral to that and and that's where and I think we don't need to focus so much on whether each country is owning

each layer of the AI but uh how uh what is the capability and confidence in the systems that manage that we have uh uh the required methods to ensure that it takes care of the priorities and values

that each country wants to push forward. &gt;&gt; Thank Thank you so much and I agree with you. It's it's a a big challenge but but um I'm glad that you're there to to take that forward. Um this week you you may

have seen the the photograph of um uh Modi here with um many of the leaders in tech and it's it's a great pleasure that one one of the large uh organizations in the private sector Microsoft has got

representation here. So I I come to you Natasha. So Natasha Crarampton is Microsoft's first chief responsible AI officer and leads the office of responsible AI and it was interesting

how long that's been going. I heard earlier this week. Um, but she's putting Microsoft's AI principles into practice by defining, enabling, and governing the company's approach to responsible AI.

The office also collaborates with internal and external stakeholders to shape new laws, norms, and standards to help ensure that the promise of AI technologies is realized for the benefit

of all. As I said, that's what been a key theme. So, I saw Brad speak yesterday, a fantastic speech and um that that was based upon a recent blog post that you and uh Brad put out just a

couple of days ago. So, can you tell us a little bit about that for for some people who haven't had the chance to absorbed in this session, please? &gt;&gt; Sure. Thank you. And it's

&gt;&gt; uh and thank you Gustin and it's a pleasure to be here uh the panel and the audience today. So I think our announcement earlier in the week was about how Microsoft is contributing to

uh bringing AI to the global south and the headline that you might have seen is that we're on pace to spend 50 billion US dollars in order to do that by the end of the decade. What we've seen from

the diffusion data that we have access to and that we've publicly published already is that um there is an urgent need uh to focus on the diffusion and what it's going to take to do that

broadly and beneficially of AI to the global south because we're already seeing that diffusion in the global north is roughly double what we see in the global south and so for Microsoft as

a private sector player here. We think we have um a role to play in help in helping to close that gap and we see it as being um centered on five different components. First, as Dr. G mentioned

initially, we need to help build out the infrastructure that is needed for board AI diffusion. So this is both investments in in data centers to power AI um applications but it's also

investments in connectivity as well. Um there are real electricity needs that need to be uh met. We're trying to do that with an eye towards the sovereignty of countries around the world. We

realize that the world is a fragmented place and so we uh design our data centers and also the services that run on top of them with a recognition that there needs to be real agency for um uh

the countries hosting those data centers. And so we have a range of different uh controls that we put in uh to our data centers which include sovereignty controls and public clouds.

Sometimes we build private clouds, but most importantly, it's all built on a a foundation of collaborating with our our government partners um around the world. Um the scale of the infrastructure

investment that's needed is just so great. It's really um hard to see um how we'll achieve what we need to without significant private sector investment as well as uh funding from a range of

different uh sources as well. governments, venture capitalists and others. So the first limb is all about infrastructure. The second limb is all about skilling. What we've learned from

the history of of diffusion of other general purpose technologies like electricity for example um is that the countries that succeed in these really transformative economic uh moments are

not actually the countries that necessarily invent the new general purpose technology. They're the countries that diffuse and adopt that technology fastest. And if you look back

at history, skilling turns out to be one of the major unlocks to that adoption um and board diffusion. So um we've made a range of skilling announcements. One that I'm particularly uh energized by

myself is um a very specific one focused on uh educating educators um to help them with an uh an AIdriven uh education uh educational future and of course when you teach teachers you're teaching

students and therefore the um uh the workforce of the future as well. So we um committed to uh teach uh AI specific skills to two million Indian teachers in partnership of course with Indian

national standards and training uh institutions um which is is an exciting thing um to me to support the future. Third um the third limb is all about uh investments in multilingual and

multicultural AI. um you know AI is is no good to you if it does not work in the language that you speak and the culture in which you use uh the system. So we've been pleased

to collaborate uh with uh Peter Matson from ML Commons on um an expansion uh to uh represent Hindi, Tamil, Malay, Japanese, Korean um of some safety uh benchmarks uh that ML Cummings has

played a key role in standing up, but we're working upstream of um testing and evaluation as well. So we've we were pleased to um announce a Lingua Africa initiative where we are working with

local communities in partnership with the Gates Foundation and others to really make sure that we're collecting lots of that really rich local uh data with and and and for communities. All of

that data is not well represented on the internet and and spoken languages in particular um require that careful collection. Um fourth um is all about supporting local innovation. Um I think

it's critically important that as the private sector we uh really deeply understand that um AI will only be meaningful in people's lives if it's actually solving the local problems that

matter to them. So uh we announced some initiatives um here in India and further a field that are designed to really support that local innovation. Last um we announced also as part of the new

Delhi Frontier AI commitments um that several leading Indian AI companies and frontier AI um companies from around the world signed on to uh yesterday that we're going to be contributing our data

as to what we can see about adoption and usage of AI in the economy um into um some central uh projects including new one led by the World Bank so that policy makers are in a a good position to

understand how is AI being adopted in in the economy. Um where are the places where it's going faster than expected? Where are the places where it's going slower? Because I think that kind of

data is incredibly useful for policy making because it allows you to spot those places where you might need a skilling intervention or an infrastructure intervention.

That was fantastic. And if you ever want to know about really believing in something, having such a complex blog and then just reeling off the five pillars and and that really just shows

that commitment I I think that we're seeing uh from from Microsoft taking that leading role and actually collaboration has been since Brad's presidency really has has been one of

the things that he really encouraged about saying look we've got to work together. &gt;&gt; Absolutely. I mean, not one of those five limbs is possible without deep

partnership and and that coordination of those of those partnerships and deeply investing in them over time is really what's going to give us the outsized um impact here.

&gt;&gt; And if if we think about this because because Microsoft is a global corporation, yeah, you've got lots of um countries each with as just as Dr. Gag said, you know, they've got their own

customizations. think they've got their own local laws and regulations and some things, you know, there's something called the the Brussels effect around GDPR, for example, which went pretty

global, but it's it's not the case for AI, for example. How do you think you you manage that challenge of trying to make sure that it it's broad enough but but focuses for for the individual needs

of of nations? Have you come across that challenge? &gt;&gt; Yes. Um that's that is um part of what I work on day in day out at Microsoft because uh part of my role is working

very closely with our product teams to make sure that we are building um our our products, our models um in a way that's trusted and trustworthy by design. And so um we are building uh

products and technologies that we aim to share with the world. Um and it is absolutely true that uh not every part of the world has the same um rules or expectations and and part of what we

need to do is to make sure that we're building technology in a way that has enough sort of controls and choices that people can make downstream of what we choose to do at Microsoft to apply that

technology in their own context. So um we ourselves do have a point of view about um how we want our technology to show up in the world. So you know we do think carefully about um if we're making

available a service that's got some configurable controls. We do think carefully about what we think the default should be. But we also really do recognize the need for that agency and

that the and we do deeply understand that not every part of the world is homogeneous. I think it's you know here in India it's just a beautiful place to recognize the sort of linguistic and

cultural diversity of the world quite honestly if we don't build technology that can be easily adapted and applied in in people's local context with their values with their laws we're just

missing the opportunity to you know have our technology reach the world so there are complex challenges sometimes there are direct conflicts between what jurisdiction wants and what another uh

jurisdiction is sort of declared as a matter of law. They can be worked through and this is partly why um you also need a great partner ecosystem right um uh being able to make available

models open source or on an open weight basis which you know Microsoft has long done for example with our five family of models. this is another way of like empowering the ecosystem to adapt and

build um based on that. &gt;&gt; Thank you so much. And and you just touched on uh you mentioned ML Commons and you touched about um culturally sensitive and it's interesting there is

a report that's been um uh released by ML Commons this this week on robust and defensible benchmarks. Uh and part of that was some great work from uh the Singaporean agency IMDA. um which you

know the response from an AI is has to be culturally sensitive and that's the point that you made I think I think culture is is important because um what is seen as acceptable in one culture may

not be in another um so that brings me nicely to to Dr. Peter Matson. So who's the president of ML Commons and also a senior staff engineer at Google. So he founded ML Commons uh himself and uh was

previously pro uh the head of the programming systems and applications group at Nvidia. Um so on on that ML commons I think I think it's done some great work as as we've heard it's played

a major role uh in benchmarking performance and efficiency of AI. How how do you see that open benchmarks can contribute to building sovereign capabilities? Peter,

&gt;&gt; I I think that's a fantastic question. Um I'm going to start with a very broad context and then narrow it down uh to to that uh that specific u and the broad context I want to start in is why is

trust and reliability so vital for AI? Uh AI has tremendous potential uh to change everything we do. But in order for it to do that, people need to feel comfortable

adopting it. And we're all smart. We don't adopt things we don't trust. You don't give them your banking information. You don't give them your business information. You don't give

them your uh your medical information or trust what they they say or do about it. Um if they're not reliable. And so the question becomes, how do we make AI reliable? Because if I had to

point to anything that's holding back AI today, it's not capability, it's reliability, right? Is it correct? Is it secure? Is it safe all the time? And if we can make uh AI truly reliable, the

potential for benefits to everyone around the world and frankly the potential for businesses and markets is fantastic. Um but the way that we drive that is with metrics is with

evaluations. AI is incredibly complex blackbox system. So to make it better you need to have common yard sticks that you use to measure progress and we need those common yard sticks badly for uh

all aspects of reliability. Uh so you alluded to the work uh on uh security with INDA. Natasha alluded to some of the work around multilingual safety. um that we're uh collaborating with

Microsoft uh on and uh and with folks at Google as well. Um these are examples of what's necessary to to drive that push towards reliability, but they're very

technically hard. This is something that I don't think people appreciate enough. They see someone publish a paper. We made a benchmark for something, right? And they made a data set and they did it

once, but there's a tremendous amount of technology to go to industrial quality benchmarking which is what we need for industrial level reliability. Um there's uh work to take the experiments we're

doing in multilingual benchmarking and turn those into a dependable framework that empowers people around the world to produce very high quality multilingual safety and security benchmarks and then

to maintain and evolve them over time. Right? If Eml Commons can help lift the resources there so that people can make the choices about language and culture where they have expertise without having

to grapple with the really hard technical questions of how you do AI benchmarking. Uh we hope that could be very empowering. Um, an example from the health care space, uh, we have a MedPerf

project that uses what we call federated evaluation where it sends models out to different facilities, um, and then tests them on a small bit of data and accumulates the results. This is how you

do uh, healthc care benchmarking for reliability, for correctness against very very diverse uh, data sets potentially around the world. It's technology like that like dependable um

industrial scale multilingual safety and security or medical benchmarking made possible uh with data sets across disperate legal uh systems through technology like federated eval and

confidential compute that we believe really unlocks that future of high reliability systems. &gt;&gt; That's excellent. Thank you. And and the repeated use of that term reliable. So

what we need is um reliable LLM but we need the reliable benchmarks as you said. &gt;&gt; Yes. Yes. &gt;&gt; And I think this point about healthcare

is really interesting because what we need to do is you mentioned industrial scale as well. We need this process that that can be trusted and and that's one thing that I found working with MLCOM is

how we all come together the people from industry many academics around the world. um you just look at any of the papers released uh so so you can go to the website and how many authors and how

many how many years of expertise is donated to to to that effort. Um where do you see Peter the the the the next sort of big movements for for ML commerce because as these yard sticks

will change you you've done healthcare where where do you think is the important area for for you in in benchmarking in the near future? I think uh thanks to the contributions from all

of those experts um and I truly think it is a testament to the industry that we are getting uh very in demand experts from some of the leading companies to contribute to this

work like people really care about doing AI right that is uh that is unarguable if you look at as you say the author list um what we need to do is leverage that expertise to scale it's not enough

to do a benchmark and publish a paper. We need to make that benchmark available to the entire industry um to drive that push towards reliability. We also need to scale in terms of technology. Right

now a lot of our benchmarks are prompt response. You ask a question, you look at the answer, you see whether it's safe or secure or correct. Um but the future as everyone knows is multi-turn and

agentic. And so we need to uh drive uh you know wider and deeper at the same time. There is tremendous demand for what we do. It is tremendously resource intensive and we are trying very hard uh

to meet that demand uh as quickly as we can. Thank you so much. Um you mentioned the work of of Google. So I'm going to come to Dr. Aya from uh the Gates Foundation

in a moment just talking about some of the conversations. So, we were hoping to have um Vince surf who who some of you may know. I know Wendy, you know him very well.

&gt;&gt; Um travel. &gt;&gt; No. Yeah, that's the thing. He couldn't travel. He's got some issue that he couldn't but he he was very strong and supporting and he introduced me to the

the chief researcher at Google and Google Deep Mind um who's made quite a few comments. Sorry. &gt;&gt; Yeah. [laughter] we quite a few comments about, you know,

the opportunity um here and and um for for global development and Africa in particular not being left behind and and earlier this week I was with Joshua Benj if there's

exponential opportunity with AI if you are behind that by a number of months then the distance between you and others is also growing exponentially right so it's really important this this democra

ization of AI and as as I mentioned earlier I've had the pleasure um of of working in partnership with the the Gates Foundation and uh Dr. Harisha Aya is is joined uh is joining us today.

He's the director um a director at the Gates Foundation looking at health product research and development, digital innovation and AI and he plays a leading role in supporting innovation,

science and technology to improve public health and economic development. He's a strategic partner between Indian researchers. you're based o over here in India, global partners and Gates

Foundation teams in areas including vaccinereventable diseases, disease surveillance and modeling. Um so thank you for joining us to today. Um we we've heard a little bit of course you know

India has really pushed forward um with its digital public infrastructure um and we we've heard in the last session Dr. go was in from Sanjay Jane uh your colleague about MOSET which is

modeled on ADAR in some some ways and is an open-source initiative. So what what I'd like to ask you is um where countries lack foundational infrastructure what role do do

organization philanthropic organizations like the Gates Foundation play in enabling access to trustworthy AI capabilities? Thank you so much for inviting me. I

think this is obviously a very complex question not fully settled I will say for sure. Um so I I mean my most of my experience in this field is in India. So I think u first off I'd like to start by

saying it's great that India is hosting this summit. It's fantastic and uh and showcasing a lot of the work that the country has done the capability um and the use cases that are you know

that we are very you know closely supporting. Um I think the trustworthy question is very much uh and and I would say sustainability as well is another

question that we have to think about is about u you know what sort of models do we need to have um are they large centralized models or are they disperse decentralized models um on the edge uh

do we need uh in in countries with poor connectivity so trustworthiness has got many aspects to it right is it going to be ready to work when you want it to work, right? Suppose um again my work a

lot of it is in health and agriculture and things like that. So if you had a frontline worker, how do you make sure that they can if they have to make inferences and primary care and primary

care is something we're very focused on. Can they make inferences if needed on the edge? If you're a health system person um and you want to improve the working of a health system

uh making sure the right experts are in the right facility, the right medicines are there, patients are taken care of, there's a great opportunity to make this very high quality. Uh but u again the

question becomes you know how do you access the compute? Uh how quickly can inferences come? how easy it is to prompt and there's all this which is very because if it doesn't work well

then you lose trust that's the it just doesn't work the next level question is um language I think Dr. talked about it the whole Bashani project in India and there are similar projects that we've

been involved in and there's been a lot of debate even within the foundation as to which models can perform on language well right which pom pro which um systems can interpret super complex uh I

think uh we heard from the other speakers about how complex this is what works well so trustworthiness will partly come from how systems respond respond and the lived experience in

terms of simple things like is it accessible? Is it the right language? Um is it relevant? I mean India is a continent on its own between different states. The health systems and

approaches are often different based on local policies. How does it work in terms of policy in a particular state? Um one thing I'm particularly familiar with is um pregnancy risk ratification.

We talk a lot about how to reduce maternal mortality, infant mortality, still birth. The rules in Uttar Pradesh for example may be different from the rules in Telangana. How do you make sure

that if you have a tool that supports frontline workers in understanding and improving identification of risk of pregnant mothers? How do you make sure that it works in that context? So this

context is important. I think trust has all of these things built into it. the the I'll also talk a little bit about sustainability question. Sustainability also requires these kinds of questions

to be answered. Well, you know, how uh what's the energy consumption? Um are there simpler, lower parameter, lower energy consuming models rather than the giant models? That's a very to me it's

like a core question. Uh and I think um it's it's nice to know that there are researchers in the country who are thinking about that. Beyond that can compute it hardware itself look

different you know beyond digital let's say I saw this researchers recently looking at you know multiparameter uh multi-state uh compute capabilities and that was really fascinating I just saw

it two weeks ago because I was prepping for a bunch of meetings uh can those be great opportunities maybe there are further in the future to improve the likelihood of edge computing and edge

inferences so there's a lot of and and then I think Finally, open source. I think open source is going to be in my mind a critical aspect of it. We'll have to see how far open-source movement

takes track here believe because many governments in the global south may not be able to afford the large amounts of money that might be needed in for a long period of time,

right? How do you do these use cases? as well. So that I think is going to be another aspect of it that allows for adoption, trust uh at the highest levels. Again, I'm talking about the

bottom 50% of the pyramid. Top 10% of the pyramid, they'll do what they have to do, but ultimately to build trust, you need to get to the bottom 50% of the pyramid. And so there are different in

quotes markets here, if you will. People who can pay at different levels. Even within a country like India obviously there's multiple different levels how can you make sure that this thing can

this can reach everybody and don't create a divide not just between global north and global south but even within countries you want to make sure that this doesn't create a divide and that's

I think another important part of building societal trust the last point uh which I think is also important is what is the impact on society of this technology I think uh this is going to

be anant important one as well. Are you able to create jobs, employment, and you know, there's a meta question about, you know, how does it, you know, ultimately play out. Thank you.

&gt;&gt; Thank you so much. And we'll come back to some of those uh points in a minute if I if mayor Harish um because um as you may have seen, we've just been joined by Dame Professor Wendy Hall,

someone I've &gt;&gt; dame, but don't mind [laughter] &gt;&gt; cast. You should know that you're a Brit. &gt;&gt; I'm I'm not a dame. [laughter]

&gt;&gt; But if you were a sir. &gt;&gt; Yeah. So is Professor Sir. Yeah. &gt;&gt; But if I keep being nice to you, maybe maybe you'll put a word in for me. So I I I've known uh Wendy for for a long

time. She's Regis Professor of Computer Science and Associate Vice President International Engagement at the University of Southampton where she's also director of web science. There are

so many accolades. She's been a a dame commander since 2009 and is a fellow of the Royal Society and the Royal Academy of Engineering and the ACM and was president of lots of those

organizations including the British Computer Society, BCS, sorry. Um, and most notably, she was the co-chair of the UK government's AI review and a member of the AI Council. We've talked

also about skills actually Wendy. We were both on the I think you were probably leading it but I was just a member of it the uh review with Nigel Shabbol into computer science if you

remember. &gt;&gt; Professor No. No. Okay. Okay. Um anyway, you've been involved in uh advising many governments around the world. Um, &gt;&gt; could could you tell us a little bit

about the UK's approach to developing sovereign AI capabilities? &gt;&gt; No. Um, no, I'm not going to answer that question because this is a trustworthy panel.

&gt;&gt; Yeah. &gt;&gt; Right. &gt;&gt; And I want to talk about trustworthiness. &gt;&gt; Okay.

&gt;&gt; And um, that's why I was asking what the panel was about because casten because I've been I'm doing three panels this morning and I've got a lunch date to go to. So, an important one. So um I was

asking Peter what the panel was about because it's about trustworthy AI right [clears throat] &gt;&gt; so I want to I want to say if you don't mind casten I could tell you what the UK

is doing that it's very parochial okay &gt;&gt; I'm I'm very excited that this conference is in has been in India but I have a lovehate relationship with it it's been a ter a really difficult

conference to navigate um 250,000 people here but you end up talking to rooms of you know tens of people um okay it's out on YouTube um does AI need this sort of jamboree I

don't know for the future but it is fabulous to have the spotlight on India I'm a member of my long think I'm a member of the MOSIP advisory board I've been course you are yeah

&gt;&gt; yeah [laughter] I've been involved I'm in awe of what India's done with the ad h built the digital public infrastructure and I want to see how that worked I

would love to see how that works in the UK, but doesn't translate. It works in developing countries. It's much harder to translate it to an old world that has longestablished rules and regs and ways

of working and um anyway, so that's I'm I'm really excited it's here and it was fabulous also to see the young people here because uh in the UK and I think it's

probably true in most of Europe and US, people are really worried about AI. They're scared because that's what they get. They get scaremongering. They're scared it's going to um attack them.

They're scared it's going to wipe the world out. They're scared they're going to lose their job. Here the kids are going, "Wow, what an opportunity, right?" And for for India, I mean,

that's been an eyeopener for me. I mean, I know I've been working in India long enough to know I mean I helped introduce the web into India, right? or web and internet and the web science

stuff of work I've done here and I know what you can do with the power of that technology for people you know that are can't read and write and are live in the rural areas I mean it's just amazing

what it does add AI on top of that then when they're not worried about the deep fakes yet what they want is to get the information to their you know people in the fields the farmers in the fields you

know in in rural India um I suppose deep fakes I mean I don't know but that's not what they're worried about at the moment so it has been fabulous um and I love the slogan

um India here a in India AI is all inclusive but it isn't AI is missing out 50% of the population right this a a this technology and I've been fighting ing this sort of thing all

my career. It's totally male-dominated. Totally male-dominated. And I love I'm very sorry, but the way we talk about women's safety, but women aren't involved in these discussions,

right? Children aren't involved in these discussions, but 50, you know, 50% of us are women and we're not involved in the discussions about keeping us safe.

Actually, we need to keep men safe, too, right? Men suffer from deep fakes as much as women do. Um, so you know we we well maybe someone's not agreeing with that but may

you know it could I mean it could be disproportionately hitting women and children but I don't want to exclude the men here. Um so I have become I'm I have become even more passionate.

I talked about it in my keynote on on Wednesday, not in the talk itself, but in the conversation that it's so important that this is really all inclusive and that women are involved at

the top level in the decision making about what we do. Take for example the um Australian experiment to stop you know the kids under 16 using social media. Now that is an experiment.

Everything about this world is a global experiment and people are doing different bits of it. The web was like that, right? The web itself from you know the genius that is Tim Berners Lee

was a worldwide experiment. There are many different ways that you could have built a hypermedia network on top of the internet. And boy, I tried to do one myself and it was better than the web.

But what Tim did was give it away, make fantastic, you know, make it um open and then and actually that that led to its com the rise of the use of it, but it's also left us with the stuff we've got

today because anyone can do anything on the web. So bad people can do bad things and bad things happen un unintentionally the unintended consequences what I tal called my talk on Wednesday. So this ban

on social media for we need to we've got to be able to study the effects. Now I know the Australians are we heard Macron say here in France it's going to be under 15. K star saying under 16 but he

changed his mind on a on a p penny. So um that it'll probably change but that's a joke for the Brits. But um uh uh I think so several Spain has said under 16. US of course Trump says no no no we

we don't need won't need to worry about safety. But I made this joke in the other panel he's the man that drank bleach during COVID. So um [gasps] but the point is we have to study and it

people say oh it's all moving so fast. The alpha males say that right? The alpha males say it's all moving so fast and I'm I'm bigger, better, faster, and cheaper than you are. Right? It's all

that sort of alpha male stuff. Um, we have to think about how we actually measure the effects of what we're doing. So, two good things that have come out of the UK. This is my last point. All

right. &gt;&gt; This just this last month, um, the National Physical Laboratory, I'm their AI adviser, but that's beside the point. It's like the equ the UK equivalent of

NIST. We they do our metrology. It's a word I've learned to say very well. Metrology like you know they do weather forecasting is metrology studying the weather. We can if we can do that we can

do flipping AI. So [gasps] cuz that's complicated. The thing about AI is of course it's got people in it, not just physical objects doing things, systems, but so it's harder in that sense. But

they the national physical laboratory announced two weeks ago fund backed by the UK government the center for AI measurement and the UK AI security institute which

was founded by um Richie Sunnac at Bletchley Park from Bchie Park um is part of the network of security institutes and the US this is the man again who drank bleach during COVID says

no regular population. So we can't talk about the network being a network of safety institutes. Why would we want to be safe? But sorry joke, but the um but what they've renamed it the network for

AI measurement and evaluation. Now this is brilliant. So with my ACM hat on and everything else I can do in the my the dying embers of my career. No, it's not dying yet.

But the is to start a science of AI that's about AI metrology. But what we're doing of course is we are measuring the effects of social machines which is difficult. You have to like so

you know the social scientists have taught me how you have to gather the evidence and we can do it. We we don't have this there is time to do this. The world is not going to end at the end of

this year because of AI. other things yes but not because of AI. So that's where I want to leave you the thought. I think if we can if we can develop this new science put all our you know the

compute power the the best brains from social science and computer science and psychology and uh all the other disciplines we need the law everything we can really start to think about how

we measure trust and one of the metrics in AI metrology will be the trust factor. I leave it there. Thank you very much. Um,

&gt;&gt; a round of applause, please. Thank you. &gt;&gt; And I'm ever so sorry. You can ask me what I've got to go in two minutes. &gt;&gt; I'll ask you one thing very briefly, then. Open data. You've you've been a

proponent of, right, &gt;&gt; Tim and Nigel? Yeah. [clears throat] &gt;&gt; Yeah. Yeah. Yeah. So, I I just wonder openness, collaboration is important. We've talked about open source. What

What role do you think open data as in trustworthiness of of &gt;&gt; Well, there's there's two things about that. The open data movement has been really important but not all data can be

open right it can't be &gt;&gt; y &gt;&gt; and um I mean you can have data that is exchangeable sharable that won't necessarily be open. So another thing

I'm on is the UN it's the CSTD that's uh commission for science technology in the UN um data governance working group and I could tell you in much more detail about that for me data governance is we

ignore that when we talk about AI governance we ignore data governance at our peril and we've really got to build on that from the UN report we did the uh general assembly accepted all the points

we recommended they're being implemented. That's the other panel I should have been on today. There's a UN panel um and they accepted everything that we recommended. The global

scientific panel, the global dialogue, the um global fund and the secretary general yesterday asked for three billion. That's not very much you know for global fund to develop AI in the

global south. But um our recommendations on data governance were not accepted because people would not the countries would not vote for them because it's so difficult. It's so complicated.

And so um that's another thing I'm working hard on is how can we actually get some you know how do we do crossborder data sharing? How do we get the data flows so we can actually share

data sets? And another thing we need to do which is something I want to do is build a data tell people where the data is. We need we need data repositories or at least registries around the world so

researchers know where the data is so they can do this study. I leave you with that. That's something else that's on my agenda. [laughter] &gt;&gt; Thank you so much Wendy. Um I'm gonna

Yes. Thank you. Thank Thanks so much. I'm going to go go to each of the panelists for just 30 seconds. I'll start with Dr. Gar, then Harish, then uh Natasha, and then Peter just to make us

dizzy. just just one comment for for the audience about how we really push this democratizing AI and trustworthiness. U I think uh one issue which I mentioned in the earlier panel is that we perhaps

need to give a lot more attention to the models uh because uh that will also help uh more efficient models will help reduce the requirement for compute uh and energy which is among the biggest

costs presently and having models which are more domain specific would also enable uh better usage of those models and widen diffusion across people. Thank you so much Harish.

&gt;&gt; Just very quickly, I think um real world evidence is going to be very important in terms of is it actually useful. I think we all assume it's useful but in I'm talking about social and the

development sector. I can imagine so many ways it is useful but be good to make sure we build evidence on how it can be trusted and of course be useful metricizes a bit bit more. Thank you.

&gt;&gt; Thank you Natasha. &gt;&gt; Well I think uh one of the points that's come out clearly in this discussion is that you know trustworthy AI diffusion is not

going to just happen by itself. We have to make choices that lead to that outcome. And so for that reason I am excited about these ex attempts at measurement in multiple dimensions.

measurement of the systems but also measurement in the changes of our economy so that we can then start to see whether the interventions that we're putting in place are actually having the

desired effect because we get to write this future um but we have to actively guide it and I think data in multiple dimensions is really key to that. &gt;&gt; Thank you. And the final word on

measurement should should go to Peter. So Peter, &gt;&gt; I I'm going to uh echo the obvious point which is that measurement is tremendously important and then the

hidden point which is the scope of measurement is vast and so we need to get really good at it both in terms of quality and the efficiency the cost efficiency with which we can implement

it and with which we can evolve it. &gt;&gt; Thank you. Could you please give a round of applause to an excellent panel? Thank you so much for from me. Thank you. Take out.

Hello. Hello. Hello. Hello. Hello. Hello.
