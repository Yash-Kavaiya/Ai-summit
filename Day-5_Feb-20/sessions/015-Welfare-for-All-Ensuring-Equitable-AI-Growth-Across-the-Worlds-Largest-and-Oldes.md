# Welfare for All: Ensuring Equitable AI Growth Across the World's Largest and Oldest Democracies

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 9 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/bgXxCE5q3Rk?feature=share) |

## üé§ Speakers

- Mr. Amit Chadha, LTTS
- Mr. Brad Staples, APCO Worldwide
- Mr. Julian Waits, Rapid7
- Mr. Michael Sellitto, Anthropic
- Mr. Sachin Kakkar, Google
- Mr. Saurabh Kumar Sahu, Accenture in India
- Ms. Amanda Craig Deckard, Microsoft
- Ms. Lee Tiedrich, University of Maryland

## ü§ù Knowledge Partners

- APCO

## üìù Summary

This high-level panel will convene World's largest AI practitioners from Google, Apple, Microsoft, Dell, and others will explore how the world's biggest tech companies can work with governments to achieve democratic access to AI on a global scale. With India and the U.S. as democratic anchors, the session will highlight practical pathways to ensure AI-driven growth delivers broad-based welfare and equal opportunity for all.

## üîë Key Takeaways

1. This high-level panel will convene World's largest AI practitioners from Google, Apple, Microsoft, Dell, and others will explore how the world's biggest tech companies can work with governments to achieve democratic access to AI on a global scale.
2. With India and the U.S.
3. as democratic anchors, the session will highlight practical pathways to ensure AI-driven growth delivers broad-based welfare and equal opportunity for all.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/bgXxCE5q3Rk/maxresdefault.jpg)](https://youtube.com/live/bgXxCE5q3Rk?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

by corporations, by innovators to secure to secure that outcome. And if current trends continue, the majority of um AI's economic value risks being centered in the hands of uh countries and

corporations in in the western economies in China. And some estimates suggest that 70% of the value could be created and reside in those locations. And I think it's for us in this context to

think a bit about why we don't need to accept that outcome. It's by far means not an inevitability and to dem democratize the impact of AI. It it requires intentional design. It takes

international collaboration and it takes societies coming together to ensure that doesn't happen. It al also takes innovation and research, workforce development, private sector partnerships

and also trust, safety and security and they're the things we're going to talk about on the panel today and the my colleagues are extremely well placed to share their thoughts and insights on

those topics. So let me introduce the panel. We have Amit Chand managing director and CEO of L&amp;T technology services. Good to see you Amit. &gt;&gt; Happy to be here. Great to have you with

us. Uh Amanda Craig Deckard, senior director, office of responsible AI Microsoft. Great to have you with us. Sachin Kakar from uh India site development uh pri privacy safety and

security at Google. Good to have you with us. Sachin, thank you for being with us. Lee Tedri, inaugural AI multiddisciplinary initiative fellow, University of Maryland, senior adviser

on the international AI safety report. Lee, good to have you with us. And last but by no means least, Julian Weights, chief experience officer with Rapid 7. Good to have you with us. Good to have

you with us. &gt;&gt; Okay, so um without further ado, let's take a look at international and scientific research uh collaboration. And Lee, let me come to you. Let me pose

a question. Um the second international AI safety report was released just ahead of this conference, something that you're very much an author of. Let's start by hearing from you and then maybe

Sachin I'll bring you in. Um what opportunities do you see Lee in open international standards to address the technical challenges uh that we face while also building trust in AI based

systems and services? Which of these how would you characterize those challenges and which are most critical in a developing country context? &gt;&gt; Yeah, thanks for the question Brad and

there's a lot here. So the international AI safety report um that I worked on with a panel of about a hundred experts was just released and one of the key takeaways from the report is that while

we have made a lot of progress over the past year in evaluations and developing evidence there's still a long way to go there there's a gap and I think you know international standards organizations

and similar efforts um is a good way to work together to try to fill some of the gap. ISO has already released one standard um 42,01 which is a good start but we need to

accelerate this and we need to um also recognize the fact that standards and evaluation metrics um you know there's a tension on the one hand we want them to be able to apply across borders because

we want to enable companies to have responsible technology flow across borders but on the other hand it's really important because we all differ in terms of language and culture that we

need to be able to um customize them um for different cultures, norms, languages and I think you know the the standards organizations will continue to play an important role. Um I spent a year

working at NIST uh the US National Institute of Standards and Technology. One of the NIST projects is working on what we call the zero draft of trying to create um a draft that we could then

feed into the ISO process and NIST is trying to collect stakeholder input um into you know into that draft. And I think you know more globally um you know efforts like the Hiroshima AI process

there are sort of all these pre-standards efforts where different stakeholders across different regions can can work together and I think that and the the AC's the um AI uh safety

institutes um and and across different countries and how they can coordinate. So I think there's a lot of work to be done but I think there's a lot of avenues where we can collaborate

together and make sure that we're addressing the needs of everybody around the globe. Thank you. &gt;&gt; Yeah, thanks Lee. Very well covered. If

I can add just few more points. I think one of the challenges we see is copy pasting the regulations or standards from you know international markets to local markets may not always work. So

localizing them understanding the needs and constraints of the local area. Uh Google launched India uh Indiq gen bench. It's a test bench for fine-tuning and assessing the LLM models for local

languages supporting 29 uh Indian languages, 12 scripts and four language families. So that shows an example of how we need to localize things. The second point is one-time audit or

certification may not work as AI evolves. uh we need a continuous scanning and auditing uh to make sure we avoid any temporal drift in these standards and the applications.

So Sajin let's build on that. How do governments and developers collaborate in a way that we get um the outcome that everyone desires which is not to see the developed markets race ahead of

developing countries. What what does that collaboration need to look like? &gt;&gt; Yeah, that's an interesting question. Bad. uh I think at highest level the way we

think to bridge the gap between AI divide is to move away from traditional transfer approach to more co-creation where developers and government coming together and and the underlying goal is

that standards and regulations are seen as enablers and equalizers not as barriers or compliance hurdle. So three specific dimensions in which uh we believe developers and government can

collaborate and Google specifically focuses on. Number one is open-source frameworks and interoperability and standards. Second capacity building and third is workforce upskilling and

research. I'll quickly unpack each one of them. So starting with open-source uh frameworks. Uh AI is not new to Google. We have been working on AI for past decades. I mean remember AlphaFold and

we were the first one to share the transformer paper on which all the LLMs are built. uh when we were building AI we were also focusing on best AI practices uh and safety practices on AI

and we have open sourced all the best practices to keep AI safe uh safe sif uh secure AI framework is something we have shared outside and it is important to understand supply chain risk and India's

digital transformation is characterized by DPI the digital public infrastructure on which Aadhaar and UPI are built So they can actually leverage some of these secure AI framework uh to make

sure the malware attacks and the vulnerability in open-source components are taken care. Now standards is one thing the collaboration goes beyond to adoption of them and Google has coil the

co-ai uh coalition of secure AI framework with various industry partners and this is what we are expanding in APAC including India. Now we are also committed to capacity

building with the government uh and which means we need to provide tools and infrastructure not just standards. So we are proactively sharing the threat intelligence. Uh we are building tools

like synth ID and sharing with the community abroad. Synth ID is a watermark technique which goes into the text, image, video, audio and it can tell you whether it is AI generated

content. So some of these tools are also helping us to make sure our commitment towards standards goes into actual adoption. And finally upskilling workforce, digital literacy,

working with government to make sure the vulnerable section of the society like elderly and teenagers uh are aware of some of these challenges and giving grants to institutes like IIITs uh to

push the frontier of research uh like PQC postquantum cryptography are another areas of collaboration between AI developers and and the government and academia.

&gt;&gt; Let me just ask you both a question. Is there a trade-off between setting global standards and regulation and ensuring the right environment for innovation and collaboration?

Oh yeah that's that's right and that's where you you can start with the global regulations but then adapt them to the local constraints like we have bandwidth constraints in India we have linguistic

diversity and therefore the global standard should not become hurdle for the young startups in India rather they become co-creators in enabling the innovation that can happen and then

evolve from there so it's a creative tension and and I think the best way is to be adaptive in this situation and and eventually evolve to the international standard.

&gt;&gt; How do you see this this this interplay, Lee? &gt;&gt; Um yeah, I I think I mean kind of in my work, you know, both in government uh academia and I spent 30 years working

with the private sector. I think sort of figuring out the standards and the evaluation techniques is really key. You know, how are we going to evaluate these systems? Um so we can they they can meet

a certain threshold of safety and then I think the question kind of comes in you know afterwards once we know what it is you know should there be regulation or not you know I I worry a lot of times

that when we go too quickly toward the regulation you know the best of intentions may be there but um you know the the the technology is moving so quickly regulators don't necessarily

know how to style the regulations to achieve the goal and I think sort of working from the bottom up with the science science. Um, developing the evaluation technique, taking into

account that we do need to social, you know, customize for local um, markets is really important and then we can get to the question of well, should there be a regulation or not? And that's where, you

know, different countries may have different answers, but at least we're working from a common technical framework and evaluation framework to to assess systems.

&gt;&gt; Thank you. Thank you both. Let's make a shift to the conversation towards more public private collaboration which I think we know is at the heart of of driving the success that everybody's

looking for and Sachin was talking a little bit about capacity building maybe we focus on those two elements and Amanda I I'll come to you and then and then to Amit um so there's a persistent

skills gap in in AI it's very apparent and a lot's being done to try and bridge that here in this country how are your organiz has your organization and and I'll come to you Amit with the same

question how are your organiz organizations grappling with that challenge and also collaborating with government to help to narrow that that skills gap.

&gt;&gt; Thank you. Yes, skills gap is really important. We see it as part of the sort of foundational infrastructure for what we need to work on together uh as Microsoft with other industry partners,

government partners, other local partners, right? It's going to take a whole community really working together to do this at scale. And just to take a step back for a moment briefly before I

talk more specifically about skills, you know, we kind of see this as part of an a holistic effort where you kind of need to support all of the enabling infrastructure for AI deployment um uh

kind of from the infrastructure layer all the way through sort of realizing value in local use cases. So we actually published on Wednesday a blog from our president Brad Smith our chief

responsible AI officer Natasha Crarampton where we talk about sort of five areas where we're really focused on investing to kind of close the gaps between AI diffusion and the global

north and global south. So talk about like hard infrastructure investment right in terms of connectivity AI compute capacity scaling is the second part of that plan. Uh the third part is

really thinking about multilingual multicultural AI capability. Uh and the fourth is really working with local partners on um local AI deployment and uh really what we can learn and what's

going to serve local communities also what we can learn through that process around how we need to adapt the technology so it's ready for those local use cases um and then really measuring

diffusion so that we actually understand how things are going and we can and have really informed interventions. So that's the kind of holistic approach that we're thinking about for public private

partnership. Um and looking at skilling more specifically you know we uh actually have the a new sort of initiative that we launched last July at Microsoft called Microsoft Elevate which

is really bringing together um a number of um ways that we engage with um the community that is going to also be part of scaling everyone at scale. So sort of nonprofit communities, schools and

ensuring that they're equipped with the technology itself. So with cloud uh compute access and with access to AI and then we uh are coupling that with investments in scaling. Um so we have

made some big number commitments around you know how we are really um trying to do this at scale. What I would say specifically for India um is you know we last last year early last year we made

this commitment to um scale up uh 10 million Indians by 2030. This year we um upskilled 5.6 million Indians. And so we actually doubled that commitment to 20 million people by the by end of 2030.

And one of the ways that we're doing that um is we're actually um we just announced this week a new uh elevate for educators in India program where we're partnering with local schools with

vocational institutes with higher education institutions to sort of teach the teachers right so you can actually work at scale and we're working with a number of Indian government ministries

and this program um to figure out you know what how we can um ensure that we have program tailored program programs for all those different communities. Um, and that we're thinking holistically

about how you know we across those different sort of educational paths are really meeting people where they are and equipping them to kind of do the next powerful thing with AI.

&gt;&gt; Thank thanks Amanda. Um, I mean as a business L&amp;T tech services I mean part of L&amp;T originating here in India but now very much involved in that that that in in global markets. how how are you

tackling this and in in in terms of addressing the skills gap? &gt;&gt; Sure. So, thank you. Um, so before I I go to skill gap, I do want to make a point on the regulation part. Uh, I do

believe that too much of regulation can stifle innovation as well. So, we got to be careful on how much we do and where do we take it. And then the second part of course is to do regulation of traffic

control in Delhi for a next event that we have. Right? I think all of us will agree. Okay, let's get down to skills in a second. Now, I had to say that because it was a mess in the last two days. I've

got pictures of myself in an auto rickia as well. Okay, so so if we get down to to skill gap, I want to address this three ways, right? So, we so I am responsible. I I run a company which is

potentially India's first engineering intelligence company with about 25,000 employees, right? I've been CEO 5 years. When I took over, we used to be about 15,000 employees. We about 14 now. We

about 25,000 employees. So if I look at skill gap and I look at skill levels u three things you have to think about whatever work we're doing in engineering consulting today I want to say

40 to 50% of that is new and built in the last 5 years did not exist I also want to say that whatever we are doing today 60% will be gone in about 3 to 5 years

time that's the rate and pace of change. So while my colleague from Microsoft spoke about skilling school, STEM as well as colleges, uh we're doing two different things to

stay current with the changing dynamics or three things. One, we actually reaching out to colleges in the last year of their curriculum and we are making sure that the curriculum in India

is contextual to what the industry needs. So we are sending our employees to teach. We are we using CSR hours. We are doing all of that to build that up. We

actually participating with NASCOM as well to be able to do that in the skill development. The second thing we're doing is upskilling our own employees.

Now um again in a developed economy it's very simple that you know you hear these layoffs that happen all the time and they are not because people don't have work but because the skill is redundant

so let's go ahead and get a new set of skills in an Indian context and my colleague here spoke about that very nicely you can't cut and paste you fire a thousand people you will actually end

up spending half your working hours plus more with the labor commissioner here locally you can't do that so you have to be able to skill people up while they are in the workforce

right now. One thing is developing curriculum, developing modules for them to go through, but the second part is actually making them do it. So, and normally in a consulting

company, you would send people to get get coached and do upskilling when they're not billable. We actually doing it while they are billable because when they become non-billable,

u that's not when you want it. You want it before that, right? So that's uh and it's a major shift in how we've been operating. The third thing that we are tracking as

an engineering and a technology company is how much of personal time is the employee spending on technology development efforts beyond billing hours to the client.

So you come in and spend 40 hours, right? And that's what you normally work. Now if you spend another 3 hours to write a technology paper, you file a patent, um you actually go speak at a

symposium, all that is towards technology effort beyond billable hours. The percentage of workforce within the company 5 years ago that did that was at 19%.

Today that number stands at 52% of our workforce spends time personal time to go spend time on technology beyond billable hours. And the net result of that has been we used to file a 100

patents per year. Um we've gone from there sorry we used to file 50 patents per year we've gone to filing 200 patents per year. So the point is that so again summarizing one um reach out to

the local ecosystem and do it and and spend the last year with them. That's the hook in. Second, upskill the workforce within. And third, beyond, you know, beyond just money, find a bigger

purpose like technology or betterment of human race with technology to motivate your workforce to actually spend time on that. And I think that's what we've been doing and we think will be helpful. One

last thing and we keep discussing India but if I look at the US today and I've lived there for 27 years now is we will need schools to start mandating a certain level of STEM education that has

to be done um today and my both my boys went to went to public schools in in Virginia. I can tell you that in some schools that's broken and we don't do that in the US. We don't do it in parts

of Europe. We will continue to look at different countries for skills and that is not where we want to be in 20 years time. &gt;&gt; Okay.

&gt;&gt; I'm sorry. &gt;&gt; No, jump in. Jump in. &gt;&gt; Sorry, I was going to agree with what you just said, but uh because Rapid 7 like your company, of

course, we're software company. We've basically mandated the use of agentic technologies by our employees, especially the ones in developing countries for countries that aren't as

developed as the United States. What I would tell you also on the education system, which is unique to the US, which is what makes India such a wonderful place, is because we're so far behind,

we're forced to use labor in other societies that appreciate the use of uh STEM technology and where it's embedded in the way that they learn. We have no choice. If we didn't have foreign

workers in the US, we would fall behind the rest of the world. &gt;&gt; You don't hear that too often. &gt;&gt; Um, let me just probe a little bit on this. Is it how much is carrot and how

much is stick when you're looking to upskill the workforce and and bring them into a more of an AI mindset? I mean, you you've got a very bold program at Microsoft reaching across colleges, but

you you're also active, I know, in in in creating the the capabilities within the workplace. How much how much of this took to to both of you is is carrot or stick. I I was at a at a at a dinner in

DC a few weeks ago where the head of a large media group had told his team they had to be two times more productive by the end of 25 using AI to stay in their roles and 10 times more productive by

the end of of 26. That was an expectation but it was set very much as a a minimum standard and goal. They were putting training programs in place but there was a clear metric to achieve.

What's your what's your perspective based on how you've seen this work &gt;&gt; with either within Microsoft or or within the companies that you collaborate with in training.

&gt;&gt; In our experience, um I think we have are much more leaning in the direction of using carrots. Um so we have a lot of programs internally that are a mix I think in terms of tactics. Uh

that's important, you know, both kind of like here's a dayong training or a week-l long training program, right? Which I think is really valuable. It's gives you an opportunity to really like

dig in, but also really difficult to find the time for. Um and so, you know, we actually have like weekly tips for, you know, how colleagues that are in similar roles are using co-pilot, for

example, internally to have more efficiency in their work. And I feel like that's the kind of thing where, you know, is that skilling, is that training? I I don't know, but it

certainly is helpful. Um because that's the kind of thing that in my day-to-day job like I can look to and integrate much more easily. Um and the other thing that we've started doing um is uh

hackathon type exercises internally that are not just oriented towards engineering communities but actually our corporate external legal affairs group which is not just lawyers but is a lot

of lawyers. Um, for example, uh, having a a hackathon that's really meeting that community where we are um, and building a co-pilot to serve our kind of day-to-day work. And so, a lot of like

different kind of carrot approaches is what we're doing um, internally and where we see um, I I personally can say like I I feel especially the latter two, it's just hard to find like time to do a

deep training program, but if you integrate sort of into your day-to-day work, make it easy with these kind of carrots. um you can really start seeing the impact and that motivates you to use

the technology more. &gt;&gt; So stick is out of the window. You can't do that anymore, right? But we use carrots and budgets.

Okay. Uh when I say carrots, it's basically uh appealing to the individual now and their glorification. So if it's a patent or patent, you are filing it.

the company doesn't own it. You own it, right? Uh if there's a paper, you're writing it. If you're speaking at a symposium, you're doing it, right? And that allows them to think and then we've

actually spent a lot of time through HR to try and explain that with the pace of change of technology, if you don't upscale, you don't change, you actually are facing extension in about 5 10 years

time. Gone of the days where you can be there on the same technology for 30 years will not work right so we we home in the message provide that and then provide the push um we glorify people

that file patterns we we glorify them within the company so that's one second when I come to budgets we actually leverage budgets with our segment heads so they given budgets uh they're giving

train they're given training budgets we also provide them headcount budgets and say can't exceed so we've been able to actually improve productivity with AI. So we used to run on a utilization or

productivity basis the metrics all service companies track at about 73% 5 years ago we are already at 83% and um I think I can push this up another 2% in terms of productivity

levels uh in the company again leveraging AI and that's the budget approach that we use but with the seniors so it's a it's a mix of both if I may uh to be able to manage this and

motivate this but it's an ongoing exercise &gt;&gt; it's fascinating Maybe we'll come back to it as we as we draw to a close. Let me shift gears a little bit and talk a

bit more about security and trust and come to you Julian if I can. So I I think we've recognized and we've heard it you know in different conversations this week that there's a there's a

trough trust deficit around the use of AI in certainly in a public context there is some some fear suspicion and anxiety in a global context. I'm not talking just about India. Yuggov uh

carried out a survey in the US last month and in the context of fintech they found that less than 20% of Americans trust AI in financial services and and and they're also sort of struggling I

think with some of the cyber security questions and issues which you which you're very well placed to address. So if public um trust in AI remains fragile and AI specific cyber risks are growing,

which they which they clearly are, what are the immediate steps that industry should prioritize to counter those threats? Uh um things like prompt injection attacks, how can these

solutions be scaled particularly for developing countries? &gt;&gt; Sure. So again when you look at technologies like AI

um let's separate old school AI just machine learning from today what we have in agentic AI AI has been involved in the security game for

20 years. The issue is is with aentic AI, the speed at which an attacker can work is a thousand times faster than it's ever been and it's increasing exponentially every year as the

technology becomes smarter. The problem with everything that we just talked about today is a part of the human equation governance is far behind the usage of

the technology in the environment today. So every country, India being at the top of the list, just this conference speaks to it. Every company that's in a commercial space,

we're all using AI because it gives us greater productivity. It allows us to rapidly upskill our employees. You know, years ago when I would talk to someone early in their career in technology, it

would be you need to learn how to be a great programmer. Now they don't need to program anymore. Now they need to learn how to be great prompters, understand industries,

understand outcomes. But the problem is security always follows the use of the technology. It doesn't precede it. And so the issue that we have in our environment today and what we've learned

at Rapid 7 is the basics all still have to be in place. You need to have proactive controls in your environment and then you have to have reactive or what we

would call compensating controls in your environment. The proactive controls are, you know, it's it's the old school. It's the oneplus one. I need to make sure that I'm protecting against the

vulnerabilities in my environment. I need to understand the entrance and exits to my attack service, my mobile device, my cloud infrastructure, the home networks of my employees, uh, and

and other supply chain vendors who may also connect to my work, which actually represent a greater risk to my environment because I don't know if they're doing the same things. And then

most importantly helping the people specifically in our case our employees understand and it's it's important to me to tell them that as I'm now entering the latter well the end of my career I

tell my employees all the time you know you're average tenure in a technology company in the United States is three to five years. The first thing I tell them is you're

not going to retire from rapid 7. So other than the incentives that we're giving you to learn these technologies, which of course is to the company's benefit, it's to your benefit because

these these skills that you're learning and that you're going to be using, will translate to the next thing that you do and it makes you that much better. If we do enough of that, not only are we

helping the employees, but we're helping the societies and the and the ecosystem that they live in, including in India. to you. &gt;&gt; I wanted to add one um additional

area that we're really focused on to address the kind of AI cyber threats um particularly relevant in India and other areas uh in the global south. I mentioned that one of the areas that

we're focused on is multilingual and multicultural AI capabilities. And one of the most important the foundational reason for doing that of course is that you have an AI that works well and in

different languages and cultural context is reliable, performs well. Another reason is also that AI that um is not robust in its multilingual and multicultural capabilities does have

additional security weaknesses. You mentioned prompt injection attacks. Um and you know one way in which um you can think about a prompt injection attack is basically if you have

AI system and you have the sort of safety system around that. Uh someone who is misusing the technology can sort of try to break that safety system or or get around it. Um and one of the ways

that uh attackers do that is by using languages that are not well supported in that model or system. Right? So um if a model or system is primarily uh prepared to perform well in high resource

languages but not in low resource languages, Tom for example or some other sort of um language that it is not really built into how the model performs if if companies aren't in tune to that

um then an attacker could use that language and jailbreak the the system basically get around the safety system. And so it's a just another reason why it's really important from our

perspective and we're partnering with a lot of others in industry and government. So this comes back to a public private partnership opportunity to really work on multilingual and

multicultural AI capabilities. One of the things that we announced this week is actually um there's a there's a benchmark u from an organization called ML Commons which is a jailbreak

benchmark. actually measuring how robust systems are against that kind of prompt injection attack technique. And we worked with a number of others to to

really um build out the current version of that jailbreak benchmark which is really English specific to include um multiple indic languages and Asian languages in terms of um its capability.

It's a it's it's not going to solve the problem. It's um one step of what we see in the right direction. But I just want to draw that sort of you know really specific area of focus um in India and

other areas for thinking about the kind of AI and cyber threats. &gt;&gt; It's wonderful. Thank you. Sat can I add a point? &gt;&gt; So this is about the rise and prominence

of AI agents and we have been constantly investing in self-defending systems just like a human immune system. As agents grow and they can the scale and speed at which they can attack infrastructure,

the hospitals, the energy grids, we need agents on the other side and this becomes AI versus AI story uh where we are smartly inventing agents and we believe first time with AI we can

reverse the defenders dilemma. So, so the dilemma many of you might already know attackers have to find just one open wallet in this crowd but defenders have to protect all the wallets all the

time and first time AI will give us aggregate advantage to defenders because majority of defenders time 80% goes in drudgery and skunk work and AI can actually automate and uplift that work

so the entire stack of defenders can improve and uplift with AI Okay. And and and we believe that we'll be able to build a self-defending adaptive system which can protect us from various

vulnerabilities. &gt;&gt; Wonderful. Thank you. Well, we're we're drawing towards the close of of the session and it's been a very rich conversation. I just wanted to take a

step back and ask you all, you've been most of you have been here all week and and you've heard a whole host of different interventions and some very significant investments and initiatives

from government as well. What what are your conclusions? What's changed in your perspective when you look at AI for the future from your own vantage point? What's this what's this event given you

a new perspective on or crystallized in your minds? Maybe let me go back to what Lee do you want to share your thoughts. It's it's reinforced for me um you know something I've seen through a lot of my

international work uh with OECD with global partnership on AI just the need for the global um cooperation and not just at the government level but among all different types of stakeholders you

know within academia um within industry within civil society and and working together and I think you know we can sort of pause at this moment and say you know we if you look at

safety report. We've made a lot of progress over the last few years, but we need to continue to work together and not just focus on the harms and the risk that AI can have, but think about the

benefits. You know, if we are able to leverage AI, we might be able to um you know, help achieve some of the UN sustainable development goals. I think one other thing I want to just kind of

enter into the mix. you know the um customization of AI for different regions also depends upon data and a lot of my work um has focused on you know how do we create voluntary foundations

so we can exchange data more easily like right now we don't have data standardization so if I want to exchange my data with any of you my data may be in a different format um as a former

lawyer a lot of my work is also um focused on we don't even have standard agreements So, if we want to exchange data, um, how can we easily transact and not have all that friction and

transaction costs? You know, we don't have the creative common licenses right now for data. And if we're ever going to get to that localization and that ideal point where we're customizing for

different cultures, we're going to have to figure out ways um where we can voluntarily and responsibly share data. And this has been part of the discussion, but hearing um the

conversations over the past week um kind of underscore the need to continue to advance that work while we work on some of the other topics that we've been discussing.

&gt;&gt; Great. Great. Jun, &gt;&gt; more than anything, what this week has taught me is I'm old and this industry is moving. &gt;&gt; Okay, so stop saying you're old. You

don't look old. You look great. So again, this industry is moving so quickly. Um, again, skills that are needed and considered to be important today will no longer be necessary in

five years. And if the workforce and if the users of the technologies aren't evolving with it, we all fall behind. So while there's a great advantage and opportunity in using AI, the danger is

it also can obsolete at the same time and we need to be very careful of that and how we use it and then how we help hopefully to promote this throughout the world in a way that makes it equitable

for everyone. &gt;&gt; Great. Thank you Amit. Sacha, any reflections? Yeah, I think one of my big takeaway from this week was

some parts of the world are focused on AI as an influence. Some some part of the world is focused on governance of the AI. I think India is focused on impact of AI at the grassroot level. uh

thinking about how AI will impact a farmer or a small school or an NGO or a small hospital has been the has been the focus and it resonates with me because mission of my team is to keep everyone

safe at scale and when I say everyone it's not just about Google or Alphabet or not just about our billions users but the entire society everyone at scale and how to make sure we become the architect

and not just the consumer of AI and and make sure it reaches to the grassroot level is one area to think about. &gt;&gt; Yeah, I would agree with that. &gt;&gt; So, um

of course outside of the traffic bit, right? Um what you learn if you ask me uh in the whole week that I've seen is that if I and I've been in this business for I don't want to date myself so say a

couple of decades and we leave it there. But people used to say India is a back office. That's how it started in '90s. People said India is a back office. Y2K happened and they said the IT industry

will be over. Right? Because Y2K that's all there is today. The IT industry, engineering industry together is $600 billion. We move forward. People said are you

going to take data and are you going to is is data going to get leaked? And then COVID came and India proved yet again there was not a single data leakage that happened from India Inc. anywhere,

right? There are some draculin rules. We don't allow our employees to use USBs, blah blah blah blah. Net result, zero data leakage, absolute privacy and um and the government comes down

very heavily if they get something like this. So they've been able to create a safe environment, move forward. People used to say is India a market this last week and forget technology companies. If

you just walk the floors, you see people like Schneider, you pe you see people like Vertive, you see others, they are developing products for India in India, you developing products to the world

from India and it's no longer just a cost base. &gt;&gt; So if I was to say there's one thing that I've learned in the last week, it is that India is no longer the back

office for AI. It is actually the front office for AI for the world and that's the net summary that I would draw in the entire week that I've been here. &gt;&gt; Thank you. That's very valuable.

&gt;&gt; And I, you know, zooming out to the sort of highest level, one of the things that I've really genuinely felt this week that has been very exciting to me is that there is a lot of energy around how

to deploy this technology, how to have impact. It's been actually fun to be in a lot of sessions with students and entrepreneurs that you can really feel the energy. Um, and I feel that it has

the the conversation around governance has come along and felt integrated in a really genuine way as well. If we look at the kind of um summit series that that kicked off a few years ago at

Bletchley, I think it's fair to say early on the emphasis of the conversation felt very safety and securityheavy last year. um in France there was a a big pivot to trying to

think about the opportunity and what I see in India this week is a genuine integration of those conversations and a deepening of those conversations. So really what do we mean when we say

impact what really um do we want to see in deploying this technology and then sort of not taking for granted that of course governance actually has to come along with that you have to really do

the deep hard work around things like multilingual AI and there's a real for a partnership and moving those things forward. Um, and there's a real need to think about, you know, governance steps

so that you can have trust in this technology. You know, India actually just passing a law last week thinking about how to mark AI generated content. there's a real sort of recognition that

some of those steps are going to be important and you don't want to stop um or have those steps sort of prevent deployment of the technology or realization of the benefits but like you

know we have to do the deep work together to sort of move forward across adoption and impact and governance together. &gt;&gt; Thank you. Thanks Amanda. We've got a

few minutes if anyone would like to chip in. Great. Hands are going up. The room's filled by the way while we've been going along and it's been a great conversation. Let's hand one or two mics

out to to colleagues around the room if we can to the lady here on the front. &gt;&gt; Oh, hello. Okay. Right. Um, thanks and I appreciate the uh comments and the traffic. I think we've all got our

traffic stories now. Um, I I hear a lot of talk about um upskilling, co-creation, which are all very important things. I agree. But uh what I'm also hearing a lot from and I'm sure

you all are too is the issue of speed of this technology that could potentially outspace some of this um uh real scenario. So my question to you is you know what do would and this goes to

anyone who might want to answer or has some real thoughts on it. What do you think might be the gaps between that uh that we would need to address in a transition process between upskilling

and real economic displacement? &gt;&gt; Who can grab that? &gt;&gt; Yeah, you got the mic, Julian. You going to give it a go? &gt;&gt; I was trying to give it away.

&gt;&gt; Yeah, I know you were. Um, it's a real problem, right? Meaning technology is moving so quickly. As I said years ago, I would tell young people in technology, learn to be the

best programmer you can. Now with Agentic AI, especially with the usage of MCP, where you can have multiple agents talking to each other, sharing information, it's now learning to be the

best user and prompter of the technology, understanding the outcomes. Uh, but there's going to be some displacement. It's you know right now I would tell you AI especially in the

security context u I can probably eliminate 60% of the things that humans have to look at today but there's still the 40% where a human has to be involved to make a

determination around risk to an entity where it's a government whether it's defense whether it's a business and so it's really helping them evolve to this next level of user this next level of

programmer if you want to call it that and there probably will be some displacement that we just can't get around. &gt;&gt; Gentleman at the front,

&gt;&gt; I actually have an extension of the same um concern that the lady shared. Um the speed is one aspect but also I think um there's a whole whole information arbitrage between the people who are

creating and pioneering in uh the AI space versus the others to whom the information is reaching and the impact of that on the power polarization

and even the democracies uh you know that possibly I sense um And a lot of the conversation that I hear today is assuming that you know AI is moving linearly but I see it moving

exponentially. &gt;&gt; I agree and &gt;&gt; with a polarizing effect. &gt;&gt; Yes. Yes. Both the polarizing effect and the effect you know like I think 40%

that that uh sir just spoke about uh for me that 40% is not really 40%. It's just that we want to be very very careful. But if we were to not care so much about how accurate and how much data standards

we have &gt;&gt; 100%, &gt;&gt; you know, it's it's very large, you know, I think the displacement can happen very fast. So I'm I'm really

concerned about how things are moving. I'm not sure if my concern is being shared by people in the panel. &gt;&gt; Anyone want to respond? &gt;&gt; I mean I I think um we need to focus on

AI literacy because you know again the technology is moving so fast. How do we make sure people in their everyday lives, people in the workforce have access to education so they can continue

to upskill? And I I also think um you know being in academia after having been in the private sector for we won't go into how many decades but um you know teaching students how to think right

like I think a good student when you're looking at your career trajectory &gt;&gt; you know it's not just coming out of college with a set of skills but teaching them how to think how to

problem solve and you know I think it's really the public private partnerships that Amanda mentioned with with academia is really important because a lot of times, you know, the tenure faculty,

they don't know how to teach that to students and bringing people in um to tell them, you know, this is how you adapt. These are sort of what you're going to expect in your career. And I

say this not only from the perspective of being in academia, but having two children of my own in their 20s who are just starting their career and it's sort of expect the unexpected, but learn how

to be on your toes. I think a lot of it's just having the good analytic skills, having good communication skills, and if you have those core skills, you're going to be able to adapt

and it will carry you forward in the future. &gt;&gt; Great. I think we got time for one more question. Okay, gentle. Oh, the lady who sorry, the lady who has the mic, she has

the mic. &gt;&gt; Thank you so much. My name is Rita Sony. Um, I work with a company that's operating in smalltown India, uh, delivering all these tech services that

many of these companies are doing. And um my question is actually for Amanda because I think she was the only one who really brought up the digital divide that continues to exist um both

in India and across the globe. Um I I actually didn't feel like I heard very much about how to actually bridge that. Um yesterday I didn't have one of those special passes to go to the events on

the 19th. So instead I visited a local nonprofit called the digital empowerment foundation which has been around for more than 20 years doing incredible work in rural India and they're simply

talking about last mile internet connectivity let alone the enablement or even the critical thinking that that um Lee just mentioned. So, just a few more words on

how it is that we can bridge this digital divide and make it more equitable because I think the more folks are going to be excluded, the more different kinds of problems that we're

going to have. &gt;&gt; Yeah. And I I think you may have come in after um I we talked briefly about some of the work that we're doing to address the digital divide. Um, and for a lot of

words, I would point you actually to we published a blog on Wednesday where we talked about like investments in five areas that we're thinking about to close the gaps that we see. And we actually

point to the work that we've done using our own teleimmetry to sort of track these gaps and their trajectory and like really lifted up our own concerns about the trajectory. Um and so among the

areas of investment, you know, infrastructure is really foundational and we actually do talk um in in the blog about of course infrastructure in terms of like AI, compute, capacity, but

actually the fundamentals beyond like in terms of connectivity uh energy access as really important as well. And then we talked about scaling multilingual and multicultural AI capabilities. Um really

working with local communities on local use cases and um the kind of deep work that we can do to sort of help bring the technology to people and see like even in agriculture for example we at

Microsoft research have done a lot of pro projects like in close collaboration with local communities and try to see like how could this serve you and then also learn from what the how the

technology needs to evolve in order to do so better. uh and basically then also taking a step back and continuing to study diffusion so we understand like are our interventions working are they

not if so what can we learn and how can we improve how we're intervening &gt;&gt; okay so time's up everyone thank you so much for your contributions and for and for joining us at different points

during the conversation thanks to the panelists for a really rich and diverse conversation it's been a it's been a real pleasure to to have you with us and I think we end with a sense of optimism

that no matter what the challenges of the digital divide and those other elements. There's probably an AI solution to the AI challenges that we're creating. Thanks,
