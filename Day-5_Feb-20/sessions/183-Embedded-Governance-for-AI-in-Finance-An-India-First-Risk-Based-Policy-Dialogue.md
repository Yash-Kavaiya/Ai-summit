# Embedded Governance for AI in Finance: An India-First, Risk-Based Policy Dialogue

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 16:30 ‚Äì 17:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Shakuntalam Banquet |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/7eDj05DNdeg?feature=share) |

## üé§ Speakers

- Kazim Rizvi, The Dialogue
- Priyanka Jain, Fi Money
- Vikram Kishore Bhattacharya, Amazon Web Services

## ü§ù Knowledge Partners

- The Dialogue

## üìù Summary

This panel discussion will bring together regulators, financial institutions, and fintech stakeholders to examine how risk-based, embedded governance frameworks for artificial intelligence can be designed and operationalised within India's financial ecosystem. The discussion will focus on approaches to balancing innovation with trust, accountability, and supervisory oversight across emerging AI use cases in credit, payments, fraud detection, and compliance.

## üîë Key Takeaways

1. This panel discussion will bring together regulators, financial institutions, and fintech stakeholders to examine how risk-based, embedded governance frameworks for artificial intelligence can be designed and operationalised within India's financial ecosystem.
2. The discussion will focus on approaches to balancing innovation with trust, accountability, and supervisory oversight across emerging AI use cases in credit, payments, fraud detection, and compliance.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/7eDj05DNdeg/maxresdefault.jpg)](https://youtube.com/live/7eDj05DNdeg?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

I think this is okay. This is okay. Thank you. Uh we will begin our uh proceedings today. uh with a keynote address

from Mr. uh Mr. AK Churri who uh who who is the non-executive chairman uh and um of NPCI uh what we are going to discuss today is uh very uh very much in line with the overall theme of the summit. We

are looking at the overall aspect of uh governance of AI but uh not as something that will be set aside and and looked at through a different lens altogether but something that can be uh looked in as an

embedded layer of governance that we uh already govern technologies with. uh in the interest of time that we uh have uh with us I will request uh uh the panelist to be seated on the dis and I

will uh request AK chiser to please uh begin his keynote sir. Thank you. [applause] Uh good afternoon to everyone distinguished policy makers, regulators,

industry leaders, members of the fintech community and esteemed guest. Uh I was just very closely following last four days how and what are things happening and it was amazing the type of

inas type of excitement and type of budge around AI and this summit and I believe and that whatever is there actually is a real thing which is happening possibly

multiple small applications are going to come in coming days uh which will solve multiple issues and problems in coming days and we'll have the real leading role actually to play as a country. That

is the way we look at it. We also will have a uh great role to play on the data side particularly when we are going to train the models for that. Uh obviously when we are going to scale up the entire

thing then possibly there might be some risk also and those risk uh something is known something is unknown and for unknown much cannot be done except we need to do take care of the embedding

the governance part that is the theme of today's talk how we need to embed the governance actually the entire life cycle of the AI the design of the AI that is the way we have to Look at

uh yesterday I was again listening our honorable prime minister and the beautiful way they he summarized the entire theme in one word that is called mano that is called humility. So

possibly in future I'm going to use that instead of responsible AI that is possibly we can talk about human AI and because it is going to touch upon uh moral and ethical systems accountable

governance to sovereign uh national sovereignity accessible and inclusive and valid and legitimate all the aspects what we are going to touch upon everything is covered in this one word

that is called mano. Now coming back to the my uh uh address proposed address I'm coming back to this now. It's uh indeed a privilege to participate in this dialogue at a defining moment in

India's digital evolution. Over the past decade, India has demonstrated how population scale digital public infrastructure can drive inclusion, efficiency and

trust. Systems built with interoperability, transparency and scale at their core have reshaped financial participation by millions. Today we stand at the next

inflection point in that journey. A new tech layer is being superimposed. Upon this digital foundation, AI artificial intelligence what we know it is not arriving in isolation. It is

integrating with payment systems, credit and risk management platforms, supervisory frameworks and cyber security architecture that already operate at national scale. This

convergence of scale and intelligence marks a structural shift. Unlike earlier waves of digitalization that automated existing processes, AI introduced adaptive systems. Systems that learn,

recalibrate, and influence outcome dynamically. In a country as large and diverse as India, such system do not merely improve efficiency that seek access, opportunity

and systemic resilence. The question before us is not whether AI will transform finance. It already is. The more fundamental question is whether

governance will evolve at the same pace as innovation and whether it will be designed into system from inception rather than appended ladder as a compliance after all. In financial

services trust is foundational. AI system cannot function as opaque black boxes especially when they influence access to credit or flag financial behavior. Governance cannot be an

overlay applied after innovation had already been scaled. It must be embedded by design. As Peter Ducker observed, quote, management is doing things right. Leadership is doing right things. In the

context of AI in finance, governance is not merely about tech correctness. It is about doing the right things at the right time in ways that preserve trust, resilience, and inclusion.

Now looking at AI as infrastructure tool, it has evolved from analytical assess assistance to shaping financial outcomes. In Kahit market, machine learning model analyze transaction

histories, behavior signals and dynamic cash flows to generate granular borrower assessments. In fraud prevention, AI detects anomalous activities within milliseconds, processing volume beyond

earlier systems. AI enabled detection can reduce certain categories of fraud losses by up to 25 to 30% at this point of time in high volume payment environment. What we are witnessing in

NPCI uh compliance functions increasingly rely on automated pattern recognition while adaptive cyber security models respond to emerging threats in real

time. The difficulty the diffusion of AI across the finer value chain enhances efficiency and precision. Yet when models operate on a systemic scale, even

marginal inaccuracy can produce material consequences. In finance, where stability and trust are public goods, the tolerance for systemic error is limited.

India's finance system adds its own complexities. it scale of digital participation, linguistic diversity, demographic heterogeneity and income variability heightened model risk. Algo

trained on narrow urban centric or historically squid data sets may inadverently mclassify, mis mispriced or exclude segments that digital finance intended to integrate. It is therefore

imperative that we do not view AI as a periphereral tech enhancement. It must instead be understood as a component of financial infrastructure which is systemically relevant and should be

subject to the same standard of resilence, governance and accountability what we expect of any critical financial utility. When we talk about embedded governance

in AI, historically regulation in financial services often responded to innovation after risk gets metalized. Governance in the AI era must however be embedded into systems design. Embedded

governance means integrating accountability, transparency and risk management into very st every stage of the AI life cycle from conceptualization and data acquisition to model

development, deployment and ongoing monitoring. It rest on several foundational pillar. I'll mention four. One is proportionality that is the governance

intens in intensity should be risk based it should be risk based intensity fairness and non-discrimination third is explanability and transparency and fourth is accountability which must be

clearly defined while institution may collaborate with tech providers on or leverage shared infrastructure responsibility for outcomes cannot be outsourced

potential vulnerability of AI system that save their operations board and senior management must understand that logic limitations etc. Further and more

importantly in financial AI algo efficiency should not compromise equitable opportunity. Now specifically coming to risk based approach to AI governance just I'll

touch upon this a risk based approach to AI governance acknowledge that innovation and prudence are not opposing forces they are complimentary financial authority globally are converging on

principles that emphasizes robustness resilience transparency and human oversight India's regulatory thinking reflects this balance encouraging experimentation while reinforcing

institutional responsibility The objective is not to slow innovation but to ensure that systemic risk does not accumulate invisibly. Several risk dimension deserve

particular attention as AI becomes integral to financial system. It may include multiple issues. I'll touch upon only four. One is the model integrity. For instance, it can no longer be viewed

as a one-time validation exercise. Intell system must be evaluated across economic cycles and stress against extreme but plausible scenario. As data patterns evolve and models recalibrate,

continuous oversight become uh inevitable to guard against drift, unintended bias or reinforcing feedback loops. Second is operational concentration risk. I will detail

subsequently also it is an emerging systemic concern. Diversification and resilence planning are essential to safeguard continuity. Data governance through data integrity, consent

management, purpose limitation and minimization principle is foundational. Financial data is not merely transactional. It reflects livelihood, behavioral choices and economic

participation. And the fourth item is cyber security risk that are amplified in the AI environment. As AI strengthens defense mechanism, it can also be leveraged by adversaries. institution

must anticipate adversarial AI and strengthen detection capability accordingly. A risk based framework recognizes that governance cannot be static. Systems that learn and evolve

demand demand oversight that is equally dynamic as also measured, proportionate and forward-looking. Now just touching upon supervisory intelligence as AI permits finance and institution

supervisory framework are also evolving. Supervisors increasingly leverage advanced analytics to monitor systemic pattern, identify anomalies and strengthen early warning mechanism. This

creates a reciprocal dynamic. Institution embed AI in operation while oversight bodies integrate intelligence into supervision. However, governance cannot be regulatordriven alone.

Institutional capability is critical. AI literacy at the board and senior management level is no longer optional. Leaders must understand model architecture, validation methodology,

vendor dependency and ethical li implications. Effective governance requires interdisciplinary capability bringing together tech risk compliance and legal

experts as well as business leader together. institution that integrate AI governance into their erm framework that strengthen resilience. Chris Christristen Leagard has noted

innovation and regulations are not adversary they are partners in progress unquote that partnership must guide the embedding of AI within finance. Uh coming to the inclusion part what our

honorable prime minister have mentioned about the last a in a mano that is access and inclusion. India's financial transformation has been anchored in inclusion. Over the past decades tech

has lowered barriers, reduced transaction cost and brought millions into the formal financial ecosystem. And AI now offers an opportunity to deepen that trajectory through granular dynamic

risk assessment. It can reduce reliance on collateral heavy models and static credit history. Transaction level data, cash flow analytics and behavior indicators can provide more nuanced

insight into the repayment capacity uh particularly for MSME who are presently outside the traditional credit framework. India is expected to account for a significant share of global

digital transition growth this decade. If harnessed responsibly, AI can convert this expanding digital footprint into broader formal access to fair financial services. I'll underline formal access

to the fair financial service and adoption at scale yet in inclusion cannot be assumed. It must be intentionally designed. Algo train on historically squid data set risk

perpetuating structural inequalities. Informal sector income volatility may be misinterpreted as instability. Gender based data gas may distort trade outcomes. Whether without corrective

safeguards, technology may reinforce rather than reduce disparities. Inclusive AI thus requires representativeness in training data sets, periodic impact audits and

community level feedback mechanism. It calls for institutional mechanism that allow individuals to seek clarification and redrace where automated decision affect their

finance standing. Now coming to the sovereign and resilient AI foundation. AI governance intersect not only with the institutional risk but with strategic resilence.

Concentration in advanced chips and foundational AI models raise critical concentration for economic sovereignity, financial stability and I can further add the national security. Uh dependency

on limited supply chains can create systemic vulnerability. If we may look at AI stack more granularly, it rely on five interdependent layers. At the base are specialized semiconductor chips. We

all know above this sits the cloud and datacentric infrastructure that provides a scalable processing capacity and these systems are fueled by vast data sets drawn from public and proprietary

sources. On this foundation operate large foundation models adaptable across domain and finally at the top are application and that embed AI into financial services and everyday economic

life. In this context, we should be conscious of the fact that one firm controls more than 90% of advanced ships. Three dominate cloud capacity and a handful command foundation models

threatening financial stability and economic sovereignty. We must therefore diversify supply chains to the extent possible through domestic innovation and international collaboration to secure

resilient AI foundations. Further the if you look at the how to what is the pathway for ecosystem scaling possibly we have to look at the institutionizing the consent based data sharing shared AI

and risk infrastructure investment in AI literacy and governance at all levels including board and senior management and most importantly encouraging homegrown tech and AI capable entities.

Uh it may be appreciated that an India first approach is not inward-looking. It is contextaware. It ensures that governance reflects local realities while remaining global

coherent. Uh now coming to the uh operationalization of embedded governance. Uh it may involve multiple issues but I am touching upon five to

six one. The life cycle based model governance. Institutions should embed governance checkpoints from data acquisition to deployment and post- deployment monitoring. Obviously clear

risk classification framework based on their systemic impact that we should have to have independent review and oversight enhanced oversight on that. It should be auditable and documentation

should be there. Cross functional governance committee will be helpful. No doubt on that and continuous monitoring and feedback loop that basically helps in periodic reabulation by way of extra

extra audit. Consumer centric safeguards uh obviously by way of transparent disclosure, clear appeal processes and human intervention mechanism are critical to maintain public trust. These

pathway ensure that governance is not episodic but embedded women into operational DNA. Now I'll just before concluding I'll touch upon the role of India in AI and trust as a corner corner

store of financial AI finance rest on confidence confidence that systems are fair stable and accountable deposit trust institution to safeguard assets borrower trust system to assess risk

fairly and market trust transparency and stability. EI has the potential to enhance distress by improving fraud detection, accelerating compliance, and broadening access and inclusion. But if

governance is inadequate, AI can erode confidence rapidly. Trust is built when systems are predictable, explainable and accountable. Trust deepens when innovation aligns with public interest

and trust endures when leadership anticipate risk rather than reacts to failure. India stands at a pivotal moment working across all five layers of the AI stack and demonstrating the

ability to deploy application at population scale. It is shaping a global agenda for inclusive AI. The convergence of digital infra regulatory foresight and entrepreneural innovation offers a

chance to show that scale and safety can coexist and governance can catalyze innovation. Coming to the conclusion, artificial intelligence will save the next chapter of financial services. But

tech alone does not determine outcomes. Institutional design does. Design choices, governance framework and institutional culture will determine whether AI strengthen finance financial

resilience and inclusion or not. Embedded governance is not a regulatory burden. It is a strategic imperative. It ensures that innovation is sustainable, trust is preserved and the system

stability is protected. If we embed fairness, transparency, accountability and proportional oversight into the architecture of financial AI from inception, India can chart a distinctive

path, one that aligns tech ambition with ethical responsibility. Let us approach this moment not with hesitation but with disciplined foresight. Let us ensure that as our financial systems become

more intelligent, our governance become more robust, our oversight becomes more anticipatory, and our commitment to inclusion more resolute. In doing so, we will not only harness the power of AI,

but we'll also shape it to serve the broader goals of stability, opportunity, and share prospectively. Thank you, Jim. Uh thank you sir that was uh very insightful and uh sets the context uh

for the panel discussion to follow. Uh we could also request you if you would want you could join us in the audience. So that would be great. Yes. Um over to you Priyanka for introduction to the

panelist and then taking this discussion forward. Thank you so much. &gt;&gt; Thank you. Uh our panelists need no introduction. I'm going to keep it very fast so that we can make the most of uh

you know capturing their thoughts. Uh first I have miss with me Mr. Sanjiv Sanal. Uh sir is the uh economic adviser to the prime minister's office and he needs no introduction. uh I if I

actually go by what AI has given me as his persona um AI summarized it as a macroinker, a historian, auh historian of structural cycles and a strategic geopolitical

lens. Fortunately today we have the OG himself in the room and without any further ado I want to ask him uh my first question. Uh sir historically countries that have mastered

generalpurpose technologies right from the steam engine early electricity internet uh they've gained outsized economic advantage is AI that inflection point for India and if so does early

well-designed self-governance accelerate trust or does it deny us of any competitive momentum &gt;&gt; so yeah so First thing you need to know

about these foundational uh multi-use uh technologies is to understand that it is almost impossible to tell how they will evolve and who is where it will all end up. Yes, it is

important that you are uh engaging in it. But let me point out that uh it's not always the first movers who benefit from it and it's not the case that even those who invent these technologies know

where they're headed. I mean just to give you an example the European renaissance which led ultimately to uh the western domination of the world for half a millennium uh was based on three

technologies. One was the printing press, the other was gunpowder and the third was mathematics. The first two were invented by the Chinese and the third was

invented by the Indians. But it is the Europeans that took it, horned it and dominated the world. So one important thing to recognize in all of this is that do not try and necessarily guess

where this is headed. But of course we need to engage in these technologies and build on them otherwise uh you know somebody will take your technology and dominate you. So it is very very

important that India does participate in this AI revolution. But again in this context let me say do not that does not mean that we should spend time trying to work out exactly

where this is headed. For example, when the social media revolution was happening 20 years ago when fin when uh Facebook and all these things came about the marketing tool of the people at that

time was see now everybody can talk to everybody we will all move to the golden mean because we'll all you know have similar views because we can all talk to each other and so on. But in fact the

algorithms went out of their way to put us in bucket uh buckets and echo chambers. So in fact we ended up social media ended up doing exactly the opposite of what

the you know the the technology experts were telling us social media would do. Now why does this apply to AI as well? And here I'm going to talk about this riskbased thing that uh everybody is

talking about. Let me tell you that you cannot actually put AI into or any types of AI into any real risk bucket because this is an emergent evolving thing even more so than social

media. So consequently if you're saying I am going to do risk based it means that you have some assessment of where that thing will go and I'm telling you that it is almost impossible to do this.

So for example in my view the European way in which they're going about and having you know risk they are the pioneers of risk based systems I understand you it's pretty obvious

that you don't want AI to take over a nuclear buttons but other than that the risk levels of most of the other things is utterly unknown something totally innocuous might go and blow up the whole

system because these things are emerging they are evolving they're interconnecting Therefore, I actually do not think the risk uh a system that is largely based

on perceptions of risk will work because it is not possible exante to work out what is dangerous or for that matter what is beneficial. Now what should you do if you can't tell

what is going to happen? Now I'm telling you the European system is either going to be strangulate the system by being too stringent or it will open things up because it

wants progress but will ultimately the riskbased system will not be able to take control of it. So the other model that is there is of China which is the state knows best but we know from the

experience we had with the Wuhan virus that the state can very often lose control of things that are happening and it can spiral out. The third model that is mostly the

American model is to have a lesser fair and let anybody do whatever they want. Now the dangers of that are obvious. In my view the way they control it is through tort laws. I.e. if something

goes badly wrong you will then end up with a you know billion dollar fine or something like that. So in some ways it works better because it's expost rather than exanti.

It depends on those who are running the system having skin in the game. I.e. your company will go down and you will be jailed and you'll have a billion dollar fine on it you if things go

wrong. That is how they are doing it. It's an export punishment but uh as you can tell that is some ways is an expose system and if something really bad goes wrong um you know it will it will you'll

only find you know you can punish the person after the after the the the horse has already bolted you are going to lock it. So all these systems have their downsides but I'm just telling you that

whatever system we design to in order to control this has got to be based on being agnostic to how this whole thing works going forward. Now I know I'm taking up their time but give me a

minute. There are other systems that we manage where we have no idea where they are going. Take for example the stock market. You and I don't know where the stock

market will be in a decade's time. It's a complex system just like artificial intelligence. But we manage it. How do we do it? Well, we do it by creating a framework which does the following

thing. It first of all has deliberate. It institutes audits and enforces transparency and explanability. If you h can't explain your accounts, you can't be in the stock market.

Two, it has systems of shutting things down when things go wrong. So there are the every stock market will have when things spiral out, it shuts down. Three, it deliberately creates

systems of separation. For example, um the you know there are um uh the same company cannot you know be a bank as well as being a company that uh so there are conflict of interest. So in the same

way AI will need to create compartments. I am personally very suspicious of any idea of the internet of everything and the AI of everything. That would be a disaster. I think we need to be willing

to allow compartmentalized AI. I think it'll be more efficient anyway from an energy perspective but I think it's also safer and most importantly you need to create skin in the game i.e. X ante tell

people who will be held responsible when things go wrong. So in the case of financial markets the directors of the company are the ones hauled up when things go wrong

or the CEO. In the case of AI, we will have situations where when things go wrong, the person who made the algorithm will blame the data. The data guy will blame

the company, the guy who's the user. All kinds of things will happen. We need to exante decide who in the system will be hauled up when things go wrong. That will create skin in the game.

But we cannot wait for something to go wrong and then this happens. We need to decide this Xante. So all of these things exist in the case of financial regulation. I personally think a similar

system needs to be created for AI. Thank you sir. Um rightly put technology moves fast but trust takes time to build and um compartmentalization is a great way to uh de-risk in some form and also

look at it with a focused uh agenda and attention. Uh with that we can actually bring in Mr. Kamat. U Mr. Kamat is from the uh gift city IFSCA a compartmentalized

uh you know global financial hub in a way that India has created and we are very fortunate to have you sir here. Um give city actually operates at a unique intersection of innovation and global

credibility. Uh it competes with the likes of Singapore, Dubai, London. Can give city become a lab for AI governance? And we wanted to know your view sir and especially a great segue

from Sanjie sir on how we could look at it differently and a compartmentalized manner. &gt;&gt; Uh uh see if you if you see gifts as a

jurisdiction uh it is just uh uh it was set up in 2015 so it's just 11 years old. We are building it up from scratch. Now when you build something from scratch and when you have a brand new

regulator like IFSA which was created in 2020 uh you start with a clean slate. So that means you have more leg room and you have uh more space to experiment. So we don't have baggage of the legacy

systems. So if you see uh the way we have evolved over the last uh six years if the way regulations have evolved uh we have all the verticals across finance uh capital

markets, banking, insurance, pensions and we have introduced new verticals uh ship build, ship pleasing, aircraft pleasing, ancillary services and so on you know in line with all other global

financial centers. So uh with respect to experimentation when you use the word lab uh you you you implying experimentation. So the appetite for experimentation and the appetite for

taking risks is is much higher uh than than other say domestic regulators or regulators overseas because of the absence of retail investors. So yes, gift city has an immense ability to to

come across as a lab uh for AI governance. However, building a financial center is a is is is like a 45 km marathon. You know, it's not a 8 km dream run. So it it will take its time.

uh we are on the growth trajectory on the upward trajectory and there is a certain gestation period for every financial center that that period gestation period cannot be skipped we

are in that gestation period so once we reach critical mass you'll you're going to see a lot of things happening and coming out of gift IFCS &gt;&gt; thank you um actually I'll go to Mura in

the RBI free AI report or the framework on uh you know enablement of ethical AI uh I think it's very forward-looking. It is actually building on existing regulatory controls and architecture uh

to bring in uh you know the principal based AI ecosystem. So my question to you is u if a company uh has embedded robust controls, model inventories, bias testing, continuous monitoring, should

regulators reward and discipline such companies with a calibrated supervisory relief? Um and in other words, is there a safe harbor for somebody who's um you know who's uh put in risk based controls

uh but uh uh you know has been a first time defaulter. &gt;&gt; Yeah. Uh in fact in the same report uh it was suggested uh that uh the entities which uh which put in place all the

guard rails and then uh in case of any labs uh if they are uh doing the root cause analysis trying to address the problem uh they should uh have a uh the the regulator should have a lenient uh

supervisory approach uh and it should be seen as a uh it should be seen as an instance rather rather than a uh uh overarching uh risk area. So that is uh something which uh we've recognized. So

on both fronts one is we understand the technology is probabilistic uh and then it can have uh lapses but once in terms of governance if you if you put in the guardrails if you put in

the processes if you put in the uh mechanisms across the life cycle to see that uh uh there's the the customer doesn't face the risk. So that is the main focus the customer uh it should be

transparent to the customer. So it should not be a black black box rather that it can be a a glass box. Uh so so and and it should be understandable to the customers. So once all the measures

are taken uh take uh are taken into consideration by the by the entity in terms of governance as well as the processes uh because of the nature of the technology presently we understand

uh it can it can uh lead to some aberrations but then uh as long as it is uh it is taken in a in a right process uh you have these incident uh reporting mechanisms you have uh the

you'll have the manual override. So the once you have this controls and the and the right approach the uh supervision uh will not should not view it as a uh as a systemic or or a greater risk. uh it

should rather it should allow first time lapse and then in terms of uh say rewarding it it we have also suggested that there would be an award for AI in finance particularly if there

are uh specific works uh done in in terms of say priority sector or or the weaker sections uh the use cases for the global uh or not not global for the for the bottom of the pyramid So these

should be encouraged and then uh uh supported to make it say open source or uh to be used by the other smaller organizations. So those uh those things are already there but then we also the

report also recommends that these should be rewarded and then also help in achieving greater scale. &gt;&gt; Thank you. I think Vikram uh you're a vantage point here because you're a

global infrastructure player. You're seeing regulatory trends across uh the US, UK, Singapore and many other markets. Uh you've heard about uh you know how the panel has been shaping

right from the policy makers to uh international uh the international financial center and also RBI. Uh want to know as a infrastructure provider how are you looking at cyber security and uh

its evolution in the age of generative AI. &gt;&gt; Um thanks so much Vanka. Um I would just make one correction as a cloud service provider and not merely an

infrastructure provider. I think one of the things is um for good or for worse we've seen the benefits of generative AI but we're also seeing bad actors use generative AI for

fishing attacks for credential attacks for malicious code. So you know with the good comes the challenges but one of the more important elements is that while it's serving as

an accelerant to existing methods I don't think it's foundationally changing the nature of the attacks and in fact there was a report that came out in 2025 it talks about how generative AI has

lowered the barriers for a lot of these threat actors but I go back to what I said it's because it's not foundationally changed the same principles and the same

foundations of cy cyber security that held true before geni still hold true. So you know multiffactor authentication, strong passwords, regular updates, scanning your systems and I think it is

imperative for organizations to fundamentally especially in the financial services who are always being attacked and India is a country where not only the banks but we have a huge

citizenry with different levels of financial literacy. So therefore how do you use these tools to actually safeguard the financial system? So I think that in that respect you know a

lot of uh sort of kudos to the RBI for also thinking about it on uh you know on these principal lines but also the banks for actually leveraging these uh technologies and I think that one of the

elements that you need to always do is you know trust service providers like us but also banks should verify and that is done through standards like ISO or the NIST and you know independent uh third

party reports. validate the various controls that are there and and I think that now and it's a point that I was making a little earlier you have to become an active participant in cyber

security no longer can you be a passive passenger in it because the landscape is changing and as more and more people are digitizing so are the people who are willing to and are looking to attack any

vulnerability so geni does provide you with the tools because again I'm also a believer in not you know human in the loop but having AI in the loop So how do you or use these technologies to have

faster responses? How do you automate scanning? How do you automate uh getting reports to be able to make those value judgments at the right time? So that requires skilling that requires

awareness not just about you know something like an AWS or a cloud but also banks and also uh you know the work that again regulators as well as uh cloud service providers are doing is

having these awareness programs to make sure that the more people understand the technology the better the framework and the groundwork will be for them to adopt.

&gt;&gt; Thank you. I think I also refer to our earlier discussion today afternoon wherein rather than AI thinking about a human in the loop uh you know humans think AI as a loop uh you know to move

forward and I think that was a great uh you know paradigm shift that we can look at um Sanjis I'm going to come back to you but I also want to give a um backdrop to this question India has

never simply adopted technology we've created it we've adapted it we've scaled it and we've governed it in our own way. We did it with identity, we did it with payments and we did it with digital

public infrastructure. Um if the governance frameworks around AI are beginning uh to emerge and um they are also being divergent globally like US being innovationled, EU being

complianceled, China being stateled. where is the axis that India is going to strategically position itself and how are you looking at it uh from your lens? &gt;&gt; So I think uh I'll continue from what I

was saying earlier. Um we [clears throat] need to be very very careful that we don't end up with a bureaucratic risk based system. This is an emergent technology. It'll evolve in

all different ways and we'll have to be very very creative about this. Now there is a difference between say uh the systems uh as a architecture AI as a is an emerging thing. It's not just

infrastructure in the sense that say you can think of UPI as infrastructure for example uh digital identity as infrastructure. Um it doesn't in itself have emergent behaviors. AI has emergent

behaviors i.e. it evolves and interacts with other forms of AI. And which is why I said you need to be fundamentally suspicious of anybody who says that they have very clear idea where this whole

thing is going. We don't at all have a clear idea. Nobody in the planet has a clear idea where it's going. So we do need uh some regulation of having human in the loop. Uh as I said right in the

beginning, you need to have systems switch off buttons. um you need to create um um what are called in finance Chinese walls uh which separate different tracks as I as I said earlier

I am not a huge fan of the AI of everything I think that's dangerous uh and will lead to bad outcomes however AI can be run in compartments rather well and why don't we use that because in any

case that's less energy using and any case it is better at solving bounded problems. When you give AI an unbounded problem, it tends to hallucinate because unfortunately it has learned uh

another uh human uh trait but it doesn't like to tell you that I don't know it rather make up stuff. So consequently I think it is better that we deal we give it bounded problems let it solve those

bounded problems and get back to us going for this AI or internet of everything which everything is interconnected sounds very good but just it was last July or was a bit July

before that we saw when one very small code of a Microsoft uh uh program which was by the way static it wasn't even a fluid one. It went wrong and you ended up with causing havoc in airports, ATMs,

all kinds of things around the world. Now imagine the same thing happening in a system where the the it has emergent characteristics. It by the time you've fixed one bit of it, it has flowed into

some other part of the system. So I personally think we need to create uh firewalls. Um you know forest fire is also an emergent thing and the way we control it

is not by predicting where the fire is coming from and where it will go. We just have these firewalls from time to time. Uh we do that in finance all the time. We don't try to work out what the

conflict of interest is. We simply ban situations where conflict of interest will emerge. Um and the same thing is true of skin in the game. I think we need to exante work out where in the

chain is the responsibility. I personally think that it should be done at the level of where the algorithm is made public to use. Whoever is making it even if their data is wrong, you cannot

blame the data. You're responsible. So somebody else may disagree. Whatever point of the matter is we need to have very clear points of punishment when things go wrong. We need to have uh

audit systems for explanability. There's nothing very deep about this. After all, every uh company listed in the stock market has to audit itself several times a year. Why can't we ask major uh AI

companies to be audited? If you cannot explain why your results are turning up, too bad. you shut it down. We do that even with you know relatively small companies have to go to a chartered

accountant several times and chartered accountant has to sign it off. Maybe we have a chartered AI audit for uh for anything that goes beyond some threshold.

And I think given how potentially dangerous it is and I I don't and and lucrative it is as well I don't think we should be um you know uh thinking about this um as a problem rather than doing

what I think many others say okay they understand it's dangerous they will say but why don't we have risk based now x anti you cannot work it out all you will do is you will have technologies that

are just uh you'll end up with regulations that will become just too stringent and will kill the sector rather along the way you have a system of explanability audits with that let me

hand it back &gt;&gt; Mr. Kamat I'm going to come to you. Um economists worry about tourists under regulation that creates instability and overregulation that will kill dynamism.

Uh where do you see GIF city? Uh you know because again it's at an intersection of glo and hear your views on it. &gt;&gt; Yeah. See that that's the problem facing

all regulators worldwide across financial sector. Overregulation repels innovation. Under regulation repels serious long-term capital. So now where do you draw the balancing equilibrium

point? Uh let me explain it with an example simple example. I joined SEBI securities and exchange board of India in 2008. I was posted to the surveillance department. Uh in 2008

itself the financial crisis was in full flow. So in our surveillance systems which which are very very powerful systems we noticed 10,000 orders being entered in a span of couple of

microsconds. So we were wondering how is this possible? How can a human enter so many orders? Then we came to know algorith algorithmic trading terminals have been deployed by certain entities

in the stock market. When we dug deeper we came to know that initially it was deployed in 2004 by one entity and then slowly slowly it was the volumes were increasing. I mean it didn't reach a

critical point but they were slowly increasing. Now in 2010 the inflection point came when it reached a critical mass se came up with guidelines to protect uh safeguard the retail

investors and to preserve financial stability. So here is a perfect example where an innovation in the capital market which is algorithmic trading was deployed by entities for for a good six

years. It was not regulated. It was being used and the regulator didn't do anything to to stop it. But when the regulator issued the guidelines, the necessary safeguards were put in place.

However, at the same time, there were no breaks applied on the rollout of the innovation. So algorithmic trading even after the guidelines grew exponentially in the Indian capital market to where it

is today. So in the same manner we hope to facilitate innovation in gift if at we we have sandboxes in place uh for startups as well as established entities they can roll out their AI pilots in in

the sandbox. The goal is to cap the risk. Uh like sir said it's very difficult to identify all the risks but whatever possible risk can be identified. Let's cap the risk without

going into the technical mechanics you know the internal mechanics and then see how it flows out based on the data that you receive in the experimentation accordingly the regulations can be

tailored. &gt;&gt; Thank you. Um I know we are at time but I'm going to still extend because I have such a prestigious panel uh by another few minutes. I'm going to come back uh

to you uh with a quick rapid fire. Uh if you could tell us one risk that we are underestimating when it comes to AI. &gt;&gt; Uh no uh in general we would not like to

talk about risk. So that is our approach. Uh Mr. uh our keynote speaker Ajit Chri was also at the helm when the department was formed. So it is uh uh risk is uh maybe underestimating the

risk that is what I can say that can be addressed only through the governance uh particularly in the in the present uh emergence of technologies

&gt;&gt; actually I like what Sanjie sir was telling us it's never going to be risk- free but we'll have to move forward we'll have to figure it out and we'll have to do it in a as much as possible

compartmentalized manner so Um any risk that we are overestimating? Anybody from the panel who wants to talk about any risk that we are overestimating? &gt;&gt; Let's give Vicram a chance.

&gt;&gt; I mean I think the fundamental nature would be there is no zero risk is how do you equip yourself to handle risks because I think a point that Mr. Chri Mr. Sel also made is as a regulator or a

regulated environment. How do you create the tools to be nimble to adapt as the technology adapts? And I think that that is the important element. Right now the tools are there. There is so much we can

do that we're not maybe we're not doing as well. So maybe we can focus very well in the here and the now and equip ourselves to be nimble enough to deal with anything that comes because anybody

who's telling you what's coming with a certain amount of certainty I take that with a pinch of salt. I think that the future is a little unknowable at this point of time but there are so much so

much that is known and you know we should be able to tackle that right now. &gt;&gt; Thank you. I think that's great. Say I'm going to again come to you. One reform that India must prioritize. what is your

view on &gt;&gt; that's a long uh issue um I have said this before uh and this will relate even here I do think we need to begin to prioritize speeding up our judicial

system because one of the things that's going to happen that as AI evolves it is going to throw up new kinds of problems that we haven't dealt with before Um

now there is no way xante we're going to work out what those problems are or what are the sensible solutions uh to them. Um if that is the case then I think the judiciary will be uh an important play

an important part because we are a common law country and when disputes of of of this new nature turn up uh then what is going to happen is that you will require for example uh let's say AI

gives you a particular kind of outcome somebody uses it to do something and it turns out to be a disaster who pays for the uh damages for Or for example in copyright law, who is

the owner of a particular innovation? At which point do you call it an innovation? Um and and is that innovation owned by the person who put the prompt in? Is it owned by the person

on whose data it got trained or it belongs to the algorithm that uh created that innovation? So all of these I would say that we need to begin to think of a judicial system that can deal with these

kinds of problems. We already have a clogged judicial system. But do remember that these uh very different kinds of uh and I would almost call them philosophical problems are going to turn

up at our doorstep very very quickly and we need to be thinking about them. &gt;&gt; Thank you. Um when UPI came in I think about a decade ago and we have the benefit of having the NPC chairman

himself being in the room. I think it was uh more than payments. It was trust in an invisible system. And today AI is becoming that invisible system that is sitting quietly in our credit

underwriting decisions, our onboarding flows, grievance redressal systems, even regulatory reporting. Uh and I think that's um it was a great discussion to talk about how do we embed trust in an

AI system that is fast evolving. uh because at the end of the day we're thinking about the theme of the summit which is people, planet and progress all in the same breath. uh people how do we

protect them from opaque systems or bias planet how do we scale sustainably and responsibly and progress because it doesn't have to be only fast innovation it has to be fair innovation so I think

a lot of great thoughts today that came in uh in the panel discussion and I'm extremely grateful to everybody uh who made time to have this discussion uh Sanjep sa we could have some closing

thoughts from your side Well, you mentioned uh trust. Let me say that uh uh while it is uh fair to trust uh UPI uh but as I said it is relatively speaking not an emergent system

deliberately in fact uh you don't want the UPI to be innovating on the interface. It can innovate at the back end however much you want but you don't want any surprises. I send somebody 100

rupees and he gets 120 rupees or 80 rupees or on average you will get 100 rupees that can't be the basis of a UPI. So in that sense the UPI based system is an backbone infrastructure. It is not

deliberately emergent. But AI systems are emergent. It can give you different answers at different points in time depending on what it's trained for, what is the

context, what is the things you have. And in fact, that is the innovation. If you if you fix it in a box to start with, then you won't get the innovation. But on the other hand, if you give it

some open-ended thing, yes, I presumably it will improve, but sometimes it may deteriorate. Sometimes it may lie to you. So in that context what I'm trying to say is that in the case of

artificial intelligence we should use it but we sh certainly should not trust it. Uh in fact its future is based on a certain level of skepticism healthy skepticism that we

must have about its capabilities. um it will do amazing things but in my view we should be clear that it is probably much much better at solving bounded problems. It can play chess for

example very very well but I doubt it can plan your career. It's an unbounded problem. So in if that is how you think about uh AI then uh what you need to do is to as I said begin to think this

through uh in uh in in terms of how you apply it in particular boxes and uh and where it has a clear set of things that you're trying to do. So as I said bounded problems and even there verify

Um with that we have audience questions. We have one question from Adita the founder of first high. &gt;&gt; Thank you. Good evening. Uh that was an incredible set of points that came up

actually made some really interesting notes about the capital markets equal in Sanjep that you drew. I thought that was a really interesting way of looking at AI and we've been in so many summits. I

think this is a very very interesting way that uh you've put it about risk and uh exante versus postante. Um I had one question for you and I had uh two suggestions or requests for Pravin and

Mr. Muri. uh from a AI stack perspective, every uh every summit or every conversation across different countries is um looking at all the different components of the stack and

there are two things that kind of come up in most of these conversations which is around sovereign data asset and leverage that comes out of it in terms of tools and models and so on. what

where is India's perspective in all of this from a sovereign data asset utilization the model leverage and I think different countries are looking at their stack as their stack and which

they're going to give you access and so on and so forth so I think that is something that'll be great to get your perspective so obviously India with its uh very large population has stacks of

information on all kinds of things from health to consumer behavior etc. So in some ways this is a good place for uh huge amount of data for experimentation on human behavior and so on. But of

course um you know if data is the new oil then you we need to be clear that we own uh those rights if it's our data uh I mean I'm not even getting into the privacy issue. I'm assuming here that

it's all uh that has been taken care of. Uh so we are using anonymized data but even then we we should at least have the rights to that data and also to some part of the processing of it. Um there's

no point in u and uh saying that you know um that we have the data but we neither have the rights to it uh or and nor do we have the oil rigs to pump out and pro and or the refineries to process

the new oil. So this is the context in which you may have seen in the latest budget we announced uh almost quarter of a century uh sort of tax holiday for putting up data centers in this country.

Uh that's not a trivial thing to do. Why are we doing it? Uh well basically because as I said uh data centers are the oil rigs of this new kind of oil and then of course we need new companies

that will process this oil. Um those are the new I we have created one AI LLM but frankly everybody gets very excited about LLM. LLM is only a very limited in my view not even the most interesting

usage of artificial intelligence. It just happens to be that it is linguistically talented uh and consequently you know we use it uh for that. But

there are many many more interesting uses of AI. And as I keep coming back to you and stating that we need to create an ecosystem and that ecosystem we all say oh you need to have you know

half a trillion dollars of investment to create actually no much of where you will end up with this use or these refineries so to speak will be quite uh bounded problems in in certain spaces.

So there is more than enough space for uh startups with much more modest um budgets to do interesting things in AI. And I'm not just talking about people building use cases on other people's.

I'm saying literally bottomup uh uh uses of AI. So I think uh there's a lot to be done here. It's an open space. Um this is basically like discovering the Americas. Um but uh you

know yes Spain did have a initial uh sort of uh starting advantage but the great empire in the world was actually built by Britain uh which was actually a late

starter. So there are many many countries in the world who you do not think today to be a particular player in this game who will also turn up here and one of them could do much much better

than the the guys who you think are at the cutting edge today. So this is an emergent situation with all kinds of um what's unintended consequences uses positive and negative will happen out of

all of this. I think the key here is to be nimble keep your eyes open including on the regulatory find and do not have set ideas where this whole thing is headed because frankly we don't know.

&gt;&gt; No thanks for that. Um you know we uh I'm the founder of first time which is a customer data platform. We work with a large number of enterprises on data all consent and so we get a ringside view to

the application of all of that that you're saying and this kind of leads me to the suggest &gt;&gt; supplement we have AI course which is a uh which is a repository of data sets

which is which is growing and then for the financial sector as well we are looking to uh say uh aggregate to start with synthetic data and then maybe uh take up uh take correlate data from the

uh regulated entities. is with their concept. So that will come in. &gt;&gt; Okay. Awesome. Actually that kind of goes towards uh my suggestion bit for the two of you which is I think uh you

know brain when you spoke about the sandbox from an IFSCA perspective. I think the ability to extend that beyond just IFSCA to you know also the other regulators in is is something I think

will be very very interesting for uh at least folks like us because we work with a number of entities which are which cut across different regulators and an associated point is uh you know today

there are so many regulations that come in and I think there's a lot of there are two two opportunities that I see exist one is there is different interpretation of the regul relations by

different entities and second is as a large data processor not a data owner but a data processor I think there are there is stakehold we are one of the stakeholders in that whole process and

today we may not have the adequate access or a seat at the table from a uh regulatory interpretation standpoint and there there is I think an opportunity for us to define something which is like

you know what is a consentbacked API for data consumption for example and having a regulatory definition of that with participation from a data processor like us and we'd love to kind of uh see if

there are processes that allow somebody like us to engage with the regulators. &gt;&gt; Uh uh I we we are open to that idea but but you have to remember one thing I is a jurisdiction you know it has it set of

rules which are different from domestic India. Uh so there is a interoperable sandbox mechanism in place between IFIC, RBI, SEB and AI. So a solution that spans across the four

regulators can be tested within the sandbox. But the issue is not technological or or financial it's legal. Uh for example in India INR transactions are are the norm right in

IFSC INR transactions are not permitted. You have 16 foreign currencies that are enabled and you have to do transactions in those 16 currencies. So if you if your solution is not compatible across

these these areas just to give you an example then you know the sandbox experimentation will not go through. So there are lot more nuances like this you know which uh which affect the rollout

of pilots within the interoperable sandbox. So just to give an example &gt;&gt; uh with respect to uh movement and processing of data I'll not comment at the moment uh because there are certain

things in works in IFSA. So I leave my RBI colleague for that. Yeah. Uh so just uh like uh my colleague said we already have an interoperable sandbox across regulators uh and it is on tab. So so

earlier it was uh it was uh theme based but then now it's on tab any type of product can uh can be tested in the sandbox but just to clarify on the sandbox it is only when the regulated

entity feels uh that the existing products or service is violating one of the regulation. So there are very few number of entities which come to the sandbox because in general they are not

required to be uh required to come to the sandbox. If if they if they feel they are compliant to the regulations there's no need to come to the sandbox but we but then we

are also thinking of another sandbox where we also provide some uh more than in terms of monitoring the regulation we can provide we can support the innovation in terms of say compute data

or tools. So that is that's also in the in the thought process. &gt;&gt; Okay. you've been one of the beneficiaries of the sandbox and the hackathon uh at five money and uh the

process has been phenomenal the way the RBI fintech teams engage. So maybe Adita I can share some uh notes with you offline but I think thank you this has been a phenomenal panel and a great

discussion on embedded governance when AI is making space in all things financial services how do we make space for governance in AI that was the theme of the discussion and I'm very pleased

to hear the views of this panel and I'm grateful for making time thank you everyone &gt;&gt; thank you u I'm I'm actually not going to say anything more apart from the fact

that thank you and we will have a quick uh give off the momentos from India mission. So my criti my colleague Kiti will uh will do that. So starting with Thank you. [applause]

Thank you. &gt;&gt; Can I insist all the panelists to stay back for another group picture? Yes, please.
