# Smaller Footprint, Bigger Impact: Advancing Resilient and Efficient AI Models for a Sustainable Future

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 14:30 ‚Äì 15:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 10 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/hZ8Ny0MfNhA?feature=share) |

## üé§ Speakers

- Dr Tawfik Jelassi, UNESCO
- Mr. Arthur Mensch, Republic of Kenya
- Ms Anne BOUVEROT, Government of France
- Ms Anne LE HENANF, Government of France

## ü§ù Knowledge Partners

- French Ministry of Environment

## üìù Summary

Generative AI now serves a large number of users daily but comes with significant energy costs, which may contribute to unequal access. Training and inference at scale consume substantial electricity, and research suggests that more efficient model design can reduce energy use significantly. This event highlights resilient, resource-efficient AI leveraging lightweight models, compression, and optimization to reduce energy demand, broaden access, address emerging energy bottlenecks, and support sustainable AI deployment worldwide.

## üîë Key Takeaways

1. Generative AI now serves a large number of users daily but comes with significant energy costs, which may contribute to unequal access.
2. Training and inference at scale consume substantial electricity, and research suggests that more efficient model design can reduce energy use significantly.
3. This event highlights resilient, resource-efficient AI leveraging lightweight models, compression, and optimization to reduce energy demand, broaden access, address emerging energy bottlenecks, and support sustainable AI deployment worldwide.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/hZ8Ny0MfNhA/maxresdefault.jpg)](https://youtube.com/live/hZ8Ny0MfNhA?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

And this is what we will explore at this event. To introduce the topic, we will first have two distinguished speakers. First, I have the honor to welcome Mrs. Anne

Luenf, France Minister Delegates for AI and digitalization affairs. Welcome, Madame Minister. [applause] Excellencies, distinguished guests, ladies and

gentlemen, it's an honor to address you at smaller footprint bigger impact co-organized by France UNESCO and the sustainable AI coalition. This event is the continuation of the work co-chared

by India and France in preparation of this AI impact summit putting resiliency, sustainability and efficiency at the uh art of the global agenda. The question we face is no

longer how can AI work for us but how can we ensure AI works efficiently, responsibly and fairly for people and for our for our planet. Resilient and sustainable is the key to

unlocking digital transformation. Environmental protection and inclusive development. Sustainable AI is not an option. It's an imperative.

First, it's an energy and environment imperative. As governments decarbonize, AI's energy demands threaten to outpace green energy progress. Model providers face a stark reality.

AI's energy needs are growing faster than supply. Second, it's a fair fairness crisis. massive AI models without sustainability creates new divides and can exclude

regions and communities lacking resources. That is why France at the AI action summit made sustainable AI a priority through the sustainable AI coalition

launched with UNEP ITU and India as a founding MA members. Our goal leverage AI to solve environmental challenges without exceeding planetary boundaries. From 90 initial partners, we

have grown to over 220, including tech firms, startups, utilities, NOS's, and research institutions backed by eight international organizations and 15

countries with the Netherlands joining this year. Sustainable AI is now a glo global priority embedded in the U

and global digital compact and a U a UN environment assembly resolution to turn vis vision to action. We focus on three pillars. First, research. In 2026, the coalition will launch AI research pitch

sessions to connect university projects with funding and industry partners. Second, measurement. You can't improve what you can't measure. Today I'm proud to announce on behalf of the coalition

ITU the Institute of Electrical and Electronics Engineers and ESO that we published the second version of the global approach on standardization for AI environmental sustainability to

promote consistency in AI environment sustainability centralization. And third action France is imple implementing policies for low carbon efficient AI powered by renew renewable

energy hosted in green data centers and designed to be learn leaner and small smarter. This approach is boots boosts competitiveness competitiveness and discovery with minimal environmental

costs. That's why as an AI summit impact summit outcome, India, France and UNESCO launched the resilient AI challenge, a global

challenge to en advance compressed more energy efficient AI models. This initiative supports innovation aligned with our shared goals. Sustainable and resilient AI must be the global

baseline. The only path to equitable development that services people and the planet. France and India have led this effort from Paris to New Delhi by focusing on

people, planet and progress. Now we must deliver together. I look forward to our panelists insights and now invite to continue. Thank you. [applause]

Many thanks uh madame minister for this uh insightful introduction and the pioneering role of France in societal AI. I have now the pleasure to welcome Dr. Tafi Jalassi, assistant director

general for communication and technology sector at UNESCO whose landmark report on smaller models was published in uh July last year. Madame Minister,

Madame Longa, distinguished participants, esteemed colleagues, dear partners and and uh ladies and gentlemen, I'm very pleased on behalf of

UNESCO to be with you this afternoon for this important session. But allow me first to raise a question. What if the next breakthrough in AI is not about building ever larger models,

but about building leaner, more resilient systems, systems that can solve whole world problems and real world constraints, including in low resource environments.

Before turning to the resilient AI challenge, I would like to warmly thank the government of India for its leadership in convening this timely, strategic and important forward-looking

summit. I also would like to acknowledge the co-chairs of the working group on resilience, innovation and efficiency, the ministry of power of India and the ministry of ecological transition of

France for their strong commitment, engagement and stewardship. My sincere thanks also go to our technical and ecosystem partners including Mistal Google Hugging Face

Alam AI and the broader sustainable AI coalition alongside many academic experts who have contributed to this collective effort. UNESCO is proud to

serve as a key knowledge partner for this initiative and to support the vision of India regarding AI that truly serves the people, the planet and prosperity.

I would like to convey briefly three messages. First, the future of AI will not be defined by scale alone but rather by resilience. Second, resource efficient AI is not a

trade-off. It is a path to inclusion and access. Thirdly, delivering impact at scale requires a global collaboration that is truly grounded in real world validation.

We are at a crit critical inflection point. Generative AI tools are now used in more than by more than 1 billion people on a daily basis. Yet behind every prompt lies a growing energy and

resource for foot footprint. Inference already amounts to hundreds of gawatt hours per year and this is comparable to the annual electricity use of millions of people in lowincome countries.

Training frontier models is even more energy intensive. A single large AI model can consume over 1,000 megawatt hours of electricity, enough to power villages across India for a whole year,

placing increasing pressure on energy systems and reinforcing inequalities in access to compute and infrastructure. These challenges are not theoretical. They are real.

They directly affect whether AI can be deployed in public services also by small medium-siz enterprises in rural health systems and low connectivity environments both in

developing countries but also in advanced economies facing growing energy constraints. This is why the next breakthrough in AI will not come from building ever larger

models. It will come from building smarter, leaner and more resilient systems that can deliver impact under energy constraints rather than exa exacerbate them. A proverb says a good

life is for everyone. It captures the spirit of living well together in community inclusively and in harmony with our planet. In the same spirit, AI must be designed not only for those with

the greatest computing power, but for all communities everywhere around the world. The work of UNESCO shows that small but conscious design choices such as model compression, task specific

architectures, and optimized inference can reduce AI energy consumption by up to 90% without compromising performance.

Resilient AI is therefore not only greener, it is more inclusive, more affordable, and more adaptable. It lowers barriers for researchers, empowers local ecosystems, and enables

AI solutions to reach communities too often left at the margins of the digital transformation. This brings me to why we are here today. It is my pleasure to officially announce

the launch of the resilient AI challenge which is a flagship initiative under the India AI impact summit working group on resilience, innovation and efficiency. This challenge moves us decisively from

principles to action. It brings together model providers, researchers, startups, and academic teams to demonstrate how open-source AI models can be optimized, compressed, and deployed to achieve

strong performance while significantly reducing the use of energy. Rather than comparing entirely different models, the challenge focuses on improving one base model per task,

ensuring transparency, fairness, and rigorous benchmarking. Submissions will be evaluated on shared infrastructure and ranked by both uh on both accuracy and energy efficiency,

generating clear and actionable evidence. The winners of the challenge will be announced at the AI for good summit this coming July in Geneva. But the real success will be of course much

broader than that. Stronger evidence for policy makers, [snorts] deeper collaboration across regions in the world and the global shift towards AI systems that respect both a human and

planetary boundaries. Let me conclude with a call to action. Resilient AI is not a niche concern. It is the foundation for trustworthy, scalable and f futurep proof AI. I

invite governments, researchers, innovators and partners especially from India and the global south to engage actively in this challenge and to help us shape a new generation of AI that is

efficient by design and inclusive by default. Together we can ensure that the impact of AI is measured not by how large our models are but how widely, how

ethically, how responsibly and how sustainably are the benefits from AI. Thank you. &gt;&gt; Many thanks Dr. Jalassi, Madame Minister for setting the scene and challenging of

challenges of this topic. Before we uh delved into the panel, I will invite uh the keynote speaker and the panelist to go up front for a picture that now that we have the final uh lineup, please. And

then we'll start the panel. Happy birthday. Thank you very much. Thank you very much. Um, so now let me uh welcome our

distinguished panelist and Mrs. Anouvo spe special envoy on AI for France, moderator of this panel to discuss how to make these models work and deploy in real life to the benefit of all. Thank

you so much. Thank you very much uh Elena. Uh thanks um to uh the two keynote speeches that we just had. First um without further ado, I think what we

want is to head into the discussion. So I will not make long introductions. I'm delighted to uh welcome our distinguished guests. James Manika, senior vice president Google Alphabet.

um Archio Mench uh CEO of Mistral AI um Abishek Singh um uh lead organizer of this summit. A round of applause for him please. Thank you. Um and uh Ambassador Philip

Tiggo, ambassador and tech envoy for Kenya. Thank you. [applause] Um so the AI industry um according to the intern international energy agency

uh will probably consume 3% of uh worldwide electricity production uh by uh 2030. Uh this is not the end of the world but this is a huge expansion from its current consumption. uh and

therefore uh there are uh uh environmental costs and impacts that we need to uh mitigate. AI of course at the same time also creates opportunity to optimize resources um uh including um

energy. Um so um uh how can we ensure that AI's development in particular in developing countries but everywhere uh as well uh is something that comes together uh with um uh a focus on the

planet. I'll start with a a question for ambassador uh Philip Tigo. Let me turn to you first. Um uh you're an attractive proponent of active proponent of a more efficient uh and sustainable AI. Uh

Africa is one of the most energy constrained regions. Um it's also a continent where adoption uh is is uh becoming uh very fast. We saw that with mobile phone payment. We saw that with

other technologies. How is Kenya approaching efficient AI? What can you share with us please? &gt;&gt; Thank you so much and I'll be very quick because I can see the ticker. I think a

couple of things. One is that uh we're very lucky as a country that our energy mix is already 95%. And we keep on investing into that. So we have geothermal, we have wind, we have water,

we have solar and we have hydro. So that's the first um the first kind of framework that we have that we it really must be green by design. Um the second part of course is that where the green

comes in is always not necessarily on the on the efficient data centers or how they're energy efficient but also on the use of it. So part of part of our green by design is also kind of widescale

education around how people use these resources. For example, you shouldn't be looking for the next Starbucks for example when you're using AI. You should should really be using Google as an

option. So people need to have those choices. &gt;&gt; Yes. &gt;&gt; Uh in in in their heads by design. The third part of course is protecting Kenya

alone is not enough. Uh you can put a green shield around the country but AI is global. So the third part quickly is is working in the international framework. So as you know we we worked

course with the coalition on sustainable AI to champion the first ever AI resolution environmental sustainability and part of it had the four parts right the energy the life cycle the

sustainability piece but also the the the the improving the state of the science to continue to understand the energy efficiency components of AI &gt;&gt; excellent thank you so much and we'll

we'll try to keep this uh lively my next question will be for James for James Manika uh Google is one of the key players of course Mistral as well and hugging face but you're a key player in

publishing transparent uh data on environmental impact of AI and you develop both um very large frontier models uh and also smaller very efficient models it's the Gemini and the

Gemma uh uh family uh from a business and an engineering um standpoint where is the real frontier is it scaling up or scaling down Well, thank you. Pleasure to be here um at the summit with you an

I I think just to get to the question uh we're actually looking at this on multiple fronts. On the one hand, if you look at for example our Gemini models, it's not one model. Uh we have a whole

model family which starts with the Gemini Pro goes to the Gemini Flash models which are some of the most efficient models. So we're trying to make sure with our models like given our

family we cover the performance efficiency frontier of these models. You may have noticed that recently no one really talks a lot about model size two years ago. used to be the big craz

how many parameters and that's because even with the pro models we're now pursuing these mixture of experts architectures where the activation of the model doesn't activate the entire

model no one &gt;&gt; so on the Gemini models we're trying to cover the performance and efficiency frontier then we also have Our Gemma models our Gemma models are our most

efficient open-source open weights models. In fact, here in India, uh on AI Kosh, which is the platform in India, we actually have on there 23 Gemma models and that's because we've optimized them

for different sizes. Some of them are efficient at run on a single GPU uh because we know that the needs on the edge, people want a variety of model choices to make sure we drive

efficiency. I'll say two more quick things very quickly. Every year we focus on efficiency because it's both in an from an energy point of view, from a computer efficiency point of view, even

from a business standpoint, it's the right thing to do because as you start to serve many more people, you want the most efficient systems. I'll say one last thing finally which is uh you know

we are making probably extraordinary probably the most investments of anybody into using green energy clean energy for our energy for our computes. In fact we've made this audacious goal that some

point in the 2020 2030 2035 era we want to be 247 carbon free. So we've made investments in nuclear in in geothermal. We actually have several operational data centers in geothermal. We're using

hydro uh we're using wind and solar. So we're m making we're trying to get to a point where all our energy uses for our compute is carbon free. That's our kind of our moonshot goal.

&gt;&gt; Excellent. Thank you so much. I'd like to move to um Archer Mench to um Archer. Um uh Mistral is developing very large models but but really also being very good at uh high performance um uh

compact models. And I know your engineers and and you as a co-founder and CEO also strongly believe in uh the environmental impact of AI and and what can be done there. So um uh what can you

um uh share with us on that and and uh with your both business and engineering um uh experience where does model efficiency have the highest return? So I would say

&gt;&gt; you can thank you &gt;&gt; wonderful teamwork. &gt;&gt; So I would uh I would start with a couple of technical aspects. So to James point uh the model size is indeed not

only the only thing that we should be looking at uh effectively now we're using sparse mixture of experts because those are uh models which have a lot of parameters to store knowledge but that

where you only activate 5% of them. So that has been a key way of reducing the number of flops you do to generate one token which is the one thing that matter for energy and therefore for carbon

intensity. It's one of the multiplayer actually. Um so the sparity matters uh and then you the the other thing that matter is the systems on top. Um I would say the the caching systems that you can

put the the way you're you're managing the context so that you're not reprocessing information and uh beyond uh just releasing the model weights that is something that we've always done.

We're also heavy contributors to to inference frameworks uh that are doing more and more advanced uh uh that are using more and more advanced technology uh to handle the caching systems uh in a

way that where we are actually removing the wasteful computations that we used to do. So it's a it's an algorithmic problem. It's actually very interesting. Uh it's also a machine learning problem

because depending on the request that you're getting, you can actually routt uh the request to a small model or to a large model. And so to James point, it's actually very important for any company

doing models to actually have small models all the way to large models in particular because the large ones can be used to make specialized models uh uh after that. So

&gt;&gt; very important point. &gt;&gt; So that's that's an important point. I would say if you look at the carbon footprint today of artificial intelligence because most of the GPUs

are currently being used for training. Uh I would say most of the waste comes from the fact that you have around 10 labs in the world that are training models that at the end look very

similar. uh and so for us if I look at uh our biggest leverage there uh the fact that we've been open sourcing models that are very large and uh and we've been open sourcing our our best

models really uh is have been a a major way of reducing the externality cost that we're producing uh because we're investing and it cost a lot of of of carbon to actually train a model but

then we give it for free to to everyone else and what that means that people can build on top and that's amortized cost so suddenly you don't have 10 10 companies doing and training the same

kind of models. Uh you only have but uh you you you this thing is out there and you don't need to reinvest. So I think that's the big part. Now on the in so that's really on the training front and

today training is the thing that takes most of the cost and it has the biggest externality cost uh when it comes to to training. Now, um, when it comes to, uh, to our own approach to, uh, to

sustainability, uh, and I think I agree with James, the the one of the multiplayer is the carbon intensity of your energy. And so there is a locality aspect to it and we've been building our

data centers, uh, and and training our models recently. We've been training our models recently on our own hardware uh which sits in in in France uh which France is uh is heavily nuclear so the

carbon intensity is low &gt;&gt; also 95% Philip sorry &gt;&gt; yes &gt;&gt; and in Sweden uh it's not it's not 95%

uh but &gt;&gt; still very good still very good &gt;&gt; but uh in Swed and in Sweden where where you have hydro so uh choosing the locality is important because it's one

of the multiplayer that you want to optimize for and finally the one thing to worry about is I mean model size is one thing, carbon intensity is one thing and then chips are also another thing.

So being able to use the diversity of chips uh is super important and we are investing on using new kind of chips that are uh much more efficient from an from a from uh from a an energy

perspective. Now to James point I would like to add the good thing about AI is that we are energy constraints and so suddenly it means that efficiency is actually driven by business. Uh so I

mean I I would say transparency is super important for us and it matters for our customers. So we give uh we've done like a very deep study on how that works and and the carbon intensity or for

training. We've done it with Mr. Lash too with third party uh uh auditors etc. But the business is also driving the reason it's also a reason why we're going to toward more efficient models

because we don't have enough energy. we need to have things that that run on on smaller hardware and it depends on the countries as well like uh there's actually the US the constraint is higher

than in Europe I think it's high it's going to be very high as well uh in Africa and in India down the line so so uh it's always good when business aligns with uh with with climate yes of course

you can I think it would be valuable for uh public procurement particular to put more pressure on uh on on sustainability uh as a way to accelerate to accelerate the industry uh because that's that's uh

that that raises the stake and so that also pushes us to want more efficiency. &gt;&gt; Wonderful. Thank you so much. I think that was really Do you want to react quickly James before we go to

&gt;&gt; Abishek? I was I was going to agree with with Arthur but maybe add a couple more components. One of the things that is also important in this conversation is what you actually apply AI to. So

there's a whole range of applications of AI that actually are helpful for sustainability. Grid management uh with the adaptation and effects of climate change and we're seeing a lot of those

kinds of applications at scale in ways that make enormous difference to the sustainability question. &gt;&gt; Say adding to that you have agriculture as well where we have a lot of leverage

uh you have material science and chemistry so we work with vertically companies to try and make that happen. &gt;&gt; Great to see this exchange I think we have a very high quality exchange in

this panel. Uh Abishek I'd like to move to you and and um yeah and the microphone as well and and Archer actually introduced the fact that um energy constraints are real and and

they're real in India of course and you have such a high uh uh population and and wide market and also of course infrastructure uh constraints. How do you approach this? How does how does the

AI uh uh mission in India approach this and and and what are you doing on this front? &gt;&gt; Like uh thank you thank you for and excellent thoughts by the tech leaders.

uh so like sustainability will is an issue not only in India everywhere because ultimately the way AI is being built out currently we are in the phase wherein we are pouring in billions of

dollars into building the infrastructure building the compute building the AI factories with the hope that ultimately this investment will pay out but when we ultimately look at how it will pay out

it will come out through inferencing and we are doing inferencing at scale ultimately users will have to pay So until unless you have focus on efficiency and sustainability actual ROI

on the investments will not work out. So it will be in the interest of everyone and only those players will survive who actually ensure that per token energy use is the minimal. So it will require

innovation at multiple levels. It will require innovation at how do you do the to uh the algorithms, how do you you do the inferencing, how do you use it and therein the value of small language

models will come in. While it's fashionable to go for a trillion parameter model and more, but ultimately if you are building use cases in key sectors like healthcare or education or

agriculture, you'll need to go through smaller models which will be consuming less energy and which will able to cost less. The sustainability is something that is given. So what we are doing of

course in India AI mission and in India is number one we are not chasing the trillion parameter model. We are not in the parameter game number one. Number two, we are not even right now at the

stage in which our companies are. I don't think anyone of us is done chasing AGI which is like glamorized by some of the frontier AI models. We are trying to think of what are the solutions which

can be built by using current level of models which are available which can solve societal problems in various sectors to have real impact. &gt;&gt; Real impact for you.

&gt;&gt; Yeah. So ultimately yeah exactly. So, so and when we do that the cost per inference, the cost per query is something that becomes material because many of the public sector applications

especially in sectors like agriculture or healthcare, education for some time will have to be funded by government which will mean the taxpayers money that we cannot be extravagant in doing that.

So ensuring that the pees of data centers are lesser ensuring that grid efficiency we have in fact we are doing a project with the ministry of power which is I think finds a mention in the

resilient uh uh committee's report also wherein we are using AI for improving grid efficiency reducing the transmission distribution losses and what we have felt is that doing it

smartly and using technology for doing that brings down the T&amp;D losses by almost 10 to 15%. That's again a big big gain. So we'll have to look at the entire ecosystem right from what kind of

chips you're using for what if you're doing inferencing do you need the highend uh high-end chips for doing that. So classifying it having a very sector specific application specific use

case basis uh approach for designing your systems will ultimately be where the game is and those who are able to do that will be able to build more sustainable systems their cost per uh

query will be lesser and they'll be able to survive. We as government we are trying to enable this but ultimately I feel that business sense will ensure that sustainability comes in. We cannot

be it cannot be like that we can consume as much energy as we want and mindful of the ramifications where the funds and the VCs will pay only till a particular time. It cannot

be forever. &gt;&gt; Excellent. Thank you. We're unpacking a number of things and we're unpacking training from uh uh inference and utilization. uh we're unpacking large

models with smaller models and actually um you need to get the larger models uh ideally through open source to be able to do the smaller ones. We're looking at how AI can further then loop back and

help optimize. We we've heard a number of super interesting things. We we started um you started a little bit on this Archer but let me ask this question of of everyone quickly. what uh we we

first of all we also heard that uh business interests and commercial interests are aligned uh with um uh the desire to uh uh make AI more sustainable which uh is a very hopeful message but

what can governments uh and institutions do uh to further help u improve this? Uh Archer, you hinted at uh public procurement. Do you want to say a few more words on this or

Okay. Uh yes, it's one of the way in which uh in which we can build uh and make sure that this is uh that uh efficiency is favored. Uh again, I think the market can solve it. Uh it's uh but

but it can be accelerated and the faster we can go the better. Uh because there's effectively we're really building a lot of electricity at the moment for for AI and so if we can just make sure that

efficiency is part of the constraint that that's good. The it's worth noting that uh for better or worse artificial intelligence generally is turning into being a utility being an AI company is

turning into being a utility company. Yes. In that term we're basically turning electricity into tokens. It's highly competitive. So that means the margins are getting I would say thinner.

Uh and so the and which means that things are also getting price sensitive and so when it comes to being when things get price sensitive you efficiency really matters. So so that's

that's going to be partially solved by the market but can be accelerated. Um and I would say the the way it can also lead the way uh is probably by sustaining open source projects that

actually go beyond the models. uh the inference path, the hard what we call agent harnessing is also something that will eventually become uh common goods and and can be used everywhere and so

good practices incentivizing research as well because those the the the domain of rooting picking the right models the domain of distillation those models do not require you to have thousands of

GPUs uh and so you can do efficient research so public research on that domain is very much possible and and and would love to see more of it. Uh so I guess that's the that's three things

that they can mention. &gt;&gt; Wonderful. Thank you. James, do you want to add a few words on that? &gt;&gt; U yeah, first of all, I agree with the the three things that Arthur mentioned.

I would add a couple more. One of the things that's actually quite interesting is the more government can actually incentivize and encourage uh companies to use off-grid solutions uh is super

important because that takes the burden off the public infrastructure that affects citizens. And so, for example, we're a lot of time think about off-grid solar and offgrid wind and we're

thinking about geothermal. We've even uh building our own small modular reactors. Uh and we're also investing to this point in breakthrough research. One of the most exciting areas by the way which

is not as far away as people think it is is actually fusion energy. So we've we've made some of the biggest investments in fusion energy. And by the way, AI is actually helping us make that

progress because one of the things you worry about with fusion energy is how do you do what's called plasma containment uh where you can actually hold these high energy particles and contain them

and AI has actually helped us do that. So even the use of AI and breakthrough research like that is pretty important. I'll say one other quick thing very uh quickly because it reinforces I think

something that Arthur and said which is inference is going to turn out to be the most important thing. more than the training part of this and we've actually started to invest in that. So for

example, we've actually built you know we have our own chips TPUs we use TPUs and GPUs in TPUs we've actually built some inference specific TPUs just for inference uh to be able to do inference

even more efficiently than what you would typically do with a general kind of GPU. &gt;&gt; Wonderful. Thank you. uh ambassador uh Philip Tigo what can you maybe

microphone from a neighbor and then I'll ask Abishek [snorts] to conclude &gt;&gt; that'll be very quick because uh a lot of these solutions are for developed economies so I think we have to be a

little bit realistic in terms of where emerging economies I think one there's a bigger question of sovereignty right so and there conversations around that and and there has to be trade-offs uh like

every country wants to have the entire stack in their country so I think governments need to be very realistic around which parts of the stack they really want to in their country

especially if you have this AI for green and green AI conversation. I think the second part again is to look at especially then in emerging economies is to look at sovereign uh sustainability

across the stack right so we may not have compute necessarily but we have other parts of the stack so how do you ensure that part of the training um get gets that done the the the third part I

think is to expand this definition of safety right because AI safety is very much around the models and not necessarily around the use and potential harms of the environment I've not seen

that research so there could be an expansion of research around looking at AI safety including environmental um uh concerns. The the other quick one of course is you can only know the

environmental footprint from use cases and it has to be specific and these are deep dives and and I have a sense people need to invest in deep dives. When I look at food systems that's an entire

food system. So there's there's potentially problems there if we do not necessarily have to my last point around the standards. Uh we really have to invest in the standards. We've seen that

in in in other electronics, right? So we need to see that so everybody knows the kind of environmental standards that you do that uh and that needs to be done at scale.

&gt;&gt; Thank you so much. Uh Abishek what can governments do? You you represent a government. You want the um you have your &gt;&gt; Yeah.

&gt;&gt; Are doing governments are doing every every government is conscious of this and in India in fact recently we did uh kind of focus on uh the small reactors which James mentioned is that we came

out with a new policy under which the sector has been opened up for the private sector also to invest. What we do believe is that as inferencing needs go up and India when we're talking

inferencing we're talking inferencing at scale uh so if 100 billion or 200 million in the first phase and up to ultimately 500 million and more people start using these services then the kind

of back-end infrastructure that we'll need will be huge which will consume a lot of energy. So to reduce the load on the existing uh grid we will need to think of off-grid solutions. we will

need to think of of dedicated small modular reactors which can power the the AI applications the world over what we are seeing is the more and more AI adoption is going up energy cost go up

and if energy cost goes goes up ultimately for elected governments it doesn't so well so it has to be thought of the strategy has to be thought of how do we balance the needs between having

more efficient and more uh intense AI solutions with the needs for sustainability with the needs of reducing the carbon footprint because we are also a few years away from 2030 S

SDG sustainable development goals. So ultimately we'll need to balance the both the need for having more efficient AI and the need for reducing the impact on environment otherwise we can't uh

solve one problem and create another. So that's again something the governments are concerned of and I think augmenting the renewable energy sources solar wind and nuclear will will the fusion thing

will be the way to go forward. Yeah, thank you very much. I think this has been a fascinating discussion. Uh the um uh we we can we heard from all of the panelists that uh the environmental

impact of AI is not an afterthought. It's actually uh front and center. It's part of the competitive advantage. It's part of um uh what companies and governments think about. Um uh this is a

very um strong and positive message um that I think we can all be reassured with. Um let me just close by uh mentioning the resilient AI challenge that was mentioned at the beginning.

Registrations uh close on March 15th. So please submit your solution. Please join me in thanking this wonderful panel. Thank you everyone uh for uh joining us today and really hoping to see uh you

engage uh into this uh uh resilience AI challenge. This is a first at the international level working on uh improving research on compressed models. So one of the uh uh solution and tool

that was uh uh presented uh in the panel. So we really uh encourage you to uh uh to register. So thank you so much to our panelist. Uh another round of applause

to wait for the photograph. The moment is just coming in. So it'll be better if he be able to present them. Okay. Just a minute. Can you tell uh if you could just make that announcement?
