# AI governance in the Age of Powerful AI - IInternational Perspectives and the Code of Practice

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 6 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/iXb3emd9_jc?feature=share) |

## üé§ Speakers

- Henna Virkkunen, European Commission
- Lucilla Sioli, European Commission
- Sean √ì h√âigeartaigh, University of Cambridge
- Yoshua Bengio, Mila Institute

## ü§ù Knowledge Partners

- European Commission

## üìù Summary

Bringing perspectives from government, academia, industry, and civil society across regions, the session will explore how AI governance frameworks can support responsible innovation, and build shared trust in widely deployed AI systems. This panel will also introduce the Code of Practice for general-purpose AI models and examine its implications globally. The discussion will unpack requirements on transparency, copyright, and lifecycle risk management, including safeguards for advanced models with systemic impact.

## üîë Key Takeaways

1. Bringing perspectives from government, academia, industry, and civil society across regions, the session will explore how AI governance frameworks can support responsible innovation, and build shared trust in widely deployed AI systems.
2. This panel will also introduce the Code of Practice for general-purpose AI models and examine its implications globally.
3. The discussion will unpack requirements on transparency, copyright, and lifecycle risk management, including safeguards for advanced models with systemic impact.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/iXb3emd9_jc/maxresdefault.jpg)](https://youtube.com/live/iXb3emd9_jc?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

So today's discussion, we're very fortunate to have leaders from across the AI stack, if you will, who are here with us to discuss how governments can help industry, work in partnership with

industry, if you will, to align uh responsibilities to reduce fragmentation and to build trust in AI systems that are built for scale. Uh we are very pleased to have with us um some uh

luminaries from across the tech ecosystem. Um Jay Chow Chowry is the CEO of Zscaler. Um Aparna will be joining us in just a moment. David David uh Dep David Zapolski I almost made it. Um is

the chief global affairs and legal officer at Amazon. And um Dr. Yarik uh Coutilowski, how did I do there? &gt;&gt; Thank you. Is the uh CEO of Deep L. So um to set up the conversation, I wanted

to ask each of our panelists to help us think through the AI governance conversation that's taking place globally. So as we've seen here at the AI impact summit, there are efforts

among uh global governments to uh uh align their approach even though they may take different directions. Hi Aparna. And um as Aparna is now joining us, I will introduce uh Aparna Bawa who

is the chief operating officer of Zoom which is not only a technology company, it is also a verb. And so thank you Aparna for being here with us today. So uh as we were uh getting ready to talk

about AI governance conversations, it is absolutely the case that there is a need for governments around the world to align their approaches to AI governance because of course technology doesn't by

its very nature want to stop at borders. It wants to cross borders and unite people uh around the world. So I wanted to ask uh each of our esteemed panelists and and Jay I'll start with you for uh

uh a perhaps your philosophical perspective on uh how AI alignment can take place across governments. Why is it that that alignment matters and perhaps even share your perspective on what

happens if that AI alignment breaks down and governments are going off in different uh directions and taking different approaches? Where do you see the biggest challenges around this idea

of alignment of AI governance around the world? Jay, thank you. &gt;&gt; Thank you. So, we are We are a highly connected world. Imagine [clears throat] any large corporation

that's doing business in 50 countries. If each country has its own governance rules and all but using AI and you're using some systems locally, some system globally, it'll create a lot of issues.

So having some line of alignment is good, but over alignment doesn't help either. In fact, I have the similar thoughts on governance too. Some level of governance is needed. When we start

doing too much governance, too much compliance, we start killing uh innovations. So that that's personally my view. &gt;&gt; Yeah. No, it's a it's a it's a an

important viewpoint because uh there is this idea that governments need to act. They need to protect citizens. They need to ensure security. Um but uh acting too much perhaps in advance uh can stifle

innovation. So Aarna I want to go to you um with the same question. Uh as we're having this global AI governance conversation here at the AI impact summit um you know governments are going

in different directions in many cases. This is the first time the conversation has taken place in the global south. So I think that's a a good thing for aligning uh governance approaches. So

from where you sit, why is alignment across the AI governance ecosystem internationally so important and and what can happen when it doesn't happen and and goes wrong. I will say um just

to start uh as an Indian-American um and someone who has lived in India um and we talked about this this morning at a breakfast we were at um it is quite striking to me um some of the uh the

halves and have nots like even we were talking about this morning for example during COVID how some countries were fighting for PPE and fighting for oxygen tanks

And you know, we in California were stockpiling toilet paper. I mean, the the the contrast is so stark. And I I remember during co thinking to myself, that doesn't seem right. And so I do

feel like countries should protect the rights of their citizens and should want to advance their economies. Um but it is a tradeoff. And I think um it's very well put to say it's a trade-off. So for

example, Zoom, imagine you would not be able to connect with people globally if we did not have crossber data flow. So when we're talking about AI, everything's you can

you can you can talk about AI, but it's no different at the data layer, but we would not exist if we didn't have crossber data flows and free unencumbered data flow. Um and when

governments start putting more and more restrictions on them, it rec on [snorts] their own sort of uh in their within their own countries, it impedes their own citizens progress and so at some

point it becomes a trade-off. Now obviously the requirements around privacy and security are table stakes. Um, you don't if you if you if you get on a a a Zoom meeting with someone, you

want to know that the person on the other side is that person. That is sort of table stakes. But I'm with Jay on this one. I think there's a basic level framework that is necessary to be

honest. We live today um with multiple in the United States, we live with multiple states privacy frameworks. And is it great? No. Is it inefficient? Yes. there's something in between where you

have a framework that is commonly understood with common set of norms and values. Um I also respect a right of sovereignty for a nation. So something some there has to be a balance that is

struck. &gt;&gt; Makes sense. David, Amazon operates pretty much in every country on the planet. Um although I'm sure you can name a few that you're not in yet.

&gt;&gt; There's a few. Yeah, &gt;&gt; there's a few. Small number. Um, can you share your view on how this AI governance conversation uh needs to have some perhaps some unity to it?

&gt;&gt; Sure. And first of all, I I I'm going to try not to repeat this view because I I we basically agree with just everything you just said. If you think about every one of Amazon's business models, our

stores, the the the way we're able to export 20 billion uh uh of uh Indian small and mediumsized businesses to overseas markets, we're looking to take that to 80. If you look at the cloud, uh

if you look at our our our entertainment business, if you look at our the satellites that we're we're we're launching to to launch a global internet service, every one of them depends on

free flow of goods, free flow of information, open skies. That's just kind of the way we've designed the company to be global and to to have interoperable uh services. And so every

time a government erects barriers to that, um it it creates friction. It creates potential problems. and uh and and I think the the global trend towards more of that is is concerning uh with AI

particularly I think the danger of uh of some of the regulation that we've seen around the world is that we all still don't really know how it's going to be used where it's going to be most

effective where it's going to be dangerous there's a lot of theories about it there's a lot of fear uncertainty and doubt about that a lot of science fiction and I think the

danger in in regulating before you really understand the technology or how it's going to play out is that you you you create uh you create costs. Uh you create um uncertainty uh and you inhibit

innovation. You inhibit adoption. Um and that's kind of what we're seeing a couple years into this large language model journey. You know, there are parts of the world that were quick to regulate

and you know, civil society was like all over that. We're going to regulate all these things. we have come up with these theoretical constructs of high-risisk, lowrisisk, and and and we don't really

know what that means in practice yet. And so what's happening? Well, look at Colorado. Colorado was one of the first states out of the box with uh with comprehensive AI regulation, which by

the way isn't bad in principle, but they don't know how to apply. No one really knows how to apply it. And I think you're seeing some buyers regret. There's they put the the the

implementation on hold. They want to figure out standards. You know, I won't even talk about the EU, but they're pretty much in the same boat. They're all looking for ways to not have to put

the thing into practice because they don't really know how it's going to play out. So, so I think what we need to do is step back, look at look for some common principles. What is a high-risisk

use? What can we all agree are high risk? Well, if you're using a technology to make decisions that's going to affect the life, health, or civil rights of an individual. Let's talk about that. Are

there are there are there laws that protect that already? Do we need to supplement them? Let's work backwards from the harms we can see today and and regulate there versus trying to come up

with the unified field theory of AI regulation because because that's that's only going to uh uh slow us down. &gt;&gt; Great. Uh Yaric, uh we've been talking about unifying global governance

approaches. Uh making sure one might say that they all speak a common language. That's what DEL does. See what I did there? Your language AI platform is all about making sure everyone can

communicate with each other regardless of the language they speak. Um, from your perspective, you're our European headquartered uh, representative here. Um, but you do business around the

world. Uh, what can you share with us about how AI governance conversations being unified across governments is important to to deepel? &gt;&gt; Yeah, I I truly believe that any kind of

successful technology needs to be inherently global. uh that holds both for kind of the commercial models of the companies that we are that we're representing but it also holds for just

the access and the ability of of reach uh towards the towards the whole globe with with what we are building. I think this creates the um the the the economies of scale on on everything that

we're building and and when we are in AI like obviously you're running very very high R&amp;D costs and you have to be able to offset that with a with a huge customer base. So having having a global

market and and being able to deploy uh to the whole world and therefore also to fulfill the mission of our companies whether it's just enabling communication maybe in the case of of of Zoom uh or

making sure that this communication can happen multilingually as in the case of of DL that really depends on a framework that is that is transparent and on a framework that is maybe like not too

different in in all of the parts of this of this of this world and therefore having like some common layer having this this right balance of protecting the sovereignty and protecting maybe

like a slightly different approach and slightly different mindset uh to certain topics like like privacy uh where we do have differences across the world. uh but doing that in a way that is that

that has a common understanding uh that would be incredibly valuable I think not only for the companies that we represent but also really for our users and of our customers who depend on on the best

possible solutions. &gt;&gt; Jay I want to come back to you because you are our resident security expert and sometimes doomsayer about what happens if we don't include trust and security

as part of the conversation. And I've heard you remind um members of the government of India indeed that although the five pillars are enormously valuable if you don't have security overlaying

them, we're all in trouble. Talk to us about how the trust and security conversation is still a vital component around all the excitement about AI. &gt;&gt; Yeah, I have said that AI is powerful

but AI is dangerous. Okay, because this technology can be abused. In India, there's a great focus on five layers. And the focus is about being sovereign, having everything that you can control.

It starts with application and models underneath and so on so forth. While it's good to have that sovereign stuff, imagine a bad guys can control all of that sovereign stuff sitting

somewhere out there. Data poisoning can be done. All kinds of stuff can be done. So having a layer of security across all five layers becomes very important. So we should think about sovereignty not

just in terms of this thing is sitting in my country but also in terms of who can access who can do some of these things with it which is often overlooked and also the adoption of AI is happening

very fast and it's wonderful and I'm not saying we should slow it down I think we should embrace fast but we should also start thinking about embracing cyber uh to make sure things are used securely

at the same pace &gt;&gt; and in order to make sure that security is part of the AI ecosystem apart and I want to ask you about what we all have responsibility to be thinking about as

users uh what enterprises have a responsibility to be thinking about you know we we've talked about governance from the policy perspective but of course users and enterprises also have a

responsibility uh around AI and as the COO of Zoom you look over both the public policy and business aspects of what you're deploying. How does the conversation about what we all should be

thinking about uh factor into product development and deployment conversations? &gt;&gt; It is a true partnership. And you know what when Jay was talking um it

resonated with me when you work for a technology company um that is what you want to develop technology and you want people to adopt it as fast as possible. You want them to be early adopters. It's

so exciting. In fact, in our company, um, you know, the companies have lots of different functions. Obviously, our engineers, our developers, our product people are super they're super early

adopting. They're first to to take any sort of app that's come out with its cursor, etc., and use it in their day-to-day. And then there's other people who have other day jobs. I mean,

there's finance people and the people people, the HR people, they have day jobs and they're learning AI at night because they're realizing that if I'm not on the AI bandwagon, I'm going to

get left behind. And by the way, if you're looking to develop apps, it's actually yes, you can focus on the sort of the the tech applications, but the real sort of the the the secret that not

getting a ton of attention, maybe a little bit of attention is this non-technical roles that could be augmented with AI. So in that framework when you work for that kind of

technology company it can be difficult to then start saying but wait a minute you need to slow down because you need to make sure that you are your CI/CD work work is still going and it's it's

amplified because of the risks of AI your security um certifications your red teaming your privacy standards all of that stuff is is maintained I will tell you the the user plus the enterprise

that is pushing out this technology it's a partnership Um it is so important the one thing that we learned during the pandemic if you think about zoom before pandemic it was a enterprise focused

company a work focused company and basically when the pandemic hit we said okay all you consumers we will just hand you a platform that we usually give to IT administrators and what do IT IT

administrators at our customers do they decide whether the turn up the security and privacy controls turn down usability because it's a trade-off it's a it's definite trade-off they decide we in

turn just handed it to consumers and said you decide. And we realized, okay, public schools, they don't have IT administrators. They don't know how to turn on waiting rooms. They don't know

how to, you know, hide the meeting, the meeting invite. They don't know how to do these kinds of things. You have an obligation as an enterprise to make sure that there's sufficient controls for the

individual user and it scales all the way up to the enterprise and maintain that level of flexibility. You have that obligation. But on the same side, I would say the user to be smart has to

understand the some basic levels. I'll tell you an for an example. My kids use all the AI the the AI engines chat PT cla they use it all. And it is a conversation we have to say is you don't

put all your information into your prompt because if you put all your information in your prompt, it is going into that engine and it will train that engine. On the flip side, we as an

enterprise provider, um, we have made the statement and we have made the policy decision that we will not use our customer content to train data. When I'm training my kids, I have to tell them

you can't put your address into chat GPT. It you have to make sure that you are maintain, you know, you're safe in some way. Um, so those are the kinds of things that you have to keep in mind.

It's a partnership between the user and the enterprise. And I think the enterprise obligation scales as you get down into the consumer use. &gt;&gt; And I want to stay on this theme of

training the user, if you will, whether they're your children or a customer. Um, because it is important for the tech industry to be mindful of the downstream. And David, I want to come to

you with this question. Uh, Amazon is in a lot of ways an upstream operator. you enable uh business and consumer customers on everything you do from content to e-commerce to broadband in

the future to your cloud customers. So, how do you think about the upstream governance decisions that you're making at Amazon and how they impact the downstream decisions or ways of

operating that your customers are going to have to make as a result of those decisions you make at the Amazon level? Well, we're fortunate to to have the scale to be able to serve enterprises in

the cloud at the at the uh at the service layer. And so we have, you know, even before the AI sort of current AI craze, we have a a couple of decades of experience in thinking through what does

governance and security look like for our enterprise customers. And as we moved into this um you know newer age where there's AI services available you know one of the best solutions that we

could come up with is creating an environment within the cloud uh the cloud services that so many hundreds of thousands of enterprises already use to give them access to models not just our

own and we do our own models and there's upstream governance on those you know testing uh um uh making sure there's you know we we correct for bias the things that a responsible model builder will

will do. But at this enterprise level and the services called bedrock, you know, we try to think through what are the what are customers going to need? Um uh so we build in uh security, we build

in uh the type of infrastructure that allows customers to scale up or down. We build in choice. Enterprises can choose from among over a hundred different models, open source

and closed source. um not just ours but you know all of the the leading models uh from all around the world. And so we try to create an environment a platform where enterprise customers can come to

use this new technology get first of all get access to it without having to build their own servers and their own train their own models and secondly to um to do it in a way where they can be they

can rely on the security of the infrastructure. Amazon. The other thing that that we will provide um customers is that the data they they use to uh to to employ those models you know stays

their data. It doesn't go to the uh to the model builders and it doesn't go to us. Um so you know think you can build that into the system and then on top of that given the way that um enterprises

are using this technology we try to build as many tool tools as possible to make it uh to make to put the um control of how this uh technology is deployed into the hands of of enterprises and

users. And so for instance on the bedrock um uh platform we provide guard rails that allow you as a as an enterprise to basically control what types of outputs the models are going to

give you. You know are they more toxic? Are they less biased? Are they are you know can you uh filter for certain types of content. We build those controls right into the interface so we so so uh

enterprises can have that control. We build disclosures uh into the types of services that we offer so that that we provide some visibility and transparency into here's how this thing is built.

Here's what you should use it for. Here's what you probably shouldn't use it for. And we provide those kinds of choices to to consumers. And so you have to think through uh the the the overall

security environment uh and the accessibility of this of this technology. And and as far as you know, our approach is that the cloud is probably the best place to do that. is

certainly the easiest way to to access the technology and and likely the safest. Y you've moved uh Deepel's business model from uh it started as uh translation uh now it's getting into

Agentic AI and you have agents uh on your platform that can execute tasks on behalf of your customers which I can imagine raises very different governance policy decisions that you have to make

on behalf of your customers when you're just translating versus when agents can act autonomously particularly because you're a global business and they can act autonomously. ly across borders. How

are you thinking about the policies and procedures for governance that you have to put in place in a in an agentic AI world that are different than perhaps you did in a language translation world?

I &gt;&gt; I I think generally but also in the language space just like this the stakes are becoming higher and higher. AI is becoming more and more powerful and even

if you look into translation like couple of years ago DBEL would be translating your your typical email to your customer and that that is important of course you want to you want to look great in front

of the customer you want to be eloquent you want to be be able to connect with them maybe like really on a human level when it comes to the language that this customer is speaking and and you're

enabling your business to basically become global very very easily. uh but now what DPEL is translating it's plain maintenance records it's R&amp;D documentation for new drugs that

actually influences how those drugs are developed and and uh whether they're being approved by the FDA or or not. Um so these are highly critical uh use cases and I think it has been mentioned

that like privacy and uh is it is just the table stakes it's just the beginning I think creating a layer of trust into the outcomes of the AI whether that's translation whether that's agentic AI

that those decisions are really following what the enterprise is expecting of the AI that is really where kind of the battle is right now and that is where both the governance aspect of

that uh that's coming from the political side and from the governmental side needs to obviously be included but there's also the aspect of how do the enterprises how do our customers want to

regulate the AI that is uh that is being deployed and how flexible the products that we all are providing can be towards those very different approaches that we're seeing across the world and with

different types of enterprises maybe even &gt;&gt; each of you mentioned the concept effect of risk management in your in your comments and I want to come back to the

balance that that Jay alluded to uh earlier between promoting innovation and balancing risks and obviously there is a trade-off it's a sliding scale the more you regulate risk the less room there is

for for innovation so I want to ask you uh I want to ask each of our panelists Jay I'll start with you about how you've seen a flexible riskbased approach um from government um be the most effective

where you see um that flexible approach still leave room for innovation. Or the flip side to that, if you want to give any examples, uh where you've seen it go wrong, where a uh a more prescriptive

approach to regulation has denied you the opportunity to bring products or services to market or has generally been more of a challenge for industry because a government didn't get the balance

right between managing risk and promoting innovation. There are many facets of governance and risk. Uh take for example uh data privacy. Obviously that's one kind of

factor but potentially hacker attacks from cyber point of view is a different kind of factors. We look at more in terms of two things. One

making [clears throat] sure your data is not lost. So the data becomes very important. There's a consumer end of data, but there's bigger issue on the data side is enterprises. Okay? And you

don't try to treat the same data the same way in the practical business world. I'll give you an example. Uh when I worked with General Electric, the CISO, a very smart guy, Larry Vagini

would say, "When I tried to secure everything, I secured nothing." So then he would give an example. So he says, "As a CISO, I need to protect IP or intellectual property of my products,

but my but my washers and dryers are out there. I don't spend time trying to protect its IP at all. You can buy them in a store and figure it out. But I'm dead serious about protecting IP on my

jet engines. That's very important. trying to just say all consumer data, all this data, it just starts creating issues. That's why I also like to say compliance doesn't

mean security. In fact, when you work on compliance, all this thing works through the government entities, pros, cons, and it takes a lot longer. And by the time it's

out there, the cyber and compliance needs are moved on. So the stuff you put in place many many times is old. In fact, when Zscaler came in came out with our zero trust cloud-based architecture,

a lot of these regulators came in, wait a second, where is your firewall? So what do you mean firewall? Firewalls don't we don't use firewalls. We are anti- firewalls. And they said, no, no,

wait a second. The banks can use it if you don't have firewall. when we went through certification for the federal government in the US uh the certifying body first came firewall said no it took

us 3 months to educate them so that's why I think overregulation I'm really don't like it there needs to be a way of saying what's the impact of this thing on what kind of stuff that's a right

approach all data is not created equal trying to put the owners of securing all data gets hard now and then classification data gets hard. So these are not simple issues. AI makes it very

hard. We don't even fully understand how AI does what it does, how it does. So I think a flexible policy that evolves is a better thing while keeping track of the most important data. And then beyond

data, hackers too, that's a big problem. Um we talked about agents. Today a user is the weakest link. Tomorrow AI agents will be your weakest link and they'll be all over. I mean they are maturing.

They'll come there. Imagine an agent getting hacked or hijacked in your company with access to all kind of stuff. So that's where companies [clears throat] like Zcaler we are

focused on making sure our zero trust exchange can be extended to deal with agents starting with understanding the identity authorization all those things those things are very important. uh the

way we look at it otherwise business will shut down. &gt;&gt; Apartner Zoom brings some amazing innovations using AI to the platform that we're all familiar with. Um makes

it a lot easier for us to do everything from transcribe meetings to um uh you know to pretend to be a cat when you're in court. Um no that's not a that's not that's a not

&gt;&gt; I was going to say it can summarize your meeting. It can take act notes for you. It can send action items to your teams. It can calendar those action item follow-ups. It can give them deadlines.

All done. &gt;&gt; There it is. But I can imagine you've had some challenges around the world in that balance between innovation and risk management from governments.

&gt;&gt; Can you either share a positive example of where that's gone well in your mind or if you want to an example of where it hasn't gone well where consumers and businesses have been denied Zoom

innovation because that balance isn't struck or perhaps you can keep it at a higher level if you prefer. Well, I I'll just give you a little bit of how our how I view our framework and if and I

was as you were asking the question, I was thinking to myself the buck stops with me in all honesty like I am the person who um has to weigh that balance between innovation you know our product

team innovate innovate innovate our governance team security privacy etc is always thinking about that as well and so how do you strike that balance and I think I'll start at the top level it's

it's a sliding scale on many different fronts but if look at it like a layer cake or even a a data stack, but at the top level um it's customer choice. So David was very appropriate when he said

customer choice, but customer choice is different by the category of customer. If you are an enterprise and you have 200 people on an IT admin team or under the CIO and you are buying Zoom and you

have a giant security team and a giant compliance team, you're going to be making choices for yourself. I'm not going to tell, you know, HSBC what they're going to do. They're going to

decide what they're going to do. And we deliver the platform and we have toggles um to for them to decide what they want to deploy, what they don't want to deploy, how they who they want to deploy

it to. We make it very easy. So, we provide a lot of choice. So, the same platform services fortune 1. The same the same platform also services my mother-in-law who is on the free

account and who is, you know, chatting with her friends and won't upgrade. I tell her, "Please upgrade." She gets off, waits 5 minutes, get back on, and that's how they do it. So for her, it's

very different. Well, so for her, you have to mandate a few things. You can't tell your give your meeting ID to everybody. It cannot be on the top of the UI. You know, those are some basic

things. You have to have waiting rooms. If you're in a school environment, you have to have mandatory passcodes. These are sorts of things that you So that's a sliding scale. I would say take it one

level deeper. I think the biggest thing I have learned from working at Zoom, and in all honesty, I credit our founder for this. The biggest thing I've learned working

at Zoom is everything goes back to the user experience. And our customers are not monoliths. They don't just want to take down all the technology, they want to do it in a safe and secure way. They

don't want to be surprised. So, you have to think, I am a user. I'm an enduser. It doesn't matter that I sell to Zcaler. Thank you very much. doesn't matter that I sell to zcaler. I need to worry about

how Jay Chowri's engineer feels when he gets on Zoom. And that's the user experience I'm going for. So if you are a user and you feel like, wait a second, I don't really want if I'm a finance

person in Jud's team and I and I say I don't really want my meeting to be automatically trans transcribed and then spit into an AI engine because I'm worried or if I'm a lawyer, I'm worried

about attorney client privilege. Well, I need to give them the option to say I opt out of that. I need to be able to give them choice. And I think that's how I think about it. I every riskbased

decision is you are a user. You're not one kind of user. You have multiple types of users. How do you make it easy for at a very lowest common denominator for them to trust you? And that's really

the answer that you you you you go through. &gt;&gt; That's great. David, let's go from different kinds of users to different kind of products. You were the first on

the panel to use the phrase riskbased approach and nowhere is that more evident than Amazon's wide range of products and services to your customers. I can imagine it's a very different

internal conversation about governance and risk when determining how AI is going to on Amazon Prime recommend my next series or show. Not a lot of risk there. um but other Amazon products uh

could have more risk to them. So on the sliding scale and you also you travel the world quite literally now you're doing it talking to governments about that innovation versus risk management

uh and the risk of getting that balance wrong. How do you communicate that to governments and uh also uh make the internal product decisions that you need to around those issues? Well, you sort

of sort of kind of stole one of my talking points when I have some of these conversations, which is which is you do like it does matter how this technology is used and where. You know, it's a

different set of considerations when we think about, you know, what kind of protections or risks arise from a an AI assisted shop, you know, shopping assistant versus um, you know, a tool we

might make available to help doctors um document um uh what they're what they're um how they're treating patients and make it easier for people to prescribe medications. like those are two very

different risk profiles. But if you start with a regulation that doesn't differentiate between those, you're you're going to uh you're going to inhibit innovation. You're going to

prevent adoption of really useful ways that this technology can be used. And so that's that's you know that's the pitch I make when I get to to talk to to people who are whose business it is to

think about regulation. It is about risk. It's about how the technology is used. And my point earlier was that we don't really know yet how the technology is going to be

used. When we see it, we can we can we can we can analyze it. I can't you know and on the the the on that point generally you know there are cases where uh te technology companies have made a

decision to not bring certain types of technology into say Europe because of regulatory uncertainty. But um and and typically those get worked through. Um but I can't tell you how many

conversations I've had internally where folks have come up with an idea or a product and uh and and our and our our sort of internal mantra is we want to we want to launch something everywhere all

at once. That's that we want to serve customers. If we if we have conviction something's good for customers, why just do it in one place? And sometime the answer to that is it's too costly. It's

going to take more time. we can't really figure out how this is going to fit within, you know, the regulatory scheme in in a certain other jurisdiction because they haven't thought of it

either. And so we're going to wait. We're just going to, you know, wait on that. We'll launch it in this place first uh and we'll see if it works. And then if it works, then we'll think

about, you know, the costs associated with with with scaling it over globally. And so that's a real world uh issue that that governments have to understand and deal with when they make decisions about

how prescriptive their regulations are going to be especially in the abstract. And so th those are the sorts of of of conversations I have. I think you know in the AI space I think you can look at

um uh countries like uh Peru, you can look at countries like Japan that have proceeded cautiously. I think India has the same approach and I and I'm very encouraged by the way India is is is

approaching these issues. You have to you can't rule out regulation completely and and and Amazon's an advocate of regulation um that that uh mandates that people developing and deploying this

technology do it responsibly. But we have to understand what we're regulating before you can really pull the trigger. And so that's that those are the you know that the I think those types of

examples are are useful for people to keep in mind when they're considering how to resolve that balance &gt;&gt; and and the result of those conversations not going in the right

direction. Uh David is that consumers or businesses might get denied the technology that their neighbors are are enjoying. So, Yaric, I want to ask you um as the CEO of Deepell in the process

of expanding around the globe, uh are there examples that you can think of where you've had to make a go no-go decision entering a particular country or launching a particular product

including your new Agentic AI products because of the regulatory environment or because of the uh the way in which a country looks at or the flip side of that if you want to take the positive is

are you attracted to to a particular market because as David said it's done the right thing like Peru or Japan or even India is endeavoring to do where they're more likely to get deep service

because of the decisions they've made the approach they take to these AI governance decisions. &gt;&gt; Yeah, Jason let let me first start with a principle like I'm a I'm a scientist

by heart. So I'm really excited about bringing the best possible technology to each and every one of our customers and users. I think they all deserve it. I think they all should be equipped with

that. Um, but yes, there is there is kind of some of those uh things that we need to take into account and actually quite often those are not really location based or country based or

regulation based but really also based on the use cases of those of those customers. Um, AI can be incredibly powerful. Um but that power also demonstrates its possibilities in

different ways in in different applications. And going back to my example from earlier like the translation of an email has just a different criticality grade than a uh

translation of a of a patent uh application. Uh the execution of an agent in a particular environment versus in an enterprise environment has a different grade of um of complexity. Um

but going back to kind of the regulation aspect of it, uh I think we're lucky as a company to have grown in Europe in kind of an environment which is maybe like slightly earlier on regulation than

than other places in in the in the world. Um, and I think that gives us an edge to be able to understand how to work with this regulation and how to uh prepare and then also like be very very

early in in in other markets like you mentioned Colorado uh earlier and be able to handle that that complexity and be able to handle that complexity for our customers really because most often

it is our customers who do do not understand this space. we do and we have to go all of the way to give them the possibility to figure this out for themselves for their applications for

their use cases and across a whole range of of products. So in short I think it can be managed but it is really like part of the excellency of a company to be able to manage that together with the

customer. &gt;&gt; The last question that we have time for that I want to address to each of you is a forward-looking question. It it used to be possible to have conversations

about policy outcomes years in advance. I think the best we can hope for is to for me to ask this question uh in advance of Switzerland uh hosting the next AI impact summit or whatever they

choose to to call it uh next year at this time. So my question uh to all of you uh on the panel is uh a year from now if we are to gather um and something had happened in the AI governance AI

regulatory space over the course of that year that you'd like to see happen and you were looking backwards to India and say I'm really glad that one thing happened or that one thing changed or

this government or this international body um did this thing uh over the course of last year to really help unleash the innov innovation and power of AI uh in a secure way that we all

want to see. What could that one thing be that you're looking at? And it can be something that you're focused on in your business as well uh over the course of the next
