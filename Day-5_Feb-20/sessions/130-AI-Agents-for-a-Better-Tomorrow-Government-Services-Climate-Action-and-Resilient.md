# AI Agents for a Better Tomorrow: Government Services, Climate Action, and Resilient Infrastructure

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 14:30 ‚Äì 15:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 8 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/kRv4Axjjzw4?feature=share) |

## üé§ Speakers

- Lee Tiedrich, Pratt School of Engineering, Duke University
- Mike Haley, Autodesk
- Sridhar Babu, Information Technology, Electronics & Communications, Industries & Commerce and Legislative Affairs, Telangana
- Srinivas Tallapragada, Salesforce
- Victoria Espinel, Business Software Alliance

## ü§ù Knowledge Partners

- Salesforce

## üìù Summary

This panel will bring together industry and government stakeholders to explore the shift towards autonomous AI agents. The discussion will focus on the engineering architectures required to scale these systems for climate resilience and public services, alongside governance frameworks that support trust and accountability. Moving from theory to practice, the session will examine pathways for public‚Äìprivate collaboration to support secure and responsible AI deployment with tangible outcomes.

## üîë Key Takeaways

1. This panel will bring together industry and government stakeholders to explore the shift towards autonomous AI agents.
2. The discussion will focus on the engineering architectures required to scale these systems for climate resilience and public services, alongside governance frameworks that support trust and accountability.
3. Moving from theory to practice, the session will examine pathways for public‚Äìprivate collaboration to support secure and responsible AI deployment with tangible outcomes.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/kRv4Axjjzw4/maxresdefault.jpg)](https://youtube.com/live/kRv4Axjjzw4?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

We are going to start with a very special guest. Minister Babu is going to join us for a keynote. Um very excited to hear what you have to say coming from Hyderabad and sort of the one of the

centers of technology in India and in the world. So minister thank you so much for joining us and if I could ask you to come to the podium [applause]

I know that my team would appreciate I would as well. Great. Thank you so much. &gt;&gt; A very good afternoon to all. In fact, uh we welcome you to to our city of

Delhi, a beautiful city, a capital of India. And many people are from India too. And we welcome the distinguished panelists eminent uh panelists who are sitting

here to sit and discuss the quotes uh for better tomorrow and uh I welcome the leaders of the industry and the delegates over here and uh especially coming to the subject

AI agents for better tomorrow. You know I wish to see that you know where we stand today and where we would end up tomorrow is a point of discussion over here too.

We stand today at a fundamental inflection point in the history of governance. As a policy maker, I would like to mention few points because all the technocrats are sitting on the all

the eminent u you know scientists maybe from physics or the maths may be sitting on the other side to develop uh AI into the next level. You know for decades the digital

revolution in the government was defined by transition from paper to portals and from physics cues to digital cls. But today we are witnessing the birth of the new

paradigm. We are moving beyond generative AI that simply answers. We are moving from them to agentic AI that acts now what I've been discussing

with Mr. train was just now and for 30 years our relationship with technology was a series of commands. We used to give commands and used to get the answers.

We typed, we clicked, we prompted. We were the masters for the such bar. We used to, you know, we were the masters. Nobody can say that. But I stand here today.

I can see and everybody can see the search bar is dying in its place. Something more profound. Just now Mrs. Shini was just telling about agency

is just evolving. In the first era of our national building was defined by land, the second by the industry and third has been defined more LU the

intelligence of the system. And the nation that lead this century are those that learned to treat intelligence not as a product but as a form of a public

infrastructure. The idea is no philosophical for our state of Telangana. It is a story of our everyday governance because it's ITdriven state as we are known for.

And I often say that artificial intelligence has three lives in the government. The first life is in the research labs. The second we take into in the policy

papers but the third ultimately both of this combined together how we are trying to affect the life that truly matters for each and everybody.

You know how do we see it is that when AI meets the real challenges of of our lives, when artificial intelligence meets the dust

where we face, AI meets the drought, when it meets the monsoons, when it meets the markets of the living society

and this is where its legitimacy is earned. when it really counters this dust, drought, monsoons and the markets in Telangana we see agents not as a tool

here we would like to take them as a teammates you know as the way the pilots rely on the co-pilots tomorrow as our government here in

Telangana also see that we rely on AI as co-governors system that can predict a flood before the first cloud gathers over the Musi. Musi is our river in the midst of our

city. You know, allocate resources before the crisis and deliver services before citizen ever need to ask. For example, if you

take the agriculture, a small farmer I held from a very remote area and that to a rural place a farmer farmer in my place or in some other place from the rural

area when the climate is not environmental concept for them. It is right now a daily negotiation with uncertaintity. So when we built our AID

advisor, we did something unconventional. Right now we are playing two ads on the pil stage. We asked farmers to train the system with us. You know the dialects, the soil wisdom,

the lived patterns become the pattern of the modeling. This is where the governance comes into picture to use the best of the technologies where you invent produce or do sitting

in R&amp;D use you know best of your gray matter to come up with some products until unless we use and induce into our governance there will be no end result that's what we believe in that is why

you know our Telugu first AI can record land records, interpret satellite indicators and compress the time between the climate event and an insurance

settlement. So this saved lots of time you know for our you know government agencies as well as to the end user as a farmer. Our satellitdriven heat analysis no longer stops at mapping temperatures.

They now shape zoning, green belts and urban cooling strategies for Hyderabad which we are planning to take up to the core by 2035. And across 33 districts in our state,

our solar power edge computer nodes ensure that the government service and the climate remains operational when the grid fails. And this is also one of the novel things what the Telangana is the

first state where we have implemented yet I don't claim that these are examples for climax of our story this just the beginning this is the first the preface we can say that because the real

breakthrough is not from each project it is from the architecture that binds to together our future projects [snorts] like our coming up the state-of-the-art

infrastructure in the upcoming AI city absolutely dedicated AI city and the barat future city which shall be the net zero city or designed not as a smart districts

either for technology or for other aspects but as a self-arning cities territories that define sustainabilities territories which can

you know provide themselves for the compute and make them policy advisers you know our country's first sovereign AI nerve center

I come you know this is a first ever initiative by any state in India that we have come up with the first sovereign AI nerve center that is supposed to be the AI I innovation hub

that is named as icon. that the aim and objective is you know this intelligence should be shall go deep beyond just for incubation

but also render into R&amp;D and shall be the prime focus of creating AI ready talent for tomorrow's world and I would like to mention here uh that Hyderabad and Telangana is the

first state to come up with a platform that is Telangana data exchange platform the sovereign data open pipeline ensure that the intelligence is grounded in

integrity. So the platform is on the open and uh this is the first state we have put all the data on this platform you know

if we go through it by this open data pipeline you know,84 data sets they have moved from administrative exhaust to ecological signal. We have

created something rare in the global south that state that generates its own intelligence at a scale and we have seen the results too and results shown the healthcare doesn't

wait for symptoms it now anticipates risk because the data exchange we have done with our co-artners either in the healthcare or with the doctors or with the uh public health institutions

they are Not waiting for to deliver the medication but predicting the risk and try to put it into actions and we are not waiting for the heat waves to come. We are trying to analyze for through the

data and how we should place ourselves and we are preparing corridors for of the ship and farmers also we believe using this AI technology don't we don't want farmers to wait for the loss

you know they have to receive assurance before despair and we are also planning that infrastructure doesn't wait to break you know it has to whisper when it

will fail. You know when all this the cutting edge technologies especially AI deployed with purpose

and AI agents offer government something rare in public life. The ability to act before harm to prepare before shock to preer to protect before loss and how resilient our

infrastructure emerges. How safe the climate resilient cities take shape and how our public services become anticipatory, humane, interested

and this is the future what we are imagining and we're trying to put all our actions into stream and it is this operating system we dreamt and we started running and I

believe the next chapter of the state craft will not be written in the boardrooms of traditional power centers but in the living laboratories of the global south in the cities of Hyderabad

and uh the world can already see a preview of what an intelligent century of governance look like. Let us leave bat mandapam today here where this great convention is

taking place with a shared conviction that the tomorrow we are building is not just the smarter it is braver and you know the great caption goes AI

for everyone AI for human welfare should be the theme and also we should I as a policy maker you as a technology expert sitting over [clears throat] there should aim and anticipate for it. I

thank the organizers for giving me you know a length of year to air my pitch on behalf of our state of Telangana. I would like to thank the Salesforce team especially the team

management who I invited me over here uh for gracing this and having to see you know all the best brains sitting over here and the gray matter who would be doing much more for our welfare of our

human being. Thank you very much &gt;&gt; minister. Thank you so much for joining us. Um we very much appreciate it. Um it was very exciting to hear what's happening in the honor. Um let's kick

our panel off. All right. So um I am going to start with an icebreaker. Um everyone gets 30 seconds to respond. Um this panel is about AI agents. So what would you say is I'm going to start

there and then go towards me. What would you say is the single difference that you see between AI last year. We've been sitting here AI this we've been sitting here last year and the AI agents that we

are seeing it today. Syel could you kick us off? &gt;&gt; So I think uh in my mind the conversation has moved decisively towards agentki. We are no longer uh

we are no longer talking about as uh honorable uh minister also said about you know solving discrete problems or discrete uh searches. We are now looking at end toend AIled execution of business

processes or government processes. I think that's the single biggest change in thinking that has come up. Professor Teter &gt;&gt; to put this in context um I was involved

in the international AI safety report and we just um had our panel on that a little while ago and uh professor Benjio was saying you know the biggest change from 25 to 26 is the emergence of aentic

AI and you know my perspective is its ability you know not only to do the end to end but to also act on behalf of people um is is really the big change &gt;&gt; Mike

&gt;&gt; um so I'm probably going to jump on train here. Um, you know, what we were seeing last year was was narrow agents able to solve specific problems. What we see now agents that are able to abstract

the problem, chain of thought reasoning, being able to take that and turn it into sequenced action and turn the multi- aent sort of systems level thinking. So, it's the move from task specific to

systems level is the big shift that I'm seeing. and &gt;&gt; yeah so I think for me the big shift has been from co-pilot human in the loop to agents which can act and really provide

value business value and that's been the big shift &gt;&gt; so let's talk about that value let's talk about AI agents as a force multiplier I'm going to start here this

time you lead engineering for one of the biggest platforms in the world um there's a lot of discussion about AI agents can you demystify this what does that mean

&gt;&gt; yeah so I think what does that I mean an agent just like a human first of all agent has to act that's it has agency and it acts that's the first big difference and like any agent it has to

have couple of things it has to know a role just like a human it needs to know what it's supposed to do what is the jobs to be done it needs knowledge you know just like a human if I have in my

mind a agent has to have knowledge some memory so both short-term and long-term memory and then it should also be able to act you know it should be able to in a the digital world should be able to

act on an a API or something and then it should be able to act wherever the surface is maybe it's in WhatsApp channel wherever the user is interacting with it in a WhatsApp channel or web

channel or a digital channel or a SMS text more importantly most important in all of this is we should have guardrails on what it's not supposed to do that's the most important and then all of it

has to be covered to make it useful with what we call a trust layer because these things can hallucinate. It can have bias. It can have toxicity. Avoid all of that and they're

unpredictable ultimately. So it should have governance. Then it's auditability track. So you can do all of this. This and all is to do all of this is what an agent does. So this is the also the why

even though there's a lot of hype in reality it hasn't diffused enough. This is the business value which we are trying to bridge as vendors.

&gt;&gt; Right. Thank you Syel. I'm going to go to you next. So let's talk about governments. We sit here in Delhi the capital of one of the greatest nations of the world. The public sector. Are

they ready for this? How do we think about that? &gt;&gt; So I think uh let me not answer that question. I think the public sector needs to be ready. Okay. Uh so all the

way from managing public finances, public procurement, uh managing their workflows and processes better, there is no way that public sector can avoid this. However,

as um uh Shiny you pointed out, um the stakes here are very very high. Okay. So imagine um uh an agent crafting an RFP, a multi-million or a billion dollar RFP on behalf of the government. Okay, how

do we and you know in in in public procurement we often sacrifice speed for you know uh procedural uh uh tightness. Okay. So how do we actually what guardrails do we put around an agent or

more so can it really be end to end? Can it really be fully autonomous or do I still need that last human layer to make sure that the tees are crossed, the eyes are dotted because the stakes are really

high and a mistake can really you know lead to a lot of uh negative impact. So I think the public sector has to be ready but I think some of these guard rails has to be thought through and in

the context of public sector are agents fully autonomous or do they still automate or do they still operate with a little bit of you know that human layer? I I think that has to be thought

through. &gt;&gt; Okay, that's great. Thank you. I love that you said RFPs because that's a concrete example. So let's talk a little bit about use cases and Mike, I'm going

to go to you. Uh, let's talk about resilient infrastructure. One of the examples I hear a lot for AI agents, they can help you make reservations. And I love to eat. I think making restaurant

reservation actually pretty valuable to me. But could an AI agent do something like design a bridge? Could it design energy grid? Like where do we stand between reality and and science fiction?

&gt;&gt; Yeah. So, I think we we we're tracking pretty quickly to agents being able to do just those kinds of things. Um in the past what's been difficult is using computational methods in AI which has

been around for for a reasonable time for these things has been very difficult they it's because you know when if you're using some form of computational method AI to design a bridge you have to

specify that bridge perfectly you have to give it perfect inputs now it turns out that when a designer is designing something they don't have perfect inputs that's the process of design is actually

figuring out what your inputs are right so this has always been a little bit of a barrier for people to use these advanced methods methods with AI and specifically AI agents, you've now got a

much easier way of interacting. You know, it's it's more forgiving towards fuzzy requirements and earlier stages of thinking. It's able to give you things that inspire you. So, you know, one of

the things I talk a lot about publicly is that the notion of agents and creatives working in a loop together that it's sort of breaking the it's breaking the cycle where the the the

engineer has to come up with every idea from scratch from a blank canvas. Rather, describe what you're doing. Let the agents explore. So I'll give you one example specifically in infrastructure

because you wanted to get concrete. I mean something that we we we work with is is water systems for example a lot. So we we've built AI agents that can analyze flood planes that can analyze

how you might want to think of water drainage and these kind of things. So every time you're making a decision early on in your design, you can let this thing run through and it's going to

optimize your design in order to ensure that drainage is going to be successful on that. Now, drainage seems like a small little side thing, but it's a pretty massive part of infrastructure.

And having an agent handle that for you, it's pretty big deal. &gt;&gt; Mike, I have very close family ties to Louisiana. So, drainage and flood zones, that is not a small thing. That is a

very, very big thing. And actually, that's a perfect segue to the question I wanted to ask Trini. So, one of the most complex things that a government might have to deal with is disaster response.

Um, that is that a place where AI agents could be helpful? I mean I really like the theme you know welfare for all and I think while we can uh think of very big things or where AI

is doing AI can add value right now and disaster response is one good example um another small example which I wanted to give was like you know the we the key is to give back time to the people you know

that's very valuable giving back time is a very noble goal in my opinion to everybody body. Uh so we have this um we have a very interesting use case where there is a city in News in UK where they

created an agent called Bobby where the the it's like Bobby is a UK term for policemen and the citizens are asking a lot of questions which are not emergency and Bobby is answering them. Okay more

than 90% of them they get a lot of value. What is was interesting for me was we have another city in Tasmania which is using our product agent force to roll out agents to their police

people more than thousand police people because lot of times when they're in the field the policemen new or more experienced they have a lot of questions and they're asking and they call this

agent Terry and a lot of policemen say Terry is their best partner you know they have been so I think while we can think about futuristic uh val ways here and now. There are a lot of things we

can provide right now with the technology guardrails in the public sector in private sector obviously where with if you have the right platform where you have trust governance as a

foundational value with all the right guardrails we can still add a lot of value and we are seeing thousands of examples across public and private sector where you have

the crawl walk run mode you know you start something basic you can will add value. You still have the most esoteric cases with multi-agent orchestrations. I feel like but you you can start with

basic today and still get a lot of value. That's what we are seeing. &gt;&gt; That's great. So, Professor Tedri, we've talked a little bit about how agents can help governments serve their publics.

Are there are there risks there? Are there risks? Are there a risk of over reliance? Yeah, I mean there definitely risks and I think I share the view with my co-panelists that I think there's a

lot of benefits um to using AI in government and improving government services worldwide, but like everything else, we have to do it um cautiously and smartly. And I think some of it kind of

comes back to the human factor like pick your use cases wisely. One of the um themes in the in the safety report is that you know AI is emerging very jaggedly. We have some use cases like

computer programming that are really good. There are others that may not be quite ready for prime time. So I think when we think about over reliance is thinking about where AI is excelling,

focusing on those use cases and maybe doing sandboxes um around some of the others to give them a little bit more time to mature. I think also you know the over reliance picking up on some of

the great points is the guardrails. You know one of the things in the safety report is good news. We've made a lot of progress on guardrails and risk management, but still as the technology

moves quickly, a lot more work to be done. So, not relying too much um that we overlook guard rails and thinking about where humans should be in the loop. And then the third thing I'll just

mention is, you know, the interoperability of different agents and as we start to as as agents start to call upon third party agents is just thinking through, you know, what guard

rails, how how do you choose that? How do you allocate liability? How do you test the agents that you're going to bring into your system? &gt;&gt; Oh, uh, so guardrails have come up. Sini

mentioned it. You just mentioned it. Let's talk about guardrails um, a little bit. Um, so Shiny, um, we hear about chatbots, we hear about hallucinations. Um, those can be

annoying. When you're talking about a government deploying an AI system, AI agent, the consequences can be extremely significant. They can be a hallucinating government agent can be quite dangerous.

So let's talk about guardrails. How do you engineer trust into a system so that a minister or secretary feels confident that that's a tool that they can use to serve their people?

&gt;&gt; Yeah. So I think um um first of all one of the first things we had to build uh we realized that this is going to be an issue because these things can hallucinate and then not only they're

hallucinating they're very confident hallucinators. Correct. So it's like you know so that's the so [laughter] very content liars if you could look you could say even in that I mean

hallucination is a better term. Um so I think one of the first things we have to build is this trust layer where we everything like it could happen in the prompt injection like sometimes you

write the prompt wrong people could hack that you could have bias creeping in you have to red team it you know you have to put uh toxicity all of these guardrails and one of the things we had to build is

that layer even though the model providers usually they don't have the liability if they think like it's your problem you know that's the model is what The model is we inherently know

it's a foundational technology and one model was other at some point you could switch it but what the gap we saw why did why can't you just roll out a model and suddenly everything works magically

it doesn't you need this layer this infrastructure layer a trust infrastructure layer which is very important couple of examples so if you uh if you are giving loans

um and if you ask the AI to just look at the current pattern uh of usage and decide alone it the data it has seen may have inherent biases and it reflects that so you need to have mitigating

circumstances to ensure that that bias doesn't leak in uh so I think as the system has to put these guard rails it has to so one of so the other thing is as a regulator if you take the loan

example further let imagine You gave a loan to somebody or you rejected a loan 6 months later you want to check you know if you want to test that it is what it has done why it rejected you need the

reasoning traces on that point of time what did the agent say what was its assumptions because some of it is based on the data it's grounded in so that's the context it has you need that so what

we found is unless you have these tools and you take these specific examples so in a government use is today we have New York City public uh government today what they're doing is for their benefits

they have an agent which is answering lot of the questions for their constituents and and they are able to get 92% of the questions are being answered but how do you know what is the

proof that it's doing right so we have to build something called a testing center which you can validate that the answers are doing so agents are think like they're h like employees you need

to performance manage them you know they can drift they can hallucinate so you need a command center where you can say all of it is this is the difference between a pilot or a a demo which you

can find thousands of demos in YouTube versus real life where these things become so we had to build all of these things for both the customers or governments to build confidence they can

audit they can test not even if themselves an independent party also can test all of this infrastructure is what is required to make this a reality but once you do that there's a huge value

you can immediately provide to the either the uh customers or citizens &gt;&gt; can I just add to that quickly because I I I think you hit a really interesting

point at the end there that you know when when people talk about guardrails they think of guardrails as this perfect thing that at some point the guardrails are going to get strong enough that

every result is perfect. It's completely predictable and we're good. And and and I think we need to talk about the honesty of that. I mean, we're we're we're talking about systems that are

inherently probabilistic systems. You're never going to make a probabilistic system 100% deterministic. It's it's anism, right? So, so what we've discovered is that you I mean you do do

all the guardrails work that we're all talking about, but where you were going at the end there about making systems that can look at the accuracy of what's produced give you some feedback on how

accurate this solution or how well it's going to perform and then and this is very importantly what we've discovered is giving control to the human being giving giving control in our case to an

engineer right who is able to say oh I get it this is kind of you the result is a little off I'm going to give it some more feedback I'm going to reassess the results I'm going to run it again or I

might even go in myself and kind of tweak that information. And what we've discovered when I'm talking to an engineer and explaining how this stuff works. If I don't give them that level

of control, they don't trust the system. The minute they know they can actually control it. So it's not trust doesn't depend on a perfect answer. Trust actually depends on on transparency and

understanding and then the ability to come in and control something. &gt;&gt; But I think that's also because the engineers understand this is a tool. It's a tool for them to use to help

them. It's not something that is that is going to take control. Exactly. Um &gt;&gt; is there anything specifically with respect to infrastructure that you think government should be mindful of?

&gt;&gt; Um yeah. Well, look, so I mean I mean infrastructure is is is not known as the easiest and quickest thing to build right in countries. Um and I think one of what you know one of the really

boring things but absolutely necessary things with infrastructure is to make sure your digital ecosystem around that infrastructure is set. And I see a lot of places in the world getting into

building infrastructure trying to do this quickly without getting all that digital infrastructure in place. So building information modeling um getting in ensuring that every part of your

infrastructure is correctly modeled. It's represented at the right level. AI is not going to just magically come in and solve a bunch of problems unless you've got a lot of that digital stuff

in place already. So it's it's kind of a little bit of the boring work, but getting that stuff in place early um is one of the biggest things. I mean I've had a number of conversations here this

week about the 2047 initiative in India the amount of infrastructure that that is that is needs to be built in this country and the importance of using something like building information

modeling getting standard data getting that in place now if you get that in place now all this AI goodness you know is way easier to deploy against it. &gt;&gt; Yeah please. Yeah. So I think I heard

lot of discussion around sovereignity and I think the way uh we should think of sovereignty as two levels. There is strategic sovereignity and technical sovereignity. Strate by strategic

sovereignty I mean is like you get control on data your governance policies you know uh and your uh operational policies that I think you can implement it right now and get value

and I think and then on the technical one where people want to control their entire supply chain from the chips and all I would like to for governments to and public officials and policy

officials to think is as two tracks one takes longer in a lot of capital investment. Don't let the second track stop getting the benefit of the first track. So first track is easy. You can

ensure the data doesn't leave your country your policy guardrails have control human in the loop. It'll still get lot of benefits while you still want to uh um continue on the second track.

That would be my request to all the &gt;&gt; Yeah. Can I just make a quick build on what uh Mike said and because I do a lot of my work in the public sector with uh with governments. I think one of the

biggest guardrails beyond policies is actually the skilling the upskilling like Mike you said it's a probabilistic system inherently right so you cannot expect it to give correct results all

the time there's nothing called a correct result. So the person who's actually using this, who's using the tool at the district level, at the state level to make real government decisions,

that person is not an AI engineer. That person needs to be upskilled and needs to be told what can be trusted and what requires that additional layer of check. So I think if agentic AI has to take off

in public sector at scale then that upskilling at various levels of the government on what can be trusted and what cannot be trusted is also a very very big component.

&gt;&gt; Yes I totally agree. Um professor I wanted to ask you so you know it feels so trit to say technology is moving really quickly but in the last few years I mean AI is

moving very very quickly. We've talked a lot about guard rails. How should governments think about this? I mean, how how how are governments going to be able to keep up in terms of, you know,

setting government expectation, setting potentially regulation? Um, and for a technology that is moving so quickly. &gt;&gt; It's it's it's a hard one. I think you know

AI has evolved into a global multid-disciplinary field and I think you know we need to bring the global community together. I think we need policy makers, lawyers talking with

engineers talking with sector specialists um to really inform the policy in in real time. I mean I'm a big fan. And I spent a year working at NIS, the US National Institute of Standards

and Technology. And you know, we need to figure out how to do some of the guard rails. Um, you know, starting with the science and then the science can inform, you know, how to develop the standards,

how to develop the eval becomes, you know, a question. I mean, different countries um have different views on whether we should regulate or not regulate. You know, the US has a very

deregulatory approach. Europe is is the opposite. But if we can kind of agree on what those common standards are for evaluation and testing then governments can be free to decide do we mandate this

or not mandate that. And I think one um important nuance to add to the mix and this has been a theme of the conference is you know we have to well we want some standardization on these evaluation

mechanisms. We have to recognize that we speak different languages. We have different cultural norms. So while we want to have standardization, we've got to be able to localize what the

evaluation looks like because what might be appropriate in one country isn't going to be appropriate in another country. So it's hard. But I think you know starting with the science the

scientific report I would point people to you know building on that working through the AC network working through standards organizations and all these other initiatives to develop the

evaluation to build that evaluation ecosystem and then regulations can kind of overlay on top of that as policy makers think appropriate for their for their jurisdictions.

But if I could ask a follow-up question to you or or any of the panelists, I mean, I think one of the challenges there for companies is that it's really helpful for companies, I'll just speak

for enterprise software companies that I represent, it's helpful to know what those government expectations are. Like industry is looking for clarity and predictability. Um, and it's and I don't

I mean then I know it's also a tremendous challenge for the governments to be able to to move regulation or move the government expectations in line with that. Um, but I'd welcome any of our

panelists who's talking about from an industry perspective, how do you think about operating in a world where the technology is moving more quickly than the regulation?

&gt;&gt; Take a shot at Yeah, I see. Um, as as a as a software provider, you know, at we definitely deal with that. Uh, Victoria, um, the, you know, we've had a couple approaches.

One, I mean, we're we're obviously got to stay on top of this all the time, working with governments, making this part of a conversation. I spend a good part of my year traveling around the

world talking to governments and trying to sort of help them understand what needs to happen but also help us understand like you said what they're wanting. But the the the main problem is

just the sheer variance. I mean the the you you I mean even within the United States we have things between different state efforts right and then you get around the world it just gets even more

complicated. Um what we've tried to do is we've we've we've tried to run as far ahead of this as we can. So if there is a way that we can build in good controls right from the beginning we actually

build those controls to the maximum extent that we can within reason right um so what we've we've done is we found now we've run like for examp I'll give you an example in every AI feature we

have in our software we have something called a transparency card which looks like a nutrition label on like food but that nutrition label tells you what kind of model is behind it what data was used

to train it what kind of level of control you have what accuracy it has any bias that we know about in the that kind of stuff and it's a standard thing. So we rol we rolled that out about a

year about a year ago really to try and stay ahead of things. So if government started asking for these things, oh well we got a transparency card. What's actually happened now is that there's a

bunch of interest in that becoming part of a standard. So I and I mean I'm I'm not saying that really just to tout us because I think other companies are doing great things in this space as

well. You guys are doing a bunch of good stuff in the space too. I think this is an opportunity for us in industry to run ahead to try and help define some of these things because it is moving so

fast. I I'm hate to maybe I shouldn't say this publicly but the government doesn't always have the best answers right so I mean we can work with government to help them get develop

those answers and come up with good things which helps us then you know resist some of the complexity that's coming down the line &gt;&gt; yeah so one of the challenges in this is

projecting too much it's an exponential curve it's very hard to project so I think sometimes it's learn by doing I think the biggest thing the government can all governments can do is the policy

framework on how to update these standards. Today usually it takes a long time and so everybody's afraid and then it takes even harder to change the standard. So then the then everybody so

then they try to solve everything and when things are changing and so I think the main thing policy makers could do is just like the feedback loop there's a way to improve the policy framework

because then you don't need to be [snorts] afraid of getting everything right you know you you understand that hey some basics and as new data comes in you can update it and and then I think

that I think that in engineering and product we call this the product feedback loop and If you have something equal and all that then I think then everybody is clear

because we all want the right thing. I think there's no disconnect in the foundation of the want AI to help in a positive way to positive way to our entire community and the regulatory

framework in a changing technology. If the regulatory framework is able to change uh if you can change that then we are not afraid to say we need to get everything right on day one and we can

learn by doing [snorts] &gt;&gt; so agile regulation &gt;&gt; um I have loved this panel um unfortunately we're coming to a close so I'm going to ask each of you one final

question and sel I'm going to start with you and then head this way but if we were so fortunate to meet again in three years um so fortunate to meet in Delhi again in three years.

Looking back, what would you say is the one thing that you think would be the best way to determine whether or not we have succeeded in addressing some of these challenges? I know it's a big

question sorry but uh going to start with you. &gt;&gt; So since we are in uh Delhi, I'll give the answer in the Indian context. I think as um the primary theme or one of

the primary themes of this particular conference is inclusivity. So for me the success of AI, the true success of AI will be if uh a farmer could uh talk to a

small language model powered tool in his or her own vernacular language and get practical advice on how to manage the crop, how to manage the cattle and if that could be scaled up uh across the

length and breadth of India then I think that for me is the real win for AI. &gt;&gt; That's a big win. I mean that's a significant impact. Thank you. Great professor teacher.

&gt;&gt; Yeah. So I um kind of coming back to the evaluation ecosystem. We've made a lot of progress over the last couple years but more work needs to be done. You know more countries including the global

south are launching ACS you know AI safety or security institutes which is not hard regulation binding regulation but it's governments weighing in. And I think real progress three years from now

we have an active AC institute that's sharing information making real progress on evaluation techniques and one of the commitments that came out of some of the companies yesterday is you know also

localizing that so everybody can benefit from that global north global south. &gt;&gt; Thank you Mike. &gt;&gt; Um so so earlier on um I spoke about infrastructure um and I you know

physical infrastructure that is in in the in countries. Um, what I would hope to see is in a couple of years time we're actually seeing infrastructure genuinely get developed faster than it's

ever been developed and which is a really really tough problem making that happen in the physical world. So as a measure of AI truly doing this, that's an incredible measure. But on top of

that, it's doing it needs to be doing that without compromising safety, without compromising it. Just not a big black box that nobody understands, right? So what I would love to see is

not only is that infrastructure being developed faster, but the public is engaged with it. Engineers and people that are doing it feel comfortable with it. They feel secure, they feel fine

signing off on that because they feel that this is reliable. &gt;&gt; Thank you, Sheni. is so revolutionary as we all assume I hope in three years the bottom 50%

income has measurable that for me is &gt;&gt; that's fantastic um I want to say thank you to all of our panelists I want to say a special thank you to Shini and to Salesforce for bringing us all together

here today um thank you to our audience for joining us big round of applause for our panelists &gt;&gt; [applause]
