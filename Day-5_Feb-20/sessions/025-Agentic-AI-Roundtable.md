# Agentic AI Roundtable

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 15 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/0XPe93YjDwE?feature=share) |

## üé§ Speakers

- Caroline Louveaux, Mastercard
- Daniel Castro, Information Technology and Innovation Foundation
- Danielle Gilliam-Moore, Salesforce
- Jason Oxman, Information Technology Industry Council
- Mohak Shroff, LinkedIn
- Prith Banerjee, Synopsys
- Sam Kaplan, Palo Alto Networks
- Syam Nair, NetApp

## ü§ù Knowledge Partners

- Information Technology Industry Council

## üìù Summary

This roundtable will convene senior industry leaders and government officials to examine governance, interoperability, and responsible deployment challenges posed by emerging agentic AI systems capable of autonomous decision-making and adaptive behaviour. Grounded in real-world use cases, the discussion will focus on cybersecurity, enterprise productivity, and autonomous systems. Participants will explore risk-based governance, secure-by-design principles, and the role of open, industry-led technical standards in enabling safe, scalable, and interoperable agentic AI across borders.

## üîë Key Takeaways

1. This roundtable will convene senior industry leaders and government officials to examine governance, interoperability, and responsible deployment challenges posed by emerging agentic AI systems capable of autonomous decision-making and adaptive behaviour.
2. Grounded in real-world use cases, the discussion will focus on cybersecurity, enterprise productivity, and autonomous systems.
3. Participants will explore risk-based governance, secure-by-design principles, and the role of open, industry-led technical standards in enabling safe, scalable, and interoperable agentic AI across borders.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/0XPe93YjDwE/maxresdefault.jpg)](https://youtube.com/live/0XPe93YjDwE?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

Just a second. Our second discussion will be this panel which will discuss the business case use of Agentic AI. And then we'll we follow that with a second panel which will discuss the public

policy implications of Agentic AI. That is to say what government should be doing to encourage and to safeguard the use of Agentic AI. We all know that Agentic AI is quite literally the AI of

agents. And there's been a lot of discussion here at the AI impact summit about how Agentic AI is creating new opportunities for jobs, for societal benefits, for use cases across different

industries. And one of the most important questions is of course what public policy solutions are going to be necessary to encourage the use of agentic AI. So I'm very pleased uh to

welcome as our opening speaker Austin Mayoron who is the acting director of the center for AI standards and innovation and a senior you have the longest title in the world. Uh Austin

senior legal adviser to the under secretary of commerce for intellectual property and director of the United States patent and trademark office. Austin we are thrilled to have you here.

you have some uh very interesting updates on how the US administration is approaching Agentic AI, including what the office is doing, which I think is enormously important as well. So, you're

going to join us for a few minutes of uh table setting remarks, if you will, and we're thrilled to have you here, Austin, I'll turn it over to you. &gt;&gt; Absolutely. Thank you, Jason. Thank you

to ITI and thank you all for coming today. As Jason said, my name is Austin Mayron, and I'm the acting director of the US Center for AI Standards and Innovation, also called Casey. Um, Casey

was originally founded as the US AI Safety Institute, but last year in June of 2025, Secretary of Commerce Howard Lutnik refounded us as the Center for AI Standards and Innovation. That signaled

a shift away from safety principles more towards standards and innovation. I think there's two organizational aspects of um, Casey that are worth note. The first is that we're located within the

Department of Commerce. We are very focused on helping industry. The secretary has tasked us to be the front door for industry to the United States government and we really see ourselves

as serving in that role. We collaborate with various aspects of the AI ecosystem including the frontier labs for instance on pre-eployment evaluations and we like to partner with industry to help

understand government. Um, as one example, you know, sometimes there's a lack of AI expertise within the US government and Casey, because we have talent from Frontier AI Labs, were able

to help explain novel concepts to other aspects of the administration. The other aspect of our organization that bears note is that we're located within NIST, the National Institute for Standards and

Technology. And the thing that's worth noting there is that NIST throughout its history, it hasn't been a regulatory organization. It's been an organization that's promoted economic growth and

technological development by um developing standards and facilitating the development of standards and best practices. And so Casey, we see our role as partnering with industry to develop

the standards and best practices they need to flourish. And here we're here today to talk about AI agents, which is an incredibly timely topic. And so I thank it for organizing this. Um just

this week, Casey, my organization, we've kicked off an AI agent standards initiative. Our goal is to hear from industry how traditional standards work, best practices, guidelines can help

unlock and facilitate adoption. So, one area where we've already started that work is on AI agent security. We put out a request for information or RFI about what challenges industry is facing with

AI agent security. Our colleagues at NIST at the information technology laboratory also have a publication out for comment on AI identity and verification um which we encourage you

um if you're interested please look at the documents review them send in your comments. We also announced this week that we're going to be holding sector specific listening sessions on barriers

to adoption the sectors of healthcare, education, and finance. And our goal here is we want to learn actually what are the challenges that industry is facing. These AI agents, they have

tremendous potential, but we want to understand how Casey and NIST and the US government can help unlock adoption through standards and best practices. So, I'm delighted to be here and and

take part in this conversation and and learn more from my fellow panelists. &gt;&gt; Thanks, Austin, so much. really appreciate you being here and helping set the stage for us for our discussion

of Agentic AI. As I mentioned, we have uh three great experts here to start us off on the business side discussion before we move to the policy side discussion because I really think it's

important for us to understand exactly what use cases of Agentic AI are happening across different segments of the uh AI stack. So, we're very fortunate to have three experts here to

help us with this discussion. Pri Banerjee is the uh CTO and SVP of Synopsis, the uh design software automation semiconductor uh uh company. Um great to have you here uh PR.

Caroline Luvo is chief privacy AI and data responsibility officer at Mastercard. Caroline, thanks for being here. And uh also delighted to have uh Sam Nair who is chief product offer

officer at NetApp, the global multicloud service provider. And so the three of them are each going to uh share a couple minutes uh of opening remarks on Agentic AI use cases. What we've asked them each

to do is uh share with all of you kind of the the top favorite Agentic AI use case that's happening um so that we can use that as a uh as a way to frame the discussion around business and policy to

solutions. Um so if we could Pri I'll start with you for your favorite agentic AI uh use case uh that's happening at Synopsis. &gt;&gt; Sure. So, so I'm Prit Banerjee and my

role is to look at sort of the future directions of where synopsis is headed and Agentic AI is actually the core of this. But before I do that, I want to share with you what synopsis does.

Synopsis is the leading provider of electronic design automation tools and IP to design chips. So the chips from say Nvidia or AMD or Broadcom, Qualcomm are designed with with this billion

transistor chips, trillion transistor chips designed with synopsis tools. But the opportunity that synopsis has seen is these chips are going into systems systems that are like cars or or

aircraft or spacecraft or system data centers healthcare etc. Right? So we have this vision of chips to systems that and because of that synopsis recently acquired anis for $ 35 billion

right to be a chips to systems company. I came into synopsis as CTO at ANIs. So now the challenge that I want to share with all of you is as you are designing a car right it's a softwaredefined car

right you that a Tesla car has more than 100 million lines of C core in that car that code runs on an ECU an ECU designed by NXP or ST Micro or or Qualcomm and that chip is still not yet designed

right it is being designed with say synopsis tools but you're writing software on the tool on that chip And so you have to do what is called softwaredefined

verification validation right before the software is before the chip is designed and that that control will control the electric brakes the electric steering the autonomous driving of the car and

the the car is it's a physical product is being driven on the road right and so you use anis physics simulation like fluent for aerodynamics or or ls dino for crash or electro or hfs of

electromagnetics So essentially what we are doing is bringing the physics of the world around us powered by AI along with the chip design in this what we call intelligent product design which is

silicon design so the chip inside any complex design software enabled so you can do software updates over their updates and AIdriven so the so that's all the context and if we are a 10

billion company with a market cap of 100 billion so the agentic AI part is the following that the pace of innovation in the world is changing. You used to design a new car every seven years or

maybe 5 years. That pace of innovation like Tesla, Elon Musk said we have to do it every year. Every year they want to bring a new car to market or Nvidia Jensen, right? The chip design used to

be every three years. Nvidia Jensen says you have to do it every year. So the pace of innovation is becoming faster and the complexity. You used to have a chip with maybe a million transistors.

Now it's a billion transistors. It's a trillion transistor. It's incredibly complex. And then you have the the chip with all the complicated system. The complexity is so hard that you used to

have human designers at the Qualcomms, Nvidia, Net, right? Who could do use those things using the synopsis tools. You cannot do that anymore. It is very very hard. That's where agentic AI is

coming in. So at synopsis what we have created is agentic engineers. These are like human engineers that are not trying to take the jobs of human engineers away. They are going to

complement the job of a human engineer. So you at at Broadcom call may have a 100,000 engineers but you'll be complimented with another 200,000 agentic engineers from synopsis who will

do the lower level reasoning job. like a human, right? But the human will still be in the loop to make sure that you're not doing drastic sort of bad things, right? This is the incredible

opportunity. But as the world talks about agentic AI in the world of large language models and data and words as tokens, our world is what we call physical AI, which is physics and is a

physical AI part where we are applying our AsiTic engineering technology to very very exciting area. &gt;&gt; That's great. And I love how you described the human engineers being

complemented by, not replaced by the agentic AI that's helping them be more efficient and do their jobs better. Caroline, I think of uh payments networks as having used AI for decades.

Literally, the fact that you can take a plastic card and tie it back to a human being, no matter where they are in the world, is actually truly remarkable. When you think about how payments

networks work, it is truly remarkable the technology, especially since you're processing literally millions of transactions a second around the world. So with that, you look over uh global AI

for Mastercard and I'm curious how Agentic AI is influencing the work that you and your colleagues do to make these payments rails run around the world. &gt;&gt; Absolutely. And hi everyone, it's great

to be here with you. As you said, uh for Mascat, AI is nothing new. We have been leveraging AI for decades to make our payment network safer and more secure for everyone. Now with Atlantic, we are

moving from AI systems that recommend to AI systems that act. Right? And in cyber security in payments, the shift is already real. Today AI um agentic systems are being deployed for example

to detect suspicious transactions, to triage fraud signals, to initiate secure payment flows. If you think about it, if we want to be able to detect and to block fraud in real time, decisions have

to be made in milliseconds at scale. And of course, while speed and scale matter a lot, accountability is a must. What's important is that these agents don't make decisions um with open-ended

autonomy. They must act within clear values, principles, within clear permissions. What is the agent allowed to do? What is not allowed to do? And when does a human

need to step in and of course humans have to have full oversight end to end. So um I mean there are many other use cases. I'm happy to talk more about that. But I think that's really our main

use case. But of course the technology is moving really really fast. Uh we are now talking about uh these multi- aent ecosystem. um that raises a whole new range of

opportunities as well as novel challenges. And so that's where these kind of summits where we all come together are really really important to to really get it right.

&gt;&gt; I love how you characterize it as moving from what we call assistive AI to operational AI. In other words, instead of just helping with a task, the AI as an agent can actually take a task on.

Still oversight in the system. And that I should have previewed this. We're going to come back around and talk to the panelists about guidelines and protections and as Austin uh importantly

noted at the outset um the security of the system uh how that's built in as well and uh Siam I want to come to you next uh the multicloud that NetApp uh operates obviously is moving data around

the world on behalf of customers storing data around the world and allowing your customers to access data in a multi cloud environment uh how is Agentic AI helping NetApp uh with that level of

customer service. &gt;&gt; Yeah. No, thank you. Uh so NetApp actually you know as you said multicloud we both power public cloud as well as private cloud. Many of the largest

infrastructure is actually the data infrastructure is built on NetApp from a file storage standpoint. One of the key challenges in AI itself is having quality of data right data quality is

super important and the previous session actually talked about it and uh data quality especially from unstructured truly unstructured how do you really get the structured value out of it and

that's where agents can actually help and agents help which is we are bu developing agents which are sitting closer to the storage controller if you know the storage architecture says that

without moving data and going through cluttered pip pipelines and you know positioning the data ready for AI. You can actually have the data at the source itself uh which will be ready for AI.

And how this helps is you know many of the areas cyber security as it continues to grow as a threat. You know 59 seconds is the average breakout of a threat these days. Risk and uh threat will

become super important to manage and you need to do that at the layer where the data sits. So Agentic has a really good use case with respect to that. We are still in our journey early uh journey in

terms of building these capabilities. One would say look if you have five levels of AI where you know agentic AI where uh level one is mostly assisted copilot to autonomous agents running a

network of agents at level five. We're still in that journey somewhere in the three range and that's what we see from customers to in terms of how they want to leverage data. So that's one of my

favorite use cases in preparing the data, making sure that the right data is available both for the agents and the agents can make it available for the use cases.

&gt;&gt; Yeah. Interesting. So the agents are actually helping you expose any risks that may need to be addressed as part of that provisioning of data. And Austin, I'm going to ask you to set up our

second round question um uh with me, not for me. Uh and that is um you know, the industry has a responsibility to inform governments about risks uh and how they're being addressed. So as we move

into the uh the the the next question for the panel around uh enterprise guardrails the companies are setting up for Aentic AI. Anything in particular you would flag that you're looking to

hear from industry uh in the US administration uh about those guardrails? You know you you are uh overseeing an operation that asks for industry input which I think is uh rare

and uh particularly great. Um so thank you for doing that. um any uh uh you know perhaps some practice tips that you can provide to everyone in the room about um what it is helpful to provide

government uh the US administration or other government colleagues that you've heard from uh on these issues and and how it's helpful to provide that information.

&gt;&gt; Yeah, absolutely. So at KC our focus right now is truly on unlocking innovation and adoption and we work in the standards space and so we look to how NIST fostered standards and best

practices and guidelines documents can help with that innovation and that adoption. Um and so the NIST process the way it normally works is we like to gather and convene industry to

understand the challenges they're facing. It's more of a bottom up grassroots approach than a top down. We're not sitting there in Washington and saying, you know, this is the

problem and and we're going to fix it. We we take a little bit of humility and say we don't actually know what the problem is until we talk to the people who are closest to the issue because we

only have a narrow slice of the world from our vantage point and the people who are actually in the field working on innovation, working on adoption. They have a better sense of what the barriers

are. And so we encourage everyone in industry and across the ecosystem to really engage with us to tell us the problems that you're encountering. and we have structured formal ways for you

to do that. For instance, the request for information on AI agent security. I think it's open for about another month and some some have already submitted comments, but we look forward to

comments. As I said, we're also convening listening sessions, I think in April, on barriers to adoption, particularly on agent issues for education, healthcare, and finance.

We're starting with those three sectors. Um, but we really welcome that type of engagement because we want to facilitate adoption. And one example that I sort of like to use, I I don't know if it's

actually a barrier to adoption, but let's say in a regulated field like healthcare or education, there's PII and there's a reluctance to adopt because it's unclear how the AI agents and

systems are treating PII and whether it'll satisfy regulatory burdens. Casey could play a role in helping settle concerns about that because we could develop benchmarks, methodologies, and

evaluation methods to give industry the confidence they need that, for instance, the model that they're looking to procure and adopt and implement handles PII the way they need to to satisfy

their regulatory obligations. So, that's a way where KC through measurement science, best practices, and standards can help facilitate adoption. We're also looking at interoperability, and we'll

have more about that in the coming months. &gt;&gt; That's great. Really appreciate that, Austin. And I love the focus on voluntary industrydriven consensusbased

standards because that's how the tech industry prefers to operate. It's better than government regulation particularly because those standards are global in nature and uh NIST is a great example as

you noted of support of those voluntary consensus based industry standards which we would all prefer to operate. And uh Pri I'll come back to you on this question of um I guess I'd call them

guard rails kind of the enterprise guard rails around uh risk management. um that you're putting in place. Governments are paying attention. We want to handle these issues in the private sector. What

what are you seeing that's important as far as those enterprise guardrails for risk management? &gt;&gt; So, that's a great question. Actually, at the AI summit yesterday, there's a

lot of speakers from starting with Prime Minister Modi to President Mcron, everybody kind of talked about responsible, safe AI and AI for for everyone.

But I want everybody in the audience to understand what is going on in this world, right? So there is a a problem right you have a a video that you can watch on say YouTube or or Facebook and

you want to prevent a young child from watching that right I mean that is responsible and you want to make sure that a 12 year old doesn't watch that but if he or she watches it it's not the

end of the world I mean yes you have seen this but the world that we live in is this intelligent product design right you designing a car and we have as Sham was mentioning level one which is

assistive all the way to level five which is fully autonomous. Now imagine a world I'm I'm now doing the scary part so that you understand how scary it can be right a autonomous car that is

driving on the streets of Mumbai right and it's supposed to be autonomous making sure the pedestrians and the cows are being avoided but suppose there is a cyber attack right and and somebody goes

in and you want to use that car as a weapon right as you know there are terrorists that go in and they bang into these things right so we have to make sure that this softwaredefined

systems. Just imagine a airplane, right? You have you know what has happened in in 911. A airplane hit a thing. So you could imagine a softwaredefined airplane being used as a as a missile. Right? So

this is how important is because unlike the world of Facebook and Google, I'm not undermining Facebook Google. I'm just saying you are dealing with people watching stuff and saying like unlike

right we are dealing with physical AI interacting with the real world if real world some things happen some really dangerous things can happen right and so we have to be extra careful so that's

the challenge what we are trying to do is to make sure that as part of this agentic engineering workflow we are doing it in a responsible manner in a safe manner right and the the work that

we are doing in terms of verification validation So the software flow that we do before we actually do a hardware prototyping we do full like 100% coverage at the digital level. So we are

designing the airplane on the computer designing the car on the computer with as close to 100% guarantee. Nothing is 100%. But I want you to understand how much more complicated this is, right?

Because in the hands we can design softwaredefined sort of uh data centers or softwaredefed nuclear arsenals, right? In the hands of the wrong person, some bad things can happen. So we have

to be extra careful about the responsible safe AI that we do for our intelligent product design. It is happening software define is happening but we have to be super careful. Thank

you. Sometimes the best way to get people to pay attention to what you're saying is to scare them and uh so you you've certainly done that and Caroline uh there's a lot of bad stuff happening

on the payment systems as well and the consequences of fraud and security breaches are or a actual shutdown of the network is almost impossible to contemplate global commerce grinding to

a halt. Um I don't know if you want to scare people like that as well when you're talking about &gt;&gt; let me go there. Let me go ahead with enterprise. on the plane coming to New

Delhi, I watched The Companion. It's a it's a movie around uh romance robots. I'm not going to spoil the end, but that's actually a scary story for sure. Um now, back to the Mastercard vault. Uh

the principle is very simple. Autonomy can only scale if they trust. And so at Mastercard, we think we have a role to play when it comes to agentic commerce. Meaning, you know, you use an agent to

make payments on your behalf. And so we want these agentic payments to be safe and secure and trusted. And therefore we came up with a with a playbook with four key guards. The first one is know your

agent, right? Before an agent act and before it makes a a payment, we want to make sure that it's verified and trusted. So everyone needs to know that it's a legitimate agent and not a a

rogue robot or a fraudster. Important, right? The second one, of course, is security by design. It has to be remain the foundation and so we are leveraging advanced technologies around

custom authentication tokenization to make sure that the sensitive credentials for example your card number is not visible and not exposed to third parties to the merchants to the agents or

anything like that. Third and that's a bit new we want to make sure that we have clear consumer intent. The consumer has to be always in control of what he or she authorized the

agent to purchase on his or her behalf. We learned this the practical way just a couple of months ago. An employee at Masaca decided to ask an agent, hey, are you able to buy sushi? The idea was to

just to test the the agents capability to do so. But the agent took the question literally and place an order using the employee card details on file. &gt;&gt; So, lesson learned. Clarity matters.

Clarity of the intent that can be verified. Otherwise, you end up with these platters of susies. And then last but not least, everything has to be um traceable and auditable.

And that's needed if you want to be able to give consumers the ret the red address if things go wrong, dispute resolution, and of course to make the regulators happy and comfortable. And so

these guardways are not there to slow adoption. you know, if done well, they're going to be key to scale adoption in a way that is trusted by design.

&gt;&gt; Great. Um, sushi is not scary, but the use case you described is. Um, so appreciate that. &gt;&gt; It's only sushi. We're good. &gt;&gt; It's only sushi. That's right. Um, Sam,

uh, you get to wrap us up uh because we're closing uh the panel out. You don't have to scare people if you don't want to, but I'd love to hear how NetApp is thinking about uh enterprise guard

rails for risk management around Agentic AI. &gt;&gt; Yeah, no scary stories. Uh so I think one of the ways I would say this is you know as humans we used to make mistakes

but was much more contained as sometimes in enterprises you had insider threat but it was much more contained but now you're talking about a network of agents where the blast radius in terms of an

error or a mistake or a threat is much more profound. So guardrails become important. These they need to be at multiple levels. Number one is you know public private partnership in

identifying the guardrails in terms of how agents need to operate being very specific to the enterprise being very specific to the business uh is important and working together with the consu with

the customers and in some cases consumers others and businessto business understanding the use case and for which how we need to build guardrails within the system and more importantly I think

you know I'll go back to what one need to figure out is the governance of the data Because data is the one that is actually going to power how agents make these decisions. Right? Unlike human,

there is no empathy built into the agent. At least not at this point. And it is not making decisions based on situational awareness. It's making ba decisions based on the data. And if the

data can be manipulated, if the lineage of data is not properly understood, if it is not really governed, if there are no guardrails for that, then you could actually get outcomes from agents that

are going to be scary. And the last piece of this is look unlike u um agents which can do everything agents cannot take accountability they're not responsible they can't take

accountability it's the humans it's the business owner who takes it so having those guardrails worked in tandem with the customer consumer with the public private sector partnership is super

important in terms of defending &gt;&gt; that's great as uh the PM said I think eloquently yesterday in the plenary session like GPS which can give you directions but you don't have to follow

the directions. Uh AI is a tool and humans need to uh decide what to do with it. Uh and that's an important lesson and a great way to close our uh industry setup panel. Um we're going to move

immediately into our policy discussion uh right here in just about uh 90 seconds or so. Uh but in the uh meantime while we set up and invite our next round of speakers, please join me in

thanking our fantastic panel for this great discussion. [applause] back and pause your conversation. We're going to go right ahead as promised into our discussion of the policy issues

emanating from uh our discussion that we just had with business experts about use of agentic AI. Uh if by the way you're interested uh we just released at ITI a uh a paper on agentic AI. It's available

on our website itici.org. Um commend it to you. It talks about the intersection between business and policy which I'm not going to do now because my job is to let all of our experts who are

right here before you uh do that. In fact, we have um so little time and so many great voices to hear from that I'm not going to do the usual introduction go down the panel because that will burn

valuable time. I'm just going to ask everybody to introduce themselves and I'm going to go down and ask uh everybody to to kind of uh give their framing on the on the same question.

Jennifer, I'll start with you just to um get you uh teed up. And that is uh we know about the business use cases of Agentic AI. The big question now is what are policy makers looking at and what

should policy makers look at? our goal in the tech industry obviously is to ensure that public policy um uh is uh inspirational to innovators that it doesn't interfere with the ability of

innovators to get the products and services out to market that we all want to see and benefit from. But of course policy makers have other things in mind. They want to make sure that consumers

are protected. They want to make sure that safety and security is part of the design of products that are deployed into the market. So we have a great industry panel of experts who are going

to share their views on what policy makers should be thinking about and what they should be doing to inspire the use of Agentic AI while also uh addressing uh important public policy concerns. So

I'll ask each of our panelists to address that and to introduce themselves. Jennifer, I already said who you are. Um we can uh just introduce yourself and your company and um let's

take that as the prompt. what's and and you get to pick one thing that you think um policy makers should be most focusing on. &gt;&gt; Great. Thank you, Jason. Uh Jennifer

Mulveni with Adobe and you know I learned a great Hindi term yesterday watching the prime minister speak and that is mahave uh human uh and when you really think about policy policy you

know has been around since the dawn of time and it really is about helping to prevent harms against humans. Um and so that is what policy still is meant to do today. I think when policy makers look

at anything whether it's tech or welfare or tax policy it's what does this policy mean for humans and how to prevent harm and what does that mean and we as lobbyists in Washington DC or my former

role there you humans go in and talk about what it means for whatever that that uh stakeholder group you're talking about is so when we're now in a world of of uh policy actually governing systems

not just people uh but I think that the prime minister's focus on human is something that Adobe talks a lot about as well that should be humans before models uh our CEO of Adobe often says

it's not what we can do with technology, it's what we should do. Uh and I really love that statement because that really does think about what is this going to mean for humans and uh how can we uh

advance that that agenda. &gt;&gt; Love that. Thank you Jennifer. &gt;&gt; Yep. &gt;&gt; Ellie. &gt;&gt; Hi everyone. I'm Ellie Sakai. I am part

of public policy team within Google. Um several of our colleagues in the previous panel mentioned that um agentic AI is not a point in development, right? So it's we can as we think about agentic

AI we should be thinking about the continuum depending on uh agents autonomy depending on their access to memory depending on the context of use and depending on their their ability to

do long-term planning and um basically um act on the real world. Um so that is why I think it's important when we think about policy uh to think about this continuum of agents rather than

something is agentic and something is not agentic. Uh that being said I think that um one of the uh one of the main safeguards that we talk about is human in the loop uh for agentic AI and that

also varies significantly with the ability or the reliability of an agent. So um as we move from agents that need confirmation for every single step that they want to take uh they need human

approval. As we move from them to agents that are more autonomous we should be thinking about moving from human in the loop to human on the loop or human in command. A similar analogy to this is

how um Federal Aviation Administration in the US thinks about moving from pilot being always inside of drones to pilots being in command of drones. So as the safety of these drones improve and

safety of u AI systems to keep track of these drones uh through a detection and avoid system improves we can move from pilot always keeping an eye ey line with the drone to pilot being on the loop or

pilot being on um in command. So I think these analogies within um different industries allow us to think about agents. And another thing that I think um policy makers as they think about

agents should consider is that um agents are a new may be a new technology but they at the end of the day they may cause harm. So we should be thinking about regulating the use or application

or the harm that they actualize compared to regulating the underlying technology. Otherwise we end up regulating let's say the AI models that by the time that the regulation goes into effect the AI model

has evolved into something that is now agentic. &gt;&gt; Makes sense and appreciate your perspective and I should have noted that you're not only doing public policy work

for Google but you're actually a real computer scientist. PhD machine learning. She knows how the machines think. Um, which is important as well. Um, and sometimes they talk to us,

right? Sometimes. Um, let's go to Carly Cloudflare. Next. &gt;&gt; Great. Thank you. Um, hi everyone. My name is Karly Ramsey. I lead public policy for Asia Pacific. I'm uh for

Cloudflare. I'm based in Singapore. Um and uh Cloudflare just for those of you who who don't know us, Cloudflare runs a global network and we kind of sit in between our customers and their users

and we protect the traffic that goes back and forth and um I think a large majority of all the AI uh model providers are our customers as well. So we're protecting that traffic as we go

back and forth. So we have a unique viewpoint. Um we also are we offer developer tools as well and uh people are building AI agents off of Cloudflare. So there's a there's that

angle that Cloudflare sees as well. So like you said, choose one thing that we we recommend to policy makers. That's a hard one, but I was thinking in keeping with the the theme of this summit, which

is very much about inclusive AI. I think that's something that policy makers should consider is whether or not we're making AI agentic AI specifically um available for everyone, right? So that

becomes uh is it accessible? Are the standards perhaps open? I think open models, open standards are really interesting and and allowing people to access tools that they might not

normally be able to access. Um and so as policy makers think about diffusing this technology more widely, maybe just out even outside of the enterprises, um one thing that as someone who sits in Asia

Pacific and this is really concerning to me is like how do we ensure that the different governments when they're when they're making these tools accessible are talking to each other and I think it

has a really neat role to play in that actually because we all know that NIST is the gold standard and it's a voluntary these are voluntary standards. are often referenced a lot in Asia.

Actually, Singapore just came out with their own framework on agentic AI governance, right? And the question is is that is that going to be compatible with whatever NIST is going to put out?

Big question. Singapore is a leader in cyber security standards in this region. And I've had some interesting conversations here in these past couple days about India. India obviously with

the tech bastion of tech talent that we see in India, they want to be involved in standard development and and and and for the global south, you know what I mean? So great like and how do we get

them involved and how do we make sure that as global companies that they're not all of these standards aren't contradicting each other as well right so that harmonization pieces very

important &gt;&gt; so important technology uh doesn't want to stop at borders it wants to serve the world and uh such an important issue Sam Palo Alto

&gt;&gt; perfect PaloAlto you conveniently sat the two cyber companies cyber security companies next to each other um so my name is Sam Kaplan I'm the assistant general counsel for global polic

um at PaloAlto Networks. Um and for those of you that don't know us, we're the world's largest pure play cyber security company. &gt;&gt; Can you hear me there? Okay, there it's

better. Sorry. Um I need to project better. Um &gt;&gt; uh anyways, I think Jason to pivot off of your question, I think, you know, at a high level, one of the the the one

lesson I think if we could impart to policy makers, you know, start with the standards organizations to tell you the truth. um the standards organizations both in the

United States but also abroad. Carly referred to the Singapore agency but they are in the midst of developing these voluntary frameworks that are really serving as the foundation not

only to understanding the technology but to better understand sort of the risk picture that we are facing when it comes to these types of technologies where we started with traditional model security

frameworks when it comes to LLMs that are all based on sort of prompt and responses. These standard setting organizations are now very very deep into sort of developing these same

standards on Agentic and as they are painting a better picture and working with industry to understand how that risk picture is changing and how what was once sort of almost a a

two-dimensional understanding of the risk when it comes to AI models is now very much a three-dimensional picture when you're looking at agents because these are the parts of the models that

all of a sudden have arms and legs. So when you're looking at this from a security perspective, you're taking what could be sort of a digital threat that can sort of metastasize on networks.

These are threats that all of a sudden can have kinetic consequences in real life as these agents are executing decisions across the financial system from your previous panel, but across

autonomous systems. So understanding that risk picture uh is going to be critically important. And last, I think that really pivots into one of the themes from the summit itself. As policy

makers, in particular, policy makers are looking at sort of responsible and safe deployment. They need to understand and appreciate that security, security of those models, security of those agents

is a foundational layer to increasing trust to facilitating responsible deployment of AI because it's the best way to secure and as much as we can understand the behavior of these models

and agents as they're interacting with the ecosystem and now the real physical world that we're seeing. &gt;&gt; Yeah. and policy makers are keeping an eye on all the products and services to

see if that is done well or not at which case they they may step in. All right, to follow your uh thematic, we're moving from cyber security to enterprise software. And Danielle,

&gt;&gt; you're going to take my joke, aren't you? That just you sat me next to I know how dare. &gt;&gt; It's not my joke. It's Sam's joke. But yes, I'm going to take it. I'm going to

take it. So Danielle, please commence the enterprise software portion of our program. &gt;&gt; I can speak for you if you want me to. I'm joking. Um Danielle with Salesforce.

Um I'm our director of global public policy and I lead um our AI our AI policy work. The panelists have said a lot of great things and they've also uh shown a lot of what I'm going to say. So

I'll try to make this short. But when we think about AI, I think there's um a governance response that needs to happen. And when we talk about governance, I think a lot of people

conflate governance with regulation. And governance is more than regulation. Governance can be regulation, but it's also standards. It's also global norms. It's also you know risk and uh quality

assurance uh procedures in in companies. And so along with the standards piece I think a critical thing to remember is that you know ISO controls takes about three years to that process. So it's

quite a long process. So when you look at the ISO 420,01 standard, it's a great standard, but it'll take time to further build on that, which I think then makes in uh organizations like Ness, the

different safety institutes incredibly important in filling in the gaps while work is being done to bring about new controls around aentic. The other thing I'll say is on regulation there's this

emerging um framework that it was first kind of started in the UK but I'm seeing governments like Indonesia also take this on of instead of having this large overarching AI regulation they're

looking at they're allowing the different um ministries that have compet core competencies on things like financial services or healthcare to take the lead. So you have a more diffuse um

model that's happening and I I would encourage I would encourage lawmakers to look at that. You know, some of these agencies have years and years and years and years of of relationships and

expertise. And so wouldn't they be best placed to think about um not necessarily regulations but frameworks, rules that best suit, you know, a small uh startup that isn't that is operating, you know,

a financial services agent or something like that, some edge use case. I think that is a more agile way to look at agentic which you know agility does I think bring about adoption and is very

key to adoption. &gt;&gt; Thanks. &gt;&gt; Perfect. Kambies is anything left for you to say now?

&gt;&gt; I was just going to say ditto to everything that [laughter] Danielle said because that's basically what I was going to say. Uh and she said it way better than I could ever do. Um you know

yeah service. know I you know I guess I would add just you know having worked in government now within industry you know there's kind of I I like to think like I could sort of have like the vantage

point of like a former regulator policy maker as well as now in industry and I think what we are looking for and what we've heard earlier today is like we want clarity we want clarity we want to

we want standards we want to like we want to see what good governance looks like right don't give us you know if I could give a message to to governments and regulators you know Don't give us

sort of theoretical abstract principles but give us actually what you know practical standards what does good governance look like operational clarity you know um playbooks um model

frameworks uh Jason and I you know I remember um for many years ago when I was at Treasury and you were at ETF you know there was this line like you know these technologies are rapidly evolving

and as they're evolving policies and regulations need to evolve with them otherwise it's going to stifle these innovations and it's gonna it's going to actually create more harm than

good. &gt;&gt; Well put. Well put. All right. So, uh now that we've provided a wish list for regulators, um the next question and um Danielle, I'm going to give you the

chance to go first because of your observation that sometimes panels go down the line and it's not fair to the people who are at the end of the panel. I think that's absolutely true. I would

have let Kambies go first but um you're speaking for the enterprise software uh okay &gt;&gt; industry generally so the question is uh you know one of the big themes here at

the AI impact summit is uh unification of the policy uh agenda across countries across governments across regions so is there a particular platform you've seen or organization you've seen is there a

particular place where conversations like the ones we've been talking about here should be taking place you know the US, India, like-minded uh governments around the world, they want to be all on

the same page, but there is a tendency for India specific standards for US specific standards. There's a tendency for that in the physical world and in the digital world and that's very

difficult for us to operate in. So in the agentic AI arena, I'm curious from all of you if there is a particular um multilateral venue or a particular platform or particular thing you've seen

work well that you would recommend to governments here that they look to for this. And Danielle, have I bought you enough time to come up with uh your answer um so that I can call on you

first? &gt;&gt; I woke up this morning knowing the answer to this. Excellent. Okay. I live for this question. &gt;&gt; It's all yours.

&gt;&gt; Which is the OECD. All right. &gt;&gt; The the OECD I think is kind of it's not where it all started, but there was this really interesting moment where the OECD puts out uh principles in was it 2019 I

believe. Um and then it was like it it set the floor for everyone else. I mean the EU AI acts uh definitions are ba are based off of those principles. Um we've seen draft legislation at the state

level um that's based off of the OECD AI principles uh globally when I was doing rounds of meetings in Apac they were looking at the OECD principles. So I feel like the world is shouting OECD and

a lot of the regulatory work that they're doing but they don't necessarily say uh they're not always looking there. But the OECD has been doing such interesting work. They now have the

reporting framework. You know, they're doing doing work with GPA. Um them having that Hiroshima AI process framework. That was them taking the work of the G7 and bringing it into what

they're doing. So the OECD is doing so much work to reach out. And so I would encourage governments to look at what the OECD is looking is is doing and help them build help them address um agent.

&gt;&gt; That's great. Sam, you could pick the same one if you want to or &gt;&gt; Well, and I'm actually gonna layer it because I think Danielle is exactly right. I think when you're looking from

a policy and higher level governance, the OECD has been the leader in this, there are structures in place through the OECD to develop these. If you look at legislation, regulatory proposals

that have come out even across the various US states, they've based definitions off of what the OECD. So that that has been a foundational piece I think. So from a broader perspective I

think that's a good layer. I think you know the one that has potential I would like it to see move more tactical rather than being a little bit esoteric and studying is the international consortium

of safety institutes. Um I think the structures are there. You have the right players that are coming to the table. I think if if those organizations like what Cassie is doing right now are

advancing, you know, more tactical standards to create a taxonomy when it comes to agentic AI security, how are we measuring how the attack surface has changed when it comes to agents um to

understand the scope of the scale of this problem? I think there's there's a great deal of potential, but I think you need sort of these two levelings um to talk policy and standards.

&gt;&gt; Fantastic. Carly, &gt;&gt; just to add something uh different to the discussion is that based in Singapore, um what I've seen in the in the years that I've been there is that

the Singapore International Cyber Week has been every year has gotten more attendance from governments from all around the world. Um so that is a potential just it's an annual event and

so um there it's the the the positioning is on policy bringing governments to discuss cyber cyber policy and so potentially that is like an area that could be considered sure that like very

the varying countries from around the world the different like India is well attended at in Singapore international cyber week um make sure that they all have a voice in in in the future of

identical AI &gt;&gt; that's great love it Ellie do you have a preferred platform multi multilateral &gt;&gt; uh multinational &gt;&gt; yes I'm going to add to what my

colleague said here and that is um technical benchmarks uh we talk about the standards but we we may understand what agents do but we don't fully understand what multi- aent

systems may do they may have emerging risks they may have completely different behaviors that we don't really know because we don't really have real versions of multi- aent system there are

some emerging but uh the risk surface will change as these agents interact with each other. So I think the academic community, industry, all of us have a role to play to develop and expand the

benchmarks for multi- aent systems to make sure before we put them in into uh into the world, they are tested. &gt;&gt; Great. Jennifer and then Kies, you're going to get the last word.

&gt;&gt; Oh, yes. &gt;&gt; Thank you for sharing. Uh so what I would just say is I think that definitely OECD comes to mind as the largest most credible group and that I

think that makes sense but we do have to think about having space for some of the smaller more regional groups as well. I'm speaking in Tokyo in a couple weeks at the Friends of Hiroshima G7 where

they had the principles there back when Japan hosted the G7. So I think that's really important to have those types of smaller regional perhaps even focused on specific policy areas to then feed into

to the the bigger uh consortium in a way that people can understand. So I think that's really important. That's great. That's great. &gt;&gt; Cambies, close us out.

&gt;&gt; Yeah. &gt;&gt; Um, so actually I was surprised that nobody mentioned the one that I was like, please don't mention it. Please don't mention it. Let me be the one. Um,

so we're talking about standards, we're talking about technical benchmarks, we're talking about principles, we're talking about coordination at a global scale, private sector, governments,

academia institutions, the ITU, out of the UN, AI for good. I mean, they they do all of that and more. And I think that, you know, we want to engage with more countries, with more stakeholders

in this conversation and make sure that we are being inclusive. And that's one of the sort of multilateral forums that I would look to. &gt;&gt; That's a terrific one. Thanks for uh

adding one to the list at the end of the the round. Um this has been a fantastic discussion. I love the way we paired the business discussion of Agentic AI with the policy recommendations and hopefully

policy makers will pay attention to what we're doing. uh ITI is proud to represent all of the companies here uh on the panel here today as part of the global uh tech industry and particularly

proud to be uh partnered with uh government of India on the uh AI impact summit. Our congratulations to the prime minister and to the entire government of India for this incredible incredible

gathering. Thank you to all of you for being here uh to be a part of this important discussion and please join me in thanking our terrific panelists. [applause]
