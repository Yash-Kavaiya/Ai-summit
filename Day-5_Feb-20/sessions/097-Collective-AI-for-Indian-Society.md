# Collective AI for Indian Society

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/kun9t7kt1-I?feature=share) |

## üé§ Speakers

- Antaraa Vasudev, Civis
- Dr. Nirav Ajmeri, University of Bristol
- Janhavi Pawar, Sakal Media Group
- Kushe Bahl, McKinsie & Co
- Prof. D. Manjunath, IIT Bombay
- Prof. Seth Bullock, University of Bristol

## ü§ù Knowledge Partners

- University of Bristol

## üìù Summary

Can Collective AI close the AI Divide? Collective AI is designed to support whole populations rather than one user at a time. This panel brings together industrial and academic AI leaders to explain and explore Collective AI's huge potential for societal impact across areas like healthcare, democracy, etc. It will address the technical and sociotechnical challenges that must be overcome if Collective AI is to deliver on its huge promise.

## üîë Key Takeaways

1. Can Collective AI close the AI Divide? Collective AI is designed to support whole populations rather than one user at a time.
2. This panel brings together industrial and academic AI leaders to explain and explore Collective AI's huge potential for societal impact across areas like healthcare, democracy, etc.
3. It will address the technical and sociotechnical challenges that must be overcome if Collective AI is to deliver on its huge promise.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/kun9t7kt1-I/maxresdefault.jpg)](https://youtube.com/live/kun9t7kt1-I?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

sci-fi movies that we grew up watching. And what it primarily also reminds me of is in specific terms the Avengers, right? The Avengers are these superheroes and they're trying to, you

know, save the world and decide how one can do that and they all have very different strengths. So, I was wondering that if all our panelists were superheroes, who would they be?

Introducing our panelists, I have our first Avenger, Captain America, principled, steady under pressure, obsessed with doing the right thing even when it's unpopular. Professor Seth is

exactly that and reminds me of the lens that he brings in. He studies how societies hold together, how coordination succeeds or fails, and why systems need shared values as much as

intelligence. Next, we have Spider-Man. Spider-Man's strength isn't brute force. It's his ability to navigate through complex webs, adapt quickly, and see connections

that others miss. Professor Nirav thinks the same way at the University of Bristol. His work focuses on multi-Asian systems because societies like Spider-Man are all about networks.

Andra Vasuv reminds me of Captain Marvel operating at scale moving across institutions pushing boundaries through her NGO civ she uses AI to amplify citizen voices and reshape how power

flows between governments and people and of course we have Iron Man Iron Man who is obsessed with execution iteration and making ideas work in the real world. Mr. Bal is our iron man focused on

execution, scale and impact in the real economy. He leads the McKenzie digital and McKenzie analytics practices in India. Last but not the least, no team is complete without Bruce Banner. Deeply

aware of AI's raw power and focused on how to control it before it controls us. Professor Manunat's work reminds us that intelligence at scale can cause damage if we don't fully understand its

consequences. My name is John Havi and today I'm embodying Jarvis except for being the one answering the questions I'm the voice asking them. Every Avengers story has a Thanos. The real

question is whether AI becomes our ally or the great snap that we didn't see coming. So when we talk about AI for collective good, we're not just talking about

smarter apps. We're talking about systems that influence how people live, work, and participate in society. Before we start, I will request all my panelists to just stand up for a quick

photo op. So quick show of hands from the audience. How many of you feel that technology today is only with those who have power or resources or information?

that technology has been reserved for the elite few. Do we have a show of hands in the house by any chance? Okay, clearly we don't really have an opinion as such over here. But moving

on, Professor Seth, when we look at society, you know, governments, markets or online platforms, we often assume that problems exist because we don't have enough

intelligence or data. Your work suggests something a little bit deeper that perhaps failures come from how decisions interact at scale. From a systems perspective, do you think our biggest

societal problems are intelligence problems or are they coordination failures? &gt;&gt; Thanks a lot. Um, so it's great to be here in India. I think this topic is

extremely relevant uh to both the UK where I'm working and India and I think the answer is uh that coordination is intelligence in this situation that we're interested in. So I guess we're

used to situations now where we interact with an AI as an individual. One person asks the AI a question and gets one answer. But really, there's the potential for us to develop AI systems

that are designed to support a whole population at once. So, a population of people that are affected by a flood, a population of people that all are coping with the same uh uh disease or medical

condition, a population of people that are all trying to get taxes to and from a summit. Uh so instead of AI answering individual questions, AI can help coordinate those people, share

intelligence, share their knowledge and achieve better outcomes. Uh and I think that's quite a different way of framing AI than many of the systems that we're hearing about and requires different

technologies and different ways of delivering that to people, different ways of engaging with populations. So I think that's something that can only really be achieved by partnerships

between researchers and companies and not for-profit organizations and governments uh and requires probably interventions in the way that we uh uh promote AI rather than letting the sort

of path of least resistance develop AI uh commercial tools. Uh I think there are opportunities to really engage with the idea of making AI for populations. Wonderful. Professor Nero, you're also

from the University of Bristol and your work focuses on multi-Asian systems where basically intelligence emerges from all these entities interacting with one another. What kind of social

problems are best suited for these multi- aent approaches? Thanks Jani. Good question and I think partly Seth already answered uh what multi- aents could do. So if all problems that we're

thinking over here are in terms of if we are understanding those problems there are they are social techchnical in nature. So there are social entities including people organizations which

interact. Uh all of us also use some technical tools. uh these could be say so uh intelligent agents uh these could be applications uh softwares that we use and all of these combined together help

us. So all problems include or all domains in are so technical in nature. Multi- aent inherently can encapsulate so technical systems. So that that is how I would

look at it. Uh if you're talking about say ride sharing for instance or hailing a ride we current system could be optimizing only for me right. Uh but if you and

then what we end up with we could end up with local maxima. So if we are optimizing for each one of us we may we are doing local optimal for each of us but we may not be doing a global optimal

and we and global optimal would map to social welfare. What does social welfare mean? Does it mean just maximizing experience for everybody or are we

meaning satisfactory experience? uh so I think any problem that you think about say epidemic pandemic prevention making sure uh the resources allocated properly all of that would be multi- aent in

nature &gt;&gt; interesting professor Seth do you have anything that you'd like to add on to that &gt;&gt; so yeah I think we've heard I think a

little bit from some uh AI leaders about a next wave of AI that will be agentic uh where we won't be just interacting With chat GPT as a monolith, we will be interacting with uh an agent that has

purposive aims and is helping us to achieve tasks. And it might do that by communicating with other agents. Uh and whenever we interact with AI, we would be in fact interacting with a population

of AIS uh that are sending each other information that are tasking each other with different jobs to do. uh and actually it might not be clear whether one of those agents is artificial or a

person. And so if we enter into that sort of world, I think we have to really understand whether those agents are interacting in a way that is likely to advantage uh the community of users. uh

because the amount of resources that will be consumed by these population of agents and the potential for them to interact in ways that have unforeseen consequences for other people uh are

going to ramify. Right? When we do that manually uh really we can only hold so many interactions with other people uh at once and so we're limited in the scale. You know, one request uh does not

create this kind of cascade of other requests in the system. But as we move to artificial systems, that scaling will rapidly increase. And potentially one trivial request by me asking a computer

to make a picture of a dog riding a skateboard could create a whole kind of wave of different agentic interactions that consume loads of resource uh and also depending on what I've asked for

disadvantage other people. So embedding some kind of social responsibility into those agents, some appreciation for how their behavior impacts other agents in the system, I think is going to be

imperative. Otherwise, we end up with systems that create conflict and contest contestation for resources. &gt;&gt; Interesting. Whenever I'm on Instagram or Facebook and let's say if I'm talking

to my friends, you know, I'm really thinking about buying this Dyson or a particular product, it's always weird to me how the next time I open the app, it's almost like the app has heard me,

right? And I start seeing the ads for those exact things, even if I've not searched it, I've just talked about it to someone. Has anybody here also experienced the same thing? you know

show off hands quickly where you feel that maybe the choices that we make are they really our choices or are we being nudged by alos somewhere. So professor Mjinat you know your work focuses so

much on recommendation uh systems and we often hear that these alos are just tools but perhaps your research suggests that they actively shape what people see buy believe. How much of human behavior

today is genuinely chosen by us and how much is subtly nudged by these algorithms? &gt;&gt; Yeah. Uh yeah, recommendation systems and the way they shape many of our

feelings and our attitudes and our habits has essentially been a significant concern for me for a while. One of the things that you have to think about when you look at recommendation

systems is that they're essentially learning agents. So they want to learn your preferences, your uh your your essentially your preferences, your likes, your dislikes etc. And when they

are trying to do that learning, they do do two things. They're trying to sort of give you options uh different kinds of options and then see how you react. So, so there is the

first way in which [snorts] the interaction between you and the learning system happens uh the learning algorithm corresponding to a recommendation system happens is this they're they're showing

you a variety of things and the way you react and then your reaction is usually captured in some kind of utility function some something that that the algorithm believes is positive for

whoever is designing that algorithm. Now that what exactly is that utility function essentially determines what gets recommended to you in the future and what the system learns about you.

Now there is there is no such thing as the right utility function and every organization will figure out what they want for themselves. And if you just look at some of the and

we have actually done several models mathematical models on this and show that if I depending on the kind of learning algorithm that I have and I'm not I'm assuming a benign recommendation

system here depending on on the kind of learn uh learning algorithm that I use where I start off with a set of preferences to by the end of the day or over a certain time horizon my

preferences can be dramatically Okay. So there's a certain nudge that is steadily pushed by these algorithms and in which direction the nudge is pushed depends on the kind of algorithms they

use and the kind of what what we call utility functions that they use. So what exactly are they trying to optimize for themselves and if you look at various uh you know analysis of many of these

especially Facebook algorithms there's a very famous book that came out recently by somebody called Saravin Williams who was an insider. you can see the impact of what that had on on some sections of

some society elsewhere when the whole recommendation system went berserk. Okay. So there is definitely a huge impact on on on on the population's preferences by the recommendation

systems. And if you want to sort of give a give a give a quick understanding of that recommendation system essentially are advertisements. The difference between a standard

advertisement and this advertisements definitely shape our preferences. If you see something more often you will start thinking about it and so on. The difference between at least in my

opinion the difference between the advertisement advertising advertisements that you see on the street and the advertisement corresponding to a recommendation engine is that you are

significantly more receptive. You are looking to do something and when you're trying to look for look when you're trying to look for something to do if the recommendation pushes you in a

certain direction you're naturally going to go there. So the impact of recommendation systems on the population's preference in my opinion is spectacularly large.

Yeah. &gt;&gt; Wow. That's quite a lot to actually you know digest and hear from. I I I really wonder how much my personality is my own at this point. You know Anra. So from

your work in civic engagement when AI enters governance is it to primarily help citizens be heard or is it helping governments manage complexity? And where do citizens struggle the most when

technology becomes the interface between them and the government? &gt;&gt; Thank you uh for that question. Just want to make sure that everyone can hear me. No.

&gt;&gt; Thank you. Um some problems like onstage mics AI cannot solve. Um no but I just uh I just wanted to of course next year. Next year correct. Um thank you for that lovely question and lovely being here

with all of you today. Um Jani to your point I think AI currently is being used in both use cases. It's allowing us to engage with citizens who perhaps um have little or limited knowledge about law

and policy and to be able to help them clarify doubts for them to be able to uh air out their grievances for them to actually be able to um understand the frameworks of policy and law that govern

their lives. But in addition to that it is also being used in a very large way for optimization in a country of India's size and diversity. Um I think the only other way is to perhaps not tackle

certain important governance tasks. So better than that is to actually build strong and robust frameworks for how governance uh can utilize AI which is put out in a manner which is transparent

um accessible and one that actually has certain equity built in which is really what the the the panel is also discussing today and um once you have that to know that these optimization

solutions can perhaps be built by AI rather than citizenled so um at civis we've actually been working on get gathering a lot more public feedback on draft laws and policies using AI and um

again we see optimization in both ends. Um but very very mindful of the fact that uh the frameworks that govern that level of optimization what needs to be designed before perhaps even we race to

the next model. &gt;&gt; Got it. Can you share some examples of the kind of laws that have been impacted or the kind of work that you've done? Have you worked with different state

governments where you know citizens of that particular state have been able to engage with the government about a certain law or practice that's been happening?

&gt;&gt; Thank you. Absolutely. So I'll share one example from recent work with the government of Maharashtra that civisled. Um the government of Maharashtra actually undertook a very ambitious

mission of trying to understand how the next um 22 years of the state can be governed by citizens voice. Now um this is something which is um which is honestly quite remarkable on their part.

Um what CIS was able to do is that we built out a very easy to use chatbot wherein you could send in a voice note, you could send in um any text messages or you could even we had people uh send

in drawings, letters uh that they had personally written to the chief minister and other things. Um CIS aggregated all of that feedback. So that was almost 3.8 lakh uh citizen responses from 37 uh

districts across Maharashtra. and that was aggregated, sorted through and then shared with the government as well. Um the Vixit Maharashtra report as it's called is now publicly available. The

government of Maharashtra has put it out on their own website as well. But in addition to that, what's been really interesting about it is that they have said that every law that's going to come

out in the in the state for the next uh coming years has to in some way factor in what citizens are saying about that problem area or that district from for where the law is being made. And um you

can only do that if you're able to actually engage at scale. And I think that's the beauty of what uh what that entire project showed. &gt;&gt; Absolutely. Professor, how do you feel

about the government in terms of you know what approach should they be taking when it comes to AI and technology? &gt;&gt; Yeah. Uh one of the fears that I have when when when the government gets

involved in technology development is that they want to start controlling the direction. They want to tell what to be done at a very micro micromanaging kind of level. And you know we we I I I

recently had an article on Tuesday. I think it was in the financial express. There was an op-ed where we talked about me and a colleague of mine. We talked about you know what looking we looked at

history depending the the kind of successful and spectacularly unsuccessful involvements of the government when they wanted to direct technology. So I'll just give you two

quick examples. So in India about about 40 years ago there was something called C dot. Okay. So that that that developed some spectacular technology when it was left alone. The government start to

direct it and micromanage the flow of technology. It it's many of you probably don't even know C do they don't even come to ID Bombay campus for example for recruitment. That's just one example. If

you look at Japan I mean just to give you another badly successful story. Many of you are too young to know about something called the fifth generation computing systems that they wanted to

start off in in the AI boom that we see today was originally planned to be launched in Japan in the 1980s. Okay, there was a huge project that the government wanted to micromanage develop

native hardware for AI and everybody thought they would be successful. It was a spectacular failure. Okay, the failure essentially stemmed from the fact that the government was directing everything.

Governments are generalists. Government people who run governments are generalists. They're brilliant people. They know they know society. They understand administration, but they

don't understand technology. Especially a technology that is moving too damn fast, has a very large surface area and they cannot control it. They they cannot control that. So, it is best that they

just enable and and let others let the people on the ground, I mean people with with with with a track record and people who want to take risks manage that. They should be enablers. There should also be

monitors. I mean monitors nudging it in a certain direction, making sure bad things don't happen. But that's a very hard task. So, so the the biggest role that the government should have is is

just enable and and and and step away. You know, just to give you one positive example, the I mean NPCI in India is a spectacular example of where the government started something and let the

private sector and and sort of technologies handle that. In the in the US, many of you may be familiar with the internet. It was exactly that. It was just a vision that somebody had and

said, "Let's build this and and the technologist built it." That's the way I would think the government should handle it, but we'll have to see how that goes. So, just a quick question for the

audience. Uh you you guys can shout the answers out loud. What emotions come to your mind when we think about AI? Are we feeling excitement? Are we feeling anxiety? Are we feeling FOMO?

What are we feeling guys? &gt;&gt; Curiosity. &gt;&gt; Curiosity. dangerous. Some somebody said what else? &gt;&gt; Definitely opportunity.

&gt;&gt; Opportunity. The man over there. &gt;&gt; Confusion. Anything else? &gt;&gt; Responsibility. &gt;&gt; Responsibility. Fantastic.

Great. So, Mr. B, this question is for you. There's a lot of anxiety, a little bit of excitement as well about maybe AI replacing jobs, you know, especially in India's tech and services sector. From

your experience uh working with different companies, where is AI genuinely replacing humans and where is it actually creating new forms of value and roles?

&gt;&gt; Yeah, that's uh that's a great question. Thank you. Um so I think the um the let me let me try and give you the very brief answer because I can talk about this for a long time. Um but um there is

a lot of focus on um AI being used to replace uh humans in particular operations. So you know when you have an AI taking a call center call that's simplest example of that.

Um what uh what what and you know the the the math the way it works is that you know if you're spending 100 rupees on something you can save 40% of that uh roughly by replacing it with AI with the

current economics of the way it works. Uh and obviously if you're on a high cost geography you can save more uh in a country like even in India you can save that much. Uh what we have found though

is that um most of the cases where you do this simple replacement of a human with AI uh it that cost reduction doesn't really sustain. Uh there's a famous example of CLA in uh in um Europe

where you know they brought back a lot of the cost call center costs uh because you know they they had to bring back some of the senior customer support people because a lot of the

conversations were not going well and they were losing customer satisfaction. The same with same thing with it. you know you can replace a lot of developers with this but then people will come back

with more projects and there'll be more things to be done the real value unlock which is sustaining is actually when you get AI to do something which humans can't do or or are not able to do

because it's so uh so timeconuming and so um difficult so for instance a genuinely personalized um customer engagement engine uh using the kind of recommendation system that he was

talking about uh which actually engages in a personal iz way with with every customer that I have as a company for instance or every c you know every uh entity that an organization is any

organization is dealing with uh that genuinely has value it creates huge value unlock uh so like for instance I mean if I spend 2 3% of my revenue uh on say customer support and I even if I say

40% on that I'm saving like8% or 1%. But if I can generate even just 10% more revenue from existing customers with hardly any marketing cost uh and I make 30 40% margin on that I'm getting 3 4%

more to the bottom line. So that is a huge it's like 10 almost 5x of of what you can save. So the the value unlock is very large and that's sustainable because you're really getting AI to do

you no no human being is going to sit and figure out exactly for millions of customers exactly what is the kind of personal message to send because the amount of experimentation you have to do

and the kind of connections you have to draw between individuals and similarities and so on you know which the recommendation engines are based on uh are impossible to do humanly uh and

that's where the biggest value unlocks are at least that that I'm seeing and those are sustainable and they're actually even applicable in high cost geographies It's just that unfortunately

the a lot of the initial focus of the innovation has been on this uh just save you know do the easy stuff right have an AI agent replace a human agent uh but that's not the real uh power of where um

what what AI can bring uh so hopefully we'll see a lot more of that type of innovation going forward as well &gt;&gt; right I think I see a lot of students here today what kind of backgrounds do

you all come from hands up if you're from STEM &gt;&gt; at all stem backgrounds okay anybody from business humanities arts.

Okay, so I read this LinkedIn post. I'm not sure whether it's a great post or not. Apparently, it's going to be a little tough for STEM students to, you know, get into this world of AI because

they could be replaced a lot easier. What kind of majors, businesses, or like degrees does one should should one essentially come from to sustain in this world of AI, do you think? What should

the next 5 years look like? Yeah, I think there is some near-term potential impact on on jobs uh and particularly on entry- level coding jobs and so on. Um but honestly there's nothing which tells

us that u that there is a firstly nobody knows exactly how the math is going to work. So between new work that people do for AI enabling uh versus the old work that may get more efficient because of

uh AI enabled coding and so on uh will we net a increase or decrease of employment? Nobody actually knows. There are many many forecasts and and so on done by economists much more qualified

than me. But what one can see is certainly that the you know enterprise adoption has not of AI now has not really happened. So right now the impact has not really happened of all of this.

So you're seeing some initial uh you know hit on maybe okay this year I have promised uh I'm going to use AI and reduce my budget by a certain amount so I'll stop hiring. Right? That's the kind

of I would say almost knee-jerk uh impact that you're seeing right now. What eventually plays out will be uh a mix of okay I will do the work more efficiently and use a lot more

automation but now I have a lot more things to do as well. So I would say that students in general actually forget the just stem uh students in general I need to be focusing a lot on how I can

use AI to to do the best possible thing I can do in my field uh and in every possible field. So whether I'm studying you know marketing or if I'm studying science degree or if I'm studying uh any

form of the humanities uh you know there is a a lot of journalism if I'm you know who whoever I am right there's a so many things that that I can actually be doing with AI to do my to do things which I

was not humanly possible earlier and that's really what the students should be equipping themselves with uh and then you know potentially innovating and also creating things you know around that but

also personally equipping themselves to actually leverage AI and I think there are lots examples of of of how that can can play out and will serve people really well.

&gt;&gt; Absolutely. We're now going to get into a quick rapidfire round and then I want to open up uh the floor for audience questions. So the only rule here is I want short answers only. No

explanations. You only have 10 seconds to answer. So I'm going to start off by putting Antra on the spot. Does AI in governance shift power towards citizens or towards institutions today?

&gt;&gt; Um I want to say citizens because it um allows for a lot more information asymmetry to be addressed which is where uh a lot of the power gaps come up today.

&gt;&gt; Okay. Professor Majunat are algorithms today more likely to reduce bias or hide bias better. &gt;&gt; Oh uh hide by uh no that the options don't look right to me.

&gt;&gt; Okay. what what would you put as the options? &gt;&gt; The bias will start increasing. I think if they're not [clears throat] trained I don't expect training to get better in

the immediate future. Maybe maybe much later. But I also want to disagree with what Antara said. That's for later. &gt;&gt; Yeah, sure. [laughter] I'll come come back to you for that one. Professor

Seth, what worries you more? AI being used with bad intent or AI being used widely without anyone fully understanding its consequences? &gt;&gt; Well, they're both terrible, aren't

they? Um I think I think people will always use technologies with bad intent and it can only really be addressed if a large number of people understand that

technology and can then resist it. So I think the second is more important. Uplifting the public's understanding of AI and and kind of engagement with AI properly will protect us against malign

uses of AI because we will be able to spot them. &gt;&gt; Got it. Professor Nero, what's harder to design ethical individuals or ethical systems?

&gt;&gt; I think that that becomes tricky like what do we mean by ethical, right? So ethical individuals if you're combining ethical individuals and we say individuals combined together is a

system then then ethical individuals I &gt;&gt; short answers yeah Mr. In in India, will AI mostly replace jobs, reshape jobs, or polarize jobs?

&gt;&gt; Uh, reshape. &gt;&gt; That's a very quick answer. &gt;&gt; You um you win the car, right? &gt;&gt; Right. Professor Seth, where does AI struggle more today? With people or with

&gt;&gt; Um, probably. I mean, I think it struggles with people, but we don't notice because it resembles the kind of natural language. When we when I say AI, I'm talking about something like chat

GPT. So, I think there's a disguised problem with people there because those AIs, they don't really mean what they say. They don't really understand what they say, but it seems very strongly

that they do. So, I think that's the problem. But what's coming is AI embedded in all of our systems and then that will create its own set of problems as well.

&gt;&gt; Mr. Bal, who benefits more from AI today, companies or employees? &gt;&gt; Uh I would say that right now no one is benefiting uh from AI. But if I were to bet it will

be companies who will benefit first uh and then employees will benefit. And the whole idea of having sessions like this is that we can get the employees to learn what we talked about, right?

students equipping themselves right from college. &gt;&gt; Yeah, absolutely. Andra, for AI used in public systems, what matters more, transparency or effectiveness?

&gt;&gt; Transparency off the bat. Um, it's the only way that we can actually design AI for public systems. It has to be at the the front and center of all of our efforts.

&gt;&gt; Got it. Before we get into the last question for the entire panel, I do want to get your answer to Andra's statement if that's fine. The question I know I disagreed with her but I forgot the

question. &gt;&gt; I'd asked her does AI in governance shift power to a citizens &gt;&gt; to the institutions. They have the money &gt;&gt; to invest and and and and discover

what's going on. I mean there is no way that citizens can can can beat that so easily. It requires a different uh whatever. &gt;&gt; Okay. I'm not allowed to say it.

[laughter] &gt;&gt; My last question for all the panelists before we open the floor for audience questions. If we get AI right, what is one everyday improvement people in this

room would actually feel within the next 5 years. So I think something that connects there's a thread that runs through this or there's supposed to be and I think

one thing that AI could give us is a greater sense that we are properly connected with each other and learning from each other. So the the possibility for AI to break down barriers between

people because of language and expertise and distance I think is huge. So the kind of uh traditional collective intelligence that we're used to where we put an X in a box when we vote for

someone, it's very very simple, right? We can't write an essay like the users of Antara's system and send an essay to the government about what we want because there's so many people. We can't

read all of those essays. But AI can enable that kind of rich interaction. It's an example of one of the things that Kush is talking about that AI delivers something that is impossible

for humans to do. It doesn't just replace something that humans are already doing. So a future in which we all feel like we have a voice and AI is helping us mediate between each other I

think is something that is technically possible. There's a whole bunch of political and social barriers to prevent that from happening. But uh I think 5 years is a is a timeline during which we

could see the starts of those sorts of systems. I I can talk about what I'd like to see if we get AI right. Um we talk a lot about uh institutions. Uh we talk about

companies, we talk about individuals. Um but not enough is talk happens specifically about you know small businesses. Now India is a country of self-employed people um and small

enterprise. Yeah, I think there were 150 million self-employed people. Um, if you know if we just put uh if each of those people could somehow earn 600 rupees more um because of uh AI, right? And

I'll talk about how uh that's a unicorn. &gt;&gt; Okay. &gt;&gt; So 600 rupees more of value creation for each of these 150 million people is not I mean there's a lot of large numbers in

India but it's true, right? Is a unicorn. So I think we think of the next 50 unicorns We may not think of like 50 companies worth a billion dollars, but we may think of 50 innovations that puts

600 rupees more in the pockets of 150 million people. And how does one do that? I mean, if you look at all the important things all of us use today, ride hailing, e-commerce, u this

restaurant ordering, food ordering, right? All of these created by one institution, they make an app and then they do spend money on marketing and so on. Today you have AI systems that are

incredibly low cost. You know, 50 cab drivers can get organized there. as an AI origin can do theuling and whatever you have a WhatsApp chat with them and you can just find the driver right

there's no reason why we can't have innovation like this very low cost the price the cost of the tokens can be funded in that ride it can be right that's all that there is to run it it's

a it's an autonomous system which just runs off publicly available infrastructure uh I think that to me is the real unlock uh that we can see and those same systems can then serve anyone

in the world so you can do like you can do this for taxi drivers you can do this for lawyers and those lawyers can then serve anyone anywhere in the world. So, uh I think the I think that's the real

real unlock that we are waiting for. These systems are very low cost to build. They can be built by anybody. They can be self-built by people. Uh and it just takes a few groups group of a

few of these self-employed people to get together and then you know suddenly this can go viral. So I would love to see that type of innovation coming rather than necessarily you know the stuff that

we know for the companies will do or the things that we'll all play around with on our on LLMs on ourselves. Great Andra. &gt;&gt; Thank you. Um I think building on what

uh Seth and Mr. Bar just said, um there's two things that I see happening. One is the disagregation of systems and a lot of uh decentralized control mechanisms, right? Um when that happens

you have very fragmented channels to actually engage with institutions to to Set's point about building collective and new ways of collective intelligence. Um what I want to see happening for all

of us in the room is greater access and connectivity to public institutions. Um which actually fuels us to get easier access to entitlements and benefits that the state is supposed to provide to us.

Um if AI can get that right, if we can solve for that, I think um there is um a long and a big argument to be made about that being the sort of rising tide that lifts all boats.

&gt;&gt; Building on to what people have been talking and last on Entra's point thinking about collectives, right? So we can build systems which work for individuals. Uh but how do we make sure

that uh those individuals could be like each individual have different preferences? How do we take into account different people's preferences? Uh how do we aggregate people's preferences and

then come up with a collective decision? If we are coming up with a collective defi decision, how does that decision affect various other people? how do we explain that decision to other people

that hey we have taken into account your preferences in this particular way. So if we need to get that part of uh AI right to make sure that uh people have a buy in uh people trust the systems that

we are designing. So that that is what I would want to see and I'm thinking that we are moving forward toward that like we're thinking about fairness, we're thinking about transparency, we are

thinking about accountability and so on and so forth. &gt;&gt; Yeah, I can probably say what I already see. The the homeworks that my students submit are perfect.

The essays are spectacularly written. The presentations are beautiful. The only hope that I have is that they actually understand what they say. So if that happens, I'll be very happy. Okay.

I think the the the output is perfect. The understanding behind that output I hope will get better and better as we go. That's my &gt;&gt; wonderful.

&gt;&gt; My my wish for &gt;&gt; I'm going to open up the floor for audience questions. Yeah. &gt;&gt; My question is for uh to Kush sir. Uh I want to understand like what kind of

impact AI will be having on management consultants and the business. &gt;&gt; I have no idea. I have no idea really. It's very hard to say. I think it's I mean every every industry is going to

evolve. Uh obviously management consultants like everybody else are using AI for every possible thing that they can that they can do with it. So they're also trying to become more

efficient, more productive with it. um we don't know what that means in terms of reshaping um you know of the of the business. If you look at past tech innovations which have also had a very

big impact on productivity in many sectors it's not that entire sectors have disappeared or things have got but things have got reshaped significantly that has happened a lot. So I think the

job that consultants do like you know today when we do research you know you don't wait for one week for somebody to go and find things from everywhere it comes in a few minutes right

unfortunately I find that a lot of the output of I I have also seen a lot of the output uh like professor Majunat said uh I find two things two issues right now with the current versions of

the AI when it writes it has no soul uh so it's correct but it has no soul uh and um and and when it prepares like a presentation or a piece of communication it's not inspired hiring.

So it is correct but it's not inspiring. So I think there's a uh there is a so so the consultants will spend more time on actually communicating in a way that's inspiring while the desk you know the

basic desk work will be done for you. So you spend time doing more uh I would say human tasks. Uh and that's going to happen actually in a lot of other in a lot of service jobs, right? You're going

to do you're going to spend time doing what humans are truly supposed to do and are really good at which the AI models are not able to do. &gt;&gt; Okay. Thanks.

&gt;&gt; So my question is for everyone. I have a younger cousin who is in high school and her entire life is on Chad GPT at this point. So she shares everything, relationship issues, family issues and

it knows more about her than I do and I kind of worry when I see the younger generation getting on these uh AI platforms. So what are what are what is your take on this like impact of this

technology on young minds? So I I share your concern. I have I have slightly older kids. Um I think we have to trust that we've been through these

techn technological shifts before. Right? So my parents when they looked at me watching television had similar worries about they told me that my eyes would become square, right? Because I

watch too much television. So actually my generation became much more sophisticated consumers of television and were much more savvy about TV ads than my parents' generation. So I think

we have to listen to our children about the way that they're using these technologies. They're natives in this new world. I'm calibrated for a world where AI doesn't work, where AI is not

uh rolled out across the whole world. Uh so I'm the wrong person really to ask about how AI is going to change people. We should ask young people how they're using it and engage with them before

they start to use their AI in a way that we don't understand in secret. Um I I I have a well a funny answer and a and a short answer but I I think that um one I think we um the real danger

actually is with not with the chat GPS of the world but with the earlier uh addictive systems uh like the Instagrams of the world right because they are genuinely playing on our dop you know

brains dopamine circuits and uh and are genuinely addictive and can therefore be harmful. Um, I think with Chad GBD, I think the only thing I would say is, um, I think it it makes one actually

question where we are as as individuals, as parents, as as as family. Uh, that that our children prefer to communicate to a relatively soulless communication device, which which answers everything

like an American therapist textbook would, right? Uh, that they prefer to talk to that than to and to us. It it shows what a what a distance we have created uh with each other right and it

may be a good reminder to us as as individuals around the task that we have to do into rebuild bonds with each other. Yes. Um I think on a very similar note

actually to what Kusha just said. Um I think there have been studies from uh Youth Kavas and a number of other global uh youth-based organizations which have been looking at why exactly we turn to

AI and the phraseology is very interesting there because it it indicates that um turning to AI is something that you can also turn away from. Um I think the questions really

come up where uh exactly what was just mentioned about um understanding what are the kinds of uh tactile family bonds, what are the kinds of um lived experience-based interactions that we

can keep having with the younger generation um to show that AI is a part of their life, but it's not the only part of their life. And I think that's maybe um my hypothesis on on where we're

headed there. I have a quick followup and you can connect with it the previous question also. Uh many countries right now is trying to ban Wia 16. So clearly there is evidence it is harmful in the

course it's coming in mention Instagram or any AI is an amplifier. So unless we design whether it's regulation or whether it's guard rails or whatever what is our hope

and what what what is the hope for a society not to get amplified harm than what we have already experienced especially for the generation &gt;&gt; should we start with you s this one

&gt;&gt; well I think that's basically what I wanted to say was to so the countries are Spain and and Australia are two examples of where severe restrictions have been put social media companies to

to to at least give access to children and that's an interesting experiment one has to see what's going on there what will happen because it's not an easy thing to do I mean I think

technologically it's not easy legally I'm sure there are a lot of loopholes in all of this we have to see how that evolves and and potentially and potentially apply a similar similar kind

of guardrails with respect to AI that's the view at least that's the view that I have on that matter &gt;&gt; that is a very postmodern kind of a approach.

&gt;&gt; No, it it has to start somewhere. I mean this is exactly goes to my point that I made earlier. Generalists in government cannot handle the space at which technology can move. You cannot put

guard rails on that at the beginning. The moment you know something is happening, you have to you have to get into the act as quickly as possible. Somebody is making an attempt. So let's

understand what's going on. Maybe it's I mean exactly what goes on is what will happen is something that we have to see. I mean what was interesting at least in that attempt was that the way in which

the social media companies reacted to both the Australian and the and the Spanish ban. Okay. So to me the the the most interesting part was they all said it was too fast. They've not thought

thought things through. And then I remembered what Facebook's uh slogan was move fast and break things. Okay they are allowed to move fast but the legal system is not allowed to experiment. I

mean that seemed like an interesting contradiction for me to study but &gt;&gt; so relatedly so the first AI summit in London was very closed right politicians and the leaders of big tech firms and

the idea that a couple of years later governments would actually be legislating in ways that limited uh in this case social media companies is very good news right after London you could

imagine that regulatory capture had happened right governments were not going to be able to resist assist these big companies and their um their multinational power. So th those first

couple of steps of regulating uh social media for under 16s even if it doesn't quite work even if it's not exactly right it at least is a step of introducing regulations and it will make

AI companies at least aware that that is a possibility because it they have to take that responsibility I think &gt;&gt; professor Nav do you have any other input on that as well

&gt;&gt; I think I I agree to the points that that have been made I think so there could be different ways to think about a blanket Ben for instance Like if you try to restrict something people may not

they they could have they can have more curiosity in terms of like why is it something which is getting banned right so we have to be thinking about that as well but there is a step there will have

to be some regulations that should come into place uh what those regulations would be we need to be thinking about that uh I think lot of times the worry is people keep scrolling

uh and then uh the way the algorithms work uh uh professor Mjunath knows better but recommended systems would keep you in go put you in a rabbit hole and you keep going and uh into one

direction there could be ecochambers that could getting formed. So maybe the younger population is more vulnerable there and that is where possibly a ban or restricted access helps. uh we have

to be thinking about how can we like say in YouTube there is YouTube kids and they only see kids content but then there malicious actors who would post uh some content which is targeted towards

kid but it is not actually kids content uh there could be somebody could come up with a new social media platform for kids maybe I I'm not very sure what would look like but we'll need there

would be new technology that would come but that need some guardrails to be put into place. What kind of guard lifts the research and the legislation will have to be thinking about it?

&gt;&gt; Sure. I think we have time for one last &gt;&gt; So, &gt;&gt; can we give it to somebody at the back? Yeah, the jean jacket. Yeah, go for it. Can we pass the mic for at the back,

please? question just a thought. So definitely AI has enabled plenty of values in the education and medical domain. But do we

think that it has or in some extent breached or violated the concept of the members as well. Meaning there are singers who no longer exist but we are you know getting to hear those songs in

in the new generation the ones who are alive can definitely raise the dispute but those who are not doesn't exist right so it's it's a breach of consent uh that of course it

is falling under the domain of ethical but just wanted to know is there someone that's directed route for this question or is it open for all &gt;&gt; okay we can just whoever would like to

take that &gt;&gt; so I think it's a completely legitimate concern and it's difficult to understand where we go from here because the cat is already out of the bag, right? The

models are already trained on everyone's data without our consent. And how do we put that back in the box? I'm not sure that we can. Um I think so there are currently legal cases that are going

through the courts about the IP claims of musicians and artists. uh and it will be very interesting to see um what law courts decide about that. I do think the kind of systems I'm interested in are

systems that are built on consent. So uh a population of people that all have diabetes who sign up for an app that will track their their disease and then they gain by being part of a community

uh where information is being shared to help people manage their diabetes. So that's a much more consenting model. It's not about stealing people's uh writing and art and music from the

internet, but that activity is already underway and I don't see a way of really uh putting it back in the box. &gt;&gt; Let's do one last question. &gt;&gt; Yeah.

&gt;&gt; We are from professors in technology. Right. So the idea is that you talk about education and fraud and all of those things. uh one thing that we have observed there is

that uh instant feedback given by AI tools in education especially students do not go through the whole process stepwise process of completion right so if you're if let's say the work in a way

or the tools work in a way that they are stepwise trying to make learn the person making learn the student instead of giving instant gratification the output so one thing the question is like this

that have has any of the professors in the panel been approached for this kind kind of a thing for modeling of the education process or the process of getting educated on learning especially

and the other thing that would you would can we see a collaboration in that regard where we can try to create a regulatory thing for us or guidelines that how AI should be constructed for uh

for imparting education in a stepwise way so that that in that education does not interrupt the process of learning specifically in tech because we are from the tech so that's to all the

Yeah, the the short answer the short answer in to to honor Kusha uh to honor his uh his whatever. Never mind. I I didn't get that right. So yeah. So yeah, the short

answer is no. Nobody's nobody's thinking along those lines. And handling AI in a classroom has been quite painful. And to give you one example, you know the the there was there was an example in which

I asked somebody to to to to do some essentially execute write a certain program to perform a certain task. I gave the data the student because the student went to chat GPD to understand

what the question was about created her own data to to to to do and and was not did not know how to use the data that I was giving. So the point you're making is extremely valid. If you want to think

about legislation or any other guardrails or anything like that, I'm up to discuss those with you offline. Yeah. &gt;&gt; Give give a very brief answer to this. So,

&gt;&gt; more generally, I think every university is struggling with that question and I'm hoping that there are lots of bright people and we will start to see some answers, but it's not easy.

&gt;&gt; Well, a big thank you to all our panelists here and a big thank you to all the audience members as well for being such great and engaging people. [applause]

We have a token of appreciation from the University of Bristol site for all the panelists. &gt;&gt; From from the Okay. From all of our sides.

&gt;&gt; From somewhere. &gt;&gt; From somewhere. [laughter] &gt;&gt; Thank you very much. &gt;&gt; You're supposed to show this for a picture or what?

&gt;&gt; Why not? Thank you so much. This is &gt;&gt; I think hold this. Hold this.
