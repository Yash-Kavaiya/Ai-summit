# Humanity in the Loop- Balancing Innovation and Ethics in the Age of AI

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:30 ‚Äì 16:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 18 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/cS6THhnYSpo?feature=share) |

## üé§ Speakers

- Debjani Ghosh, NITI Aayog, GoI
- Dr Mariagrazia Squicciarini, UNESCO
- Dr. Tawfik Jelassi, UNESCO
- Justice Gilmar Mendes, Brazil's Supreme Federal Court
- Mr Brando Benifei, European  Parliament
- Mr. Jitin Prasada, GoI
- Paula Goldman, Salesforce
- Professor Virginia Dignum, Umea University

## ü§ù Knowledge Partners

- UNESCO

## üìù Summary

"Humanity in the Loop" will explore how human rights, transparency, and ethics can drive responsible AI innovation. Bringing together leaders from governments, industry, academia, civil society, and multilateral bodies, the session will showcase practical approaches to embedding values-based governance in AI ecosystems. Discussions will center on trust-building, inclusion, and leadership in ethical innovation to ensure that AI advances serve humanity equitably and sustainably.

## üîë Key Takeaways

1. "Humanity in the Loop" will explore how human rights, transparency, and ethics can drive responsible AI innovation.
2. Bringing together leaders from governments, industry, academia, civil society, and multilateral bodies, the session will showcase practical approaches to embedding values-based governance in AI ecosystems.
3. Discussions will center on trust-building, inclusion, and leadership in ethical innovation to ensure that AI advances serve humanity equitably and sustainably.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/cS6THhnYSpo/maxresdefault.jpg)](https://youtube.com/live/cS6THhnYSpo?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

this afternoon to uh this UNESCO sponsored event. My name is Tim Curtis. I'm the regional director for UNESCO for South Asia and uh very happy to have you all for the event today, humanity in the

loop, silencing, innovation and ethics in the age of AI. Uh, of course we're grateful to the government of India for its collaboration on this session because we at UNESCO believe uh which we

at UNESCO believe goes to the heart of our engagement with the ethics of artificial intelligence and namely how to ensure an ethical and human AI centered deployment whilst also

encouraging innovation in a technology that can offer so many benefits to humanity and including and in particular to the global south. So it's gives me great pleasure to just present today's

uh panelists and moderator. We have Dr. Tophik Jalassi who's assistant director general for communication and information and who's really been a pivotal figure in UNESCO's work on AI

ethics. Professor Virginia Dignam who is a director of the AI policy lab at Umea University and she's also a member of UNESCO's AI ethics experts without borders and has been supporting uh

UNESCO's readiness assess assess readiness assessment methodology in multiple countries. Uh also privileged to have Paula Goldman, chief ethical and humane use

officer at Salesforce who are a member of UNESCO's business council and she has really been leading by example in the private sector's responsible AI ethics and Deb Jani Gosh a distinguished fellow

Nitia who needs no introduction here in India a household name in India for her role in building and leading India's AI ecosystem. Thank you for coming. And finally, I'm great pleasure to welcome

Brado Benifi, a member of the European Parliament, who will share his insights on the E EU AI act and how they have been able to navigate balancing innovation and ethics. And finally, of

course, our moderator, Dr. Maria Gratzia, uh from the ex chief of the executive office of UNESCO social and human sciences sector. Please Maria Gratzia, over to you.

Hello, good afternoon. So, we'll try to have this session very dynamic because it's after lunch. It's Friday of a five day very interesting and long uh week. So, let me start by challenging the very

title of this meeting that is balancing innovation and ethics in the age of AI. Now, nobody's perfect. So, I'm a microeconometrician which is a very complicated word which looks like a rude

word but it's not. It's mathematics applied to economics and especially applied to understanding the dynamics of innovation and new technologies. Why I'm saying that because of course the

question of innovation, what drives innovation? How can we get more innovation is something that we always asked as uh by the time you study what drives productivity growth, what drives

welfare and well-being. And then at times we also hear this that like having constraint or having frameworks will actually hinder these dynamics and the position of UNESCO has been very clear.

The position is this is not true. So the what UNESCO has actually the member states that have adopted UNESCO recommendation on the ethics of artificial intelligence already in 2021

which means that you all countries including India were discussing these issues already since 2019 to get to an agreement is actually what it means and how can we put technologies at the

service of humanities and not let anything that is technologically feasible go That technological feibility actually hurts people hurt humanity and so for us at UNESCO ethics of AI means

something very concrete means AI technologies and here I would like to invite you to think that it's technologies is not one single element it's a lot of things that actually abide

by three simple thing that too too often we give for granted whereas perhaps I want to think about it more and these human rights, human dignities and fundamental freedoms. And if we are able

to develop, deploy and use technologies in a way that we abide to these three components, then for sure we do have technologies that serve humanity. And why am I challenging the very topic?

Because too often we see innovation or actually the narrative that we use out there that is used out there puts innovation and ethics or ethical AI which actually means an AI that also

throughout the life cycle is ethical as trade-offs. So if we innovate it cannot be ethical because by the time it's gone out you know we don't have the time to check on these things. Well think of a

parallel and then we take it from there on the concrete dynamics of AI. But think if you were to think about one sector that is very much regulated perhaps what comes to mind is pharma

pharmaceutical. Now to my knowledge but that can be my ignorance have never seen one single study been able to prove that the regulation in that sector has actually hindered the innovativeness or

the actually the productivity or even the remuneration of the sector. So by the same token and actually the pervasiveness of AI to some extent leads us to think to the pervasiveness of the

paracetamol for instance we use every day by the time we have an headache like I think some of you this afternoon might have and after listening to me perhaps even more but you know it's really the

pervasiveness of technology that touches our life each and every way in each and every day in many ways and this is what I think it's important to discuss from different perspectives and allow me to

start with by ADG ADG Jalassi and as I mentioned from UNESCO we give this global perspective because the recommendation was adopted by 193 member states. Now very often what is very

challenging is to go from principles to practice that is sometimes we know what we need to do but then the question becomes how do we translate it into practice. So adjaci where do you see

what are the biggest gaps that exist between going from principles and what instead is happening on the ground? &gt;&gt; Thank you Marie Gracia. Uh maybe before I briefly answer your question let me

say that you use the word of innovation and ethics. I don't see personally an issue a contradiction between the two. I see it more between innovation and regulation because you say to be

creative, innovative, you should free up the mind of the people. You should not constrain them. You should not tie their hands. I used to be chair of a telecom operator board. And there of course when

you about telecom and mobile phones and access to private data of consumers, the issue of regulation is paramount. But we don't want regulation that hinders innovation. I think here they so I don't

see um ethics and innovation being in contradiction to the contrary I think they reinforce each other how is that because clearly if you integrate ethical reflection in the design uh of AI

systems of course if you do that AI systems will be more respected more trustworthy more used and therefore more broadly deployed across society So I see ethics and innovation really

reinforcing each other and quite often at UNESCO we say AI systems have to be ethical by design it should be done X anti not exposed not when we see mistakes and hazards and risks and

harmful impact of I say wait a minute let's go back to see what went wrong in those models in the data sets are there some biases etc. So I think it has to be done from the very uh early stage and

therefore h uh innovation has to be a human centric and has to be contextualized. There is no one sizefits all we know that what you can provide is an overarching framework. So we can it's

a broad set of guidelines and principles as you said Maragasa and this is what the UNESCO recommendation on the ethics of AI is about. You know that this recommendation has been uh so far the

only global recommendation of its kind. It was adopted back in 2021 by 100 93 193 member states of UNESCO and it calls for human oversight, non-discrimination, respect for cultural diversity, respect

for environmental sustainability. These are the principles that need to be translated into action and that need to be operationalized within a certain context.

&gt;&gt; Thank you very much. Let's actually go to Dejani because I would like to go further into this operationalization question. So from your work at NITO and also your experience with NASCOM. So

what are the mechanism that can really help embed the ethical reflection into what is the everyday life of both companies and sectors? &gt;&gt; Thank you. Thank you.

&gt;&gt; It takes a second. &gt;&gt; Okay. Thank you. Thank you for having me here. So first of all, I'll just go back to the topic if I may for a second. Right. Because I don't think the choice

is between innovation and ethics. I really don't. Um I think the choice is between do we use technology to ensure that everyone in the world is cancer-free, everyone in the world lives

with dignity, everyone in the world has enough to eat or do we use the technology to make the world a much bigger conflict zone um you know develop the next atom bomb and worse right so I

think the choice is that and therefore the biggest challenge we have and I hate applying the word, you know, the label of ethics to technology because I think the biggest challenge we have is can we

all the wisdom in this room can we say that we will be successful in aligning every single human on this planet to the same ethical values? The answer is no. We're not going to be able to do that

and we know we're not going to be able to do that. So as long as we humans don't align to the same ethical values, you will always have good actors and you will always have bad actors, you know

that technology is going to be used in ways that are non-ethical. So the accountability, you've talked about humanity in the loop, the accountability comes back to us, right? So I think it's

it's very important to sort of understand that because in all our dialogues on technology we we somehow delegate the accountability to technology. I don't think we can as yet.

Maybe in another 10 years when cognitive reasoning becomes a thing maybe then but not as yet because for somebody who who actually builds codes and builds agents I know they're not that intelligent as

yet. Right? So I think the accountability on humans is what we have to f focus on and going back to your question if you're talking about how does industry ensure I mean one of the

things I'm very clear about that regulation is usually an afterthought you develop the technology and then you say okay how do we now regulate it to ensure that it's used right and I think

that has to fundamentally change oversight has to be built built into the entire development process from design to commercialization and it has to be built with the right um

flag offs at every part of the design and development process. If you do that and you're able to you know red tape the the product that you are developing at every single stage to certain standards

that have been developed. you are going to develop something that and then hopefully after the entire development pre phase there's also a sandbox where you test out the impact you will get to

a stage where ethics becomes by design versus an afterthought and I think that's what we have to move towards &gt;&gt; thank you to a bit change the order of the speakers because you brought in the

argument of the regulators and you have one next to you that I'm going to refer to and how do you see this relationship because we know fundamentally the the regulation that has been pushed

in Europe is a risk base. So what was the logic and how you know this relates to what she was discussing as the human oversight or even the redress mechanism that we might want to put in place for

in order to have AI that is &gt;&gt; well first of all excuse me for the voice but that's it but I exactly but thanks to technology you can hear me anyway so I uh I think that I can also

uh adhere to the point that innovation and ethics are not uh one against the other. Um in fact uh this summit that is concentrating on impact on action on diffusion is not separate

from keeping uh the track on on reflection on safety on how to protect human rights how to make AI humanentric the things are interwined the point is how do we regulate effectively and how

we find a good balance but I want to bring maybe a controversial point to the table because I have my strong conviction on this. We have chosen globally including in Europe that has

been often the forefront of regulating in one of those rooms now I was with her in another panel that was Anu Bradford professor of um uh Colombia University that has written

the book the Brussels effect. So in fact EU has often opened the way for many regulatory u pathways. Um I mean um even Europe has chosen when looking at the social media to actually not

regulate. We have let the social media uh diffuse without regulation. And today we are discussing about limits for minors. We heard about that also in the inaugural session. Uh we are

discussing about misinformation and uh labeling of deep fakes. Even Prime Minister Modi talked about that in the inaugural session. But we are doing it all now after a lot of things have

happened. And my point that's my opinion we have already unmodifiable consequences. So I think that when we talk about when we should regulate uh if we should let the innovation flow and

act only expost sometimes we we we we might be wrong and risk un unchangeable effects. So we need to um build a balance that doesn't hinder

innovation but also identifies human rights um challenges. The AI act tried to build a risk based approach identifying areas where we need AI to be over overseen uh workforce use of AI,

healthc care use of AI, administration of justice use of AI. We want to be sure when we deal with that that data used for training is a quality data. Cyber security is sufficient. The governance

of the data is is is solid and there is human control. These are examples of what we have identified and in fact we even chose to prohibit a few use cases. for example, predictive policing, for

example, emotional recognition in workplaces and in study places. Manipulative subliminal techniques. I don't think it's it's it's a a taboo to choose that some use cases of AI, we

don't want them in our society and we just keep them out. So I think this approach based on the risk you can look if you like it this way if you want to modify but it's an interesting

perspective because you can choose what you think is in need of of certain regulation and you can also promote transparency which I think is crucial to build trust without trust especially in

democratic contexts it's impossible to accelerate adoption of AI which is still a big challenge from both the global north and the global south. The numbers tell us

that a lot of companies of public administrations that could benefit from a ethical and correct use of AI they are not using it because they don't know what could be the advantages or they are

scared they are worried so we need to to overcome that also by the help that regulation can can give us &gt;&gt; you you put forward a very important point that is like perhaps we might not

be able We may not want to decide what the technology should do for us, but for sure we might want to discuss and agree on what we do not want the technologies to do for us because these are

unacceptable uses or deployment. And in this case, this also highlights the importance of awareness of the centrality of people of having this human- centered approach. And here I

would like to invite Virginia in the conversation because of course you as an educator as part of this world of educators as a professor you have this constant contact and the ability to

interact and nurture the human capital. So what do we have to do to avoid that people are just consumer or you know are passively in exposed to it instead of steering the technologies towards where

you want to go. &gt;&gt; Sure. Thank you very much. Thank you for for inviting me to be here again. Like all my previous colleagues, I want to go back to the title and I'm not going to

talk about the balancing part. I'm just going to claim and to be controversial and to wake up all we are doing both the innovation as the ethics and regulation side or wrong. We are doing it not in

the way that it's need to be done. On the innovation side, we are doing it wrong because we are somehow understanding innovation as the capacity of using this hammer that we found out a

couple of years ago of genai or whatever and now we want to use the hammer to nail any any nail that we find out. Innovation is much more than that. Innovation is really challenging

ourselves to go further. And I want to go back to a a sentence that has come with me and it's the main thing I'm taking from the this summit today in a couple of

sessions ago where I spoke someone was saying most people developing AI never experienced power cuts never experienced broken roads. I would like to go further AI and I have been working in AI for 40

years. All the different types of AI that exist and existed before has been developed extremely on the western tradition the cart cartisian tradition. We think therefore we are I think

therefore I am first is it individualistic and then equates intelligence with cognition. Intellig human intelligence is much more than cognition. If you would think about AI

developed for instance in the African Ubuntu tradition, it says we are therefore I am. It would be a completely different type of AI. So we do need to challenge ourselves not to go with this

hammer that it's there already and try to find the nails and call that innovation. It is not innovation. It's just running around like chickens without heads and see if one of those

hammers works. So that's the one on the side of the ethics and the the regulation we are also uh assuming there are two things that usually come with the the idea and especially in this type

of combination that ethics is this kind of finger that points thou shalt behave thou shalt be good and that regulation is about prohibiting you to do things. Neither hatics is the finger nor

regulation is necessarily only about prohibitions. The moreover regulation like AI, like the the hammer, like the telephone is a artifact that we built. We build

regulation and we can apply to regulation and to ethics the application of ethics exactly the same type of principles that we apply to technology. Let's experiment. Let's try, let's

verify, let's evaluate, let's see what's there and not have this idea of the finger or the the lost written in in in stone which stays there once and forever. So that's going back and now

very quickly on your answer because I don't want to take much time. I think that education needs exactly to start by this point. Technology alone is not enough. So we really need to up our

education of the engineers, the computer scientists, the data scientists on the humanity side. We know as as engineers we know very well how to solve a problem. We never ask ourselves why is

this a problem? Who has this problem? What are the alternatives to my solution? Who gains? Who loses? What is gained? What is loss? This is humanity's questions. We need to somehow bring that

uh together in the engineering case and in the uh human amenities and social science case we need to we need them we need because I'm an engineer to help us understand that we

can also we need to be much more precise in what we are talking about AI at this moment is actually empty signifier doesn't mean nothing is everything everything is AI nothing is AI All kinds

of things are AI. The applications are AI. The sectors are AI. The technology is AI. The research everything is AI. And we cannot just go around with this word which is actually mean means magic.

In [snorts] most of in politicians talks it means magic and we want to regulate magic. Okay. Good luck. So we need the the humanities, the social science to really help us being precise about what

are we doing. So this is the education we need. Fantast you couldn't have put it much easier to me to then ask PA how are we doing that in companies because this is very easy to say then we need to

translate the principles the values in concret concrete modi that actually work work for a company work to deliver results and work for people. Yes, indeed. Well, first of all, thank you

for that and uh I mean, we were just talking about how this is our last our last speaking panel of the of the week, and that was a fiery a fiery way of of drawing things together. I really

appreciate it. Kind of an energy boost. Um so, so yeah, I think the answer is actually much more practical and much less less abstract than one might imagine. Um and so I'll I'll just tell

you a little bit about my experience. So I'm um I spend my days at Salesforce both um testing our products and making sure that our AI has um features baked, you know, baked into it so that our

customers know can observe what's going on and know how to tweak the controls and understand for example when they should set for an AI agent to escalate to a human or a human to escalate back

to AI and so on. And um and I and when we do this, it's not like we think we at Salesforce have all the answers because clearly we don't. And we serve a variety of industries in a all over the world

and and so on. But um but everyone, all of our customers are basically asking the same questions, right? They're asking, "How do I know what kind of results I'm getting? How can I tell if

something goes wrong? What are my what are my options if something goes wrong? What part of AI ethics is your responsibility and what part is mine? Right? And these questions don't

necessarily have the most mature answers because we're in the early innings of AI agents and a lot more work to do. But um but actually these are these are the right questions to be asking and also

allows for some flexibility and some um cultural or industry specificity for people to find the right answers to the questions. Um so that would be part one of my answer. It's like it's actually

very very practical to adopt AI. Uh companies and organizations need to be able to trust that it's going to work. They don't want to be embarrassed by it, right? And they're not going to be able

to scale it if it doesn't work. So that's number one. The second thing is also increasingly what we're finding when we work with companies on this is that the most successful companies at

scaling AI put the people at the center of the transformation. They um they work with um not just top down like you shall use this application. They give people a chance to sort of have a voice around

what is actually most useful to them in the day-to-day work. Where is AI going to actually help them and where is it kind of useless, right? And it's that kind of understanding of how work

actually gets done, what actual processes are going to benefit from that kind of application that um I think is really important and allows people to sort of stay at the center of this

largecale transformation that we're part of. &gt;&gt; Thank you. Let me go back to the journey because I mean in some way in some ways perhaps your experience is really

closest to hers given that you have been the private sector in a certain direction. So if you can build a bit on what Paulo was saying and where you see the gaps and where you see the

opportunities and also the role of this multistakeholders type of discussion that might happen or should happen in the context of making AI ethical by design. [cough and clears throat]

Well, in my current role in NITIO, which is the think tank for government of India, we're looking at what are the unlocks for technology, including AI, uh to ensure that we can use technology to

solve for some of the biggest problems right now. What professor Virginia said about AI as a hammer, I think that's a luxury of the developed countries. And I do agree with you when it comes to

developed countries. But when you come to developing countries where you don't have a lot of resources, you cannot afford uh to use the technology which takes a lot of deep investment to sort

of do things where you're not sure of the ROI. So one of the things examples I want to give is as part of this summit there were seven working groups that were set up looking at different

problems. I chaired one of the working groups on economic development and social good which was all about impact and how do you scale impact right and we had around 50 countries participating

now one of the things that came out of that working group was which is one of the outcomes of this summit is the creation of a AI impact commons global AI and it's it's online you guys can

look it up a impactcom.global global which has impact stories from more than 30 countries and counting and it's growing every day with learnings on what kind of problems can be solved and how

do you how do you scale it and but why I said it's a luxury of developing developed countries is because when you look at those impact stories and most of them are from developing countries and

you'll be amazed with the kind of problems they're solving from malnutrition to farmer farmer you know suicides how do you lower farmer suicides by using uh technology to

improve yield u ensure that they don't suffer from climate changes and shocks I mean the the problems are so inspiring so I think it it it won't be fair to say that we don't know what problems we are

solving today and I will I will absolutely stand for that um and and I think it's it's I'll go back to what Paula said I'm not sure if industry today is really putting human at the

center of the loop. But I think they need to they absolutely need to because um as we develop technology for example the end goal right now of seems like the end goal of AI all the big companies are

talking about is AGI. Now when you look at what does AGI mean it's about control. Why do we want to build something to control everyone? Why don't we want to build something that is going

to augment lives? And if if we could change the narrative, then I would say yes, humans are at the center. Right now, I think we still have a lot of work to do to bring humans back into the

center of the loop. And it's something I think we have to realize and industry has to realize that that is the only way you can build sustainable businesses. Um, and that that's how you sort of

build your staying power. So it's going to be very important to do &gt;&gt; absolutely and this about you know having these different entities around the table but also having different

governments and having this multilateral setting talk to each other to have regulation or more generally because I mean at the end of the day we talk a lot about regulation but regulations are

part of the policy framework that one could put in place. So actually let's go to Brando because I was seeing he was kind of calling me with his eyes by the time you were talking and I'm sure he

wants to add the multilateral setting. Please over to you Brando. &gt;&gt; Perhaps you were not calling me but you've been called in. [laughter] Nevertheless,

&gt;&gt; well I think that it's very important that uh we use occasions like this this summit um to advance a a global cooperation uh framework. And for sure uh it's uh

it's also a a part of the mission of UNESCO to uh unite different uh uh cultures and approaches to what we are talking about and you explained it earlier the long-standing

work of the organization but I think that um we need to face the reality that there are issues where global will be crucial Well, and and that it's still not sufficient. Let's think of

military use of AI or the um existential risks of uh losing control of very powerful AI models. This is something that is part of a controversial debate we would say. But I wouldn't dismiss

renowned scientists that sustain that we are in uh a context where the lack of globally adopted rules are putting us in very significant uh danger. And this is also part of the idea of balancing

innovation and and ethics because for sure we need domestic uh um rules to uh foster uh the best opportunities out of the various use cases of AI. In these days, I met many uh companies that were

working on uh very practical, extremely useful AI use cases to ameliorate our life, to ameliorate uh societal uh um good. But uh this is this cannot be left in

the hands of u just the judgment of private sector companies that have a specific objective profit for their owners or shareholders. It's not uh societal good. They might want to

add that on top but that's not their their objective. It's it's natural. So we need to have frameworks in place on what is our daily impact with with AI and we need to build common standards.

The more broadly adopted standards we have globally the best will be to reach results. But we also need a step further that is global cooperation on those issues where we cannot actually do very

much domestically. they are global uh issues and I think that uh with an increased geopolitical tension uh the use of AI for peace uh will be quite uh an important topic on

which the international community has to uh find a way to to take uh quick steps uh forward. I hope that our leaders will will deal with that. can't agree more that we need to coordinate and have an

approach that is global and actually along with prerogative of the moderator to call my ADG to so I will take the consequences of that from jobs but what I would like to ask you what it means to

have people at the center and let's remember that in your case given the work you lead on the communication information sector also what is the role of the information was hinting at that

before in terms of awareness could you please share a bit Thank you, Man Garcia. Let me pick it up where Brendle left it. He said, "AI for peace." Maybe some in the room know why

UNESCO was created back in 1945, 80 years ago, almost to the day. The mission of UNESCO was and has been to build peace in the minds of men and women.

How? through education, culture, sciences, communication and information. Everything happens in the mindset of the people. Today, of course, a we want AI to be a force for good, but it could be

also a force for hazards, for harm, for risk. I tend to say technology is neutral. It depends what humans make out of it. It could be a force for good. It could be a force for you mentioned wars

or unwanted uh things. So yes, humanity in the loop that's fundamental. I always ask myself and ask my team at UNESCO. I say if whatever we do in the field, if that transforms lives, then we

are spot on. If you make the beneficiaries of our educational programs, whatever, if we can make them more successful through what you offer them, then that's impact. Where is the

impact? AI can transform lives. Yes. And you mentioned to us some examples. It can help cure cancer. You said provide food for the needy people and so on and so forth. We want the type of AI and AI

does not stand for artificial intelligence. AI stands for all inclusive. That's AI as well. So if you have that perspective to things, if you really put

a humanity in the loop, at the center, not only in the loop, in the center. And allow me one minute to share with you. I have been at UNESCO for 5 years. My most memorable day happened last week in a

tiny village in remote southern Africa. A village that people in which people had no access to radio, no TV, no mobile telephon, no internet, nothing. They always felt we are secondass citizens in

this country. Imagine that you don't have access to information. You don't know what's happening around you. You cannot call your relatives living in other cities. This was the case of 15

small communities. What UNESCO did? It provided first community radios. Set up a tower with transmission equipment. So through the radio people have information now what's happening. And

when we did that, telecom operators came in to plug in their equipment to provide mobile telephony and then it became internet connectivity and then UNESCO put in place early warning systems

because these areas were very much prone to floodings and whenever that happened it wiped out the cattle the livelihood of the people etc. That's transforming the lives of the people. AI can

contribute in a huge way to that extent and I think if if we put that at the center then of course it has to be ethical it has to be human- centered it has to be accountable transparent all

the principles that we talked about and then comes the issue of advocacy capacity development because more informed policy makers will go this route but if they we if we don't bring

up awareness if we don't do the advocacy and the capacity building and the training Then of course we can see that some companies or some people going for the buck for the profit out of this

technology not the social benefit not transforming lives. &gt;&gt; Thanks very much Paul over to you because he hinted at the companies at the end of the speech. over to the

companies and really how you see also this fact of including the other stakeholders in what you do and you deliver and how that can transform and help you deliver on AI that is edit by

design. &gt;&gt; Yeah. Well, thank you for saying that and I I actually think that um that it it becomes more and more obvious that that's actually the only way to scale

the technology. Um and uh you know but you just think about think about if you're developing a technology that's in meant to serve many different markets and many different populations

um that you need to know for example like we have um in our AI agent we have a voice capability we need to know that that voice capability even if we're just talking about English forget about other

languages for a second we're just talking about English, it needs to work on different vernaculars of English, different accents, etc. Um, I work a lot on product accessibility, right? It

needs to understand a deaf accent, for example. And, um, and so the most inclusively designed technology is going to be the one that's most successful. It's going to increase accuracy rates

and so on. Um I also think uh this is to that end it's actually a very very exciting time to be able to use AI for inclusion. And so I I mentioned for example product accessibility. One of

the things that to me that's most hopeful and most exciting about this time is that like we're starting to see AI agents that uh correct in real time. We're we're working my team is working

on this at Salesforce. correct in real time code that is not accessible or correct in real time a browser extension so that if you're like on your phone and and something comes up and maybe uh a

common problem is you're trying to zoom out or in and it breaks it will correct it in real time. And these are the this is this kind of technology is the difference between someone that's able

to use um some software to actually get their job done or someone that's excluded from getting their job done. And so again, I guess I guess the point that I'm trying to make is um the most

to be the most commercially successful and also this is an incredibly exciting time to be doing this work. &gt;&gt; I'm really happy to hear from the voice of industry that the more so those that

include are actually not making a favor to those that get included but actually the AI the systems get superior. And so that is something I think that's another kind of a common legend out there that

says no you know it's costly and perhaps then you don't know the the profit is not there or what we are hearing from the voices of the the companies is really like well no because it's a

superior product it's a better product it performs better last but not least back to our Virginia especially here I would like to listen to from you about what you think

is the role of a specific component of human capital that is the skill And we have heard throughout this week the importance of upskill and reskilling &gt;&gt; and is that really the solution and to

what extent? &gt;&gt; Thank you very much. Uh firstly going back to the journey if I made the impression that hammers are not useful it's not the case there are many useful

hammers. My point is more like we need a toolbox. We don't need only hammers and even outside of western world that we are too much focus on hammers. uh maybe uh the skills. Yes, we really need to

focus on skills. We need to focus on our own capabilities, on our lived experience and so on. Going back to someone about AGI and indeed at this moment the the AGI concept

or is about power is about providing power to those companies that claim they will build it. How are they building it is what I call the play-doh approach. They are putting all the data of the

world with all the capab capacities of the world creating a huge ball of play-doh. If anyone who played with play-doh before you know that after you play there is no color, there is no

shape, there is nothing anymore. It's just a a thing and then of course that thing might do but no one knows what's inside, what came in, what came out and so on. We need to go much more broader

in understanding how this AGI is what what fundamentally AGI means a system that is more intelligent than us that can solve problems that we cannot we already have AGI we always add AGI is

called collective intelligence the moment that we work together we can do more than each one of us if we are using the AI technology that we are developing to support This collaboration together

to develop the different skills to integrate all our different capabilities, our different differences, our difference experience, our different uh capabilities, our different tools

that we have developed. Then we get a much broader uh uh bouquet, not anymore a bowl of play-doh without color, but the huge bouquet of flowers of all those colors and so on. So AI AGI is about and

we we cannot let the big companies run away with the concept of AI by the idea that they are going to create God which going to solve our problems. A hi is about us is about putting all us

together because our collective intelligence is really what at the end of the day is going to solve or to support us solving our problems. It's just one more thing and I think that's

also part of the skills technology and for and I there I disagree with you is not neutral. All technology embeds and incompass our choices, our options, our data all of that is part of technology.

If we have to understand technology as a nonneutral artifact and take those uh those capabilities and also embrace the different neuters

of this but again altogether that's the only way forward is not giving up and hoping that AI is going to solve whatever complex problems we have now is really im embracing and enforcing

collective intelligence that is AGI. &gt;&gt; Thanks a lot. Now collective intelligence and now we are going to have a collective set of questions just a couple because the time doesn't allow

for more. So please by the time you want to intervene be absolutely short say your name say whom you want to ask the question to and the question without doing the history of humankind before

starting the question. So um I have to say I spotted that surface and there was a lady on this side [snorts] which now I think I she got shy and she just put her hand down. So let's start by that

gentleman. No it's the gentleman behind it. I'm sorry. &gt;&gt; Is there &gt;&gt; I can do everything from moderating to give you the

&gt;&gt; whole service you let's [laughter] go. We are proactive and problem solving. Let's go. Your name is &gt;&gt; push the button. &gt;&gt; Yes.

&gt;&gt; Hello everyone. Myself Rajan. I'm from Business Club TV and I'm the CEO and the founder of the uh of the startup. So I have a very basic questions for uh uh uh uh professor Virginia Dignam.

&gt;&gt; Yes. So professor I have a question for you. What is AI policy? &gt;&gt; Wow. Okay. How many hours? [laughter] &gt;&gt; Okay. very shortly. AI policy is about the the tools, the capabilities, the

skills, the information, the knowledge on the understanding how to um address the impact of AI, not the technology, not the designing of the technology, but really addressing the impact of this

technology from the all the whole um loop and all development from the beginning asking ourselves why are we using AI is that the best for the problem that we have to the way we are

developing it to the way that we are evaluating and addressing the impact of it. &gt;&gt; No, I'm sorry because we have to give it let's be inclusive. Let's allow the

others to speak as well please. That lady Yes, exactly. The one with the It's just down here. Three three rows ahead. &gt;&gt; I'm going to be gender equal. So, 101.

I'm not going to have the men speak because typically you're the fastest to raise your hands and women we have more. Go ahead. &gt;&gt; I love that. Thank you for that. Um, hi,

my name is Rita Sony. And I don't know who should answer this question, but at the beginning of this panel, I heard someone say, um, those that are developing AI and designing it probably

have never experienced a power cut or part holes in the road. I thought that there would be more discussion about who is actually involved in the humans in the loop. Um Dave Johnny, you know me.

So I have to ask this question about the people that are actually developing it and whether we're thinking about responsibly employing them. Uh right now we know that there's over half

a million people in the world that we consider impact workers. They've typically been excluded, but now they are. So how do we support this as a movement of getting

those that have experienced power cuts to help design and develop it? &gt;&gt; This is a development related question. Who wants to attack it? Because we are over. That's the last question and then

we will have to say thank you and continue the conversation in parallel. &gt;&gt; Yeah. fully I mean &gt;&gt; you know if you're talking about have developers suffered to to develop the

technology power cuts anyone who's working out of Bangalore or any Indian cities yes they have okay they've definitely suffered in the development now I think brea the point you were

making is how do we make it more inclusive how do we bring in um and I think that's something that goes back to the perennial question is how do you ensure that u you democratize not just

access to technology but you also democratize design and creation of the technology right and it's not just gender it's also how do you diffuse it down to smaller cities so people who are

actually facing the problems in smaller cities and I think at least in India we are doing that through our initiatives like startup India etc which is more focused today on building capabilities

in tier 2 tier three cities not users not just for adoption but actually for design and development. So there's a lot of focus and I'm sure there are founders here who have come

from the smallest of cities in India. And the best part is when we track the numbers, the growth of startups and founders is higher in the tier 2, tier three, tier four cities than in tier one

cities. So that tells us we're doing something right. So if you have join if you have enjoyed at least as like half of as much I have enjoyed this panel please join me in thanking the JOHNNY

[applause] [cheering] and we're going to do a live show. Please stand up. We will do um a selfie with all of you in the back.

&gt;&gt; Come here. &gt;&gt; Wow. &gt;&gt; So we stand like this. &gt;&gt; Yes. We stand like this. &gt;&gt; So we are all together. This is our

collective intelligence. &gt;&gt; There we go. [laughter] &gt;&gt; Thank you. &gt;&gt; Thank you very much.

&gt;&gt; Thanks.
