# Connectivity and Inclusive AI for Global Growth

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 14:30 ‚Äì 15:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 19 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/sipvt5iWlFw?feature=share) |

## üé§ Speakers

- Durga Malladi, EVP, GM, Technology Planning, Edge Solutions and Data Center

## ü§ù Knowledge Partners

- Qualcomm

## üìù Summary

This session explores inclusive, edge-driven AI and next-generation connectivity, highlighting how on-device, hybrid, and agentic AI can enable global growth, human-centric experiences, and a scalable AI ecosystem.

## üîë Key Takeaways

1. This session explores inclusive, edge-driven AI and next-generation connectivity, highlighting how on-device, hybrid, and agentic AI can enable global growth, human-centric experiences, and a scalable AI ecosystem.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/sipvt5iWlFw/maxresdefault.jpg)](https://youtube.com/live/sipvt5iWlFw?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

and inclusive across the globe. To share how these pieces come together and how Qualcomm is unlocking AI's full economic potential, it's my privilege to invite on stage Dura Maladi, executive vice

president and general manager, technology planning, edge solutions and data center at Qualcomm Technologies. Please join me in welcoming Dura Thanks Richard. Okay, so uh we're

reaching towards the uh later half of the afternoon. Hopefully everyone had their lunch and their coffee. So uh I hope to talk over the next 25 minutes. I won't take that much time but about 25

minutes talking about what is going on in the AI landscape uh from edge all the way into the cloud. Starting from yesterday there was a lot of discussions on the relevance of edge AI. What

exactly is happening in that space? what should be the opportunities at the edge and where we should be going in the cloud as well. So I'll try to distill that in a few slides and I'll probably

go through a little faster so that we have enough time later on uh for the team to actually go through the panel discussion. All right, I'm just going to click through this. This is good. This

is probably um a a good indication of why the edge matters. If you go back in time three years, um, when GPT was originally announced back in, uh, uh, November of 2022, that was a very large

175 billion parameter model. And if you take a look at what the model sizes today look like, they're more like 7 to 8 billion parameters, but they actually outperform that original model by quite

a bit. Model sizes are coming down quite dramatically, while the model quality continues to increase. This is the equivalent of an AI law that seems to be emerging as far as models themselves are

concerned. It's an important trend line because this actually is the foundation for why edge AI is actually relevant. In other words, you don't have to necessarily use the trillion parameter

models to be able to get through a large number of use cases that average consumers actually care about. And when you think about it that way, this is a depiction of just in the last one year

alone, how much of a progress has been made just in terms of the model quality index itself. There's several parameters over here, but the punch line is model quality is getting extremely powerful.

And now the question is what should we do about it? What can we actually build on top of it? So we've already established the fact that the model sizes are coming down while and these

are sometimes known as SLMs. Uh though I would argue that it's not just small language models, but these are small multimodel models that are coming in. But there are increased capabilities

coming with it. much larger context length, a lot of ondevice learning and personalization that can be done built upon that and reasoning models which actually mimic what we typically expect

to see uh from some of the larger models. When you put both of these together and build the right kind of an innovative architecture, that's what actually leads to edge AI in devices

that you and I care about. So, is it here? Is this just a PowerPoint presentation or are there actual consumer devices where you can do edge AI? The answer is absolutely yes. In

fact, today if you can get any of the premium uh smartphones where you can easily run a 10 billion parameter model without breaking a sweat or glasses which have up to a billion to two

billion parameter models which you can easily run PCs with up to 30 billion parameter models and so on. These are devices that you and I use very frequently at least the PCs and the

smartphones with more people adopting AR glasses as well. But one thing that's nice about running uh ondevice AI or AI inference that's running directly on devices is the quality of the AI

experience is invariant to the quality of connectivity that those devices had to have toward the back end of the network. That's as a attribute. I don't want to keep going back and forth

between a regular experience and an AI experience just because I don't have internet connectivity. That would not be very compelling for any of the consumer or enterprise use cases and that's key.

The second part is there's a large amount of data that happens to be very personal which can be consumercentric or it can be enterprisecentric but either way I might or not be interested in

storing the data in the cloud and if you kind of think about it that way then that's another vector that takes us towards what you can do at the edge and as you put it all together what exactly

are we trying to do with the AI to begin with now I wasn't there around in the in the 60s or the 70s well I was there in the 70s but I wasn't involved Then you know what people used to do with very

large mainframe computers where there was just a command line interface. There's a gigantic machine in front of you and you just keep typing something onto it. That was the user interface

between a human and a machine. The 80s changed that with uh the advent of you use a mouse, you use a PC, there's a graphical interface, you actually get to see something, not just see a command

line interface. That changes things. Fast forward to where we are today. About 20 years back, we started using touch as the main UI. We all have our smartphones which happen to be

touch-based and increasingly laptops and and tablets and these are places where the UI shifted from just using typing and using a keyboard to touch interface as well. Well, we are now at a different

era now. It's at a place where we now are increasingly using voice as an interface towards devices. And if you put it together, you have a combination of different modalities, whether it is

text or voice or video, any other camera interaction, some sensors which tell you exactly where you are located, provide some context to what you're doing. All of that gets ingested by a single

interface, an AI agent. Imagine the following. Let's take a smartphone because one can easily relate to it. You have your smartphone right now. People are either looking at it or scrolling

through their apps. We all have a clutter of apps on our phone today. If I wanted to use one app, I'll have to click that one. If I wanted to then correlate that information with another

app, I have to go back, then open up a new app and go in again. Instead, all you have, and this is a future where all you have is a voice UI where the device is sitting somewhere, maybe it's in your

pocket, you talk to it, your voice gets authenticated, and then it says, "Okay, I'm ready for you. How can I help you?" That's your agent right there. I would always love to say, "Talk to my agent."

But this is the beginnings of that. That agent distills all the information that you're saying, encapsulates it, maps it to apps that are running somewhere in the behind. The models are actually they

only provide a means towards an end goal. They perform a job, but that's not the end job by itself. So the agent actually picks one or two from a bouquet of models and then also uh accesses some

of the personal attributes that could be sitting right there. We call it the personal knowledge graph together. When you put it all together, you you end up seeing a glimpse into how AI can then

become the new UI to all the devices around us. And this is a very powerful concept. Is this also just on PowerPoint? Till about last year, that was the case. Not anymore. Bite

introduced a new phone in China very recently and it's not available everywhere in the world. Uh some of us do have the luxury of actually visiting China quite frequently. This phone is

like fundamentally different. It's designed from AI first. All you have is an agent, by the way. And all the other apps are actually missing. They're somewhere in the back, but you don't get

to see them. And and if you think about it, it's a very disruptive mechanism. It's still early. Of course, it's going to be a little clumsy and it does not doesn't work all the time picture in a

picture perfect manner, but it's something that is beginning to change the conversation of how you take AI agents from something that happens to be in presentations to something that is

far more practical in devices. So, I'm going to just skip through this part of it. A lot of it is in Mandarin, so it's kind of hard to see, but at the same time, you get the picture of how it can

do things for you. When you give it a very generic, nebulous task, and it figures out exactly what is it that you need and then does things for you. It's like shop something for me, check my

bank balance. If I have enough over there, I want to buy that thing and then when it is done, do let me know. It does it. You actually don't know it's happening, but it actually does it. All

right. So far, we talked about the edge. What about the cloud? Well, a lot of the data actually comes in from the edge. It's the consumers who are actually generating the data. That's where the AI

action really is. But the cloud has an important role to play as well as the data actually gets used both between the edge and in the cloud. And so our philosophy over here is to make sure

that we have AI processing that is distributed across the network depend depending upon what the use cases. For instance, the cloud is extremely powerful for training foundational

models, creating new kinds of models. That's very helpful. At the same time, there's a large number of enterprises where you have on-prem servers where with using air cooled cards, it's very

easy to run 100 to 200 300 billion parameter models. Very useful for small and medium enterprises which don't necessarily have to rely on the data center. Just buy a C server, plug in an

AI accelerator card, maybe a handful of them, and you end up with extremely sophisticated processing. And keep in mind in the beginning we talked about the fact that the model sizes continues

to actually come down while the quality continues to improve. So whatever you have if tomorrow there's a new model that comes in or you just want to replace your existing AI accelerator

card take out one plug in another one as opposed to rolling in a new rack fundamentally different in terms of the network economics. And finally we just talked about devices as well. So bottom

line is when you think of AI processing as a hybrid AI, it's a mix and match of processing between devices, the edge cloud and in the data center. And speaking of what is it that you can do

with it, imagine the following. This is one of the PCs that was launched in Saudi Arabia. It's called the Humane PC. We had a lot to do with it. It's a place where in fact the only interface is what

you see in front of you. This is not a standard PC which you open up and you have the regular kind of a screen saver and you have all the other apps that are there and you open up your you know your

mail client your calendar and so on. You ask a question and in real time and it doesn't matter what it is in real time it decides should I run it on the device or should I run it on the cloud maybe

some questions that you ask are so complicated I want to run it on the cloud and the other questions are yeah without breaking a sweat I can just run it on the device and this is a place

where you actually switch back and forth between what's running on the device and what runs on the cloud it's the beginnings of where we can go with it another step when we actually talk about

devices we all have a universe of devices around does glasses which could be connected directly to the network tomorrow and today they are tethered through a phone your earbuds your

variables it could be a watch that you're wearing and increasingly now a ring as well I think we're running out of places where you put devices but every time I think that there's a new

device that comes up already we've reached four this is like a universe of devices around you and perhaps the hub happens to be a phone how do you actually go back and forth between these

two and how exactly do you make sure I I wouldn't even probably want my smartphone with me I want to keep it somewhere just have my earbuds and constantly talk to my phone and do some

of the processing perhaps in my earbuds itself rest of it on the phone and some of it on the edge server and the rest of it on the data center that is the vision of how the evolution of AI ought to be

speaking of the number of things that we just discussed it's important this is now more of a from a Qualcomm perspective we have made sure that we have a good easy way for developers to

onboard our platform forms bring in their applications, their platforms and actually run from there. And uh in the subsequent session as we go through that, there might be a little bit more

talk about it. But suffice it to say if you go to the Qualcomm AI hub, it's a place where any developer can pick a model, bring a model or if you don't have a model, we'll create one for you

if you bring your data. Once you do that, we'll give you free cloudnative access to device form which exists somewhere, but you don't care. You just have an IP address that you log into and

you take it from there. And then the rest of it is you write your application, you you have the ability to test it without once having the device actually in your hand. If you're

comfortable with that, you get to deploy that app out there in any kind of an app store. Very powerful concept that we've actually worked on for a large number of time. And this is a place where you know

we are not a model creator. We ingest models which means we work locally with every single uh uh model provider out there on the planet and happy to actually discuss a lot more offline as

it comes to it. All right, how am I doing on time? Maybe I have 10 minutes. So, let me talk a little bit on uh data center. Um u I don't see the timer here. That's why I was asking. Um so, what

happens in data centers over here? Well, one thing that's clear is that uh the data center capabilities are becoming more and more sophisticated. And as we learned a lot of lessons from the edge,

one thing that became very clear for us is that it's important to pay attention to energy efficiency in addition to performance. So we call it as energyefficient high performance

computing and we kind of start bringing that sort of a paradigm into data center. A few other observations came in. One is that the processes that are designed for training are not

necessarily the best processes that are intended for inference. They're actually different kind of problem statements. It's a little more subtle. But once you understand that once we get past the

whole notion of let's just buy the biggest GPU that's out there and then you realize it's a little bit of an overkill when it comes to the inference task that you might have. It's a

different architecture that's needed. The second part is that we wanted to make sure that in addition to you know the rollouts that are currently occurring we bring in solutions which

would lower the total cost of ownership. So when we put it together, we introduced uh our family of solutions in the data center as well, learning from what we learned in devices and then

bringing those lessons into the data center. A smartphone today operates at 4 watt at best. The battery inside a smartphone is 4,500 mAh at best. In a data center, if you buy a

state-of-the-art rack, it's about 150 kow. Fundamentally different. It's directly liquid cooled. You need water. There's no water or liquid cool kind of a smartphone over there. two different

universes but there is a way to learn lessons from one universe and actually apply it on the other side. I would argue that in AI terminology that's transfer learning that you seriously

apply going from devices all the way into data centers itself. So we entered that space and we have two different categories of solutions. The second one AI 250 is a place where we focused on an

innovative memory architecture. As [snorts] it turns out and it's a little more of a subtle argument here but as it turns out that when we talk of inference the prefill stage is extremely

computebound. The more computation horsepower you throw at it, the better it is. Tokens per second is higher. However, the decode stage is fully memory bandwidth bound. You can throw as

much compute as you want. It makes zero difference whatsoever. So, the memory architecture is equally to uh it's actually equally important. And so, we innovated on that putting it together

for our AI250 solution. This is the one that's actually rolling out in the Middle East. And this was part of that earlier demo that we just talked about with a PC and something else that's

running in the cloud. We have an annual cadence that's coming up. This is table stakes at this point in time with the innovative memory architecture continuing into the second generation by

the time we get into uh AI 300 which is not yet announced but something that we in planning. Now finally and I want to actually move a little faster here. U there is a buzz uh in the industry about

the next generation of cellular platforms and usually one would scratch their head and say wait a minute we just launched 5G I don't know exactly why are we talking of 6G over here and besides

isn't this all about AI? What does AI have to do with 6G? Are we just throwing AI pixie dust on top of every technology right now and simply saying there's a hype cycle associated with it? That's

not the case. It is true that cellular communications and AI have evolved as two parallel uh you know sets of innovation but the time has come to actually put both of those together

because cellular technology at the end of the day does involve the very same devices that we just talked about. It involves a network through which all the data goes through and eventually goes

into a data center as well. So we have a view in terms of how 6G can unlock a full potential of AI and u you know if you think exactly how the G transitions occur it's every 10 years or so. So the

earliest 5G launches were in 2019. So we are in year 7 of the journey. It's not that far off and it turns out we have a convenient uh summer Olympics that's coming up right next door. We're based

in I mean our headquarters is in San Diego. That's where I live and uh there's the 2028 summer Olympics. So there's going to be a lot of show and tell in terms of what 6Z capabilities

can be and there'll be technology trials at that point in time culminating into the first set of deployments that we are driving towards in 2029. And we have another two minutes and just

about done. I want to actually stop with one final thing and that is uh this part over here. What you heard is just a glimpse into the kind of world that we as Qualcomm live in. We are probably the

only ones in the industry that work on everything from doorbells to data centers. There's a lot of others who focus on data centers maybe on servers but they don't exist below phones. We

actually work ground up from everywhere over there. So happy to talk with all the developers in terms of what is it that we can do for you and uh and want to continue the conversation right after

this but at this point in time I'd like to stop and hand it over to my colleague. Thank you Da for this insightful presentation. As we talk about inclusive

AI at scale, enabling developers is critical. Innovation only moves as fast as the tools behind it. Through the Qualcomm AI hub, we are simplifying how developers access optimized models, test

and deploy high performance ondevice AI from edge to cloud. to share how we are accelerating this developer ecosystem. Please join me in welcoming in welcoming Siddhika Nerikur, senior director and

head of Qualcomm AI hub to moderate our panel discussion with leading startup founders exploring the evol evolving AI ecosystem and what excites them about building with ondevice AI. Please join

me in welcoming Siddika. Right. I would like to welcome the panel over. You guys know who you are. So I don't need to. &gt;&gt; I know. Probably switch this up.

Can we just take a moment for a quick picture if that's possible? &gt;&gt; Sure. comfortable everyone. All right. I just want to explain how this will run. We

have about 20 25 minutes. So very short time. Um it's a very busy event. Some people are having a hard time even getting in here. Um, so let's make it fun for them. Let's all have fun here

while we're here as well. Um, so we'll start with uh very short introductions. If you don't mind, you can go one after another and just tell the room you know what do you build, what do you do uh and

then we'll start with some of the questions. &gt;&gt; Sure. Thank you uh for having us here on the panel. I'm Ritukur Vijay. I'm the co-founder and CEO of Autonomy. uh we

build autonomous robots and uh you know orchestration platform for different type of ecosystem and other robots as well. &gt;&gt; Thank you. So I am Shini Shinwa. I lead

the innovation track for Techmandra uh for uh AI and emerging technologies which includes blockchain metaw and I'm also responsible for creating uh an

innovation ecosystem across a network of labs that we've created globally. Thanks. &gt;&gt; Hi, I'm Madhav. I'm the co-founder and CTO at Spotdraft. We do AI for legal. Uh

we've created a bunch of agents that help lawyers not just review contracts but also draft them and negotiate them faster and better. &gt;&gt; Hi everyone, I'm Pravir Kocher. I'm uh

one of the co-founders of Kogo AI. Uh we run a full stack private agentic operating system from the edge to the cloud. So we are bringing agents closer to enterprise data uh rather than taking

uh data to uh to agents. So we are 100% sovereign uh built from scratch platform and uh we do some very exciting work with Qualcomm. I hope I get to share that with you today.

&gt;&gt; All right. Uh let's start with some questions. None of you know these so these are fun because they'll be surprised to you. They're not hard. They're very easy. Uh we'll start with

you Prairie. Um we'll we'll go in the reverse order because that kind of throws a curveball. Uh what's the most underrated pain point for enterprise users that AI will solve? You can

perhaps talk specific to your product. &gt;&gt; Uh did you say underrated? &gt;&gt; Yes. &gt;&gt; So so there's a concept called shadow AI. I don't know how many of you know

about shadow AI. Shadow AI is uh a lot of people who work in companies uh uh and sharing critical enterprise data on the cloud while using uh u unauthorized AI tools like OpenAI or claude. So 78%

of enterprise users use shadow AI u and that's a big concern. It's it's underrated but it's still driving efficiency. So, so not not a lot of eyeballs are being uh going there but uh

I think that's going to become one of the critical issues as we move forward. Uh things get more complex, agentic systems get more complex, more data is shared on the cloud. So I think yeah for

me I think it would be shadow AI that people &gt;&gt; that's a good answer. It was a curveball but you caught it. Okay. Uh let's go to Madhav. Um you work in a very niche

field you know legal which is very very niche. Uh your biggest and you also still dabble with technology, right? Yeah. So you like it. Uh so your biggest and favorite AI failure uh building spot

spot draft that set you up for success. Can you remember any of that? &gt;&gt; Uh it's a great question. Uh so it sort of goes back to our founding years where we were a little bit early to the game.

This is around 6 to 8 years back when transformers were what people were talking about and not LLMs. And back then we came in with the idea that you know cars are driving themselves. So why

can't AI actually review contracts for you? So we spent a bunch of time with enterprise customers trying to deploy AI and realized that we would have to train a model for each customer and we built

out our entire data labeling annotation pipeline as well as team at that point. So while that was in a way a failure because we then decided not to do that because we didn't want to do services

otherwise we would be building models one per customer and the genesis of spotdraft as it exists today came from there because we wanted to capture the data as lawyers were using the

technology that they anyways use which is where our word plug-in comes in. So we can actually capture what they are doing and then our annotation team was also set up back then and that's sort of

how today we are able to give grounded answers using data that is the customer's data because of all the things we built back then. &gt;&gt; That's a good one. It's so now you're on

a path of uh just never regretting making single models for each customer. Um I mean I hope we don't have to go back there and I think a lot of the models that have come out are enabling

that but that part yes not regretting it. &gt;&gt; Um all right Shini last minute addition so thank you it I know that it's difficult to get here. Um this is

probably something that you'll be able to share with us. Uh what's the special ingredient for successful AI adoption in India specifically? Okay, that's that's a tough question to

ask, but I think uh the most uh important thing uh is understanding the limitations of AI. So, typically it's very easy to understand what are the advantages of doing AI. But uh if we can

set the expectations right uh that AI will augment their work to a certain extent u that will be one. Second, the complete misnomer that it is here to take away jobs uh has to be uh removed.

I think these are two things. I &gt;&gt; see. And how how do you feel about AI being trusted in India? Is it trusted enough or is is it adopted? &gt;&gt; So if you look at uh yeah sorry if you

look at the adaptability of adoptability of AI, we are almost at the global level in terms of the enterprises that we are talking to. But the best part that I have seen is that a large number of uh

public sector banks have taken to AI in a big way. uh some of the banks have been our customers for both AI and emerging technologies and we've also seen uh PSU units talking about AI and

I've also seen a lot of U state governments I had a chance to meet a lot of ministers today uh ministerial delegations today um have set up AI center so we are in the game

&gt;&gt; yeah good good um Rukar this is an easy one you think about this probably a lot um cloud or ondevice AI which where and when. &gt;&gt; So I think uh in continuation to the

previous question so you know just uh just throw a bunch of uh compute and a problem statement is not how AI is uh you know adopted in enterprise uh settings because it's very important to

break down the big problem into smaller chunks and you know for what you want to use AI and for what you don't want to use AI and that's exactly what we do in robotics. So you know we break down what

is happening on edge and uh what is happening on the cloud. So right now at this point in time for us uh it's like you know we we do orchestration on the cloud which is for the fleets of robots

but uh you know uh we were doing all you know autonomous navigation on the edge uh part of it and uh for us it's uh very important that uh you know uh we wanted to understand more intelligent

navigation. So at this point it's been almost one and a half years since we started running VLMs &gt;&gt; on the edge to understand the context. So, so I think that's how you break down

the overall problem, not just running everything on the edge or running everything on the cloud because that's that won't solve the problem. Uh, yeah, that's uh that's pretty much uh how we

break it down into you know uh small chunks. &gt;&gt; So, you you guys are very thoughtful and very quickly giving these answers for longer questions. So, we'll go to rapid

fire. Okay. &gt;&gt; U which is just picking uh one word. There's no judgment here. You can pick uh it'll be A or B. You pick A or B. Uh maybe a couple of words about B. Okay.

Not not not too long. So we'll start with you. Uh 6G or AI. &gt;&gt; Sorry. &gt;&gt; 6G &gt;&gt; or AI.

&gt;&gt; So uh okay, this that's a long one. I I can just share a good anecdote there. So we were running uh robots in Riointo in Australia mining areas, right? There is no internet. Still we want to use AI on

the edge. And uh so what we did was we we put some installing satellites each on the robots, right? So connectivity is very important. If it is 6G, it's better. So yeah, I I I'll go for 6G

because that opens up a lot lot much possibilities there. &gt;&gt; That's a good one. I thought you would pick AI because that's the buzz word. But

&gt;&gt; that's anyways happening. So good good answer. Um data center or local? &gt;&gt; Local is the first option. But for India data center makes business uh local uh

because uh the one of the key products that we have built uh called Orion uh which a AI platform has been built for on-prem &gt;&gt; uh and uh we also see that u a large

number of requirements that have come to us is how do I process things uh in my own premises rather than doing an API call or taking it to the cloud and we have seen I know you asked for India But

I have seen this happening in the Middle East also where a large where one of the largest world largest largest company has said that can my execs uh solve their things on their own desktops or

locally. So local &gt;&gt; local for you. Okay. Um &gt;&gt; yes &gt;&gt; for you I I'm looking through because I want to ask a specific one. Um Mav

artificial or human? I mean when you deal with lawyers at the end of the day I have to go with human because &gt;&gt; I know you easily pick artificial let's

[laughter] just &gt;&gt; so you can't hold uh AI models neck but you will go hold a lawyer's neck so for us it's important to give uh the lawyer the capability to do their job better

faster with a more thorough research but at the end of the day it has to be them taking that decision because a lot of times it's not the black and white those are the easy scenarios it's the gray

area where the lawyers are able to come in and really guide their customers, clients as to what to do and what not to do. &gt;&gt; Fair question. I think we still want AI

to be human, right? So, I think it's a good answer. Um, but there is no judgment. You could have said otherwise too. Prairie, regulate or innovate? &gt;&gt; Okay,

&gt;&gt; this is in regard to AI. [laughter] &gt;&gt; No, 100% innovate. Um I I don't I don't see any reason uh anyways regulation in the in the age of AI is always going to play catch-up because technology the

speed at which it's growing uh it's very difficult to regulate it before it goes because we don't even know the social implications of what we are building and and as we build them and as it goes into

public and people start using it these tools are are very intelligent uh they're getting intelligent by the week so so I think it'll always be innovation uh at the side of caution uh but but I

don't think this is an industry that you can regulate first and then expect it to grow. &gt;&gt; I mean your first answer very first answer about uh I wouldn't say illegal

but unauthorized usage was pretty much in line to this and it still was saving time and it's still so uh yeah I I think that's a good good answer. Um for the next ones you don't have to say why. So

you can pick an answer nobody's again no judgment you can pick whichever one you want. Um, agent techic or robotics? &gt;&gt; Robots are the agents. So, &gt;&gt; to pick one.

&gt;&gt; So, agents. Yeah. &gt;&gt; Okay. Um, LLM or SLM? &gt;&gt; SLM all the time. &gt;&gt; Um, intelligence or automation?

&gt;&gt; Uh, you can't do automation without integrations. So, I would have to go with integrations. uh build a chip or buy a chip? This is just a selfish question, but you know,

&gt;&gt; I would sell a ship, but then but then build a ship always. Yeah. &gt;&gt; Wow. That's it's an interesting answer. I don't know how much time is left. &gt;&gt; Okay. All right. We'll do some few extra

questions. You you guys can take longer now to answer the questions. I guess just moderate the time accordingly. Um what's the one hardware constraint that keeps you up at night?

&gt;&gt; So uh one of the biggest hardware constraint uh is uh you know if if your entirety of the system is uh you know without any connectivity and uh you are restricted

uh that you cannot access remotely. you know if you cannot access robots remotely in any which way uh be it for scheduled maintenances or predictive maintenance or any anything of that sort

and even emergency situations like uh what we see uh you know the wayos which are running in Sanford SF right now they they are monitored in from Philippines right

&gt;&gt; so so I think uh that part is something which is very important that uh everything should be connected at all times so so I think that that keeps us awake that uh you The robots should not

go in silos or isolated where we cannot reach them and uh only then we have to physically you know make sure that somebody's around to manage a fleet or whatever. Yeah.

&gt;&gt; Um you talked about local so I'm going to ask this question um which which seems apt for you. Uh what's more dangerous? Too much data leaving the device or too little?

&gt;&gt; Too much data leaving the device. I think too much data leaving the device always [laughter] &gt;&gt; how do you train? &gt;&gt; Huh?

&gt;&gt; I was saying how do you train if it doesn't &gt;&gt; see I I think uh the focus for us also has been um how do we train with lesser data and make it uh much better. Okay.

Uh the moment we're talking about u more data and more data leaving uh we're actually talking about u more issues happening more breaches happening. uh so with lesser amount of data if you can

train uh or if you can create synthetic data sets and uh work it that's the best way uh for LLM to be trained rather than waiting for large data set to come and then like you said then then wait for it

to leave &gt;&gt; you don't if I may like you know it's it depends like if it is enterprise then less data going up is always better if it is B2C then everybody wants to learn

from that data &gt;&gt; so because that is free data &gt;&gt; so in a way uh that's that's something which is very important situation. Yeah. &gt;&gt; Okay. Um,

&gt;&gt; this is probably this is going to be interesting. You get to tell another story. Uh, what was the last thing that made you go wow about AI? &gt;&gt; And this doesn't need to don't pitch

your company. I mean, it's fantastic. So, you &gt;&gt; I'll try not to. Uh I think we've seen uh the kind of and this sort of goes back to the last question in a way where

a lot of companies have so much data sitting in people's heads in people's inboxes uh random sharepoints drives and historically what we've seen and as we

onboard customers they're like oh I have a playbook you know which is a policy of what contracts we will sign won't sign but we also know that it is out of date and we've been working on uh techniques

to be able to really infer that from older data. And one of the things that we've seen uh which really blew my mind was we actually ran one of the early prototypes of that on our internal data.

We run spotdraft on spot draft and some of the things it threw up when I was talking to uh our internal legal team and I expected them to say no this is absolutely wrong and that guy's like

actually I want to know where this came from because I have been trying to track this down that why are like certain contracts having certain clauses and not so it's that ability to do knowledge

work with otherwise would not be done at all and to have this uh always upto-ate always learning sort of knowledge base that truly captures what your company and organization policies are. That's

something that no one wants to spend you know 100k to get lawyers to create that. But if you have a agentic way of doing it then suddenly that becomes the one thing that everyone cares about because

that is now your onboarding that is now what you you know compare your new contracts with. And I think in the coding side, we've already started seeing a lot of this where uh things

like you know cloud code and codeex are able to go in and learn from your codebase and give you these insights which earlier would take a new engineer like maybe a month or a quarter to get

onboarded. Now they've started shipping code within days because of this. And that is going to start happening across all kinds of knowledge work. And for us the you know the the wow moment was when

the lawyer who doesn't trust AI suddenly said no I need to see this this is useful. So that's &gt;&gt; so I'm uh I'm going to spin uh to Madam the not CTO. Um maybe a consumer AI

feature that just wowed you in in recent time any you can think of. Um, I think I'm sure everyone has been talking about OpenCloud. Um, the ability for me to have a personal assistant almost when I

of course can't afford one, but for that to really sit and start doing a lot of these things for me and I'm sure it's going to come to everyone's devices very soon hopefully with Qualcomm chips. And

that I think is where uh I was really wowed by it because I deployed it on my WhatsApp and it started sending messages to people. A little bit scary but also saved me a bunch of time. So that was

where I was like okay this is something that was not at all possible before. &gt;&gt; All all great uh responses on WhatsApp. &gt;&gt; Uh I had to switch it off very quickly because there's just too much data in

there. But that that is the next challenge right? How do we control these autonomous agents especially when they're sitting on your personal data? &gt;&gt; Um given uh you're a rebel, we're going

to ask you what are you most scared with AI? &gt;&gt; There's not one fear [laughter] there. &gt;&gt; I I thought you would say there's no

fear. &gt;&gt; No, there's a lot of fear. uh there there's a lot of fear because uh I I think we don't know the societal impact of uh of this technology yet. Uh

and I think that's that's probably the largest fear. Uh because up till now we were we were engaging with algorithms that were trained to derive attention from us. Right now we are dealing with

intelligent algorithms that can self adapt uh and become far more personalized uh now with the ability to generate content at will uh I think it'll be very difficult to keep

attention away from from a device when you have a hyper intelligent system on the other side &gt;&gt; uh right that's changing itself based on you it'll become extremely addictive so

so I think that &gt;&gt; yes but but then but And we are pleasure- seeeking beings. We will we will go after that until it it it gives us some guardrails and then we'll have

apps that uh will lock themselves up for 2 days and we won't use them. &gt;&gt; It's possible that we'll be all on vacation and the robots will be interacting with AI.

&gt;&gt; Yeah. And then imagine what we'll be doing. We'll be interacting with these attention seeking uh agents. Right. I just want to take the last question also uh because I just I just saw a real u

recently and and they got a unitary robot in Bangalore and they they sent it out to beg. Wow. So, it was the first robotic beggar uh that somebody started out and and

&gt;&gt; was there more empathy? Probably there was more empathy than than &gt;&gt; I I don't know but but I still think that there's a lot of tangential use cases of AI that can come out of come

out of all this and yeah I mean I mean that's something that wowed me and also kind of told me that you can think very very differently about this technology and not just think what we do and and

replicate what we do. There are a lot of tangential things that might come out of this. I I asked why if there was more empathy because uh I was recently u driving and there was a two-lane road.

One lane was completely blocked. Everybody was trying to squeeze into the other lane and then when you passed by you saw a way more that was uh not operational and everybody would go oh

you know nobody was upset, nobody was screaming. I'm like just because it's a robot you're you know more empathetic but they were. So it changes your you know psychology somehow.

&gt;&gt; Yes. Yes. Yes. And and we are still not interacting with robots on a day-to-day basis. And I think that that will be another another uh kind of mystery thing added to to our societal weave.

&gt;&gt; True. True. Thanks for taking the second question too. It was interesting. Um all right. Uh we we'll get into closing. Um so we can wrap up. You all will get to pitch different companies. So that's

very exciting. Um we'll start with you know complete the sentence in one word. So you have to just say one word. uh edge AI in 2030 will be blank. You can repeat the sentence just

&gt;&gt; yeah edge edge AI in 2030 uh it will be it will be uh I mean it'll be it'll be very uh not so sophisticated I mean it'll be taken for granted so just like uh you use connectivity for granted

that's how the edge &gt;&gt; it'll be everywhere almost &gt;&gt; by default &gt;&gt; by default like like the pins and you know all the humane pins and everything.

to what we talked about in the keynote as well. So, so I think it it'll be like that. So, taken for granted. &gt;&gt; Um, will you still complete it with one word? Sorry.

&gt;&gt; Taken for granted is not one. Okay. Granted. [laughter] So, so it'll be it'll be business as usual or taken for granted. Uh, that's it. I mean, nobody will mind that.

&gt;&gt; Hi 2030 will be &gt;&gt; as a default &gt;&gt; default. It will be on all my &gt;&gt; I should have said no no no repeating answers so I would get some more

interesting answers. I'm glad that I was the first person. [laughter] &gt;&gt; 2030 it's uh quite ahead. There should be something more &gt;&gt; will be in you. It will be part of our

body. &gt;&gt; That is an interesting one. You could have a chip. That's true. Edge AI in 2030 will be &gt;&gt; uh I think it'll be ubiquitous. So, I

think there will not be anything that does not have AI and I think there's a lot of Hollywood uh sort of sci-fi that's demonstrated this, but we'll probably be trying to talk to, you know,

tables or screens or walls to that degree where anything that can have a chip inside it, the chip will also have HI inside it. &gt;&gt; AJI in 2030 would be

&gt;&gt; uh I think AJI in 2030 will be emergent. uh we will start seeing signs of u what openclaw just did uh was a very small trick in the play but it added a little bit of uh emergent behavior into a LLM

giving it autonomy to be able to create its own files &gt;&gt; that's all that opencloud did and that's the magic behind it and I think that's going to come to uh to the edge and and

with that emergent behavior you're actually giving uh a model the ability to create its own learning that that's why I say emergent. &gt;&gt; That's a good answer. Um, all right. One

last thing you want the audience to remember. This is also the cue for pitch if you like. So I mean as I said earlier robots are agents and uh I think I I kind of agree with that. So we are going

to be part part of us will be agentic as well because we'll have something some AI in us as well. uh whether it is so there's a lot of work which is going on with neurolink so you know the the

airports are uh tracking the brain waves of how you react to a particular situation so uh agentic you know uh so both robots and people will be agentic in some fa some uh fashion and I think

that's that's how things will be and you need uh some orchestration where everything can talk to each other that's what we are looking forward to do Yeah. &gt;&gt; So I think uh one thing that we should

all remember is there's a lot of work that uh Tech Mandra and Qualcomm is doing together uh in detecting fraud calls and this is using edge llm. So I think that will grow as we go ahead. Uh

that research will see a lot of uh action because the number of fraud calls that we are getting u are increasing every day. So I think uh that's an area we'll see a lot of action happening and

uh I think both our companies are geared for it. Um I think and I think it was mentioned in the keynote. I think one of the takeaways for me would be how we think

about interacting with technology today is going to change entirely like uh UIs uh phones you know screens all of these going away and everything becoming very very generative whether it is you know

slides being generated for you on the fly based on the conversation you're having or uh even entire apps UIs being generated for each specific scenario and use case. I think everything is going to

move away from just being SAS that people learn and it'll become SAS that learns what you need and what you as a individual persona is actually caring about. Uh and that actually opens a lot

more specifically in the Indian context where you might not like people might not have to go through so much training and learning and they can just go and start using it because the platform can

actually understand your needs as opposed to you having to understand the platform. &gt;&gt; Nice. Can you just repeat the question once for me please?

&gt;&gt; One thing you want audience to remember &gt;&gt; to remember from today. &gt;&gt; Whatever you want to them to remember. [laughter] &gt;&gt; So so so so remember how we used to work

um and and and and plan for how we are going to work because uh because very soon we'll have a lot of time that will be available to us because a lot of systems that we are going to manage will

be intelligence and autonomous and we'll have to only take decisions. So what we do with that time is is going to be a critical question everyone's going to ask themselves and I think all of us are

also going to be builders because we'll be a we'll have very intelligent tools to build things run them uh and manage multiple systems at the same time. So I I see that future and I think uh we

should all look around and see how how we manage things today and and how we're going to do that in the future. &gt;&gt; Great. Uh this was a chance to actually pitch the you know pitch your company

but but it's okay. This &gt;&gt; it's pitched. I I will I will give a more specific one front of pitch which is you know there are a lot of people in the audience maybe some customers if

they were to find you where should they find you or you know spot where they can talk and what should they come and talk to you about what's what specifically in what industry [clears throat]

&gt;&gt; so uh I mean u our name uh so we are autonomy so you can always find us at autonomy.io IO. So that's that's where you can find us &gt;&gt; always where we brand. I think we're

proud of it. And uh the most important thing is like uh you know robots uh and you know just like AI there's a lot of uh emphasis on physical AI and uh it's it's it's not something which is going

to come. It's it's there. It's just the adoption curve which is happening now. So uh think more ways of uh adopting technology and if you want if the enterprise uh customers are looking

forward to adopt more and more robots uh not only just uh dull and dirty scenarios but also in you know different walks of life. I think that is where you know uh talk to us and we can help uh if

even if they are not our robots we can help them to have a set of orchestration with you know variety of things but still they have some level of control. Right.

&gt;&gt; Thank you. &gt;&gt; So I'm part of Tech Mandra and u we have a booth here. Uh the booth is in hall 2 2.1 and um in the booth that we have we

typically talking about some of the areas that we doing for India but uh we have a global charter. So one is we focusing on how we are building LLMs for the education sector in India but this

is something that we can replicate globally. uh we're also talking about what we are doing in the agriculture space and how we've actually codified Indian

panchchang uh through software uh we've gone beyond AI in this sector we've also showed metaw uh and how we can actually simulate a lot of work that we are doing uh create digital tins uh

and all in our booth and then there is a robot that you most of you might have seen when you've come to a booth uh which is part of the entire uh manufacturing setup that we have done in

terms of a factory automation setup that we have done but primarily we'd be happy to engage with you to discuss how we can use AI and metawas to solve some of the problem statements uh either for India

or for your enterprise. Thanks. &gt;&gt; Uh so we can be found at spotdraft.com. I'm not wearing my t-shirt today for a change. Uh we are also present at the Qualcomm booth. You can see our ondevice

demo of you know contract review analysis everything running on the Qualcomm NPUs. Uh and if you have any problem with contracts, why is your legal team taking so long? Why does the

external legal council cost so much? You can come to us and we can help you optimize that. You can scale your sales team and your procurement team without having to scale your legal team.

&gt;&gt; Uh you can find me on LinkedIn Prair Kocher. uh and then we can connect whenever you want. Uh but um we started out we started out with a very simple vision. We wanted to build an AI native

enterprise of the future and to build that AI native enterprise. We still don't know how it's going to function but it had to run on a single stack. That's the stack that we built. Uh we

integrated the stack with Qualcomm so that we can take it closer to wherever the compute is right and whether it's on the edge or on the cloud. So uh with that stack we are we've spent the last

one good part of last one year understanding and working with industries and companies across the board from banks, insurance uh finance just understanding what they do uh so

that we can build that capability into the platform so that we can take and and literally give that power to anybody who wants to start a AI native company. Uh that's that's written on a whiteboard

somewhere in my office. uh that one person should be able to roll out an entire company using a single stack with every department getting rolled out and that's probably what I think is going to

be the power of AI where where where that one person billion dollar company that the unicorn that everyone talks about maybe KO OS is the platform on which that's going to get built so

that's uh a short pitch &gt;&gt; I hope you all had fun it was not no &gt;&gt; thank you so much &gt;&gt; thank you &gt;&gt; we we had a good warning from you so we

prepared &gt;&gt; you you didn't know any questions it was fantastic fantic answers. It was really fun. I hope the audience had a lot of fun. Thank you for being here today and

you know answering and you know participating in &gt;&gt; Thank you for having us. Thank you so much. &gt;&gt; Thank you for everyone who joined us

today. No, no, it's okay.
