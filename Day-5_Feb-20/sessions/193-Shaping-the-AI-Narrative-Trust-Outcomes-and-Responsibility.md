# Shaping the AI Narrative: Trust, Outcomes and Responsibility

**India AI Impact Summit 2026 ‚Äî Day 5 (2026-02-20)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 17:30 ‚Äì 18:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 7 |
| üìÖ **Date** | 2026-02-20 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/W6SPwKDPNf4?feature=share) |

## üé§ Speakers

- Divyesh Vithlani, First Abu Dhabi Bank (FAB)
- Erik Ekudden, Ericsson
- Hari Shetty, Wipro
- Hon. Dr. Andrew Charlton MP, Science, Technology and the Digital Economy Government of Australia
- Jay Chaudhry, Zscaler
- Mridu Bhandari, CNBC-TV18
- Tanuj Kapilashrami, Standard Chartered

## ü§ù Knowledge Partners

- Wipro Limited

## üìù Summary

As AI adoption accelerates, enterprises are assessing how the next wave of transformation differs from earlier expectations. This session brings together investors, founders, and transformation leaders to examine where enterprise AI can create value, where limitations remain, and how organisations can move from pilot initiatives to scaled deployment. The discussion will also consider how operating models may evolve in response to emerging AI-enabled workflows.

## üîë Key Takeaways

1. As AI adoption accelerates, enterprises are assessing how the next wave of transformation differs from earlier expectations.
2. This session brings together investors, founders, and transformation leaders to examine where enterprise AI can create value, where limitations remain, and how organisations can move from pilot initiatives to scaled deployment.
3. The discussion will also consider how operating models may evolve in response to emerging AI-enabled workflows.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/W6SPwKDPNf4/maxresdefault.jpg)](https://youtube.com/live/W6SPwKDPNf4?feature=share)

---

_[‚Üê Back to Day 5 Sessions](../README.md)_


## üìù Transcript

for shaping a sustainable AI future that we are calling people, planet and progress. And to translate these sutras into action, we're looking at what we call the seven chakras of aligned global

cooperation. So these are the concrete pillars that will really turn ambition into accountability. We have human capital, inclusion, trust, resilience, science, resources, and social good as

the seven chakras that we're going to be talking about today. We have with us a very eminent panel trying to answer the defining question of this AI first decade that we are in. How can we

achieve trust before scale, outcomes over ethics and responsibility as a competitive advantage? I'm Vidi Bendari from Network 18 and I'm very delighted to be joined by a panel of very

distinguished guests here tonight. Starting from my left, Pubad, first assistant secretary for AI delivery and enablement at the department of finance in the Australian government.

Next to him, Vesh Vitlani, group chief technology and transformation officer, First Abu Dhabi Bank. Eric Ekodil, the chief technology officer of Erikson

and Harishi, chief strategist and technology officer at Vipro. Welcome gentlemen. Thank you so much for joining us here today. Uh you know perhaps let's set the context with the foundations of

trust and skill and uh Paul if I may start with you first. You know I was going through your LinkedIn profile and you call yourself the AI masked economist. So uh very interesting Monica

there. Why don't you first tell us what that really means and then we'll jump into the rest of the stuff. &gt;&gt; Yes. Thanks. It's great to be here in India. I think we all bring a mic is not

Yeah. &gt;&gt; Thanks for having me and it's great to be here in India. I think we all bring a lens to AI. My lens that I bring is economics. I'm a public policy economist

which for me means AI is not about technological adoption. It's all about what can generate uh what can generate public value, what generates public welfare.

&gt;&gt; And uh why do you call yourself the masked economist? Uh that's a a good another story uh for you that started in co remember when we were all wearing masks

&gt;&gt; and uh at the time I started a podcast which was all about explaining economics and unpacking the jargon and I've kept that because I think explaining AI unpacking the jargon seeing how it

relates to everyday life is really really important &gt;&gt; right now when we talk about AI for social good public permission is really really important public trust is very

important now how do we really build societal confidence in AI without really slowing down innovation. How are you all doing that in Australia? Give us some, you know, examples of how you've been

able to do that, especially because citizens all over the world today are demanding a lot more transparency and accountability when it comes to not just AI but everything in general.

&gt;&gt; Yeah, absolutely. I think it's really important that we don't frame it is like trust versus innovation. It's actually a foundation of trust that lets you make the innovation. uh it's starting from

the proposition of what's the problem we're trying to solve or what are we trying to deliver for citizens if you're a government what are you trying to deliver if you're your customers meet

them where they're at now different countries different populations have different comfort already different familiarity with AI you've got to know where people are up to what they want

and build from there rather than just say here's a brand new thing that we're going to impose on you so I think really that framing that uh democratic participatory

uh approach that people first approach is key &gt;&gt; right Eric coming to you you know AI is often discussed as the application layer but you've often argued that

intelligence must be embedded into the networks themselves now how does infrastructure really evolve from being a very passive carrier of AI to becoming this active enabler of trust and of

resilience &gt;&gt; yeah so first of all Erikson builds networks advanced connectivities of 5G and 6G and increasingly that's becoming this fabric that we all depend on. But

um let's start by thinking about what people are using today. Yai is already hundreds of millions of smartphones actually billions already doing AI applications across the mobile

infrastructure. So it's already secure and trusted. The network is already provided the guarantees that you need. But um I think um especially here in India, we're talking about industrial AI

applications, agriculture, there's going to be a lot of AI in the fields, hospitals, education, smart manufacturing. So it's going to be a lot more dissemination of AI from where

we're focused today on training to distributed AI or inference generation. That's going to happen much further out in the network. So the network is actually becoming a host for all those

great AI experiences. We we need to scale the networks to handle that. And I I don't think I'm the only one. Um maybe not everyone carries two pairs of glasses here, but I think AI glasses and

they are already available in millions. Good AI glasses that give you navigation support that gives you realtime language translation maybe a prompt if you are on the stage making a keynote.

&gt;&gt; I mean these kind of things they cannot be done on the device on the wearables. You need to offload the AI, the inference from the glasses into the network edge. That's why we talk about

this as a transition to an intelligent fabric. The network is already secure, trusted. It's going to be a carrier all these inference workloads. So, we're just starting that journey. Uh but I

think it it really comes back to basic principles. Networks need to be trusted. They need to be secure. they are already moving from consumers into enterprise and government services mission critical

big example here here in India so I think more and more will rely on that intelligent fabric &gt;&gt; so what have the AI glasses been doing for you this week

&gt;&gt; you know I didn't mean navigation because everything is perfect in real finding new ways I I on a serious note I actually use them more privately um than than at work But um I start to see

people getting really good value because it is an AI assistant and and think of it once especially like me wearing glasses once I've switched for good to these glasses why would I wouldn't go

back even when I'm indoor even when I'm at home even when I'm on the train or in the elevator I want it to work and that of course means that the network this intelligent fabric needs to be so much

better than it is today of course great 5G networks here in India Yeah, but in the future you will need even better fullness. And I think this this is a a pivot is a change in terms of we will

not get the full value of AI. We will not leverage AI fully until we connect it to that better network for AI and that's really what I'm focusing on. But um you want to try them? This will be

really nice display. Fantastic. I do a little bit of a galling AI or AR wearables, glasses, earpods, cameras. A few well okay well two.

&gt;&gt; Yeah, &gt;&gt; probably a representative crowd here. I think we are very early on this journey. It's going to be a fantastic journey I believe for both consumers and and

anyone else working in companies. So &gt;&gt; absolutely absolutely well I'm going to come back to you with more but uh bringing the wish in you know in banking now trust is not philosophical it is

existential. So uh how do you really embed AI into core decision making and you know also ensuring we can dilute any risk discipline. So what governance models have you put in place that

actually work for you? You know any best practices that you can share with us here today? &gt;&gt; Sure. Well, first of all, it's great to be here and I'm already you know

benefiting from the wisdom of my panelists because um my kids will tell you that I've been in denial uh about want needing glasses. I said my eyesight is perfect but this you know the

enlarging the zooming really helps. But in reality now I've got a different story for them that I've been waiting for AI glasses um before I really dawn on specs. But um coming back to your

question I kind of pick up on what Paul said. It's not either or. Um you can't you know it's not about you either have trust or you have you know um productive AI. Uh what we believe is like any

regulated institution. Um that there is no compromise on risks and controls. uh our business in banking relies 100% on trust. Um so that is not um a value that we can uh compromise on any time. Uh

however in order to make sure that uh we do deploy AI at scale in a trust uh trusted manner. Uh it starts with conviction and we have conviction right at the very

top of the organization that AI is a force for good. We've heard a lot this week about AI being a general purpose technology. I really love what Eric said about AI in the network and I'll sort of

come to that in a second because that is a large part of the answer is establishing a platform. &gt;&gt; Um but if we take a step back um conventional organization

is defined by its people, its processes and its technology. And there are all sorts of safeguards, guard rails, controls that have been built in. In the AI world, I think it's going to be about

agents, models, and data. And I think we're going to have to have the same guard rails and perhaps even more stronger because it will need AI to oversee and govern uh AI to to sort of

be really effective. So the approach we've taken is on the basis of the conviction that we have that AI is a force for good. It is a gamecher and it is truly going to transform everything

about how we live, work, play and bank. We want to basically make sure that we empower the entire organization to leverage and scale AI in a safe, secure, efficient and compliant manner. Now the

only way in my opinion to do that is to take a platform first approach. &gt;&gt; Just like Eric said about the network needs to be safe and secure. Our AI platform and our agentic platform needs

to be safe and secure. So we have taken the approach of building a platform with all the different layers from data, model, knowledge, context and the jetting farm and the use cases that sit

on top of that. by building ethical AI, data governance, mobile governance, uh the fair and uh appropriate use of AI into the platform and by taking that approach we are able

to unleash the power of the technology in the hands of the end users. So just like when you open up Microsoft and start a new Excel, you're not thinking about is this safe, what's the

underlying architecture, you're doing it fairly intuitively. And we should be able to do the same thing with AI that you know our folks, our business colleagues or our engineers can use AI

as naturally and seamlessly um as they do any other task. Um so taking that platform first approach is what really uh is driving our sort of strategy to ensure that we uh drives AI at scale but

with all the right trust and safeguards. &gt;&gt; Right. All right. Bringing in honey as well. Uh you know har we've talked a little bit about public permission. We've talked about infrastructure. We've

talked about governance security. Uh there's a final leap which is from promise to proof. Now uh enterprises are of course often caught between the AI hype. There is hesitation.

You speak a lot about proof over promise. Elaborate that for us and uh what really separates scalable AI from perpetual pilots that we keep seeing a lot of enterprises deploying.

&gt;&gt; First and foremost very happy to be here with this panelist here and uh putting on the pro lens uh we what do we do? We take Eric's network layer in the pro intelligence on top of it and provide

solutions to the wish. That's where we fit into this entire graph in terms of what we do. Now coming back to proof of promise you you absolutely brought the most important topic that's in

discussion across the summit here as well. EI is no longer about you know pilots. It's about being able to get value out of EI. And when we talk about proof of promise we talk about four

distinct elements that are important from a web pro perspective. Number one, don't start with a model. Don't talk about model X or model Y. Uh and then start start with a model first thinking.

Start with a problem first thinking. So you you pick a problem, figure out what's the right approach to solving the problem and then work the way backwards to look at, you know, what models can

actually help you solve that problem. So that's the first approach. The second part that we uh that we take care of is the the enterprise story is very different than the consumer story.

Enterprises are necessarily messy. You've got technology that's like 20 years old, 30 years old. You've got different personas. You've got different security needs. Uh data is you know in

fragments across the organization. Uh so the enterprise story is a completely different story than a than a consumer grade story in terms of how how things have to come together from an AI

perspective. So in that context, our ability to prove a solution in an enterprise world is extremely important for us. And uh when we show it works in enterprise, that's when other

enterprises build trust that it's ready for diffusion. And by the way, uh we act as client zero for our solution. So if we don't get it to work in our own enterprise, there's no point talking to

any other clients about implementing the solution. The third uh uh principle here is about uh whatever solution we build, it's not about making it work once. It should work every day, every hour and

every minute. And solutions that are only capable of, you know, following that principle are the ones that we actually take it to to take it to the market. And that's another principle

that's extremely important for us. And last, going back to trust that we all talked about, uh if you look at human trust, human trust is earned. Even agentic trust is earned. you need

something that can work for a long period in time without hallucination uh without fundamental flaws in the model uh so that there's trust built into it. So only when things work consistently

over a longer period of time do you develop trust and uh these are the four principles that we use to actually talk about uh you know proof or promise as what we call the product intelligence as

&gt;&gt; right &gt;&gt; all right well we're going to shift gears a little bit and also talk about accountability because uh we're talking a lot about architecture let's also talk

about who's accountable for what in an enterprise um and perhaps in the society as well now Paul when we talk about responsible AI at a national level. What does accountability really look like for

leaders? You know, is it about measurement frameworks? Is it about reporting outcomes? Is it about, you know, independent oversight? What are the signals that really tell citizens

that, you know, this is being deployed in your interest? &gt;&gt; Yeah, thanks. I think it's really about having a clear plan that you can communicate uh in our case uh that

making it clear throughout the economy, throughout government, throughout society that we're going to seize the opportunity of AI. Uh that means uh that means better jobs, that means investment

in data centers and all the things we've been talking about. But then the second thing is really even perhaps more important is we're going to spread the benefit of AI not just to people in the

tech center but to every aspect of community people in rural areas to people from marginalized groups to people who maybe haven't had the full benefit of current technology now. So

spreading that that benefit further. And then finally uh just making it really clear that uh we're also acting at every level whether it's businesses or whether it's government to keep citizens safe uh

in the process. Uh we've had a big conversation here at a model level about AI safety and and AI harms, but we've also got to have that conversation in the context of our communities and what

does it look like to keep um keep citizens uh safe there. So I think it's a whole of society leadership piece. It's not just saying well the tech people can look after this from a

technical perspective &gt;&gt; right and you know when you look at it at the enterprise level you know ecosystems of course are very very interdependent today you have cloud

providers you have the telecom networks you have enterprises there are decisions flowing across the distributed stack by the second. So it's really comfortable. Yes,

I want to build on what what you said here and the difference between where we are today and when we are introducing agents at scale and to me there isn't so much a question of who because if you

are replacing work with an agent that basically needs to translate into an accountability and and also a transparency trust and governance issue around those agents and increasingly we

will get the agents at different levels. Super advanced agents at the top and of course further down the stack we will get more um fine grained agents having less knowledge making decisions that are

guardrailed in a different way than the top model. So think of this as an hierarchy of decision making and and of course um accountability. But to me there's no question that if you are and

when you are introducing aentic technology you need to take the responsibility for your part. If the complete service consists of many different agents on the cloud side on

the advanced connectivity side on the application side device side it needs to come together but of course responsibility should reside in the domain that you have provided and that

you are providing to the market to the customer to the employees. Well, of course it's never as simple as that, but in in the world that I come from in telecom, we're already providing

critical infrastructure, people's everyday and life depended on it. So, we have already guard rails from a safety security perspective that we have to live up to in today's world of IG and

and telecom and that to me should carry over into the agentic world. I know there are of course discussions about um increasing governance, increasing regulation. I think that's a dangerous

way to go because if you regulate before you have innovated, you never know what you you will get. But I think if you stay with these basic principles that we do have requirements and and we have

guard rails in in the world we're coming from and you translate that more or less one to one into the identic world, I think we are in a good starting point. &gt;&gt; Right. Right. And the um you know we are

talking about uh the way you know ke and machine working hand in hand now as these identities shift how should we be rethinking governance how should we be rethinking trust and u of course

governance is never static it's going to go on evolving so what does dynamic oversight really look like especially in a very regulated industry like yours Look, I really love that question. Um

because at the end of the day, as a CTO in a bank, I am accountable. I am responsible uh for the platform that we construct and the output that gets generated from

that platform whether it's from a human or an agent. Right? So that's my accountability and this is where I have interesting debates and conversations with uh colleagues from WRO and other

partners of mine who want to very eager to sell me solutions and I said if the solution is a black box then I'm going to find it very difficult to integrate that into my environment because

ultimately I have to be able to explain the output that gets generated. So to your question in terms of that dynamic oversight um it again goes back to the platform

and the way we've architected the platform is on sort of you know without getting too technical is on two planes. There's an execution plane and a control plane right but again it's not that

sophisticated. Just like when you onboard a new graduate into your organization, you will give them a set of guardrails and a set of responsibility

that is befitting of their skill set and their experience. You provide the right level of supervision. You give them the right level of oversight and as they grow, become more proficient, you

clearly give them more responsibility. We treat agents in exactly the same way. So there's a lot of conversation about agents being autonomous and hallucinations.

Well, individuals can do the same thing if they're left to their own devices, right? So the way that we have built and architected our agentic architecture is that as Eric said, there are, you know,

different types of agents. At the lowest level, agents are not just autonomous, but they're atomic and with the right set of guard rails where it's agentic operating processes. Uh they are also

deterministic, right? And we basically create agents to perform a single task &gt;&gt; and we make them as reusable as possible to compose them and to aggregate them into a higher level of workflow. And as

you get more, as they learn more, which is the the good thing about agents, they learn faster, you give them more responsibility just like you do to humans. But again going back to you know

that execution plane where you are monitoring every activity that is being done through a control plane and also the other thing you know the other features of the platform include how we

sort of onboard offboard agents just like you do with humans. And we also have practices in place to manage the conflicts between agents and humans because again just like you have

conflicts um between two humans you have conflicts between an agent and a human right and you need to be able to detect that in real time right so that's where some of the kind of um you know work

that we've done and it's again early days I don't think we have all the answers but certainly the space is moving very fast the key is that we are humans are always have to be in control.

Right? So that with the way we've designed the architecture is to ensure that happens. &gt;&gt; Right? So are agents being put through um tough performance appraisals? Are

they being fired for hallucinating? &gt;&gt; 100%. Right? And again it may sound really basic but I view an agent no different to a human. Right? So you do performance management, you do there's a

concept that we call agent university, right? Um and I love that term because I was chatting earlier with James about this. At university, you're learning how to learn, right? So that's what we want

the agents to do as well. And um you know whilst humans may fill out a time sheet to account for the work that they've done and to measure the output that they've produced for the cost that

they've consumed whilst agents may not fill out a time sheet we're also monitoring and uh monitoring the agent for the work the tokens that they've consumed for the output that they've

generated to ensure that we measure um their performance in a similar way. Wonderful. Well, um, Harry, bringing you in as well. You know, uh, how should organizations measure the ROI? That's a

question that, you know, enterprises around the world have been debating. What's the value beyond the profit or beyond the bottom line? Are we looking at trust scores? Are we looking at

productivity? Are we looking at decision velocity, risk mitigation? At the pro, how are you looking at the ROI? probably one of the most debated topics and one of the topics that I hear most

of the time and I would probably provide you the vipro context in terms of how we are looking at uh productivity. Uh point number one uh while everybody talks about use cases and productivity

measurement of EI we think you know EI is beyond just measuring return on investments are measuring productivity it's almost like uh going back in time could you ask should we implement an

email system what's the ROI on the email system could you ask for example why should I go to the internet uh I have a brochure already in the company why should I be on the internet so a lot of

the thinking should change from looking at ROI to looking at yeah as a fundamental capability and a fundamental shift and a journey which is irreversible in terms of where we are

going. So it's not a question of should we invest because there's ROI or not. It's a question of we have to go down that path and we look at it as a capability. So within the pro we look at

as a capability. So we're not really asking this question of for every single use case is there a is there an ROI on it. Now having said that you know as a business leader ROI is extremely

important. &gt;&gt; Yeah. your clients must be demanding the ROI for sure. &gt;&gt; Yes, that that's that's equally true. So, uh the elements that we talk about

is the earliest signal of ROI is productivity, right? Uh we always talk about productivity as an early indicator of what come what can come down the pipe, but productivity is only an early

signal. The resulting benefit is basically always an end outcome. It can be cost, it can be units produced, it can be lower better quality, it can be cycle time reduction. It's many of those

things. And uh our goal has always been to move beyond productivity because productivity is a is a number that people talk about very frequently in AI but we are moving beyond productivity to

look at some of those end outcomes that we can achieve and uh our models are built to help clients understand the end benefit of EI rather than just looking at productivity as a element.

&gt;&gt; Trust scores are becoming equally important. I will just touch upon trust scores for a minute. uh when we look at trust course we're looking at uh you know how many instances of failure did

it happen and is that within the uh within the uh within the vector of what an organization says is acceptable or the process says is acceptable so it's important to measure quality aspects uh

failure aspects hallucination that we talked about all the other aspects of EI where it can go wrong and then measure what's the test score go and see whether it's whether it's appropriate for the

process that we're talking about so we had situations where uh we talked about probabilistic models excess deterministic models. We had customer cases where 100% was only answer or

99.99 was answer. There situations where 85 was a good enough answer. So again there's no one single answer to this. It depends on the kind of process the kind of problem that we're trying to solve.

&gt;&gt; Right. And do you think business innovation would perhaps be one of the biggest ROIs and uh any outstanding cases of business innovation that you've seen you know with AI being scaled

successfully yet? Yeah, that's a fantastic question and uh again let me give you one or two quick uh quick examples because you know that would bring this to life. One of the uh

project that we did for a client this is energy client and this is for a refinery and uh obviously you know everything was automated instrumented there are a lot of sensors along the way and they were

asking us what's the value of EI in this context. So the work that we did for them was basically analysis of a flame and uh you know interestingly out of the flame we could extract information about

combustion efficiency, fuel toear mixture ratio, maintenance of the equipment we could derive out of models that we built just looking at the flame. So the kind of information that we could

actually secure just looking at the flame was so much superior to using a sensor based technology because sensors typically tell you something is working or something is not working based on a

threshold. Here we could actually find out the health of what's happening with incremental change compared to looking at an or on and off kind of a situation with sensors.

&gt;&gt; Fantastic. Eric, you want to &gt;&gt; Yeah. Can I just add one thing? I think it's so interesting to look at how in our world we talk about this intelligent fabric of fiber 5G and of course there

are gains if you apply AI in terms of efficiency in terms of productivity you can get more customer experience and you can measure that in in a 10% 50% as a great achievement 20% saving we're

talking about billions of dollars there but where our customers get super excited is when they take an example from the complete network they use modeling on top of it and then they can

start to produce new outcomes is going to be business grows engine and of course it's not always that you can find that &gt;&gt; clear case but that's really where AI

and autonomous networks are helping saving yes TCO is important but it's very much about that business growth &gt;&gt; any example you can share with us there &gt;&gt; yeah I think so glasses was one example

here but in the future every device every application every AI service would need his own specific service quality, latency, all of that. So you can start to sell um services that are tailored

for mission critical for enterprises and that's what leading customers including here in India are doing. So they're using AI for that kind of segmentation and and growth of the business. It's an

upside that is unlimited. So of course much more exciting. &gt;&gt; Absolutely. Well um let's also look at the long-term competitiveness and value creation that we can achieve with AI. Uh

Paul, if we were to project 10 years ahead, what do you think would really separate AI native nations from AI dependent nations? Um, you know, is it infrastructure? Is it talent pipelines,

compute capacity? What would you add to that list? &gt;&gt; I would add capability, competence, and curiosity. I think a lot of the things you mentioned in terms of data centers

and things like that um they will be built uh there'll be investment but the the underlying models the compute that'll be commoditized and what will set countries apart is the ability of uh

government institutions to adapt the ability of the economy economy to be flexible to to new uh approaches and the ability of the workforce to to find uh the new jobs the new wants and needs

that are created. and where the bottleneck bottlenecks shift being able to move to those uh and I've got to say that coming to to India this week I see not just competence capability and

curiosity but just downright enthusiasm for this so I think maybe India is one to watch. &gt;&gt; Good to know that and happy to hear that of course. Well um Eric you know AI

demands massive compute, massive energy, massive connectivity. Now how do we really reconcile infrastructure scale AI expansion with sustainability? Uh you know isn't globally and of course ensure

that efficiency is imperative to everything that is deployed. &gt;&gt; Well uh AI is energy intense especially now in the training phase. I think some of the

the data that are out there it's I mean it's mindboggling numbers and I I'm not even sure we're going to need that kind of energy that is being projected. But what I was saying before is that we're

moving from that big data center training even to the distributed inference that's kind of where the is going and that means that you need to scale it to like 8 billion inference for

glasses tens of billions of sensors using AI or visual sensors. So what we are doing and and what needs to happen is to really have energy efficient hardware, energy efficient software,

energy efficient AI models, small models when you can do away with that and of course big models when we need that. So we're not going to explode energy consumption just because we use more AI.

In fact, we're going to use even smarter and better ways to do it both on the hardware and software side. Then just as a little bit of um sort of putting things in perspective

all the world's networks is around a percent of the total power bill or the power consumption &gt;&gt; and uh it actually by using more of the technology you are able to reduce

emissions in other sectors by as much as 15%. So it's kind of a 10 15 times payback on that uh energy consumption. And again, if you combine that with what I said about really being conscious

about energy &gt;&gt; efficiency as you move further out, I think it's actually going to be the sustainable way to do a lot of things, not just replacing unnecessary

traveling, logistics chains with more digital means. Everything is going to be more efficient by using it. So, I think we have to be a little bit careful before we say that it's just exploding

and it's completely outrageous because if you just project those big data center training clusters, it it looks scary. But that's not the whole picture. &gt;&gt; All right. Um well DH you know while we

are talking of value creation from AI you know of course many organizations still counting and measuring AI success and cost savings but u at your organization how are you really

refraraming AI value in banking? uh you know resilience, fraud protection, customer trust, capital efficiency. What are some of the metrics that you are tracking and really ensuring that this

is true value creation for us? &gt;&gt; Look, I I think it's uh it's a question that sort of is is constantly exercising our minds and you know if I start with the productivity question that you asked

earlier whilst there wasn't a straightforward answer I I kind of look at it on three levels. AI will provide microlevel productivity through you know co-pilot and and sort of um technologies

like that which might be difficult to measure but c certainly it's helping with the whole literacy and raising the overall level of education and awareness in the organization.

Um secondly there the at the enterprise level and this is your point on value creation we absolutely see the potential of AI to drive significant ROI when you take very complex

processes which have been uh which have been utilizing uh hivu technologies whether it's RPA OCR etc but when you apply high AI energetic you can actually take them to the next level and these

are extremely complex processes um which are errorprone and you you're talking about large sums of money and when we've applied AI energetic to them we've seen incredible outcomes um which

is which is sort of giving us tangible value creation and the third aspect I would look at is you know if if we really take a step back. Um, you know, certainly in banking, you know, if what

is our biggest source of competitive advantage, it's not necessarily the technology or the products um or any other capabilities, right? Because the next person can come along and emulate

those. It's really our ability to respond and react to change faster than our competitors. And that's what AI is going to help us do in terms of creating value because it allows us to respond to

change faster, do rapid experiments and u and to scale and to double down where we think that we will see uh a significant ROI. &gt;&gt; Right. Okay. So I have a question for

all of you and perhaps you can uh you know take about 30 seconds each to tell me do you believe today enterprises are overestimating or underestimating AI risk and uh you know how should

leaders and boards really measure AI trust readiness in practical terms. So you know maybe if you want to start on that one. See there is certainly a level of risk

that one should be aware of and uh work with with risk and again in every business there's always element of risk that one needs to mitigate. So AI is no different from that perspective but at

the same time the own hype about risk is also overstated. It's a manageable risk. It's not an uncontrolled unmanageable risk. It's a manageable risk and with the right kind of tool set that DH

talked about uh it's definitely possible to get the best value out of EI without actually exposing oneself to risk. &gt;&gt; Okay, that's a very diplomatic balanced answer that you give us. Uh Eric, what

do you think? &gt;&gt; Uh I suspect that uh it's become quite um realistic the risk assessment among enterprises not to overestimate it. Um they're manageable. I think maybe on the

government side there's still an overestimation on the risk side trying to sort of be too too cautious and and uh that I think could hold back in in certain public sectors and and in other

areas then the risks are very very big if you mistreat this extremely powerful technology. So I'm not saying that we're over the hump but that's what I think. Paul, uh, you want to you want to take

that on considering, uh, you know, Eric just said that perhaps the public sector overestimates risk. Would you say that for, you know, the government in Australia as well?

&gt;&gt; I mean, certainly governments have a responsibility to start off probably with a more cautious approach than uh than private sector uh, folk. I'd say there's a shift between the uncertainty

of something's new that isn't quantifiable to actually I understand the risk and then once you understand the risk you can manage it. So certainly uh over the last year or so uh and the

government of Australia has taken um uh uh much more sort of active posture towards AI where um embracing uh in a sense embracing that the risk um a little bit more than we were in the past

but it's as we grow the capability as we've got the foundation of trust the guardrails that we need it means you can actually manage that risk and that's that's the key thing.

&gt;&gt; All right the wish Um look with any so-called new technology there is always going to be a level of you know FUD fear uncertainty doubt but the kind of the the sort of

the paradox for me is that AI is actually not a new technology in fact it predates cloud mobile robotics um you know judging by the lack of you know I was

writing prologue programs that university. Um, but it was AI was just well ahead of its time. We needed the cloud to be able to um process large amounts of data. We needed the kind of

data centers that we're talking about for the compute uh etc to for this for this um technology to really come to light. And clearly as we've gone through digital um social uh uh cloud and data

along the way we've seen many many regulations around uh data protection uh how best to use cloud data sovereignty data residency etc. So as long as we are not sort of shedding

those controls that we've already built and making sure that we tighten the guardrails as we deploy AI and make it and deploy AI uh through a platformcentric approach where you've

built the necessary guardrails, I think that those risks will be managed and mitigated and hopefully what we will start to see is the benefits of this combined technology will far outweigh

the kind of risks and concerns that we're seeing. Um the only qualification I would make and I think that's been talked about um at this conference is making sure that we do take everyone

along on that journey with us um because that could be the risk. &gt;&gt; Absolutely. Um I mean it has to be inclusive for all especially in a country like India where you know we

have divides of many kind kinds. Well um let's spend a few minutes trying to look ahead and do some crystal ball gazing and um Eric if I can come to you you know we are entering the autonomous

networks embedded intelligence uh physical AI from robotics to many many systems now what does an AI native network then look like say 5 years from now because um anything more than five

is just too much to envision. And how do we get today's mobile and cloud infrastructure really ready for that future? &gt;&gt; Well, I think we have to look perhaps

further out in 5 years because we're building something that should work for society in in broad terms. But of course, AI is moving super fast. And when you ask about AI native, I think

that any industry, including the one I represent, is going through major change now. And AI native is not just how you build your products that they need to be datadriven. They need to learn. They

need to be updated all the time. Uh it's very much about your processes. It's about how you go to market with that. How you engage with life cycle management handling questions and think

we talked about it in the premeating as well. there's so many things that are changes in terms of how you build AI native systems that it is a fundamental rework for I would say most uh product

actually service companies as well. So so an AI native uh world is something that is very much more responsive to these fast changes that we talked about. An AI native network is a network that

is responsive to all of these needs. You already mentioned the physical AI which is just around the corner. humanoids, robots, drones, uh all the things that are requiring much more tailoring, much

more flexibility from that network or the intelligent fabric. So, we need to do what I called uh user experience at scale or massive user experience. Everything has to have its own and

unique uh requirements met. And I think only AI native networks that are responsive in in real time to these needs and adapt and create that best user experience uh can handle it. So

it's it's going to be a very different world, very intuitive judging but what what we see on the wearable side. U but that's going to be a completely new new setup.

&gt;&gt; Right. And um Paul, you know, as we looking ahead, of course, public private partnerships are going to be key to any kind of success that we're going to see. Uh tell us a little bit about AI collab

and your approach towards, you know, bringing together public institutions, academia, industry to really advance the practical adoption of AI while also keeping it very transparent and ensuring

that public good is at the center of it. &gt;&gt; Absolutely. So the AI collab is a cross- sector initiative where folk from the government, folk from the private sector, academics, not for profofits uh

can get together uh in one place and often in person to understand things. And I think everybody who's come to the AI impact summit really understands that we can't do this alone. Like nobody in

their silo can solve the problem themselves. We've got to get capability from each other. We've got to learn from each other. And I think the 300,000 people who have been here uh this week

have certainly proven that to be uh proven that to be the case. Um I think that it's also key to actually doing safe and responsible AI. It's not just the technical controls or or the

networks that we have. It's having the people who are going to be in the room who may not care about AI, but they do care about the services that are being delivered. They do care about their

voice being heard. they do care about the environment around them as well. So he keeps on bringing you back to reframing that what's the problem we're trying to solve? What's the mission that

we're trying to achieve? And I think if we want to talk about impact, that's that's the key question, &gt;&gt; right? All right. Uh well, let's also look at the financial angle with Dish.

Uh you know, you've talked about and open finance and you very effective maybe financial ecosystems. What is it really going to take to scale AI to that level especially in the near and short

term to enable a very responsible deployment and sustain finance with borders particularly in the Indian context given the the complex complexities that we see in this

country. So I think um it's going to be a force for good. Um if I if I look at banking I don't think the core of banking is going to change uh in the area of AI. However,

how we bank, how we drive that experience um for our customers is I think going to be transformationally different uh in the future. Uh just one example to to pick up on your question.

If you combine um the technology of AI together with say digital assets and stable coins um the ability to move money faster like emails, why is it that it takes 3 or 4 days today to clear a

crossber payment, right? Uh which goes completely against the whole concept of open finance and inclusion. Um so I think AI together with some of these other technologies is going to be uh a

gamecher in uh in enabling uh things like that and really driving experience um to be much more natural much more intuitive um than than it is today. Um personally as a as a CTO um you know

there is a lot of questions about are jobs going to go away etc. Um if you if you look at sort of uh in any organization certainly banks that I've worked in typically the um capex demand

on an annual basis um outstrip supply on a scale of a ratio of you know 5 to1 right but if AI can help us change those legacy systems modernize our platforms because let's put it let's be honest

right 90% of banks still operate with legacy technologies ies there's very few in the green field. All of those technologies need to be modernized, upgraded and I think AI again is going

to be a force for good there. And once we modernize those systems will again lend itself to connecting more seamlessly through microservices APIs you know um without getting into the

technical details uh through MCPs etc. So I think that um AI together with some of these other technologies, digital assets, quantum down the line uh I think will drive a very different paradigm in

terms of how finance works globally. Very exciting times ahead. If you were to give a CEO a three-step playbook today to really scale responsibly, what would that be?

&gt;&gt; Three things. Okay. uh number one be very clear about what you want to achieve with EI. So have the vision right have the uh have clear objectives in terms of what you want to achieve

with EI. That's that's the first part. The second part that I would call out is uh don't think about task and task automation. Think about what does EI do to your business and it's an operating

model shift fundamentally which can actually deliver value. So think big. Think about the operating model shift that will require structural changes, methods of working changes, skill

changes and uh you know uh it's it's a complete change. It's a complete transformation compared to just being an automation. And third thing you know please call me pro.

&gt;&gt; All right you all to now imagine that we are at the India AI impact summit 2030 just about 4 years ahead. What has changed today in the way we

live, work, and play? Uh that didn't happen perhaps at the time you were here last, which is today. What has changed? &gt;&gt; Uh Paul, do you want to start with that?

And you can go by with the imagination. &gt;&gt; Um yeah. Okay. Um, look, it's as an economist, uh, it's very hard to predict, uh, the future. Um, I think what has changed is there's

a whole bunch of people turning up with job titles that we've never even heard of before and, uh, they're telling us about things that, uh, um, uh, people in in a bureaucracy or the government can

sort of only dream about. So I I think we'll see a lot more diversity in um in what people do. &gt;&gt; All right. Lots of new jobs and yeah most industry reports suggest that many

of the new jobs of the next decade have not been invented yet. So uh absolutely dish &gt;&gt; well in uh in four years time uh we may not be here in person. and it'll be our

agents or our avatars that are being kind of uh you know teleported in um because the technology through Ericson's amazing network has the kind of bandwidth and the and the latency is

improved vastly and obviously with group's technology around creating these avatars and these agents. Um anyway um but no I think to be serious I think what will have changed at least from my

perspective is banking will be a lot more seamless. It will really be about putting the customers first rather than sort of imposing friction that we see today in terms of how financial services

works. You know for instance we will be shopping you know much more intuitively. We won't even know that we need to get a new fridge or a new car. you know, it will kind of just occur to us naturally

and, you know, something will appear on your doorstep that you didn't even know you needed, but once it arrives, you think, "Wow, that's exactly what I needed." The payments taken care of. Um,

you know, all the servicing is taken care of. Um, so I think that that could that is a near-term reality. &gt;&gt; All right, Eric. Um, Har, go ahead. &gt;&gt; Yeah.

&gt;&gt; Couple of things. One is I'll definitely break my glasses and use Eric's Eric's classes. uh more importantly uh what I think will fundamentally change is the decision

velocity in &gt;&gt; good uh most importantly I think the decision velocity in organization will completely change in in the next four years one of the key things that we

always talk in any enterprise is our organization is so slow the processes take a lot of time it does not happen at the pace that we all want it to be and the experience that one gets out of it a

slow process is not necessarily a a great experience process the fundamental problem that EI will solve and I'm pretty sure it will solve in the next couple of years is the velocity of

everything will increase so tremendously that we'll look back and say how did we ever tolerate something that was as slow as what it is today. Mhm. &gt;&gt; Eric.

&gt;&gt; Yeah. I I wonder if it's doable in four year on on a global scale. But I I I what we see four years from now is that we have this dissemination, we have diffusion, we have everyone being

included in this fantastic journey that AI really really is about. Uh but I think it it hinges on this dialogue that we have here and it hinges it's it's conditional on the fact that we solve

the trust issues. Because these things with security, privacy, we talk about them as things we can solve technically and so forth. But that needs to have fundamental anchoring

in how humans behave so that you can really trust these agents as was mentioned before and that we put the right constraints on. If that happens, of course, four years from now, it's

going to be so seamless where we have our digital colleagues or AI colleagues, AI physical AI colleagues and so of course that is going to be a completely different way of looking at work and of

course um how you get help outsource things. I mean you're going to be an agent of something which is much much bigger than what you're commanding today. I think it's an enormous shift.

&gt;&gt; Absolutely. Well, fascinating times ahead. Uh, thank you gentlemen for your very very incredible insights. That was very very educational and informational for all of us. Uh, the the takeaway for

me I think from this conversation is clear that if people, planet, progress remain our guiding sutras and if we can align all the seven pillars of global cooperation, AI is not going to just

optimize businesses. It is going to redefine competitiveness. It is going to rebuild public trust and of course uh hopefully it will futureproof all our institutions for the decades ahead.

Thank you very much. Appreciate you all taking the time here and thank you all such a wonderful audience. Fantastic. Thank you. &gt;&gt; No, again.

&gt;&gt; Thank you. Thank you. &gt;&gt; Thank you so much. Okay.
