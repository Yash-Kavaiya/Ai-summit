# AI Compute beyond GPUs

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 8 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/Kqn2qNBKq2I?feature=share) |

## üé§ Speakers

- Abhishek Biswal, Airtel - Xtelify
- Becky Fraser, Qualcomm
- Bhawna Agarwal, Hewlett Packard Enterprise, India
- Jason Oxman, Information Technology Industry Council
- Navin Bishnoi, Marvell
- Navin Bishnoi, Marvell
- Sujith Babu, Ciena
- Wilson White, Google
- Wilson White, Google

## ü§ù Knowledge Partners

- Koan Advisory Group

## üìù Summary

This session explores the critical infrastructure powering inclusive AI ecosystems. It will examine compute networking, power, systems design and skills as enablers of innovation and economic growth. Participants will identify infrastructure bottlenecks, discuss pathways to democratize access to hardware and R&D and connect distributed, energy-efficient infrastructure to resilience. Through examples of open innovation and public‚Äìprivate collaboration, the session will generate actionable insights for policymakers and ecosystem builders seeking scalable, equitable AI infrastructure across regions globally.

## üîë Key Takeaways

1. This session explores the critical infrastructure powering inclusive AI ecosystems.
2. It will examine compute networking, power, systems design and skills as enablers of innovation and economic growth.
3. Participants will identify infrastructure bottlenecks, discuss pathways to democratize access to hardware and R&D and connect distributed, energy-efficient infrastructure to resilience.
4. Through examples of open innovation and public‚Äìprivate collaboration, the session will generate actionable insights for policymakers and ecosystem builders seeking scalable, equitable AI infrastructure across regions globally.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/Kqn2qNBKq2I/maxresdefault.jpg)](https://youtube.com/live/Kqn2qNBKq2I?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Oh, speech speech. Hello everybody. Thank you for uh being here. Exciting uh days um since yesterday we've had at the mandapam. Uh

so thank you very much firstly for your resilience uh and for showing up for this very very interesting discussion. We have a lot of wealth of uh experiences

uh and expertise on this panel. So I'm not going to do a long- winded opener just to say that obviously we're here to talk about AI compute beyond GPUs. I want all of us to be deliberate about

this theme and this framing. Uh because all the other sessions will be about AI compute with GPUs. So let us uh think of this as a vin diagram. Uh AI can still exist uh in this part of our diagram and

that's what we're going to uh try to delve into. uh it is an aspect of AI that in the frenetic pace of development of large language models and AI uh for retail in general over the last couple

of years I think some of us have forgotten about. Uh so this is also an attempt to revisit the fundamentals of how compute infrastructure is built from the ground up. So thank you very much to

all the panelists for being here especially guests from outside. I want to start off uh Jason with you. You are the CEO of uh the information technology industry council which is a global uh

tech advocacy body headquartered out of uh uh Washington but also with offices in New Delhi. Very happy that you've made it in one piece. uh can you give us like a 50,000 60,000 ft view uh on where

you think we're headed with um the conversations around AI hardware. Uh when we think about the nature of globalization today, we're seeing a lot of reassuring uh of supply chains. We're

seeing strained supply chains. We're seeing sudden disruptions. We're seeing dependencies. Tell us uh how to deconstruct this in one minute.

&gt;&gt; Oh, great. One minute. Okay, I got it. Well, first of all, thank you for all the work that you do at Cone Advisory to uh be a thought leader in these issues. Really, really important. And uh thanks

to all my fellow panelists and all of you for being here. So, the one minute version is this. It's all down to trust. We have to trust in the ecosystem, the tech stack, if you will, in order to

make sure that we're getting the products and services that we want and they're doing the things that we want them to do. And I think as as Van mentioned there's a tendency to think

about uh the consumer applications of AI and if you trust the service you're using the AI large language model the software it's okay but there's an entire ecosystem behind it from the data center

that houses the servers from the connections and the chips that are in those data centers to the uh the application layer to the infrastructure it all has to be part of trust and I

think the most important thing for us to focus on as part of that trust is trust. Trust crosses borders. Data crosses borders. Large technology companies and small customers alike need to access the

world. Most of the world's consumers don't live inside India. It's a big country, but there's a big world out there and businesses want to be able to access it. So in order for government to

have trust, we also need to have trust in the private sector. We need to work collaboratively and we need to remember that these networks are global. So we need to take an international approach

which is why it's so exciting that the AI impact summit is here in India this year to make sure that India can help lead the world in building that trust. &gt;&gt; Thanks Jason. We'll come back to this

theme. Uh there's many um aspects of what you've said that I'd like to go deeper into. Uh but without further ado, can I turn now to Bhavna Agarwal who's um the SVB SVP and MD for Huelet Packard

Enterprises um which makes servers and various kinds of uh connectivity equipment has a large workforce in India as we were discussing today some 20,000 people um so Bhavna I

want to ask you uh straight into the depth of this topic of what AI native architecture today really means. what it looks like and what part you have to play in this.

&gt;&gt; So you know when you uh look at it overall uh in every conversation usually when we talk about AI uh it starts with GPUs uh and it also usually ends with GPUs but AI in reality is actually a lot

more uh than GPUs. It's actually a system. Uh it runs on a system you know when whether you talk about you know Jason was also saying it's it's about network data security it's about

software it's about you know the compute it and even if one part fails or gets weak the whole system slows down. So when you look at the AI as a journey in its whole right that's the way it should

be and not just one of the component and if I were to further simplify this uh let let me draw a parallel right from a AI native uh architecture perspective let's say you know there is a large city

uh and you have a tall building uh which is GPU right then you also need uh data which is the road you also need transport which is your network connectivity you also need uh the

planning which is the real architecture that you know how it'll really flow. So for you to have a successful city right thriving city you just don't need tall buildings you also need an efficient

city planning and that's what you know the role of an AI native architecture or the right good city planning is because overall if you were to look at it AI has different needs you know right from

inferencing to fine-tuning to training everything and because of different needs uh it it needs to sit in different environments and that's Why traditionally you know we have seen that

a lot of times you have traditional IT systems and people try to forcefit and they put AI on top of it but more and more industry folks are now gravitating towards building or designing

infrastructure that is AI native so that it is able you're able to run faster you're able to scale uh modularly and you're able to deploy a lot faster so industry is moving in that direction and

you know happy to go deeper into it during the conversation &gt;&gt; there's an aspect of city planning as you mentioned which is also uh which relates to design uh and Naven not to

pigeon pigeon hole you into the design part of the very long spectrum of things that we have to cover but Marvel technologies of which you're a country head um is a design-led semiconductor

firm uh so can you tell us a little bit about what you do and how you contribute to this discussion through your design chops &gt;&gt; sure thank you everyone uh so if you

like we have started looking at from the tops down but maybe let's go bottoms up right and then we thought the AI mean a compute right so compute is one important part of it but along with

compute you need the whole network because we're talking about connecting a millions of them together to be able to train or infer and and then then we also need a lot of memory and other elements

to ensure that we can do the data access fast and and then transport it across the network within the data center or data center to data center so building up Foundationally what we see is that

the compute is growing significantly and it's not just the GPU there are a lot of accelerators that needs to come up that the the security accelerators the crypto accelerators there are co-processors

that needs to come in there are smart nicks and others that needs to come in into a cluster that we form and then imagine connecting them within the shelf shelf to shelf and toileis and all of

that and that's where you get to see the interconnects which was probably significantly copper interconnect but it started moving into the optical which has come all the way from data center

data center to inside the data center right close to where your server is to ensure that your data can move faster in both the training and the inference model right and and then that's what we

are seeing is that the networking and memory are the walls which is limiting your compute efficiency to be somewhere less than 50% and and then that's where my analogy for what Babna said was that

we probably I come from Bangalore Compute is your Ferrari on Bangalore road and if the traffic blocks it that's not the best efficiency of the compute. &gt;&gt; Thanks Naveen for laying that out. We'll

unpack some of that. It sounds like almost like the uh early days of uh thermal powered PL power plants uh where we're far away from like the ultra super critical kind of efficiencies. Um we'll

come back to you u that I want to now shift tracks for a minute. Uh you've got a little bit of a view just a little bit on centralized compute. Uh let's switch tracks to decentralized compute and I

want to bring in Wilson here. Uh Wilson White um is uh at Google uh looks at policy around the Asia-Pacific. Um you know part of what you do Wilson is also to look at the pixel side of the story.

uh and last mile devices obviously play a significant role in how we think about AI um diffusion uh and particularly in a developing country context. So over to you Wilson to paint us a story about uh

edge AI u the kinds of characteristics of uh edge AI that uh you bring to the table and why it's necessary in a global south framing. &gt;&gt; All right. Thank you Vivven and thanks

uh to Cone Academy for giving us an opportunity to uh spend time with you. Uh, I have a birthday this week. So, thank you all for coming out to celebrate my uh uh my birthday. It's uh

it's great to see everyone. Uh thank you. Thank you very much. Uh &gt;&gt; Jason, you got a garland. [laughter] &gt;&gt; [applause] &gt;&gt; But seriously, at at at Google uh and I

think Jason, Bara, and and Nitton uh hit on this like we are engaging at the full stack of this. And I love the fact that in this conversation, we're going beyond just TPUs because uh as you said,

Vivven, it's TPUs, it's the data centers, it's subc cables and connectivity, it's also energy, it's the platforms, it's applications that are running on this. Um but what's true in

today's terms is that most people and particularly if you think about the global south context or uh in developing markets most people are interacting with AI through devices. Uh and I know many

of you I've seen some uh pixel devices in the audience. Thank you. Other Android devices thank you for those of you who haven't converted yet there. Um uh but that's how most people

are experiencing AI is on devices. And so we're also investing in that space and we're thinking about compute both in big ways and small ways. Like for example in India last fall we announced

um a $15 billion investment in India's first AI hub in Visac uh which has a gigawatt uh data center. It also includes subc cable connectivity uh new renewable sources of of of energy. Uh

and that's infra in a big way. That's compute in a big way. Uh but we're also going small. Uh and one of the things that we are are are doing is getting uh devices to have access to these large

language models on device. Uh so one of our new services is called Android AI core and it actually gives users of Android devices uh access to uh uh Gemini Nano which is uh the smallest uh

version of our Gemini models on device. Uh and this actually creates some very useful experiences for users right on their device. um privacy by by design. So you don't have your data leaving the

device to go to the cloud. You're actually are able to do things like uh have uh scam calls uh screened right on the device uh to be able to interact with uh users as you are responding to

messages uh in an end toend encrypted way because nothing is leaving the device itself. So we're thinking about how to ensure that all users can access the benefits of AI even on their

devices. &gt;&gt; Thank you Wilson. Um &gt;&gt; again, happy birthday. Yes. Uh [laughter] we'll we'll build on from here with this

theme on AJI. Uh with Becky Frasier from Qualcomm. Uh Becky, thank you for making your way to New Delhi. Uh you've been here before. Uh and so I hope you have a good rest of your trip here. But just to

build on the uh thematic area that Wilson touched on, what does Qualcomm do at the edge? What is hybrid AI in your lexicon? Uh and what are the kinds of use cases that you're starting to see

come online in the global south? All in a minute or two, please. &gt;&gt; Well, thank you all for being here and uh thank you again for hosting this panel and I love that I get to follow

Wilson from Google talking about a very similar topic. It's wonderful to see the synergy from a Qualcomm perspective. We think about the AI stack very expansively from hardware to software,

data center to cloud, large LLMs to small language models and increasingly ondevice processing. And when I say that, I'm talking about devices at the edge of the telecommunications network

that are AI enabled. So this is in your phone, in your car. Uh smart glasses increasingly across the factory floor and robotics. This is offering a capability. Hybrid AI is spanning from

the data center to devices at the edge of the network. There's a number of benefits for edge AI in multiple markets, but as we focus on the global south, this really is an opportunity to

have near instantaneous response, to have again privacy. building on some of the comments from earlier, but it's also an opportunity um to have uh connectivity or or AI capability when

connectivity is existent or weak because when you have the AI capability on the device, you can continue to run AI. One of the uh demos I encourage everybody to come see in the Qualcomm booth is Roxa

Health. This is an Indian startup that developed an app where doctors can run uh healthcare analytics uh notetaking in a medical context by voice all on device. So they can take this phone that

has connectivity or without AI enabled into rural clinics and they can have a number of uh the benefits of AI in health care right in the palm of their hand. And again, that's an India based

startup that we're showcasing over in our booth and we have a number of examples of that where edge AI is bringing an entire new opportunity to innovate.

&gt;&gt; Thank you, Becky. Um, so much exciting stuff going on. Yes, please do visit all the pavilions. I know PM Modi visited the Google one yesterday. Uh, but all the others also deserve a visit from all

of you. Uh, over to Sujit. Sujit, uh, let's again switch tracks. uh you look at software uh as a vertical within Sienna which is a telecom equipment and connectivity company um I think all

hardware companies are becoming platform companies in some sense you have to build different parts of the uh of the value chain now uh but as far as network automation and the role of software is

concerned Sujit can you dwell on that for a minute for all of us uh in terms of its importance in AI compute check. Yeah. Um just before I start u thank you so much for the opportunity

but um just want to take a step back before your question. Have you all looked at the word India? How many letters? Six. Just look at the last two letters AI I A. Have you all

thought about it? So basically it's a cliche where AI was always in India some time back. Okay, with that start uh let me tell you what's happening on the connectivity world. We can have compute,

we can have memory, we can have with all our colleagues who are sitting on this panel, but I guess the highway is what fiber connectivity comes through and that's what uh one of the things that

Sienna does. You would have heard of u why these data centers are getting set up in India uh apart from a lot of u I would say cost pressures and other things but it's about getting AI to the

edge. Now when you have to get AI to the edge what you need is a nanom millisecond of availability before it touches you. So a simple example is let's say you're looking at Instagram.

So somebody um in Rishi wants to look at Instagram do you think if it goes if there is a turn on your screen will you like it? No. Right. So I guess if you were to get that the telecommunication

industry needs to get fiber there. So one of the things that has happened is what is called as a new ad invention of holocore fiber that has really come which brings down the connectivity

speeds by over 35%. Now now the point of what asked me about software is how does software bind all the elements of compute uh the availability the applications and all of that. So one of

the things that uh I take as an example is u about the oss which is operational support systems where you're able to bind all of this together by way of getting all of this together federate

data and give you an absolute good experience. So that's one of the things that it does and automation is super important in thish conversation. uh any stack which brings uh near availability

or an um I would say an availability of close to 100% is what is looked at. So that's one thing that's very very important in this uh journey of AI. &gt;&gt; Thanks Sujit. It's not just all us

workers who have to be always on these days. Uh the networks of course have their load to carry. Uh and thank you for doing the work that you do. Can I turn it over to now Abhishek Bisval who

is the chief business officer for digital services at AEL XTELI if that's the right way to pronounce it. Um Abhishek uh just building on what Sujit said in

terms of the orchestration of AI workloads a lot is now falling on the on the question of connectivity and uh the providers of connectivity services whether it's between data centers uh as

was mentioned or from the data center to the last mile u how is air thinking about these things as a legacy network business which is uh obviously expanding out into the world of AI

&gt;&gt; I think as um as my colleagues mentioned right we talked about two words we talked about always on and we talked about reliability across uh across the board I think uh telos around the world

not just in India have to stop being passive carriers which we've been for a very long time to being the way to program your digital infrastructure I think we have to make

that make that shift right and and there are three layers that u at least for us uh we consider uh something that we should be investing in. The first one is connectivity should be intelligent.

Today you have various types of access. You have fiber, you have copper in some places you have 5G. U I think we need to have deterministic latency. Today it's best case basis,

right? How do we become deterministic at the latency that we we provide? &gt;&gt; What does that mean? Can you unpack that? &gt;&gt; Today you expect a particular speed to

reach you, right? Can you demand a particular speed? Can the carrier give you that offering so that you can shift between the kind of speed, the kind of latency that you want, right? Eventually

it's physics. But softwaredefined networks can give the strength back to the consumer or to the user. Right? So how do you make that make that shift? How do you guarantee quality of service?

So I think that's that's the first layer a telecom network should embibe saying how do we give that strength back to our users right the second my colleagues talked about is edge how do we invest

more in the edge so that better compute can be closer to the to the customer right it could be as close as the device or it could be as close to the edge location where you can invest

&gt;&gt; CDNs and so &gt;&gt; a little more in right &gt;&gt; okay &gt;&gt; finally I think sovereignty is super important

&gt;&gt; right there are workloads that are going to be hosting public information public infrastructure right so &gt;&gt; I think it means we need to be able to

provide something which is secure compliant as well as resilient so that's those are three words that that we think we should solve for

&gt;&gt; thank you and thank you again to all the panelists for being so uh tight with their remarks uh and I hope we maintain this uh cadence uh can I turn it over to you Jason because of the word

sovereignity. Uh you know it's a lot to unpack in itself. Uh various clusters of countries are looking at sovereignity in their own ways just as they are trust. Uh what is the way to build sovereignity

and trust into the technology capabilities uh that we have around AI? &gt;&gt; Yeah, it's a great question because the some people think and there's it makes sense that sovereignty means

independence. means you close your borders around a particular product or service. But that's the opposite of what we need. So I think the most important thing to look at and this is a great

place to look at it is how international standards voluntary industrybuilt consensusbased standards for interoperability for security for safety for trust can work. It's very important

to build data centers in India to ensure that data can flow to India. But it's also important that that data reach the rest of the world and there are standards for that. In the physical

world, standards work very well. We're all familiar with them. As Wilson mentioned, everybody here has a phone, hopefully an Android phone, right? But there are other products and services

out there. If you don't, &gt;&gt; for some reason want an Android phone. But but everybody but everybody has at the bottom of their phone, they have a charging port. And that charging port,

probably USB of some kind, B or C. Doesn't matter what brand of phone you have. The charging port works. You can buy an independent charger. Those are global standards. They're technical

standards. Here in India, BIS, the standard setting body, has published over 25,000 standards, but they're not all recognized internationally. Equipment manufacturers like Sienna that

make things in India, there are India specific standards you have to abide by. That means you can't necessarily sell that product to the rest of the world. So that's what I would say. Sovereignty

is very important meaning that countries have to look out for their c for their constituents, their citizens, their consumers and protect them. But we really should look to global standards

particularly around AI to make sure we can access innovations from around the world. &gt;&gt; Thanks Jason and also thanks for the shout out to BIS. BIS by the way is

doing some work in AI. They have been part of the international standard standard setting operations at the ISO around AI. We've proposed five AI standards um via the BIS to the ISO. Uh

so so it is a a work in progress. Um and Bhavna just turning over to you taking this thread of standards a little far uh into the world of sustainability which is also an area which is being

increasingly defined by standards whether they're compliance standards or beyond just the checkbox compliance thinking thinking about ecosystems uh and how do we make sure that not uh

they're not just resilient they're also sort of sustainable um and there is no push back from society uh at some stage earn AI diffusion because of uh the kind of loads that are being put on our grids

and so on and so forth. &gt;&gt; I think uh sustainability is extremely important because as I earlier said that you know a lot of times people equate AI with power and performance. uh but

sustainability is extremely important because energy efficiency and environmental impact is as important as [clears throat] getting the right power and performance uh from your entire AI

setup and that's why you know when we are looking at it overall uh a lot of organizations industries governments are being a lot more conscious about the overall impact uh it is having because

when you're really designing something from day zero uh we are now increasing increasingly seeing a lot of players are now building sustainability not as an afterthought but from day zero uh as

part of the design because when you do that you're able to run a lot faster without giving up control because later you end up having a lot of band-aid kind of an approach where uh you know because

we need to do it either when the governments are asking for it or you think that this is the right thing to do and and that's why from a technology perspective for example at HPE we've

been doing it for almost 10 years we have over 300 patents uh in liquid cooling alone because we realize that you know more and more especially in when you look at uh high density compute

uh when you look at high performance computing you especially AI is very compute intensive very performance power intensive and more you scale uh you require a lot more energy and that's why

we came up with liquid cooling which a lot of people are now gravitating towards or even for that matter hybrid which is in a way a fanless uh you know liquid cooling because

you're able to get a much better power output performance without having a much larger energy footprint and when you're able to do that you you know that you are scaling up responsibly. So that's

something we do see happening a lot more often. But regardless of you know whatever whether organizations are moving towards hybrid liquid cooling or whatever it is sustainability must be

there as you know as as a principle on day zero right and not as an afterthought because that's where we you know no point doing it just as a tikma but for the right reasons. So, Sujit,

can I actually take this thread to you and break the uh organic flow we've had so far um because I know you care about um efficiency uh and software has a big role to play there. So, can you build on

what Bhavna said uh of course there's liquid cooling and all of these technologies in the data centers uh but again uh efficiency from the point of view of getting that data from point A

to point B uh and thinking about the power needs of your connectivity infrastructure. How do you think about optimizing that without overengineering? &gt;&gt; Yeah, I think uh

&gt;&gt; uh with your mic. Thank you. &gt;&gt; It just goes without mic always. Um data centers in India some stats for all of you. U if you saw 6 months back the predict was we would do about a gigawatt

of data centers. That's the that's the capacity everybody were thinking. But I guess uh everything shifted with the push and intensity from India perspective. of we were to end 2030 by

about 3 GW but guess what I think by 203032 I think we're going to be over a 6 1/2 to 7 GW of power which means India would stand at the top five from a data center capacity build now when you build

data centers and then efficiency comes into a big conversation uh one of the key reasons is about how do you manage power how do you manage efficiency how do you manage uh I would say the lowest

footprints because uh building an data center which have which which uses different kinds of power efficiency is super important. Now as you get into the data center I mean from an efficiency

standpoint there could be three things that somebody can think about. One is called scale out. When you talk about scale out as a technology, you could think of something like this where a

typical captive data center looks at consuming a certain X power. Let's say you started build a certain kind of technology around solutions like decoms that are that are available in the

market today. The power utilization and efficiency can drop to as big as about 70%. So that's that's one thing which is coming out very very clearly by a number of organizations. The faster you

gravitate into it, the better data centers that you build. Uh the second data point is about a scale up. How do you scale interconnects? Uh we were talking about I mean it's all about

capacities. Uh you were talking about 100g, you're talking about 200g. I think we've got into a scale of plugs going into about 800g to 1.6. So which means to say that your ability to either

inference or train your models are going to be much much easier and sustainable. Now thinking of data centers which uses obviously what Babna alluded to the liquid cooling technology would is very

very important and using scale scale out and scale up is also very very important. uh as we start thinking about these you drive down the power efficiencies in a big way and uh that's

very very important uh building uh green data centers including um uh nuclear as a technology that you can use here. &gt;&gt; Thank you. We at some stage we definitely need an intersectional

discussion between the energy guys and the infrastructure guys. Um but over to you Naveen. Uh a lot of this is very hard work which requires specialized skills. Um and you know just thinking of

something as basic as system architecture uh I don't know how many system architects we have in India that are fully capable to respond to the needs of India. Uh so it's a big area

for skill mobilization and upskilling and so on and so forth. How do you as a company which is obsessed with uh you know high high value skills uh dealing with these kinds of questions in India?

&gt;&gt; Sure. uh I think there are two uh part to again the skills part right means when we just look at AI and then a lot of people say it's artificial intelligence I say it's an advanced

intelligence it comes from five different factors you're bringing in the law of physics to get the latest and greatest what we call as a transistors and everything else so you need those uh

you bring in the latest and greatest tools because we are talking about 200 billion transistors going towards 500 billion transistors on a chip will be 1 trillion by 2030 on the latest compute

that we'll have right uh add to that we need the advanced packaging because you're hitting saying how much cores can you put in a in a in a compute and hence can you separate the memory and the IO

from this and then package it all together combine it with advanced architecture the reason I bring it because the use case is very different what we call as a workload they're very

different use case and it all does not need the same compute and and then the attached fabrics to it and and then then put all of this together in an advanced manufacture mfacturing and the design

architecture skill, right? So, so you have skills that goes from what we call as the physics and the chemical, metal energy, mechanical, thermal all the way to the electrical, computer architecture

and then to a system thinking and the reason system thinking also comes in because we're talking about now the scalability and the economics part of it, right? Can you scale which means can

you serve different workloads and hence can you create the custom silicon elements to ensure we support it? Not one can solve it and by way of custom you can optimize the power and

performance rather than just live with the same power performance curve that you will get from a traditional GPU, TPU, NPU and all other processing units that you have. So there's a custom

element to get the scalable and then when the economics comes that's where we talk about the system integration part of it because you're integrating the compute the fabrics the interconnect the

memory and all of that to be able to say that something can be fit in serves the economics and can be scaled to the million and billions of users. So so it's all about building the foundational

skills of science and solving the problem but also looking at the system and being able to integrate so that we can get the best out of all of that. So Naven, it sounds like we shouldn't be as

worried about the employment questions as we are today if we double down on the real skills that are required to uh harness the potential of this technology. Well, that's a

debate for another day. Part of this however Wilson on the softer side uh not on system architecture but you know none of this matters if there are going to be no apps uh no users to experience the

experiences the wonderful experiences that AI brings online. uh and so uh part of this is also it's incumbent on us to think about what are the kinds of uh developmental activities that are

required to actually bring AI into our everyday lives. Uh obviously Google as a platform has enabled that through the app store for years. Uh but how are you thinking now about the next decade of

app development to boot? &gt;&gt; Yep. Thanks for the question and I I'll start by starting where Jason started uh our conversation on on trust, right? It's um as we think about developing and

deploying this technology, trust has to be at the at the the core foundation of that otherwise this huge demand that we're seeing for AI applications won't exist, right? So people must trust the

systems in order to want uh to use them. Um I like what Naveen said around like this the skills that we that we have to have. One of the things that we're thinking about at Google is the fact

that we yes, we're going to need semiconductor engineers. We're going to need folks who are doing the hard hardcore skilling, but we're also going to need doctors and lawyers uh and and

uh plumbers uh and farmers. We're going to need all of these jobs. And so, we need people to be um able to exist in an AI powered economy. uh one of the areas where we're seeing that play out I think

in the mobile space and and devices is with app developers. Those are the folks who are building experiences that people are using uh and um one of the things that we're trying to do to help

developers do that and kind of come up the curve in terms of AI is making AI uh more accessible. Uh so we have a uh in Android Studio which is our developer uh uh uh suite for developers who are uh

developing uh Android apps. Um we have a new uh uh software suite that we called agentic mode uh in Android Studio and this is allowing developers to just describe um a feature that they want to

be able to build uh and the AI technology is then turning that uh description into code uh and getting applications out to users much faster. That's one way that we're trying to to

tackle this. But I'll just say one of the things that we're working with the government of India on is not just help helping upskill the population on AI but also thinking about how we um reimagine

education altogether. Um because the way we approach educating our young people to be ready for an AI powered economy is going to be very different from how uh we all grew up uh in the education

system. That's an area where it's going to take an all of society approach to do that. Um and we're very committed to doing that here in India. &gt;&gt; Thanks Wilson. Uh you know I may become

an app developer. You make it sound so easy this whole vibe coding thing you know I can get on board but uh Becky can can I turn to you uh just to expand that use case part of uh the discussion. uh

you mentioned Raxa Health and your demo outside but are there other interesting use cases um too that you'd like us to know about and also since Wilson brought the government of India into uh into our

frame uh are there some policy frameworks and I'd encourage the other panelists also to reflect on this that you think have worked in other global south contexts or any you know context

that you think uh we can adapt to here to promote edge AI hybrid AI efficient AI I whatever you want to call it inclusive AI. &gt;&gt; So from a Qualcomm perspective as we

look at the next phase of AI and understanding really moving the compute capabilities to where data and people are using devices and where the data is housed which is at the edge of the

network. So when we look at use cases across the global south and India, there's a lot that's emerging in terms of agriculture where we're seeing some robotics having the ability to test for

um insects on certain crops. We're obviously all familiar with drones using uh positioning in order to detect for drought or circumstances on certain crops or for uh watering. Again, the

healthc care space is a really exciting um incubator of new ideas. Roxa Health being one, but there's several others. Another great Indian example is um uh I think it's um site signal um He hears

sight. Thank you. Hear sight where um a uh a gentleman in Mumbai lost his sight at a young age and he's developed technology on glasses that is delivering a message as to what the glasses are

seeing into his ears so that he has an entirely new expansive range of mobility. So again, I could natter on about use cases. There's a lot that's exciting. One of the things that we're

doing in this space is the Qualcomm AI hub, which is where we're bringing different large language models and small language models together with virtual versions of devices,

um, phones, cars, computers, so that the app developer community can go to the Qualcomm AI hub and they can virtually run their edge AI app on a virtual device using different language models.

of their choice. So from a policy perspective, we very much want to see the encouragement great work of nurturing the startups, continuing the academic collaborations. Um we

personally like the Vietnam examples where they have a number of policy milestones that they're working toward four IoT connections per citizen by 2030. Um they also have a really

ambitious smartphone um milestone marker. Um I live in Singapore and I'm always impressed with the sea lion and merion um goals that that government has. So I think it's a combination of

setting some market signals from governments that they want to see edge AI. They want to see more use cases and deployments in their market so that all of our companies get organized to

deliver that. And then obviously again the innovation policies that we're all familiar with continue to be really important. &gt;&gt; So you've you've touched on something

very important which is why I want to turn it back to Wilson for just 10 seconds. Wilson uh we we haven't through this discussion talked too much about privacy sensitivity

uh of data uh and and obviously if you're processing this stuff at the last mile hopefully you're building some guardrails. Uh would you like to spend 10 seconds on that before we move on? uh

giving me a microphone for 10 seconds is almost impossible uh on on the on on this topic, but I I will say yes, for us privacy by design is is is how we're thinking about this. And we have a great

partnership with uh Becky and the folks over at Qualcomm who are our partners in ensuring that as we think about on device, we're building privacy as part of that uh part of our thinking from the

design uh from the design standpoint. &gt;&gt; Thank you. Uh glad to know there's some work being done on this. Uh Abhishek um we're switching tracks again uh and this time it's on the economics of

making all of this stuff work. Uh you know telos historically been obsessed with quarteronquarter our poos and obviously AI uh represents an opportunity in terms of uh continuing to

work on that um adding more value uh for your customers. But AI is also super expensive to deploy at scale and it costs money to get networks ready. Uh again it's like the energy analog of

having first generation network infrastructure and suddenly you need to make a smart grid and you have all these renewables you've installed but somehow they don't you know it's hard to

orchestrate this whole thing and offload that new energy into the grid without causing collapse. How do you think about the economics of this business going forward?

So I think uh &gt;&gt; and you are the chief business officer. So I know you're thinking about this. &gt;&gt; See we've uh and Airel or any telco is always will always operate at the

intersection of cost and scale. So heavy capex cycles are not new. I mean we we've seen waves of of capex cycles in telecom and uh and every time you start you look at hardware being

expensive, right? It's it's a hit that you take but if it's sustainable in terms of business impact it comes back right so the way that we see this is hardware costs can fluctuate they can go

up they can go down it could be super expensive today it may not be as expensive tomorrow the way you architect the use of this hardware is what drives sustainability

and investing based on a currency and that currency could be customer experience, it could be ROI, it could be how do you take ARPO

up, right? And having a very sharp focus on whether that is moving is key to sustainable investment, right? So get it right at unit economics keep driving consumption keep driving

&gt;&gt; I just want to press you on that Abishek and I apologize in advance if this is uh off script but uh 5G networks monetization still a work in progress in India and suddenly you have this new uh

workload to orchestrate so to speak uh is is that a bit of a challenge from the capex side or you still feel optimistic about optimization &gt;&gt; so we always feel optimistic about

optimization &gt;&gt; [laughter] &gt;&gt; U I think see as a culture uh we have this we have this term that we c we don't talk about cost control we talk

about war and waste so if we think there is some investment that is not going in the right direction don't stop the investment it's best to invest quick and fail fast right so

that's that's how we see this it allows us to experiment a little more than uh we good if you are very very conscious about it but as long as you're investing and

getting to the right architecture or the right business economics you will see I mean we see atel really propelling good money after good investments so that's how we would like

to really look at &gt;&gt; bhavna just to turn this question over to you you are also a business leader and you have to think about this stuff because from the demand side are folks

demanding that you somehow turn this new age infrastructure of sorts around at lower costs uh you know year on year and and and if so how do you do that with everything becoming so prohibitively

expensive? See if you remember just about few minutes ago when I was talking about sustainability or about AI native infrastructure uh what really matters is when you look at it as one coherent unit

as you know a unified strategy you are able to then make it a lot more predictable in terms of cost and there is this also new you know uh way of doing it in terms of bringing modularity

uh into how you're really designing the entire architecture because when you do that a lot of wastage age does not happen a lot of overprovisioning does not happen because as I said that you

know it's not about and also it's a myth that it is all the time expensive depending on what you really want to get out of it uh it's thankfully in India it has moved away from experimentation to

execution now and that means a lot more people are now looking at it that what do we want to get out of it depending on that what is the ROI that I want what are the use cases I want to Especially

in the beginning and when that happens then you involve this modularity then you design it in this manner that you only deploy in small clusters you experiment you see that what is the

result you're getting and then you bring that predictability in scale up when you do that rather than one knee-jerk reaction of saying that let me just deploy something because I want to

experiment and then you try to forcefeit things it will always turn out to be expensive but we have been seeing this not only across the world but also in India. It is cost efficient if you

design it responsibly if you design it thoughtfully and you make it accessible you'll be able to deploy faster control cost and make it sustainable. &gt;&gt; Thank you Bhavna that's very elegantly

put I think there's also element of responsible sales here because if your salespersons are upselling on the value proposition versus making it modular then it's difficult for the customer to

kind of unbundle but thank you for those remarks. We have 5 minutes left. If anyone has a question and not a comment, please direct that question at the speaker you want uh that question to be

answered by. Please introduce yourselves very quickly. This gentleman question. &gt;&gt; So I'm Vijay Kumar scholar. So like you want India to be a hub provide services for different platforms for the entire

world. So like how you think like number of data centers are required for India in such scenario. &gt;&gt; So I think Sujit answered part of that but yeah go ahead.

&gt;&gt; Yeah Vijay that's a good question. Um it's not about u how many data centers it is about how efficiently uh without spoiling the environment we would build data centers is important. Uh I know we

are a very large market uh you know billion plus people we would like to deliver services and everything else to uh to the citizens in the most effective way. It's about it's not definitely not

the count the scale of like I alluded to this point of saying we might get to about uh six uh gawatt of per you know data center capacity in less than 20 by 2030 uh I guess by 2035 we should get to

a 16 but the point is how responsibly we bring it is going to be very very &gt;&gt; you're setting yourself up for the data centers in space question but I won't ask that yes this this gentleman here

your name and uh please direct it at a particular speaker and my question is from Google. &gt;&gt; It's around how shifting from GPUs to CPUs or accelerators or something

similar to TPUs would be involved in the shift for GPU alternators. &gt;&gt; Okay. &gt;&gt; Other than that, &gt;&gt; that's it. One question per person.

Would you like to take that first? Okay. &gt;&gt; Yeah. So uh that's what I mentioned when we said that uh the starting point was GPU because that fit in with the the parallel processing and the the matrix

valuation that we doing but as we move forward with the different workloads the very different workloads you could have on the input side which is audio video text 3D all kind of things and similarly

on the output and multiple use case and hence you need that custom processing unit the the TPU NPU examples that you take is already there and then as you go to any hyperscalers or any of the

upcoming hyperscalers it's a lot of combination of what we call as a traditional GPUs that you can procure but as well as the custom that you make which is optimized for both power

performance the use case the cost the power thermal and all all of that so that you can scale at the economics that we are talking about &gt;&gt; thank you Naveen yes and we'll take a

few from the back soon question and name &gt;&gt; so my name So building onto the similar question I want to know that what are we doing to build onto the GPUs and TPUs such that

it can be utilized without much of the natural resources as well as uh there is no much exponential increment on the computation power that we need toend &gt;&gt; I think we we've been answering

questions about optimization is there a different question here in the uh mix yes from the back this gentleman yes &gt;&gt; broadband question is to &gt;&gt; you mentioned in your first intervention

about that the tempos need to actually provide quality of service a better quality of service and &gt;&gt; a uniform quality of service &gt;&gt; uniform quality of service instead of

saying up to a certain uh speed you provide the speed which you have actually given for which the data plan has been uh bought by the customer. My question is what is stopping the telco

from doing that? Why is it there is a kind of a reticence on behalf of the telco not to offer that what has been paid for by the customer? Don't you think that is absolutely a must?

&gt;&gt; I think Duji is also channeling some of our experiences in the room uh with uh bandwidth latency etc in our homes. But over to you. I think um two things our ambition is always to do as much as we

can for everybody and uh that's what networks in India do they're pervasive and they will provide you a quality of service and we don't differentiate users between one one or the other right so

our I mean our telecom license does not allow us to differentiate I think on the enterprise side we've been for a very long time providing the quality of service that's promised including

observability and being able to measure it. I think what's missing today and what a what the ecosystem can come together and do is have an ecosystem of not just connectivity but also edge

devices to give us that feedback saying what's working what's not working. Today quality of services speed I think application uptime your ability to hit a particular data center and come

back those are metrics that we don't track or we don't transparently share. Sujit would you like to build on that because I know you make routers and so on.

&gt;&gt; Itching to talk. [laughter] Uh so two things because I come from the telco world. Uh one is u I mean and we talk to very very closely. I I can guarantee you every time they talk to us

they say can you build what is called as eight cut knockout 16 cut knockout which means to say that the number of fiber pairs that are put to deliver a certain service uh service

to you the bish G is over eight pair 16 pairs up to 96 pairs of fiber depending upon where they want to put the second point is delivering quality of service that Abishek alluded to and that's where

the software hat of mine comes in is how do you use agentic AI to do this I would say balancing of act so that you know whenever you have a problem you call somebody the ability to quickly analyze

what the problem is by use of agents is very very important. So I think today on the oss world there are agents built wherein which can quickly without you talking explaining it if you answer two

questions or three questions uh and looking at the background of the telco side they will come back and tell you that your cut might be 90% due to a router problem and a hardware issue

versus actually um you know the fiber the fiber could have been stable there. Uh I same question very quickly to Wilson. Uh and perhaps Becky if you want to take that as well from a devices

point of view. Quality of service. How important is it to you to build in? &gt;&gt; I think it's hugely important but I maybe I'll just end quickly with a cliffhanger for next year's summit which

is uh uh an area that's coming down the pike pretty quickly here and that's around quantum and how quantum is going to help with things like quality of service like optimization and some of

the other things there. a lot of research happening in that space but also um uh practical applications. We have our Willow quantum computing chip already that's that's uh has been

developed. So keep an eye on that space. &gt;&gt; Thank you. Becky, any final remarks? Um I would just quickly offer uh AI Casec did a great use case compendium of AI at the edge use cases which I would

really encourage everybody to look at to be a bit more familiar with uh what is on the horizon. &gt;&gt; Thank you very much to all the panelists. There are throngs of crowds

outside waiting for the next session. Uh but this has been most enriching. Thank you again for &gt;&gt; coming together. Yeah, &gt;&gt; we just request uh Brigadia Tandon to

hand over the momentos uh with Wilson White Oh,
