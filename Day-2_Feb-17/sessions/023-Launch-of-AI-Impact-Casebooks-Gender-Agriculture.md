# Launch of AI Impact Casebooks ‚Äì Gender & Agriculture

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:15 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | Meeting Room 7, Level 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/hXAGCn30gJQ?feature=share) |

## üé§ Speakers

- Shri Abhishek Singh, Additional Secretary, MeitY, & CEO IndiaAI Mission
- Ms Christine Arab,
Regional Director, UN Women
- Smt. Rashmi Singh, Secretary, Ministry of Women and Child Development
- Shri Vikas Rastogi, Additional Chief Secretary, Agriculture, Animal Husbandry, Dairy Development, and Fisheries Department, Government of Maharashtra (TBC)
- Mr. Paul Procee, Acting Country Director, World Bank (India) (TBC)
- Mr. JP Tripathy, Director, Agriculture
- Sh. Shri Devesh Chaturvedi, Secretary,  Ministry of Agriculture & Farmers Welfare
- Ms. Shikha Dahiya, Joint Director, IndiaAI

## üìù Summary

This session will present the AI Impact Casebooks on Gender and Agriculture, capturing evidence-based use cases and policy perspectives.

## üîë Key Takeaways

1. This session will present the AI Impact Casebooks on Gender and Agriculture, capturing evidence-based use cases and policy perspectives.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/hXAGCn30gJQ/maxresdefault.jpg)](https://youtube.com/live/hXAGCn30gJQ?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Audio text check could be very helpful. &gt;&gt; It's here. It's not present. Okay, it's here. Take &gt;&gt; audio counter. How do you Thank you. &gt;&gt; I can take the mic. Okay.

&gt;&gt; Um, I'll just speak like this. I can start. Okay. Hello everyone. I'm founder of Paris speak. Listen carefully. Okay. So, the audio was only on the

laptop in this case or &gt;&gt; we'll wait. Don't worry. &gt;&gt; We'll wait. &gt;&gt; Thank you. &gt;&gt; Just fix this for

&gt;&gt; Thank you so much. &gt;&gt; Can you put your mic closer to the speaker? &gt;&gt; Understood. The mic.

Look at this. The PBT has closed. Just try it once. &gt;&gt; That's all right. I also brought some uh speakers in case that would be &gt;&gt; there's no rush. Relax.

&gt;&gt; Our kids are very different. Did you understand anyone? Neither did I one and a half years ago. Over 650 million people worldwide face voice and speech

disorders caused by conditions like stroke, paralysis, Parkinson's and more. I started with disastria and cresphonia conditions that remain largely underserved. The question is can we

enable a full range of communication for these people by converting their impaired speech into clear speech. Introducing uh sorry existing solutions are speaker dependent English only and

inaccessible to those who need them most in both cost and form factor. Introducing PASE a pocket-siz device that can convert impaired speech into clear speech on a real-time basis.

Remember the voice in the beginning? That person had disadria, a devastating motor speech disorder causing slurred speech. Let's hear what they were actually trying to say.

It feels incredible to see someone so happy to hear their voice back in a way everyone can understand. So how does it work? Press the button and speak. The speech is then processed by advanced

cloud-based AI models. Building these models was a long journey from collecting the largest database of Hindi desertric or slur speech to creating a high accuracy framework that works even

with limited data. Then clear speech is played back on a near realtime basis. This framework is patent pending and PA speak is trademark pending. But there's more. My goal is to scale PAS speak

across many kinds of voice and speech disorders. Here's another demo with the same tech. This time a patient with press bifonia where the voice weakens with age.

I will panic is portable, affordable, India first, accessible and designed to improve quality of life. My journey started one and a half years ago in

grade 10 when I went to a care center and met people who could speak but could not be understood. Then I got to work that won both national and international science awards representing team India

supported by the government. Paris speak made the national news soon after. In October, I was selected to present at IIT Delhi's empower assist research conference as the only high school

researcher and and recently pas named the national winner of Samsung Sol for tomorrow with a seed grant from Samsung as well as an incubation at FIT IIT Delhi.

Py currently stands at technology red list level 7 with extensive demos completed. Now, we've already launched a larger data collection program and are currently developing a market ready

version of Paris software and hardware. By mid to late 2026, a clinical trial for um CDSU certification and other regulatory approvals will begin and by early 2027, devices are planned to reach

the market. I'm on a mission bringing Paspe to those who need it most. Revenue will come from device sales. Rups 2,000 per per unit plus a rupees 200 monthly subscription. Paris can also power

public communication counters and other assisted devices through an API so that they can also understand impaired speech commands. Institutions including government ones can sign multi-year

install and support deals. &gt;&gt; All right. I have completed data I have completed data collection and testing at two associated care centers and I hold letters of interest from more

institutions and neurologists including over 100 people who signed up on the weight list on their website. What PASIC needs is clinical partnerships, resources, and funding, and a motivated

team. I'm ready to bring back the voice of those whose voice can't be understood. Let's embark on this journey together. Thank you. [applause] for the entire panel post three

presentations. I now invite uh UI 9405 team to make the second presentation. Is there a place to keep our laptops? No, &gt;&gt; I don't think there's

&gt;&gt; I don't have that. I just keep it for the presentation. Ready? &gt;&gt; Yeah. &gt;&gt; Correct.

&gt;&gt; Okay. We've all seen elevator buttons with these random dots at the bottom. We know it's B and we know it's used by the visually impaired to read and write. But the one question we ask is how do they

read it? The same question my partner Mana and I have been asking each other is [laughter] because there's more of teaching force present in India teaching the visually

impaired bra. This is India's biggest education and market gap that we notice and we are here to fill in. Judges we are wave wave stands for variable assistant for your vision and we bring

learning to simple gestures. We are the first and only ones in the entire variable assistive in uh India and we are the first and only ones in the entire global market segment of Bharti

rail. Over here as you can see we is a pair of variable gloves which has six f like sensors in total to mimic a traditional veil cell. This is our cost prototype

and our latest prototype is as shown here. Show &gt;&gt; this is our latest prototype here. &gt;&gt; This is our latest prototype. It's ready

to market and as you can see in the images here it's the faces are blurred out for ethical reasons but we are already testing with multiple brand institutes not just in Delhi but also in

Kolkata lighthouse Kolkata and bru as you can see here wave six flex sensors to mimic a traditional veil cell and when I fl my finger when I flex my finger the voltage on these sensors

fluctuates this fluctuation is recognized as a gesture which now to my database of my alphabets the database then moves to my website that teaches you entire braille. As I mentioned, the

biggest problem right now is the lack of teaching assets. For normal students, a teacher can use lot of assets like YouTube video or other teaching assets. But for learning Brail, it's a lot more

difficult. Of course, reading Braille is like so but learning Brail requires a lot of onetoone attention which is not easy to pay for a class size of 30. And that is why we built Wave that takes

over the entire learning process of Brail. Not just that, but it also scales to a corporate setting. Right now, we'll give a quick demo. I request one of the jury members to volunteer for the demo.

&gt;&gt; Yes. &gt;&gt; Okay. And what are we going to do? We have to use &gt;&gt; as we prepare our uh ST jury member for

the demo. I'd [laughter] like to add that we have successfully filed our design and utility patent for India and we are also building a Japanese rail prototype with collaboration with the

Japanese government for Japanese rail and this marks a significant landmark because we want to scale not just in India but overseas man and I we both come from a Middle Eastern background

she's from UAE and I'm from Bahin so we have a very solid network already built for Middle East we are spread into the Southeast Asia starting with Japan but our first motive is to start with India

and as you mentioned we We are made for Bharat and we are made in Bhat. So our first point of action is to build into Bharti Bale. And right now our prototype feature is Hindi, Tamil,

Hindi, Tamil and Mallayam for Bharti Bale. Right now we'll quickly show here show the demo here. All you have to do is listen to the interface and what

you'd want to talk to and you have to just listen to what No problem.

&gt;&gt; Just keep it straight. &gt;&gt; Can we just close it? &gt;&gt; I'm going to connect a device. Can you flip the can you show the screen to the people maybe

possible after that possible? Okay. &gt;&gt; Oh yeah, that's the demo. Yeah. Okay, I I'll just &gt;&gt; select your language. Say English or Hindi.

&gt;&gt; So our website features two modes in total. There's learning mode and practice mode. In learning mode, the user learns alphabets from A to Z and numbers from 1 to 100. For every

incorrect input, my website says, hold on, you're not exactly wrong, but if you make these changes, you'll be absolutely correct. This is very crucial because the we are building something.

&gt;&gt; Finger five is your right middle finger. &gt;&gt; Finger introduction complete. Your input will only be recorded after the two trigger beeps. We'll start with learning mode

for letters A Thursday one. &gt;&gt; I just want you to exactly hold both of them together. Okay, let's see what happens if she does

it wrong. &gt;&gt; The time is over. &gt;&gt; But finish your demonstration. &gt;&gt; Okay, so now when she did it wrong, when she did it wrong, [clears throat]

we're going to do it again. So let's go to the second. Let's go to practice mode. Switching to practice mode. &gt;&gt; Your word is kept 4C both one and four.

&gt;&gt; Now just &gt;&gt; so now we're showing a quick demo of our product here. Uh Miss Ready is trying it out and you can see she's in practice mode. She's learning Braille right now.

and we'll quickly show what the reports are if she needs some improvement in any of the finger mappings which is very important for a instructor to know. The biggest gap in education right now is

the teaching assets which is what we cover. A supervisor or an instructor just needs to click a single button and we deliver from there onwards. We teach we give feedback and the entire model is

voice control. So you can give a voice command saying stop, start or how am I doing and it gives you a complete feedback of how you're doing and where exactly can you improve. Not just that

but it generates a complete comprehensive review of how you performed where your mistakes lie and where can you actually improve for the instructor to tell.

This is the best feature so far for the teachers perspective and we received a very good response from the teachers around the baru and the lighthouse in Kolkata. They are very eager to use our

product and we are already receiving orders for them and I think Yeah, just to show the we have also added so add the less learning and faster.

&gt;&gt; When one senses sabotage, your other senses are enhanced. When your sense of vision is sabotaged, your sense of hearing, your sense of touch and your ability of speech is enhanced. The same

is utilized here as well. Your sense of hearing is utilized by adding a buzzer and an interface that talks to you constantly. Your sense of touch is utilized by adding a glove that gives

you complete authority of control and button vibrators that beep through nudity using haptics. And lastly, your ability of speech is utilized by giving you a complete freedom of speech with

interface. You can speak in your mother tongue and it responds back to you. So this was wave and we are happy to announce that we have already filed our patent successfully and we are building

a prototype in Japanese bra as well. Thank you. [applause] Oh, sorry. Yeah, &gt;&gt; thank you teamASM. Please uh we shall all try to stick to

the timeline so that all the 20 teams have a fair chance to present. Uh Julie members, our third team is UI 3536. Uh unfortunately, they're still stuck in the security process. So we'll

be moving to the fourth team for the next presentation which is UI378. Technical team please play the fourth presentation 1378

please. &gt;&gt; Hello Am I audible? Yeah. Okay. Good afternoon all. Uh myself Aniket Kilikar and this is my teammate Nikl Hay.

Imagine a consultation with your doctor where doctor is focusing directly on your patient. He's chatting with you. He's talking to you. He's reasoning well and not going through all the documents

that are that you are presenting to him looking for the information that is specific to you. It's not just about imagination. That's what Aragia literally enables.

So before understanding how it really works, let's understand the problem and the gap that is there. Today the clinical expertise in the uh India is heavily concentrated in the

metro cities. what remains in rural India is just a single single doctor clinic where he has to manage everything from taking the notes to uh prescribing the medicines

but that creates multiple challenges that doctor to ratio in the rural India is very high and that gives us very less time for the doctor to talk with the patient it's about 1 to 2 minutes so

what happens is patient doctor has to just react to whatever the patient is telling And this problem cannot be really solved by adding more healthare workers because

healthare workers with with time move tend to move towards the tire cities only for better pay and better lifestyle. So the only solution to this problem is how do we really empower the

ones that are really on ground in the rural India and to solve that thing we are creating R&amp;D AI but in this uh India's digital infrastructure digital public infrastructure as well as the

policies are very interesting and they are very aligned at this time right now India has built ABDM dishes direct digital mission which really has digitalized around 80 uh 80 cr health

ids and digitalize 67 crores of health records and with time in 1 to 1.5 years in states like Maharashtra or Tamil Nadu the adoption of these health records uh digital abha will be very high but there

is still a gap the there are solutions like ak which are really doing digitization of the documents but the gap is if we just digitize all those documents ment and

dump it to them on the laptop firstly they don't tend to use new tools and if we give them that in digital form instead of paper there is no use so there is a gap then there is a need of a

system that can reason over all of this data and present to the doctor and exactly that system is during our discussions with the doctors we noticed something really interesting

specialist setups there are juniors and assistant that are helping the doctors so before even you enter the cable of the patient you have already gone through two to three cable of juniors

where you have been done the pre preliminary assessment and everything and on paper the specialist just sees whole case and the thing uh that is suggested by the juniors he just revises

some things and suggest them our vision with RFI is that one doctor plus the system that we are building with RFI should be really equivalent to the reasoning capacity of entire specialist

setup let's just see that in action Before the consultation even begins, a regular AI &gt;&gt; Before the consultation even begins, a

regular AI captures the patient's concern in natural language [music] and structures it automatically so the doctor's time is spent on decision. is data [music] collection. Within seconds,

the doctor sees a clear criminal overview of the case. Every is by evidence and traceable sources. [music] The doctor interacts naturally, asking

questions, exploring context, and guiding [music] system. Prescriptions and investigations are generated instantly and delivered securely to the patient through AB.

[clears throat] At first when we showed this idea to the doctors they were really skeptical and they thought will this really work but after showing this UI demonstration they were like if

implemented correctly then this can really solve a lot of problem that this face every single day. So our is built on three primary pillars that is ABDM native SLMs and evidence based fact. So

our system is already has AVDM integrations and based on the consent of the patient we plug in the data into our systems. We have specialized SLA models so that we can scale to to across the

country uh in to also to the rural places of country. So evidence based right helps the system to answer based on the facts and not just on the based knowledge.

So early diagnosis becomes the default not a privilege if preable deaths become treatable conditions because every doctor everywhere reasons with special intelligence. Hence we work for welfare

for all happiness for all. Thank you. [applause] &gt;&gt; Thank you deans. Uh JD members we are open for the query. &gt;&gt; Where where are you from? I am from

Maharashtra Lu. &gt;&gt; Do you guys have a demo? Do you have a demo? &gt;&gt; Yeah, we have a demo session but we avoided it because of the time con.

&gt;&gt; Uh Judy members, we are open for queries. So for the three teams that have presented in case there are any further questions to the teams, please feel free.

testing. Yeah. Um so one phenomenal just phenomenal phenomenal to see the clarity of um both the problem identification as well as the innovation that you're applying. I guess my question

starting with the first presentation Paris &gt;&gt; Paris you said so I guess two things one is there is a little bit I know you said it's real time translation but there is

a bit of a actually there was a timeline. I'm curious how you think about closing that timeline. That's one. Two, what was the hardest challenge in solving the problem?

&gt;&gt; So, um, for number one, uh, currently the AI solver which I like the model I built is running on my laptop as a server. So, the hardware device communicates with my laptop which then

clarifies the page and sends it back. But in u in a future deployment and as most professional AI models are deployed uh, it will be put on the cloud. Um, I've already tested it on AWS and Google

cloud. In both cases the lag time has been reduced around [clears throat] 5 seconds to 2 to 3 seconds. Um so once I deploy it over there finally then even the device will be able to transmit it

pretty quickly. Uh so the latency will be reduced. Uh the second question um the hardest challenge I would say was uh so the hardest challenge I would say came um with the hardware. So when I

went to the care centers and repeatedly tested my prototypes, uh the feedback I got from the patients again and again took me through all of my prototype iterations. So I definitely spent a lot

of time on that trying to create it in a very accessible manner so that patients even if they have their body is paralyzed, they can still use the device.

I have a question for &gt;&gt; I have a question for 13788. Yeah. Just tell me about um while I understand that this is um those you know more

equipped for doctors who are in remote areas likely right that's that's the proposition that you've made. um when they are transferring data back what kind of associations do they have with

urban centers the interpretation of the data so what are the what are there any particular urban centers they're sending it back to are there any um healthcare networks that you are trying to tap into

and uh what is the what is the specific connection or understanding between them because what I'm really talking about is how do you bridge a connection gap if at all one exists.

So ma'am this specific question we don't need to tackle. Government of India by NSC has already tackled this problem. They have built a full opensource digital highway for the data of medical

records by EBDM Aishman digital mission. &gt;&gt; Okay. So they are providing us the whole data and whole data travels to their APIs to us and it is based on the consent like how we do in digatra or dig

locker 7 days we get the access of the data same way it will be implemented in the system and when pushing back to the patient it goes back to again the ABDM where it is logged into patients ABDM

account and if he even goes to chains like Apollo if Apollo is registered with ABDM they can access that data and if a primary clinic is they can also access the same data that is pushed by Apollo

to the Avidia but it depends that if Apollo will give that data or not that's a different okay and this also should ensure uh patient privacy yeah for patient privacy ABDM has already done

something like reductions in name and all what you get is just the primary pointers like a and it's like same like a case study a textbook case study that we will get the AI will process SL via

SL locally only. So what we are planning is using frameworks like ALM and all those things it can be done on device like this if government provides uh good type of infrastructure in the hospitals

at government hospitals it can really be deployed fully locally so data never comes to us. &gt;&gt; All right thank you. &gt;&gt; Thank you and great presentation all of

you all the three. Thank you. &gt;&gt; Hi I had one question for Paris. what is the accur how varied and deep your data set is right now what you're training it on and how accurate is it right now

so currently um over the past year what I've been able to personally collect is about 45 minutes of data from 28 patients and these patients have varied conditions from Parkinson's to paralysis

to CP congenital disorders and more uh the incilico accuracy rate of my model is about 96.7% I also conducted a real life pilot test with around 11 patients and the accuracy

in that pilot test varied between 80 to 95% depending on how severe their speech disorder is. Yeah. &gt;&gt; And I have the exact same question for the for one no the second 9405

&gt;&gt; on the on the accuracy &gt;&gt; raise your hand please. Um could you repeat the question? &gt;&gt; No, it was the same question about the accuracy accuracy of the mark.

&gt;&gt; So we we tested with around more than 120 students not just in Delhi but also in Kolkata and we recorded above 80% of detention rates compared to traditional braille using braille devices. Our

accuracy right now stands at a 97.3%ish because the sensors which we use are very cumbersome. If we buy high grade sensors it's definitely improvable but right now the biggest bottleneck we are

facing is the funding. So any funding we get from here will be directly supplied into the supply chain and production level uh you know uh production &gt;&gt; and you know do you think there are like

monetization or like how is it that you want to take it to market? &gt;&gt; Yes. Yes definitely. So the currently our competitions are the traditional brail keyboards which have six prongs in

total like a traditional braille cell and they starts from they start from 45,000 onwards and you can search it up. Our product right here it cost us 9 9,700 and if I build it in bulk I can

create it within 7,200 to the dot. So it's a landslide price. You compare it with 45,000 to 7.2k. It's a landslide price and we really believe we can uh you know scale over there. There's a

huge gap in variable haptics and we are fixing that. &gt;&gt; Members if we have your permission we can move to the next panel. Uh I'll also request for the ease of

logistics that the students who are uh presenting and are applicable for the query round please come forward uh at the time of jury questions. We move to UI1036

uh presentation number five. &gt;&gt; Hello. Hello. Uh I would also like to thank uh Deepak Sa for his valuable time and for sitting through the first panel of

presentations. So is unfortunately tied to another panel but we have Dr. Anish with us who will be representing the innovation mission.

&gt;&gt; Yes. Uh uh photography team can request for a group picture please. Join us. Join us. Join us for one more.

Yeah, sorry. No, no problem. They're doing such a nice job. Yeah, we have you here. It's the jewelry together.

&gt;&gt; Yes, please. Hello, good afternoon everyone. Um, let me begin. There are about 910 million population in India living in rural areas. Out of which 65%age of the people

have lacks lack of access towards the healthcare. These people faces shortage of specialist and so they need to travel long distance and also uh they they need to sacrifice their daily wages and also

they don't have proper awareness about which doctor to consult and whether the doctor will be available at the location or not. In order to uh provide in order to provide this information several tele

medicine platforms has been introduced but it doesn't adopted among the rural areas to uh and this is the exact problem we are trying to solve with our solution. Hey, Medicare is a voice

enabled AI powered tele medicine infrastructure platform. You for this you don't need to install any apps or you don't need to open any website. You just need a basic feature phone. From

that you can able to call our agent and our agent will handles perform an a and gives awareness about whether you whether the patient needs a doctor consultation or not and also and also it

says which doctor to consult and it also calculates an agency score. Based upon it the doctor can able to easily prioritize the patient with high medical emergency and also it books an

appointment uh for the patient in the nearby location. Let's let us see how our solution works. First of all the patient needs to visit the nearby public healthare centers orarmacies to make a

call to our toll-free number. From there our voice interactions are captured from Twilio and a fast AP web sockets and those audio streams are sent to text to speech speech to text transcription and

those transcription are sent to our manage agent which is powered by langraph which orchestrates symptom analysis agent and booking agent. The symptom analysis agent works like it it

first extract the symptoms from the user query using name entity recognition which is done by bioclinical bird and from that symptoms a semantic search is made into a rect database to uh ask uh

relevant symptoms as a questions and based up these questions are repeated these questions are asked until and conference in the emergency score is reached. Once the agency score is

calculated properly, the queries are redirected to the booking agent and our booking agent will uh easily segregate the users whether they are having a life-threatening situation. If they are

having life-threatening situation, their queries are handled to the ambulance and uh for not life-threatening situation uh it is handled in a smart priority queue in which the patients are arranged in a

uh arranged in the order of their medical severity and to uh then for booking based upon the the agent will ask an pin code from the user and based upon the pin code it fetches the nearby

hospitals and it uh tells the patient and from that the patient can able to easily book the appointment. We used MCP servers so that we can able to easily scale uh new tools into our

infrastructure. Let me explain the implemented plan of our solution. Um for pilot deployment which was semi- urban area with 10,000 users uh our estimation cost is around

40 to 45,000 per month in in rural area. Our expected revenue streams are governmental partnerships CSR funings and hospital subscriptions. In rural

areas, multilinguality provide a major impact. For providing that multilinguality call, it cost us around 2 rupees per minute. We assume that every patient will speak

3 to 5 minutes in that call making it highly affordable. While expanding it across villages, we store the patients conversation with their concerns and we re we fine tune our model to make it

more accurate. We we designed our architecture to handle multiple calls concurrently. Let me show you a quick demo. You can remove.

&gt;&gt; Hi, I would like to book an appointment with the doctor. &gt;&gt; Please provide your sixdigit. Please select the hospital. What would you like to go for?

Looking for hospital 20262 successfully offer standing 2026 02 items 546 of 45 days 33. &gt;&gt; As you can see that the patient can able

to easily book the appointment and it is reflected into the doctor dashboard. Thank you. Uh tech team I'd request for mic access on the podium.

Thank you Anit. You members we now move to the next presentation. Uh UI 2326. This is a young team from Thailand. How do you feel? Right. So, first of all, I would you can

use the clicker. You don't &gt;&gt; This is your translation, right? &gt;&gt; Yep. Happy.

How do you feel if your loved one was diagnosed with cervical cancer in the disease? It is so sad that over 300,000 women die each year. cancer [music] and death. Yes, because

cancer never cytos is the first innovation that protects your mother, sister and loved ones from cable cancer. That was a short video of the summary of our problem and

solution. Well, [music] so we tested our system at two cancer centers in Thailand, which [music] was in three simple steps. First of all, So this into A

[music] takes a picture of all the cells in the slide and uploads them into a into the website and the AI to do the analysis.

Now the results are the process ends immediately. Here is a video of us interviewing [music] uh patient. Now if the case is abnormal the case [music] will be forwarded to a

pathologist who then completes the diagnosis. Right? So as you can see here uh our system has already completed the diagnosis but the old system uh the case

still hasn't reached the first psychologist yet. [music] Within 6 months of waiting, women can receive their results in one day, which means they can have a chance to start

treatment immediately. Right? So, Psychosanzee is fully scalable to uh over 162 countries because it uses an international data set. And we have also tested our system

at two cancer centers in Thailand. And our workflow aligns with the WH's uh goals and standards. Right now, our system has been copyrighted and patented and has received support from both

government institutions and businesses. And next, we plan to scale our system to be able to diagnose HPV related cancers other than cervical cancer. And we also uh have a business plan that

was created by discussing with the Northern Cancer Center in Thailand in order to reach 162 countries. And here's a video that shows our full expansion plan. [music]

First, we went to the northern cancer center to test [music] our system. Next, we went to the southern cancer and tested our system there. &gt;&gt; [music]

&gt;&gt; Then we will plan to expand our system to five more cancer centers and the National Cancer Institute in Thailand to protect 4 million lives. [music] And finally, we will expand to 160

countries to protect 1.4 billion lives all around the world. Cytoscanzi can reduce the waiting time from for cervical cancer from 6 months to just one day and reduces the cost of

equipment from uh by 5,000 times making it accessible to most countries. And next we will create the first cervical cancer data center to increase our AI's accuracy and

uh teach future specialists. And cytoscanzi is sustain is environmentally sustainable because it is able to reduce transportation and is socially sustainable because it

can be used in all local hospitals. Finally, cytoke's policies and uh is supported by government institutions making it easily scalable.

And next is our demonstration. As you can see this is our sigma eyepiece the automate microscope by just add add three pieces into the standard microscope that worldwide are using

right now. Now our mic the standard microscope will turn to a million dollar slice scanners. As you can see we have two two functions. First the autofocus our algorithm will automatically focus.

It will analyze the image and now it will send a signal [music] to the motors. And next is capture. By just one click our sigma IPS will automat automatically capture all the

entire slice with our algorithms for it will capture for more than 360,000 image and all the image will be sent into our

web application. And here is our web application. As you can see, we can now upload the file analyzis and then the specialist can now easily uh

That's it for our Thank you. &gt;&gt; Thank you. Thank you. Thank you team. I'll next presentation is UI 22634. He's a 14year-old young student from the

United States and he wasn't able to travel due to his midterm exam. So he has sent a pre-recorded presentation for the jury. Video team, please play presentation 7.

&gt;&gt; Hello, I'm Sarak Mandiala. I'm 15 years old and I'm an entrepreneur here in Dallas, Texas. I'll start off with a little introduction about myself. I am 15 years old and I'm currently in my

first year engineering at the UT Dallas where I was youngest student ever at just 14 years old. So I currently run the startup circadian where we use cardiovascular oscillation to detect

diseases early. Essentially, just by placing your phone on your heart, in 7 seconds, we can detect over 40 types of cardiovascular abnormalities. As we all know, cardiovascular diseases are the

leading cause of death globally, accounting for uh 1/3 of all deaths, many of which could have been prevented if they were detected early. So what we do is we're essentially bridging that

gap in identifying cardiovascular abnormalities efficiently and effectively by using a simple heart screening app. So we've recently conducted clinical trials on about 3,500

patients in government hospitals in Pradesh. GGH ga and also GGH and we did a double blended study where patients were randomly sent who were uh high risk who were normal patients

healthy patients and also patients who were previously diagnosed with cardiovascular abnormalities and we screened them all. Whoever was flagged as abnormal were immediately sent for a

protocol designed by the department uh of medical education where they were sent for ECG to echo and then also cardiologist review and also a random sample of healthy patients also went

through the same protocol to evaluate the efficacy and the accuracy of the tool efficiently. So this led to us understanding how impactful this would be in low resource environments and also

in extremely high volume environments. So in our testing we found that this tool would be extremely useful in doing it in primary healthcare centers or providing it to nurses in government

hospitals or high volume settings because just in 7 seconds using an iPhone we can detect various types of cardiovascular abnormalities. So this tool is incredibly scalable in what it

is because it's just a software that's running on an iPhone. And the only technology that it needs to run is an iPhone itself and a microphone on an iPhone. So it's incred incredibly

scalable and it's incredibly useful in being able to identify cardiovascular abnormalities early, which is what we're really trying to do here at Circadian AI.

So here's a quick demo of the app on an iPhone. So all you do is you take it and you place it on your chest like this and then you record it for 7 seconds. Perfect. And it's just given an audio

recording that you'll be able to hear like that of the heartbeat sound. And then you click the analyze button and then you'll get the result. in this case, healthy heart.

Finally, I wanted to thank you for your time and consideration of Circadian AI. We're building the future of heart health technology one heartbeat at a time. Before I end off my presentation,

I wanted to give my sincere thankfulness for the jury and their consideration of Circadian AI, I wanted to apologize for not being able to be there in New Delhi right now today presenting right in

front of you. Unfortunately, because I am in college at just 15 years old, it does come with its own unique constraints and challenges. Currently, I am in the process of studying and doing

my midterm exams in my college. So, it becomes a little bit difficult to travel to New Delhi at this time. However, I am very happy that I've had an opportunity to participate in this challenge and you

know I hope to bring circadian AI into the use case of innovations and integrations in hospitals, primary healthcare centers around the globe. [clears throat]

Uh jury members we have UI 3536. Rishi uh is team 3536 in the hall. &gt;&gt; Are you ready to present or would you like to present later?

&gt;&gt; Okay, no worries. Uh members, we're open for Q&amp;A round to the teams that have presented so far. 1.336 2326. So that unfortunately won't be available for the Q&amp;A round.

&gt;&gt; Um okay I can go first. So um for the team that was doing the cyto scan I guess my big question that I did not really understand through your presentation is what is your innovation

right like what are you doing differently than others in the space so basically we have uh a completely full system while uh other commercial scanners or alternatives they just

merely scan slides. But for us, we have a system uh from image collection and cell imaging to AI analysis and uh sending it and transportation, right? So yes,

&gt;&gt; what how what prevents the others who are in the space and already solving it from doing the same thing that you are doing? Uh so uh with our AI so normal AI that

uh globally uh worldwide are using it right now. So they are just uh put data set in the AI and the AI app. &gt;&gt; Sure. Sure. &gt;&gt; All right. So the the images are just

inputed into the AI and it just analyzes that's all. But for us we have multiple uh we use a multimodel AI system which uh has like an entire process through in its analysis. First it is it does some

object detections and then crops out the individual cells and then it's segmented by a unit segmentation model and then the pixels in the each in each oral are counted and or calculated in a

mathematical formula which that formula is what we use to classify the abnormalities. Yeah. So I have a question to this uh 136

uh you're here. Okay. So the question is so who are your target uh this customers or beneficiaries and do you think how feasible is is it for the the rural people to adopt this technology?

&gt;&gt; Yes sir. This is for actually rural patients and um rural patients we I I have brought up in the rural areas. So I saw many rural peoples can't able to access the modern platforms. So my idea

is to uh using their tech itself they what are the technology they are using from to it we are bridging into modern uh modern infrastructure so that they can able to easily access our services

through mobile phone. But the question is how how do you think is it feasible for them to adopt this technology? &gt;&gt; They just need to call and our agent

will take care of their queries and they can able to it's like a communication with uh a health worker like that only. &gt;&gt; Are there any language barriers you anticipating?

&gt;&gt; Yes ma'am. Currently we have created for English only and also we are adopting for multilingual support so that the rural patient can able to easily access. So basically

see when when we talk about rural India and we talk about reach in rural India um we are talking about a massive country many dialects many languages right so that's an added complexity in

this so keeping that in mind if I were to compare it with let's say manipal hospital they use a app for booking it's a very simple app all you need is you download the app and you you know they

ask for an OTP you do that That's about it and you choose the doctor that you want to meet. So the question is would that interactivity be easier or would this be easier? Uh

both might come with their challenges but at this point in time which interactivity would be easier that would be better if they have smartphones but in several rural areas they don't have

smartphone and needed access. So that our our uh using our uh platform they can able to easily call and book their appointments so that uh many people can able to avail the medical services.

&gt;&gt; Got that. But your language consideration still remains and that's the scalability aspect that you need to think about. So for that uh we will be while we are scaling we will store the

conversation of the patient with their concern and we will retrain the speech to text and text to speech models so that the language and dialects will scale while we uh uh expand across

villages. &gt;&gt; Sure. Thank you. &gt;&gt; My question was the same about data privacy. when you're speaking to someone on the phone taking their information

their data how do you think you can mitigate that risk because data privacy laws are being stricter and stricter now as we go ahead &gt;&gt; so um can you repeat the question please

&gt;&gt; so when you're taking personal patients data so when they telling you what symptoms they have you you are basically uh mediating appointment for them as well so you're taking their data as well

like you said you will actually store the data and try to learn on that data as how do you then actually uh comply with the data privacy for the patients as well. So uh first of all we will be

isolating each uh users conversation and also uh we want we are storing with their uh concern but we don't store their personal details like um their name, ages or phone number. We will be

allocating a stream ID for each call there will be an ID and for that ID those conversation will be recorded so that those uh those datas won't be explicitly given to anyone. Thank you.

Thank you jury members. Thank you team. We now move to third panel for the day. It's the eighth presentation UI 22861. &gt;&gt; Do we have I think this is working. You can use this to

thank you. &gt;&gt; Hi judges. Do you ever hear about malaria? Manora is a disease that kill one life every 50 seconds. Why why can we eliminate manora yet? It's a

questions in my head. The problem is one right now we always react instead of prevent example our system they're using statistic data they not real time with

the big scale of province scale that mean the uh system of preventing is not accurate and cannot use in the real real the first ever forecasting the solution one that forecast before

the epidemic And two the problem of right now because in rural area we have only this two team while the test kit that can only assess the rural area but the problem is mia is that the have

different of species all five species and all five species have a difference of treatment. So that's why the positive or negative result is not is not have any meaning in there. So that's why we

have TO CREATE THE FIRST portable microscope with diagnosis AI code site 2 with malasite will change and break through this and this is the uh video of our innovation solution

&gt;&gt; the end to end malaria elimination system &gt;&gt; the audio respond &gt;&gt; audio audio

So this is the video showing our system using in the real place. No this one. Uh yes this &gt;&gt; uh tech. &gt;&gt; What do you want

&gt;&gt; the sound of video of this video? &gt;&gt; Play the video on the slide. &gt;&gt; Malaria X. &gt;&gt; Okay. So this video will talk about XR system that already used and deploy in

the real real test. Right now in the video I will show that &gt;&gt; yes our malware system is what we we have three part before we predict the the rich area that will operate in the

our website there and after that when you know that outbreak took place we will go into the field in just 2 hours and during we getting into the uh field test into the field rural area. We will

use our escope rapid site or our system to diagnose malaria and give a patient correct treatment. And after that, this is the patient that using all our system and next right now we already

scalability around three three centers in Thailand. First at the northern disease control center in Shangai, we deploy the scope rapite mala site and next TWO WEEK WE GO TO TR Thailand to

test all our system there and after THAT WE WE GO to the southern part of Thailand to diagnose and test our system with a special case of malaria there. So that's why right now

we already deploy to around 10 centers in Thailand. In three months we already take care about 260 cases of patient and for sustainable malware X it's not it's not just the best innovation

because Mal X not no need to youth expert or the specialist because all our system can use by just normal people like you all of you guys can use our system by just training in one day you

can be like specialist in the rural area that's why people in the rural area can get the correct treatment and like having the experts in their place and can access all of the gold standard

treatment. And next is our demonstrator. I will show you our website of using our M tech system. In this you will see that this is the screen of our officers centers. H you see

the first step one when when uh when when the place in the map have the outbreaks it will alert to the system. When it alerts, it will show the screen that uh how to adjust at that place

because our simulations will uh recommend how to adjust the place outbreak by by if if you if you click one scenario one if you click the adjust outbreak and it's not working they will

recommend another HS way for the best method to prevent malware before the outbreaks epidemic right and next is our Australia site

I am proud to present the escort. &gt;&gt; We [music] have to privacy immediately. And finally, Maria X, don't leave someone behind. We did it take to protect zero Maria. Start now. Thank

you. [applause] Can I just take one? [laughter] &gt;&gt; Thank you team for your enthusiastic presentation. We move to the ninth

presentation for the day. UI 13482. Jury members, this is UI 13482. Good afternoon judges. My name is Chiroshi and I am the co-founder of Voxet which is basically voice-based

observation using explainable AI for daisy. At first let's understand what is daia.a daia is basically a neurological speech disorder which is caused when the important parts of brain such as motor

cortex, cerebrum and the brain stain got damaged. As a result, the speak muscles becomes very weak and the speech become very slurred and the people are unable to talk.

Then the it is not only a neurological speech disorder but also an early sign for serious diseases such as stroke and Parkinson's disease which can cause a lifetime burden for a person.

If you see the worldwide daert affected rate in the world, it is about 0.1 to 0.5 percentage of the total population and in India it is about 0.5 to 0.6%. The long-term effects of daertia can be

permanent speech loss and the swelling effects and can cause a lifelong medical burden for a person. The main problem of the daertia detection is the early detection. It cannot be early detected

because the early symptoms of daertia is very much unclear and unnoticed is very much subtle. The people cannot understand they they are suffering from daia and mainly the rural people can't

get access to the costly tools and the specialist help. As a result they remain undiagnosed or get diagnosed at a very large stage when they are unable to cure themselves. So we are building an easily

accessible affordable AI powered screening tool for dice detection. At first let's understand then what is Voxit? Voxit is basically an AI powered screening tool that enables early

detection of daartheia by analyzing the speech patterns and generating an explainable report medical report within seconds. At first, we have trained our model using 2,000 open-source voice

samples, among which 500 male daertic and 500 male non-disaertic. Same for female 500 mil dissertic [laughter] and nondisertic. Then we have sampled the voice at 16 kohz in order to extract

the important features such as MFCC, ZCR, zero crossing ray and the delta and delta 2 in order to extract the most important features that are responsible for dicartia. Then we have passed it to

the CRN model in order to analyze and predict the speech patterns. Then the most important innovative part of our project is that we are not just predicting we also explaining for which

features it is dicarthic and we also showing the feature level analysis that's why the model is predicting it dicearic and our model accuracy is about 94% or above and with low latency and

this is our design software design we have made this is a very working model where the user can login themselves and then they and record their record or upload a short voice sample. Then the

voice will be analyzed and the result will be shown. If it is daisarthic or normal then a automatic PDF generation report option will be there which will tell them for which reason it is daertic

or if it is normal then okay and if it is darthic then it will tell them for which reason it is daertic and what precautions they should take. At first the the real and the market

impact of our project is that we are aiming to collaborate with the hospitals old age homes for the early and the regular screening of the person then the user can sell uh screen themselves

through their mobile phones from anywhere throughout the world and the people we can also use this in NGI health for the early screening and the most important focus of our project is

the rural people rural people can't get access to the costly tools and the specialist help. As a result, we are focusing on them and want to build our main support is the

Aishwan Bharat which really focuses on the development of the rural people healthcare. So we are aiming to uh affordable hardware which will be available at the rural diagnostic

centers for their easy and affordable screening. People can usually go there at an affordable rate. They can screen themselves and understand whether they are diartic or not. If they are

dissertic then they can perform further screening and go to the cities for the further help. And the most important thing the rural people cannot give doctor visit every time. It is very much

expensive. So they left the omit the suspicious as a result they cure themsel at a very large but it is not at all curable. And we also building an smart reference system. If a person is

detected daertic [laughter] then it will the app will suggest them at what what they should do and what hospital they should visit and what specialist help they should take. Our business model is

B2B. We want to collaborate with the NOS's hospitals and the rural development program for the uh development of the rural people. We also aiming for the multi-regard activity

which is not available in India and our project is different from the other projects because it is very much affordable and early screening detection is done and the people can easily access

themselves through the phone also. We also tells that Voxer doesn't replace doctors. It helps the people to reach doctors at the right time. Thank you. Thank you team. Uh we now move to the

10th presentation for the day. UI 21582. &gt;&gt; Oh, is that okay? &gt;&gt; Okay. I will start with Okay. first uh so

okay never mind that so in our world there will be one decision that everybody and everyone should care about is about Alzheimer so imagine you wake up one day but you can father your

father your mother forgeten you this is not because they stop loving you but because of Alzheimer disease and you know what Alzheimer disease is already kill 1.8 8 million people a year that a

big number and this come with two major problem. One is Alber said we be 139 million by 2015 and two lack of doctor one need have to carry about 36 375 patient and three for diagnosment is

called over 10,000 oh $100,000 so our head has different state and it said near confidence tment. So as you can see in early sale our simul didn't show up and can be seen. So index key

the first ever AI model to convert video to skinning and in the first step into middle step index T8 the first ever sol

VR headset then you can buy a bit under $50 US and that's simulate the VR that help you and in last you going to be die absolutely so we want you to had a happy memory before you die.

So what makes inex unique? So in that it's in all solution can be prevented statement and also screening and this can be sold that it can be access anywhere anywhere in the world and two

it have personalized AI and three is only $50 US or 2,000% oh 2,000% cheaper so what made this visibility We didn't

change how do work but we implement them make them work easily and you can see that we also implement on open cloud the new thing that's just come out like two week ago

then we also have a copy let me do it. Ah so here is our copy and also we do it under human article and also we in the king user.

So how do we we distribute this? So first of all the main target of my project is doctor and partner. So they will get um sharing hospital from their uh putting in clinic or nursing home and

then in the uh secondary target is the department of health. So they will get me in hospital in Thailand. So we using and pass playbook. So we will highlight in one one to two pilot

clinic and then if that work if that's study work we will implement it into other client clinic and we will do it into this phase. So in fact when we will validate it first then

test it with some small target group and then we will uh scale it and what make it scalable. So we have two [laughter] layer of architecture. So one is auto balance so it can handle 10

of thousand people and two data all data are incubated and and we all private and three we using all third party uh platform so anyone can access it so this uh is a okay so when somebody uh

some some have to and then you became more user more user mean data more data mean no accur Y so more accuracy then they be more user again and we get our ecosystem and community.

Okay now how we win this is my four win. So first of all, so first of all customer will get all money head for with a cheaper high at

only 50 US and two hospital will get customer from us and then they will get the ching profit when they uh bring their customer to us and three government government will reduce

financial burden reduce their and increase uh quality of life in the country and lastly in Yes, in the end we get more user and also more money. So here's the demo.

So this is the demo of uh skinning to video to skinning. So I upload the video or footage. This is about 5 minute and this will analyze uh as the video and show that what part of the video are

dangerous and have a list of our singer. this actually 97% and one is uh this we are this also generate uh a map and for a similar patient individually okay I think that's

all for me thank YOU [applause] &gt;&gt; thank you teams. Uh judges, we are open for queries for UI 2861 13482 and 2582. The teams are seated on the right.

[cough and clears throat] Yeah, I have a question for this 13482. Okay. So you have developed that technology right? So how accurate how accurate is it and how do you validate

that accuracy? &gt;&gt; So we have tested it with many people's and uh since we are students we have tested among many friends among around 100 people. We have tested with their

voice and since we don't have any daertic people we are uploading a daertic voice and if you're recording a normal voice it is showing normal and with confidence score is also showing.

&gt;&gt; So you haven't tested with the real affected people or &gt;&gt; no so uh we have tested it with the open source voices we have downloaded which are available easily from some hospital

websites or which are easily available we have tested with that only. Okay, fine. &gt;&gt; My comment would be uh Paris speak and walkage should possibly collaborate to

build on this further. That's my comment. But thank you. I I really like the problem statement that both of you took up. &gt;&gt; Some more questions.

We also have to take a break for 5 minutes or thank you to all the three teams who presented. &gt;&gt; Uh teams uh we'll be taking a 5m minute

breaks for the jury members and then we'll be back again for the 11th presentation. I request all the guests who are uh keen to see more student presentations to

stay in the room and uh please be back in the next 5 minutes. So I basically inside the hall is a bit of a challenge

and uh I don't know but let me just something to stand on. &gt;&gt; Oh my god. This is going to be a hard challenge.

My past was and I worshiped part of the country after I just thought my question time after the event I just want to talk

with &gt;&gt; [clears throat] &gt;&gt; Um I could run to another event on LinkedIn or some

I'm on class 11 Happy.
