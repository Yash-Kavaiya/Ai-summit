# AI in Climate and Agriculture: Building Resilient Communities

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:40 ‚Äì 16:40 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 2 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/8ezoXTFlsdE?feature=share) |

## üé§ Speakers

- George Richards, Jameel
- Maulik Jagnani, Tufts University

## ü§ù Knowledge Partners

- J-PAL

## üìù Summary

How can AI based technologies strengthen climate resilience and reduce impacts of climate shocks for vulnerable households? This session, featuring a presentation by an international researcher on findings from a randomised evaluation of the impact of AI-based flood Early Warning Systems (EWS), followed by a panel discussion with leading experts. Building on this evidence, panellists explore how rigorously evaluated AI applications can support effective climate adaptation strategies, improve preparedness, and translate technological innovations into accelerating climate action.

## üîë Key Takeaways

1. How can AI based technologies strengthen climate resilience and reduce impacts of climate shocks for vulnerable households? This session, featuring a presentation by an international researcher on findings from a randomised evaluation of the impact of AI-based flood Early Warning Systems (EWS), followed by a panel discussion with leading experts.
2. Building on this evidence, panellists explore how rigorously evaluated AI applications can support effective climate adaptation strategies, improve preparedness, and translate technological innovations into accelerating climate action.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/8ezoXTFlsdE/maxresdefault.jpg)](https://youtube.com/live/8ezoXTFlsdE?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Hear me now? Okay. Excellent. I'm Malik, uh, faculty at TUS. I'll be talking about using AI to reduce flood risk for vulnerable households in Bihar. This is

joint work with my excellent co-author Rohini Pande who's at Yale University. So, this is sort of like a good news, bad news, good news project. The good news is flood uh AI based flood early

warning systems are amazing. They generate really accurate forecasts in a timely fashion. uh and include information that people actually demand from the flood alerts. So that's great.

The bad news is that just generating forecasts is not enough if you they don't reach people who are impacted by floods. And that's exactly what we show is that these forecasts don't really

reach rural Bihari households. So that's the bad news. But the second piece of good news is that that this is a problem that's solvable through last mile delivery models. And I'll show you

results uh using two different types of last mile delivery models. one that didn't work and one that did work. So, climate change is escalating flood risk globally. Uh since the 1980 since

1980s the uh flood risk has quadrupled and today it affects like one in four people. Uh India is one of the most floodprone countries in the world. Close to 390 million people in India are

susceptible to flood risk. Uh and in within India, Bihar is India's most floodprone state. uh includes 18% of India's flatprone area. So what you see on the slide here is a map of Bihar

across three different time periods 1984 to95 96 to 2008 and then 2009 to 2011. And the shades of blue uh the the blue bit indicates areas that were that face flooding in each of those time periods.

And the deeper the shade of blue, it indicates the frequency of flooding in each of those time periods. What you see here is that the spatial extent of flooding has increased dramatically in

the last 20 25 years. And what you also see is the frequency of flooding has increased dramatically. So you see much more deeper shades of blue in the 2009 to 2021 period relative to 96 to 2008

and the 1984 to uh 1995 period. Just indicating this escalation of uh flood risk in Bihar. And these floods are highly disruptive. So the this is data we collected from

households after the 2019 flood season. We asked them how flooding in 2019 affected them. And over 50% of people said that it decreased harvest and increased sickness in the household. Uh

close to 25% said it damaged their house, loss of livestock and damage to goods. Right? So the floods riverine floods we're talking about freshwater floods they're highly damaging to both

lives and livelihoods in Bihar. What's a policy solution that can be designed where one policy solution is flood early warning systems. Uh however say between I mean before middle of 2010s the flood

early warning systems available to rural Bihari populations or just rural populations in India or any or even urban populations in India were quite archaic. So the CWC which is the central

water commission is the nal authority responsible for generating and disseminating disseminating forecasts in India. They generated alerts through like these manual gauge readers that

observed river river levels at stations and then transmitted the data via wireless radio to uh divisional flood control programs and then the forecasts were derived through like simple

correlations where upstream water level predicted downstream water level with a lag, right? And this these were disseminated via like district or state level bulletins uh uh via wireless fax,

press, radio or TV. There was no like last mile delivery although the police were part of the chain. So that meant that rural Bihari households relied on some some fragments of this information

that the CMC the CWC was trying to disseminate together with like indigenous knowledge. So they look at water levels, look at the color of the water, uh or maybe rely on some informal

community warnings which might not be as accurate. Uh and then they would triangulate all of these things to like predict when flooding would happen in their communities. Right? So this is

like a very this is preAI world not a very good flood early warning system. Now today uh the Indian government has like an amazing machine learning AI based flood early warning system. uh

they record hourly water levels at over thousands of go uh gauges across the river system in India and the data is then transmitted to real time uh in real time to forecasting stations that are

equipped with like modeling systems. So then they generate these basin basin level forecasting mo forecasts uh that leverage this rainfall runoff modeling framework to generate really highly

accurate forecasts 2 to 4 days 2 to 5 days before the floods are predicted to arrive. Um so this is a a graph that shows you the correlation between actual water levels and forecasted water levels

above the above a certain predefined threshold and the 45 degree line indicates uh a perfect correlation between actual and forecasted water level and you see the dots the spin

scatter plots are pretty close to the 45 degree line which suggests that the CWC alerts are highly accurate their accuracy is over 95%. uh and this is as I said is an AI based

early warning system in terms of dissemination still they rely on these state or district level warnings uh they're released via TV radio SMS um newspapers and websites another early

warning system that's available to people in India and much of the uh developing world is like Google's early flood early warning system again this is an AI based early warning system it uses

uh AI to operate a hydraulic model that combines two things One is these real-time water level uh water levels that CWC collects and the second is a digital elevation maps and combine these

two things to release like these highly accurate 2 to 5 day or adhanced warnings. There are two key differences of Google's uh early warning system compared to the CWC early warning

system. One is that they generate flood risk map which are quite granular and that they can tell you where you are relative to where the risk of flooding is quite severe. Uh so that's pretty

awesome and then the dissemination is done with a hyper local precision. So unlike CWC or this Indian government which just sends out these warnings blanket to all everyone in a district or

a state the Google's warnings are highly targeted and they're sent to people who Google predicts is going to be affected by flooding. So which is pretty awesome. And in terms of accuracy their model

also performs pretty well is as good if not better than CWC's model. So that's great. So, it's accurate, it's timely, it's delivering information that people need. That's great. However, the problem

is that people actually don't get these alerts. [clears throat] So, when you ask people if you received alerts from the CWC or Google, and I'll show you this, less than 20% said they actually do

receive the alerts. Right? Just generating alerts is not enough for impact. What you need is for actually people who are going to be impacted by flooding to actually receive those

alerts, trust those alerts, and then take action in response to those alerts. Right? So this is I'll show you some data now from um a survey that we have been doing for the last four years.

After each flood season, we contact 1500 5,500 households. Um and we asked them about flooding, how has affected them, if they received alerts, what alerts they received, uh and the impacts of

these uh of alerts as well as impacts of flooding. So what you see here is four bars for each of the years after uh and we asked them if they if their community was flooded. Um this is a floodprone

sample. So these are uh 160 floodprone panchayas where this data is coming from across 12 Bihari districts. And what you see is that flooding is quite pervasive every year, right? So every there hasn't

been a year in the last four years where fewer than 60% have said that they have not been have been not been affected by flooding. Right? uh it's it's pretty pervasive. In 2025, close to 75% of

households reported their community was flooded and forecasts have been generated. So this the second bar is showing you the forecasts were generated uh for the

community for these 160 communities. And what you see is in 2022 for the vast majority of areas where these households live, the forecasts were generated in 23, 24, and 25, they were also generated

for areas that were not flooded. Well, this is a function of the model. They're trying to minimize the risk of false negatives, which is they're trying to minimize instances of there being a

flood, but they're not being an alert. And the co the trade-off or the cost is you have instances of there being an alert, but they're not being a flood. So, false positives, right? So, that's

what you see in 23, 24, and 25 that they ended up sending alerts to areas that actually eventually did not get flooded. Okay? But the the the key takeaway here is that these forecasts are being

released for communities that are being flooded, which is great. However, when we ask people after flooding if they received alerts from the CWC or received alerts via modes that the CWC uses to

send out alerts, as you see here, no more than 20% of people say that they received these alerts that the central water commission sends. Right? So AC in 22 it was close to 5% 23 and 10% and

then around 18% in 24 and 25. When we asked them if they received alerts from Google we asked this question in 24 and 25 after those flat seasons they re received alert directly from Google via

these Android notifications. Again no more than 15 or 20% people say that they received these alerts. Right? So although these alerts are being generated, they don't get to people who

need them the most, right? And even if I then we ask them if they re like any source, do you receive alerts from any source? This includes sources that are not very accurate. So these are like

maybe you heard a rumor or the boatman is telling you that river water levels are rising. So even those sort of so you even if you add all of that up you still see this gap between people percentage

of people who are saying they were the community is flooded and percentage of people who say they received alerts from any source right so there's this gap between forecast generation actually

people getting the alerts okay so now the question is how to design a last mile delivery model that bridges this gap between like these amazingly accurate and timely AI based

forecasts and vulnerable So the first thing we tried to come up with the delivery model, our intuition was let's like send these alerts to like Panchiat Mukia. So who are Panchiad

Mukia? They're like local leaders who are trusted within their communities and they also have the capacity uh to disseminate alerts amongst the community members, right? So we we designed a

community model that essentially said okay let's make sure we get these alerts to these local leaders and then they can do the dissemination. Right? So that's what we this is what the intervention we

tested during the 2019 flood season. Our pilot sample included 77 panchayats or communities across six Bihari districts highlighted in this map right here. And to evaluate whether this impvention

worked or not, we conducted a survey after 2019 flood season and then we compared uh percentage of households who said that they received any alert between treatment and control

communities. the treatment community here being communities that had access to where the muka where we sent the alerts to the mukas and control communities where we didn't do that

and what we find is that simply forwarding these alerts to these local leaders doesn't really work right so this is so what you see here is four sets of bars one from the mukia survey

that we did after 2019 flood season and the second set of bars is from the household survey we did after 2019 flood season uh what you see here is 2019 was a terrible year for flooding

uh close to 95% mukas reported their community is flooded. The same for households. Floods were forecasted. That means forecasts were generated for all of these floods. So it's not like the

forecasts were not available. However, when we asked control households if they received alert close to 60 55% mock said uh they had and close to 60% household said they had. But the diff the key

point here is that it's not that the treatment households were more likely to say that they received an alert, right? They were as likely to say they received an alert. So it's not like the

intervention had an impact. The intervention didn't really translate into treatment households being more likely or treatment household mukia being more likely to receive an alert

which suggests that mukias just didn't pay attention to these alerts that we were sending. Even though at the start of the flat season, we had told them that they would be receiving these

alerts from us via WhatsApp and SMS. it seemed like it didn't really translate and capture their attention and definitely didn't lead to dissemination within the community. Okay. So the

second thing we did this was postcoid that we designed a last mile delivery that relied on community agents who are uh basically what we did was we recruited two to three community agents.

We trained them and then we paid them to disseminate alerts generated by CWC in 2022 because Google system was not operational in 2022 and then Google's flood alerts uh between 23 and 25. So

essentially we asked them to deliver disseminate these alerts via both traditional modes of communication like loudspeakers and flags as well as more modern modes of communication like SMS

and WhatsApp. Right? So we trained them before each flood season the last four years 22 23 24 25 to understand what these alerts are saying to create WhatsApp groups within the community to

create SMS groups within the community we provide them with loudspeakers and flags to do dissemination with across their community for five months every year right so the flat

season in Bihar lasts from June to October so every year for the past four years for five months we've been paying them to like do this sort of last mile dissemination

Uh and because the flood season is 5 months, there might be multiple events, flood events for a single community within those five months. And in each flood event, basically what uh what we

ask these agents to do is send multiple alerts. The first set of alerts they send are these warning alerts as the water levels start to rise. Uh the second set of alerts they send are these

severe alerts that transition once the water level breaches is predicted to breach the danger mark. They send these severe alerts and then as the water level starts coming back down again,

they transition back to uh sending warning alerts. This is a picture of one of our community agents um hoisting like a red flag which indicates a severe alert being uh uh being forecasted for

the community. And this is a picture of the SMS or the WhatsApp message being sent by our uh by our community agent to people in the community about river water rising uh

river waters and what they are projected to be in the next 24 hours. Okay. So before I show you the results, let me just first tell you that when we asked people if they would be willing to

pay for a flood delivery service that just provided them with flood alerts by SMS and WhatsApp, turns out a lot of people were willing to pay and this was not like a hypothetical elicitation.

This was a high stakes elicit elicitation where we actually collected money from them. Okay, so these are people who have not been exposed to our delivery mechanism. We just asked them

if you would be willing to pay for a flat alert delivery service where you would be informed about alerts via SMS and WhatsApp. Okay, for theoretically for things that they already have access

to, right? They should already have access to CWC's alerts. They should already have access to Google's alerts. Turns out a lot of them were willing to pay 60% said they would be willing to

pay for this sort of delivery service via WhatsApp and SMS. and they'll be willing to pay 66 rupees which is a non-trivial amount for one season in terms of like uh getting access to these

alerts via WhatsApp and SMS. Again, these are alerts that already available to them, but they they're paying for the delivery model which tells you that they're not getting access to these

alerts, right? Okay. So, now let me tell you about our results. Uh to eval to conduct the evaluation for this community agent model, what we did was uh as any reasonable development

economist would do, we ran an randomized control trial. uh sample was 319 panchiats or communities across 12 Bihari districts highlighted in that map right there. Uh we randomly assigned 160

communities to receive the intervention which was these community agents I described to you and the control control communities did not get these community agents. So the only difference between

the treatment and control communities was the fact that the treatment communities has access to these uh these community agents. both the treatment and control had access to like whatever

baseline flood early warning system is available whether it be CWC's, Google's or any sort of informal system that's out there. Okay. The only thing that's different between the treatment and

control communities is the the fact that in treatment communities we recruited these two to three community agents who did the last mile delivery. Okay. And then to get out outcomes we conducted

these in-person survey with 15 5,500 households every year after the flat season for the past four years. Okay. So what we find is that this sort of delivery model has seemed to have

worked. Community uh it increased access to alerts and treatment households were much more likely to receive any alert. So what you see here is a comparison between control and treatment groups um

for the last four years. And you see that in each of the years treatment households are much more likely to receive any alerts compared to control households. So for example, let's take

2025. In 2025, 50% of control households compared to 64% treatment households. That's a 14 percentage point difference of a base of 50%. That's a quite a big percentage impact. Okay.

Uh they're also much more likely to receive uh they're also likely to receive a far greater number of alerts in treatment communities compared to control communities. So again, this

effect is uh visible across the four years. Uh in 2025, control households received five alerts across the flat season. Treatment households received more than 15 alerts.

These alerts were also much more timely. Uh this is we asked households when they received the alerts and uh treatment households were much more likely to receive alerts before the floodwaters

entered the community. So if you look at 2025 again, 45% control households said that they received alerts before the water reached their home. This percentage was 60% for a treatment

household. So that's again a 15 percentage point difference. So not only did treatment households have access to these alerts, these alerts were much more timely, which is great.

they so as I said these models try to minimize uh false negatives or instances of there being a flood but they're not being a alert and this is what you see in the data as well if you look at these

are differences in terms of like false negatives uh in each of the four uh flood seasons and what you see for example in 2025 28% control households said that they did not receive alerts

but they say they were their community was impacted by flooding that percentage is far lower in the treatment group in the treatment group around 10% treatment 18% treatment households said that they

didn't receive alerts even though they were impacted by flooding right so it minimize so treatment households are less likely to not receive an alert when they were subjected to flood

okay however as I said there's a trade-off the trade-off being if you try to minimize false negatives you have there are few more false positives and that's what you see as well you see you

will see that treatment communities are much more likely to report receiving an alert but not report receiving uh floods. So for example in 2025 uh 4% of control households reported

receiving alerts despite there not being any flooding. That percentage is much higher in the treatment group. In the treatment group uh close to uh 12% households say that they were uh they

received an alert even though there's no floods. And this is important right? So if you get exposed to false positives that might decrease your trust in the system and next year you receive an

alert you might be less likely to take action right. So it's also when you think about evaluation for these programs, relying on just a oneshot evaluation or one-year evaluation

doesn't get at these like long-term impacts which are mediated through trust in the system, right? But and thankfully what I'll show you is that even despite these false positives, pe treatment

groups or treatment households perceived that these alerts were much more accurate compared to the control group and they also trusted these alerts more. So which is which is good. So this is

the results I was talking about. So here you have perception of these alerts. Uh in 20 so we didn't ask this question in 22 if you look at 2025 it says that 34% control households perceived alerts as

highly accurate. That percentage much treatment group that number is closer to 45%. So again uh close to a 13 percentage point effect which is again large of a base of around 34%. So

despite these false positives, these alerts were perceived to be quite accurate in the treatment group relative to the control group and they were also treatment households were much more

likely to trust these alerts which is important for like any sort of these AI based forecasts. You want they you're not asked people are being asked to take very costly adaptive action here. It's

not they're being asked to like use sandbags or um store drinking water and food. These are like not costless adaptive actions that they have to take in response to flood alerts. So it's

very important that they trust these alerts to be able to take these expensive steps. And what we see here is that treatment groups are like treatment group households are much more likely to

trust alerts despite the false positives compared to control households. Okay. And so this is uh the fi the second uh um yeah the second set uh the final the the the latter set of results.

So here we find that treatment households are much more likely to take action in response to the alerts. So they trust these alerts more. They perceive them they're accurate and they

take action. So what are the actions they're taking? They're stocking food. So they're 6% more likely to stock food uh before flooding. They uh 13% more likely to ensure drinking water access.

Uh they use sandbags. So they're 22 percentage point more likely compared to control groups to sandbag their house to protect themselves from flooding. And then they take health related

precautionary measures. So 8% increase. So these alerts in the treatment group that are being disseminated, they are being trusted and people are acting on these alerts to protect themselves.

Okay. And then finally before I end let me show you this result which is like I think related to this theme of AI u uh which this uh this this conference is about. U what we also find is that the

treatment group because they were exposed to these highly accurate flood warnings. They changed their perceptions of science and technology more broadly and they increase their trust in science

and technology more broadly which is super interesting especially because this is a context when you ask people do you do do people these days rely more on science and technology than they should

a vast majority close to 90% said yes this is a population that feels that we rely too much on science and technology and not enough on faith so in that context what we show is that treatment

households because they were exposed to this sort of like delivery mechanism that gave them access to these highly accurate flood warnings. They changed or updated their perceptions of science and

technology more broadly and they increase their trust in science and technology more broadly. Okay, so this is u 55% control households said that they changed their perception of science

and technology after flooding that was much higher in the treatment group statistically significantly. So there's a 3 percentage point difference or a 6 percentage difference in in uh in change

in perception of science and technology in the control group in the treatment group relative to the control group. Uh and this is in the positive direction which is like super exciting. So let me

just end here in the last minute I have. AI based flood forecasts are amazing. They're highly accurate as I said they are timely and they provide information that people actually need and want.

However, just because you're generating forecasts that are accurate, that doesn't automatically translate to impacts. To get at impacts, you actually make sure that people get these alerts.

People get the fruits of these AI forecasts. And you can only do that once you get last mile delivery, right? And we tested a couple of last mile delivery models. One that didn't work that

leverage local leaders for dissemination. One that did work leveraged community agents who we incentivized to deliver do the dissemination. that seemed to work

really well. Um, and it's also widely scalable. The Indian government already does a lot of like last mile delivery while like community agents embedded in like rural India. So it's not it's not

like we're doing something very unique. It is also very scalable. Okay. So and then broadly uh the last thing which uh is relevant for this conference is like when people experience these accurate

forecasts that changes their perception and makes them trust science and technology more broadly. So we're excited to like delve into like uh spillover effects as well. So I'll end

here. Thank you for your time and attention. [applause] &gt;&gt; Thank you Mollik for the wonderful talk. Please remain on stage for a group photo

with the rest of the session speakers. I would like to now invite on stage Vina Shinwasan to steer the panel. Vina is the executive director of well labs which aims to translate scientific

research into real world impact by designing solutions that create livelihoods while conserving the environment. Well labs has will develop advanced models for village level water

scarcity insights which have been funded by a apac sustainability seed fund 2.0. A fun fact, Vina has served as a judge for Bezos Earth fund $100 million AI for climate and nature grant challenge.

Next, I would like to invite Nikksha Shetty who serves as the chief executive or officer of precision development, an organization which is harnessing datadriven innovation to support smallh

holder farmers. Precision development is a leading uh is leading a number of AI based climate and agriculture initiatives including message design for AI weather forecasting program reaching

38 million farm Indian farmers. Uh fun fact Nishka has previously been a member of the jal south Asia team. Our next panelist is Fatima Al-Moolah, senior specialist international affairs office

at the UAE presidential court. Her work bridges policy innovation and investment to transform food systems at scale. The UA Presidential Court and the Gates Foundation are collaborating on AI

ecosystem for global agriculture development that seeks to use advanced technology to help farmers adapt quickly to extreme weather and give them access to the tools needed to cultivate a

better future for the communities they support. A fun fact, Fatima has been recognized as Emirati women achievers uh as one of the Emirati women achievers in 2023 for impactful contributions.

Finally, uh we have George Richards. George is the director of community jam, an independent global organization advancing science to help communities thrive. Community Jamil is a partner of

JALL in the AI evidence alliance for social impact and initiative driving evidence informed deployment of AI solutions for social good in Africa and Asia. A fun fact about George is that uh

beyond his work in committee jam, George is an established leader on cultural heritage protection and has served as a special repertoire for cultural heritage to the Kurdistan regional government in

Iraq. If you would like to ask our panelists questions, please scan the QR code on the screen. &gt;&gt; Thank you so much. uh welcome to this panel on AI for climate and agriculture

and specifically we're going to be looking at uh impact evaluation evidence around AI applications in this space. So as we've been discussing all day um measurement is really important to

ensure that uh uh AI interventions are effective. They don't result in a waste of resources. they don't have unintended consequences and impact evaluation whether through RCTs or other types of

impact evaluation are really important in generating this sort of evidence and feeding that back into actual program design. So we have three really eminent panelists here and through the day we've

been seeing some very consistent themes on this exact topic of impact evaluation. We saw this consistent emphasis on trust and humans in the loop and last mile delivery. Um and then we

saw this issue of the there's a difference in speed between how fast the AI models are developing what it the time it takes to actually put one of these real world interventions whether

an entire cropping season or building an embbackment the time it takes to actually generate evidence and then the time time it might take for the impacts and and unintended consequences to play

out which might be in a decade time scale. So very consistent messaging through the day. So I'm going to start with all three of you to basically ask a broad question about how uh AI is

actually um making its way into your own programming. Uh Fatima, we'll start with you. The government of UAE of course has been an global leader in the space of AI and AI in agriculture and water in

particular. Um, and I was wondering whether you could tell us a little bit about the types of investments UAE has been making, how you pick the investments and maybe a couple of use

cases that have really worked. &gt;&gt; Sure. Thank you so much, Vina. And first of all, thank you to JPAL for hosting us today. It's really great to be here. Um, maybe a little bit about the UAE. Um,

the UAE has taken a deliberate action and decision to treat AI um and embed AI into our own infrastructure. Um and it's also become part of our national strategy. Uh we're the first country to

appoint a minister of state for AI back in 2017. Um and in 2019 we launched the Ahmed bin Zad University of AI which now ranks one of the top 10 universities in the world for AI. Um and then we embed

AI strategy across the cabinet level as well. So now we're seeing that we also have a cabinet member that is an AI member. Um and there's a a lot of things that are have been coming out um from uh

from what we're doing. Um another thing is the UAE's development strategy is also been shifting and a lot of that is going into agriculture development. So we saw [snorts] in G20 the announcement

of the $1 billion for AI development in Africa. Um and then later this year the first phase of the AI the 5 gigawatt AI data center will be launched which will be used to train and run models advanced

models at a global scale. So we're seeing a lot of exciting things in the UAE specifically at the part the the type of work that we do when it comes to agricultural development. One exciting

area that we're seeing is um aim for scale which was launched with um Nobel laureate Michael Kmer who JPAL knows of course very well and um the aim is to create uh to to launch evidence-based

scientifically proven technologies in agriculture that could be scaled at a large level and we're doing this through several different technologies. We're seeing the AI weather forecasting um and

then also in AI digital um agriculture services now um as well as AI and livestock. So I think this would be one of the up andcoming things that's really interesting to see in the development

space. Fantastic. Um George uh in terms of community J has always had the mission of advancing science to enable and improve community action and I was and you've focused specifically on food

and agriculture for a while. I was wondering if you could talk about how AI is changing your current as well as future programming. &gt;&gt; Thank you. Um yeah well I think the

probably the first thing to say and it was mentioned generously in the introduction is that uh you know at community jal we're big evidence guys and we're big JPAL guys principally and

I think on top of that we're also increasingly big AI and evidence guys with JPAL and so we're very proud to be uh supporting uh PI um along with the British and

Canadian governments Google.org of course and and and others and I think um all the work that's obviously the focus of today's discussions around evidence for uh the

safe [snorts] deployment of AI for social good is is vitally important. The other thing to know about community j is we're glutton for punishment and we love nothing more than a naughty problem to

sink our teeth into. And one of the not naughty problems that we've been looking to tackle for a while is this question of the deployment of technologies in agricultural settings. And I'm a huge

admirer uh not something that we've directly supported but a huge admirer of JPAL's ATI initiative the agricultural technologies adoption initiative which looks um specifically at this question

of the adoption of agricultural technologies. And I think that as AI becomes this game-changing technology which we can all see before us, the question actually is to some degree the

same as it always has been about the adoption of technologies in agricultural context. It's building trust. It's understanding how these technologies are integrated into existing practices.

We've heard a lot today and Mollik's brilliant uh presentation about um flood warning I think demonstrates the importance of last mile delivery which is another area that we that we think

about a lot. So I think in some ways it's the same as it always has been. Uh but the potential that AI the promise that AI holds makes it all the more important. Thank you.

&gt;&gt; Fantastic. Uh uh Narika I was wondering if you can tell us from precision development's point of view what does precision development do in the agriculture and climate space and then

how is AI kind of shaping that? &gt;&gt; Thanks Vina. Um so there are these amazing evidence-based innovations that exist that can help farmers. Mik just talked about flood forecasts um but

they're not reaching most farmers when they need it in ways that they can actually use. So that's essentially the problem PXD is trying to solve. We're trying to take, you know, this cutting

edge innovation, uh, translate it into digestible material that can reach farmers through channels they already use, you know, simple, easy to use technology. And I think the big priority

for us is institutionalizing and scaling through government to ensure long-term sustainability. So, we've already reached 45 million farmers, you know, working with government partners in

India, uh, Ethiopia, Kenya, and so on. But I think why AI is really exciting for us is it can sort of transform uh the quality of information reaching farmers at scale. And so there's three

ways we're actively using it. Uh one is referencing both what Mik and Fatima talked about which is improving the types of content that are reaching farmers. So things like early warning

systems, AI based weather forecasts, you know, pest prediction systems. So thinking about how can you get farmers information earlier at better granularity and faster and cheaper. The

second is targeting advice better. So you know the the cool thing about these digital technologies is you can learn how farmers engage with these systems and over time you can target based on

their past behavior. And so that's really exciting for us particularly as you know different farmers use different channels have different preferences when it comes to accessing systems. And then

the last one is actually making the delivery more engaging and faster. So things like getting voice advisory in local language out to farmers using Genai and those are the types of things

we're testing. Uh but for us we see it very much a vehicle to sort of catalyze scale and impact on things we're already doing. Great. So I just wanted to encourage you

to send questions because I actually am miraculously seeing your questions here. But while we wait for a couple of more questions to come, George, I'm going to ask you a follow-up question, which is

um this question of because this is an impact evaluation session. So, how does community jam actually use evidence and how do you actually decide? There's a ton of different AI uh opportunities out

there. How do you incorporate evidence into your decision-m? What kind of indicators or what kind of, you know, theories of change? what kind of outcomes are you looking for in making

your decision to say this is the kinds of things we think it's worth these are promising. &gt;&gt; Yeah. I mean I think may maybe to give an an example of a practical example um

we don't the question that we typically ask ourselves is a simple one which is does the technology work and is it being will it be used or is it being used adopted

um and I'm always thinking of how we can push the envelope and and and try to generate evidence of effectiveness and adoption in uh more extreme settings in in in harder to reach communities. Um,

and that's I think what we what we have a hunger for when it comes to evidence generation is is really uh those those sort of edge case scenarios. As a as as a more concrete example um uh nonjar

related I I hesitate to say is that um we support an uh a research center at MIT called the JL clinic which looks at AI and and health. Uh in fact um professor Zed Omayer who spoke earlier

is uh is affiliated to the to the clinic um and and they've developed um a couple of AI systems tools for um early detection and in fact for prediction of breast cancer and lung cancer up to five

or six years before they're typically visible in uh you know common practical uh uh approaches to screening and just before coming to India and I've been on a whistle stop tour of India from

Bangalore to Chennai to Jaipur to Mumbai and finally to Delhi after hearing Mik's presentation I want to add Bihar but my my team refu said no too much enough next time um but before that I was in

Egypt in upper Egypt in Luxaw and um you know what you see the the Fuca boats gliding gently along the Nile and the Valley of the King's of course they recently discovered Sanskrit and Tamil

inscriptions um but far from the beautiful hotels in the winter palace it's actually one of the poorest parts of Egypt very rural community. Um and there there were for the longest time no

cancer hospitals and uh as a result cancer outcomes were very unfavorable because people had to once save up the money to travel all the way to Cairo to a hospital. there was a huge mental

burden of doing that and inevitably there was lots of late late diagnosis and as I said um cancer care was poor and then the community themselves local people Egyptians put their hands in

their pockets and built what can only be described as the most impressive state-of-the-art hospital uh in the middle of nowhere and I was just there and into this hospital uh we've managed

to build a link now with uh this MIT Gmail clinic to deploy these AI uh tools and What's exciting is that the clinicians and the researchers in this hospital are not only sort of taking

these tools and deploying them and using them to inform decision-m about it's it's initially with breast cancer about uh women's cancer care but they're also validating and improving the tools

themselves. So there's a genuine research collaboration between the researchers and clinicians in Upper Egypt and their counterparts at at MIT. And I think that model of trying to

build trust and collaborations with institutions with partners in harderto-reach um settings and then creating the the framework and environment for collaborative research

to generate evidence that these tools work and how they can best be adopted is is critically important. &gt;&gt; Fantastic. um you've said something very important which is it's really there's

the the the really really difficult to reach populations and then there's sort of the people who sit in big universities or research centers in the global north or even in India and

basically the the speed at which you can you can close that loop between what's happening in in these places with their AI models and what's actually delivered to make a difference on the ground. Now,

we've got four a bunch of questions that are coming in from the audience that uh are asking us some really hard questions and Shoguni said I should be really hard on you. So, I'm going to be um and one

of the questions is that agriculture is hard enough and many of these farmers lives are hard enough. What makes us sitting in this nice auditorium here believe that people who are barely

surviving are going to adopt any of these technologies? So that's one question and I'm going to read out a second question which is um for any of these AI models to work really well you

kind of need really highquality data and we saw data in the previous sets of panels as well. You need high quality data but more importantly you need data to not be siloed and fragmented. you

kind of need nations, states in India, uh private sector, civil society to all kind of be sharing data so you're able to kind of increase quality of the the the data that goes into developing these

models. What hope do we have for being able to to to gen generate models but also induce a fundamental culture shift in the kinds of data that's shared on agriculture and climate? So if you can

take both of those questions, why do we think farmers are going to do any of this uh when they are barely surviving uh and then what would it require for data and open data for that to happen?

Uh Nikka, maybe you can start and then I'll take the first question. Um, I think when we think of what farmers are trying to do, they're trying to deal with an increasingly changing climate

and most often they're not make decisions to prevent their entire crops from getting wiped out, right? Um, and so traditional knowhow helps, but as the the climate is rapidly changing, there

are there's better data, better models that can help them make better decisions. And so I think that's where technology can help. It's not about providing a shiny app to to change

decisions. It's, you know, you can have better decision- making conditions. As long as that information is reaching them in ways that they can actually use, there's still a huge upside from that.

So, if they can know 3 months out when it's going to rain or if they can know with enough advanced warning when the floods are going to arrive, they're in a position to take preparatory action for

that. Um and so if you think about farming in it essentially being about managing risk, that's where we're seeing the big shifts even in the evidence um on digital tools being able to help

minimize downside risk and protect farmers. Uh so it's not necessarily about introducing some complicated technology that nobody can use. It's about taking these innovations in

technology and using them to help farmers optimize better for decisions they're already making. &gt;&gt; Fatima, would you like to comment on the data and the open data? Sure. I think

one of the most important things is data ownership. So there needs to be the people need to feel like they own their data rather than giving it out and it being used for other things. Um and I

think also that when when we're building solutions, we're building not for with the farmer but with the farmer. This is something that we mentioned yesterday. Um evidence-based also is very

important. So when I look at um aim for scale as an initiative, it's so far it's been an incredibly successful initiative. We know that um people and farmers are being reached in the

millions but what we do with that information we still don't know you know we need to take it like after listening um to my colleague here I wrote his name down I forgot Malik um with the the

flood forecasting the granular granularity of the information that he provided is amazing we still don't have that and I think if we're able to do that with AI weather forecasting with um

with with livestock with any with any AI product development that we create as an open source then the likelihood that there will be trust in not just the governments but also um the the adoption

of the information will will increase u by far &gt;&gt; great uh George I was wondering whether you want to comment on that but I'm going to ask a further follow-up

question again based on the questions coming in from the audience so couple of them one of them is people uh there's a couple of questions around barriers to adoption and saying where are we seeing

that there are great ideas but they're getting stuck in pilots and this this is a theme we've been seeing through the day on this issue of barriers to scaling. Um and uh the second question

on on what what's kind of missing in the current ecosystem that we think uh really needs to be solved for. So what you know based on again the evidence so we can learn from both failures and

successes but sometimes you learn from failures and you realize that that's actually telling you what's missing in the in the ecosystem. So I was wondering if you can think a little bit about

what's not working well both in terms of barriers to scaling but also what's missing in the ecosystem uh that we're learning from all of this evidence that we think needs to be done.

&gt;&gt; Yeah, I I I might um pick up on what my colleague said and then also I mean on the scaling question um Fatima's extremely well positioned with aim for scale to talk about that but but may

maybe just to respond to the the the earlier questions as well. I think that um what we found is that there's no one-sizefits-all solution and um in some contexts well in all contexts I think

that trust remains this vitally important component uh to bridging between new technologies and adoption. um in Mollik's uh uh presentation and and the technology he described, it's

interesting that it's the community extension officers for one of a better phrase who help provide that bridge between the uh the alerts that people were receiving and their action in

response to them. Um, in other cases, there's a uh a great uh JPAL study um um I've got it written down here actually, digital greens, farmers chat AI, which is is is a fantastic piece of kit which

allows um farmers to kind of take photos of their crops and and and get advice through a through a chatbot effectively. But there's another program which we've supported which is got JPAL's

fingerprints all over it which is called the J observatory cruiseet which is operating both in Bangladesh and in Sudan. uh JPAL's part of the consortium uh behind it and it's a uh aim for scale

selected project and in that um they haven't done a an uh it it's focused on farmers um and it's trying to tackle many of the issues that we see around climate change and and and the

challenges they pose. They're using longterm climate models like 30 years and ahead to help farmers now start to plan for the changing world that they're going to be inhabiting. And that

includes through selecting new seeds. But rather than relying on, for example, a chatbot, they've set up these kind of clinics that pop up and allow farmers to come in uh bring seeds or leaves and

say, "What have I what what's wrong with this plant?" And then there's somebody there who can advise them on on what to do differently. And that's how they're starting to build trust. So my point is

that there are there's no one sizefits-all. It's sort of horses for courses, as we would say. And um and I think that but but it all goes back to this question of trust as a key

component. &gt;&gt; Is trust scalable though? &gt;&gt; I think I think it can be. &gt;&gt; How do you scale trust? &gt;&gt; Yeah. I mean I I I think when you look

at um the the widespread adoption of new technologies, it's there's a in in in the example that that Mik gave I think you know we talk about scale. It's three plus million people who have been

reached through starting small and in building from the pilot stage to widespread adoption uh you know as you would describe using um a very new piece of kit. So I think that was a that was a

great example of of how you can scale &gt;&gt; um Fatima. &gt;&gt; Sure. Um maybe I I want to touch a little bit also on the scaling. Uh, one of the great things that aim for scale

does first of all was created with people who feel this the same frustration about technologies not reaching the people that need it the most. They say that every technology

that we need to solve every crisis already exists but we're not putting it in the hands of the right people. And I I really believe that being able to institutionalize these technologies and

to be able to scale them is so important. So what aim for scale has been successful in doing is embedding um these ev evidence-based technologies into the development plans of the

development banks so that you can reach as many people as far as possible and really reach the first mile. &gt;&gt; Got it. Um I'm actually going to the questions here are really fantastic so I

don't know how we're going to get to all of them but there's a really really good question and I was wondering whether you could take this um on we've talked about AI and then from my world which is much

more grassroots people talk about indigenous wisdom and you know indigenous knowledge and so on how does how do those two worlds kind of interact so how do we move AI from being this

black box which is trained primarily on formal data sets and maybe western paradigms with u grassroots and make it respect what indigenous knowledge and what people know and and where do those

worlds inter intersect? Is there a way to Yeah, &gt;&gt; I think this is back to the point Fatima made, right? Like all these technologies only work when you design with the

farmer uh and when you design for scale. Uh and that often means designing with people farmers trust. So governments, uh extension workers and so on. Um I I think a good example of this is when

we've tried to send weather information to farmers and the you know what the AI tells you deviates considerably from what farmers prior might be for religious reasons. you know, you have to

design the information in a way that acknowledges both those realities and anchors the advice on on sort of, you know, symbols farmers might look for or sort of their priors that you have. So

that's one. I think the other is this has to be a repeated game of trust. So what we found is if in the early years you know the advice is accurate or you know may deviate from their priors but

is actually uh proving to be helpful we see engagement with these types of services spike. So I think both making sure that the AI doesn't exist in the silo but the practical advice that you

pro provide from it anchors on and feeds on these like traditional you know indigenous knowledge and there's this like two-way feedback loop but then also making sure that over time that cycle of

trust builds so you're able to sort of get to this happy medium. &gt;&gt; Yeah. I mean absolutely I think that if anybody goes if if I was a farmer and someone came to me and said I have a

technology that's going to change everything I'm not going to trust them like there there needs to be this process this this feedback loop this this process where we keep coming back

taking that that feedback and putting it into the AI technologies as well. So you have to take it step by step and we need to also be working to showcase the evidence. So with organizations such as

JPAL for example, this is one area where we could ourselves even improve some of the work that we're doing when it comes to AI digital advisory services. How do I know that what I'm actually building

is actually effective? And there's so many layers to that as we saw with Malik and the the flooding forecasting. Um so I think it's two things. I think it's building the trust but showing the

evidence as well. &gt;&gt; Fantastic. So I'm going to have each of you end with sort of one thing that gives you hope and one thing that you think we need to be worried about or or

design for uh so that we actually protecting on one hand developing effective interventions u and then building evidence generation into that but also um uh protecting the weakest.

So Fatima do you want to start? One thing &gt;&gt; I think one thing that gives me hope is that I believe in people and I believe in the goodness of people and I really

think that if you put the right minds together you can create something so beautiful even if it if it's AI. Um but one thing that is also the same thing probably that would be something that

worries me is what if it reaches and goes into the hands of the wrong people. Um so I would say it's it really comes down to the people and the partnerships that you work with.

George. &gt;&gt; Um, I take hope from the fact that I think everybody I nearly everybody I've heard today has been putting people at the center of the discussion and great

that this panel I think has put farmers at the center of this discussion about farming and agriculture. um maybe not a cause of despair but a challenge that we need to tackle is to push the envelope

even further to reach even more vulnerable communities and and and some folks that we thinking about a lot at the minute is how to harness AI for postconlict settings where farmland and

agricultural land has been devastated and there's unexloded ordinance and what can AI do to help tackle that challenge I'm excited by how quickly innovators governments

uh you know public institutions, nonprofits are coming together to scale effective AI powered information services for farmers. So we're talking already tens of millions. I think what I

continue to worry about is um who gets left behind and what can we do to make sure to design services that are inclusive but also what happens when the information is wrong. Have we

communicated risk clearly? Have we communicated? You know, like Mollik said, farmers are making big changes in response to this advice. Who takes accountability of that when it goes

wrong? &gt;&gt; Fantastic. Thank you so much to everybody in the audience. This has been a great panel. Thank you so much. These are fantastic questions. So, I hope JAL

is going to somehow archive them and put them out in some way. But thank you so much. Thank you panelists for that [music] insightful discussion.

&gt;&gt; Please exit [music] through the right. I don't know.
