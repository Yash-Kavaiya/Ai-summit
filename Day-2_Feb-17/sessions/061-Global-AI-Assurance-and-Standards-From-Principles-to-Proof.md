# Global AI Assurance and Standards: From Principles to Proof

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 15 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/5SDX01Vr94I?feature=share) |

## üé§ Speakers

- Bindya S RaJ, Infosys
- Carsten Maple, University of Warwick & Alan Turing Institute
- Natasha Crampton, Microsoft
- Raj Bharat Patel, Holistic AI
- Sue Daley OBE, techUK
- Tim Mcgarr, BSI

## ü§ù Knowledge Partners

- techUK

## üìù Summary

This session brings together leaders from policy, industry, and certification bodies to explore how AI assurance is shaping governance and practice. It will spotlight key practical standards, real-world adoption across sectors, India's strategic role in quality infrastructure, and UK-India collaboration on standards, skills, and market access to build trust and responsible AI globally.

## üîë Key Takeaways

1. This session brings together leaders from policy, industry, and certification bodies to explore how AI assurance is shaping governance and practice.
2. It will spotlight key practical standards, real-world adoption across sectors, India's strategic role in quality infrastructure, and UK-India collaboration on standards, skills, and market access to build trust and responsible AI globally.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/5SDX01Vr94I/maxresdefault.jpg)](https://youtube.com/live/5SDX01Vr94I?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Um, uh, TechUK, we are the UK, um, trade body for the tech sector as a whole, and it's our absolute pleasure to be here at the summit. Um, myself and Tess Buckley, who's the organizer of this session.

We're really thrilled to be here. So, thank you for the invitation. And if you want to know more about TechK, go and check out the UK Pavilion. Um, we're in the stick as well. We're in the UK

pavilion over in Hall 14. It's worth the extra security scanner. go and check check us out. Um, today we're going to be talking all about a really a topic that's close to our heart. AI assurance

um and driving trust and adoption of AI from principles to proof and really how AI assurance and standards are helping us to do that. Um, AI assurance really uh arrived in a bit more of the

mainstream last year although many of us have been talking about it for for many years now. uh we saw governments in the UK, Europe um and and in in Singapore starting to integrate AI um assurance

into their governance frameworks into their principles and their controls. We've also seen companies not just the big four but companies like JP Morgan starting to talk about AI assurance. So

it's becoming part of the conversation with the goal being how you put ethical principles, ethical frameworks into practice and establishing real trust that can then drive real adoption of AI.

So I have an amazing panel of experts. We hope one more is joining us. That's why there's an empty chair here of experts on AI standards, governance industry. We're going to talk about what

does transformation, what does development actually mean in terms of the role of AI assurance and AI standards. What are the opportunities here for India? What are the

opportunities for the UK and India to work together on this? Which sectors are leading the way? And I'm sure a lot lot more as well. Um, so it's all going to be about AI assurance and practice,

strategic opportunities and collaboration, which I think is really the collaboration is the word of the summit, right? That's why we're all here. Um but before I introduce the

panel and before we kick off, we're really thrilled to have um with us a presentation that's going to start kind of setting the scene for the conversation. So Carson Maple, who's

from the Alan Cheuring Institute, Carson, thank you so much for being with us. Can you perhaps set the scene a little bit and give us a bit of overview of AI standards in the ecosystem where

we are and then I'll get the panel to introduce themselves and then we'll kick it off. &gt;&gt; Sure. Thanks. Thanks very much. Uh Sue, it's a it's a real pleasure to be here

and it's great how packed this room is because it's a really important area um assuring AI. So um my name is Carson Maple as as Sue mentioned. So I'm from the Alan Turing Institute, the National

Institute for Data Science and AI in the UK and also the University of Warick. And in the UK we have a national hub for edge artificial intelligence. I've got some colleagues from from that hub here

as well. So, why why does AI assurance matter? I I find myself talking at quite a lot of events to all kinds of audiences. Um, and it's great to set the scene for such

a talented panel that's really going to delve into some of the issues around this. But what we're seeing is and and part of my session, so I will be speaking um organizing a panel on Friday

around democratization of AI. And that's that's a really great thing, right? And um AI's got the power to really lift nations and it I I think we're going to see a lot of global effort in this area.

But democratization of AI means it's in the hands of everybody. Um and that brings problems as well as some great things. Um you've probably seen recently Open Claw um or Clawbot or Maltbook. um

the biggest changes in in uh rebranding exercise in one week um and some some great power and for me as a director of cyber security quite a bit of worry as as well. So this age of agentic AI

really means that we need to start thinking about how we um govern and assure AI. So, agentic AI um is autonomous or semi-autonomous agents that they can plan tools, they can talk

to other agents. Um and this example that I've spoken about in the UK um to the digital regulators cooperation forum before was about a holiday agent you might have. So if I decide to to have

this agent and actually this was before open claw was around but the technology existed prior to that but I would have to give access to my diary maybe and maybe also my bank so they know how much

money I'd got maybe of my partner and children um and this this agent could then go and discuss with other um agents perhaps some kind of hotel booking agents or um Tvago or whichever you

decide to use rather than individual hotels and look at flights. All of that communic uh coordination seems fantastic, but there is a risk. Yeah, there's a risk because this low or no

code agents that's proliferating and I've got to say I see this not only hobbyists but actually in industry people who really are not grounded in um developing software that's that needs to

be resilient. Um but we're seeing many nonsecurity engineers people who are putting out these systems um and one of the concerns that we've seen already with these agentic systems and you'll

hear from some of the panel I'm sure because holistic will do some of this testing um there could be privacy uh exfiltration so data exfiltration uh that can go on as agents start

communicating there will be trust gaps and we're seeing uh the development But um A2A has been around. So agentto agent communication has been around for a little while now. Um and it's much more

powerful than MCP, model context protocol. Um but we're seeing also A2P develop and we'll see more um systems and communication protocols develop. So it's really important that we develop a

AI assurance uh processes. So it's not new. Um this is a a paper that a a bunch of academics um I was included uh developed about AI governance back in 2021 in one of the leading journals for

machine intelligence nature machine intelligence and this set out some of the principles what we're looking at now is that's okay. Um, one of the things that

we've got to decide is how do we test AI systems? So, the NIST risk management framework, uh, AI RMF version two gives some idea about some of the things that we want to look at. Is it safe? Is it

secure and resilient? Is it valid? So, that's one of the questions I hope that the panel will consider today. We need to think about how appropriate and verifiable is that assessment. You need

to test the right things for the right questions and you need some kind of audit. It doesn't need to be a public audit, but what you do needs to be auditable by somebody and that's

certainly some of the work that we're looking at in ML Commons at the moment. We need justified evidence collection of um to show how trustworthy our AI is. But there are many ways to test. Yeah.

And the problem is if we t take the wrong instrument to test then we're actually not assuring the AI appropriately. We need to think what is sufficient and

acceptable. What are the benchmarks? So I mentioned ML commons and its AI luminate that is one such benchmark. It's a global effort and it will provide um the standards that are required the

de facto practical standards that are required but we still need to decide for every other type of uh system for a health system for a finance system what is sufficient and if we test how long is

that assessment valid for so I've just put a list of things and we've got the British stand uh standards uh institute here BSI who have coordinated this event and I'm just

putting up the fact that there are so many different standards and I think Tim who's an expert I've known for many years can talk about some of these but these first standards are just software

standards been around for quite some time but then we see the development of AI standards most notably many of you will have heard of 421 quite analogous to 271 in the security

arena. There's 4219. I'm not going to go through them all, but I just want to show you how many different types of standards there are. So, there is a plethora of support there

in terms of standards and guidance. And what's important is to reflect on those questions that I set out and think what's the most appropriate way for your um system that you are developing.

Sue, I'll hand over to you because the panel can talk a little bit further. &gt;&gt; Great. Thank you, Carson. Thank you so much for setting that scene. So, let's get to the panel and um some amazing

experts for you to hear from and then I've got some questions for them. Hopefully, we'll leave a bit of time for some questions at the end as well. I'm just going to ask them each to just

quickly introduce themselves, their title, and their organization, then we'll get going. Natasha, great to have you with us. Please just introduce yourself briefly.

&gt;&gt; Thanks, Sue. It's wonderful to be here today. I'm Natasha Kmpton. I'm a vice president and chief responsible AI officer at Microsoft. What that means is that I both help to define and govern

make sure that people are doing what they say they are doing. Um the internal practice of responsible AI at Microsoft. That means I work very closely with our engineering teams building new AI

systems and models. And I'm also responsible for uh working externally as well and being part of the conversation about what are those new standards or norms or laws that we need to help make

sure that this technology is made available broadly and beneficially for people and Natasha's been working in this field for a number of years now. So it's really great to have her with us.

Raj, great to have you with us as too. &gt;&gt; Thank you very much. Um hi everyone. Good morning. My name is Raj Patel. I'm the VP of AI transformation at Holistic AI. Holistic AI is an AI governance SAS

provider um spun out of UCL 5 years ago. Um we provide end-to-end governance for enterprise clients for um smallmedium businesses for startups that have AI core to their business offering. We take

um a view from ideiation all the way through to continuous monitoring and retirement of models. Um because of our close affiliation with UCL, we we are at the forefront of testing as well. So we

are looking at agentic AI testing um explanability techniques um we're prevalent in that in that domain um and we work with the likes of Unilver GSK GE healthcare to help them get a good

visibility of their entire ecosystem to maintain um effective guard rails so that they can identify areas of risk mitigate them effectively and move forward with confidence. Thank you.

&gt;&gt; Thanks Raj. Great to have you here a real leading um UK company. And then Tim, great to have you as as well, but obviously, you know, this has been a joint BSI and Tech UK panel, so we're

really thrilled to be joining forces to do this today. So, please introduce yourself. &gt;&gt; Thank you to Lawrence for helping that as well. Um, yes. So, I'm Tim McGar from

BSI, so the British Standards Institution. So, the part of BSI that I work in leads around certifying testing of AI. Um so particularly one of the first cro certification providers for

2001 and also doing reviews of medical devices and the like but prior to that I spent over a decade in the standard side of BSI so involved in the area standards right from the very beginning as well.

Yeah, exactly. Lots of experience. A really experienced panel. I'm sure you'll agree um to really get into the the devil of the detail. I want to start with um

and custom set us up in terms of the kind of parameters, but let's talk about AI insurance and practice. Raj, perhaps I can start with you drawing on your experience and what you're seeing from

um sectors particularly in the UK but obviously from from wider that you're seeing the most mature around assurance practices already and perhaps why and are there

sectors that are leading the way or there are some that are perhaps lagging behind and what is your sense of where we are right now if that's a good place to start?

&gt;&gt; Yeah, it's a great place to start. I think um it's an important question because different industries are within a spectrum. I think sectors have uh some that are leading, some that are lagging

definitely, but within that sector, there's also a spectrum of companies that are leading and lagging within them. So, if you're in a sector that I'm saying is at the forefront and you're

not quite there yet, don't feel bad. You're not you're not going to be alone. Don't panic &gt;&gt; for sure. So um I think Ken you set this up really well with your introduction to

this that we have to really look at um what does AI assurance mean in practice and that is taking something from an ethical statement or a principle to something that's quantifiable with

evidence and that is where we see the industries that are leading really make this scalable and repeatable. So industries that are leading this are ones that have had a history of um

reputational or governance requirements. ones that have the highest consequence of something going wrong. So they're touching end customers, they have real liability against it going wrong and

ones that have been able to create these scalable processes. So these are industries like financial services, healthcare, uh critical infrastructure, defense, these are areas that if

something is to go wrong, it will have a material consequence to their end user or to society at large. So when we look at those I take financial services because I have a a history with

financial services institutions we look to see what has made them successful in this number one is that they have been operating in a highly governed um environment highly regulated environment

for a number of years. So from the financial crisis in 2008 onwards, banks as an example have been required to keep strong model documentation be explainable in all of the outputs to

have good risk controls in process so that there's not a repeat of um that catastrophic time um back in 2008. Secondly is that um that kind of stakeholder impact they have

reputational financial damage that could happen to the company as well. So they need to protect against that. And then finally is the innovation side of things. is they want to make sure that

they're moving forward with the right AI use cases given the risks that are prevalent. So when we look to companies that are or sectors I should say that are lagging what they should be looking

to do is identify um the AI use cases. First of all you should have a good idea of what AI use cases are operating in your environment already. You can't govern what you can't see. So that's

always a good starting point. Have a good robust living inventory. And then is to set up your risk appetite as the core backbone of your AI governance process and your AI assurance process

going forward. What I mean by that is that you don't need to throw the kitchen sink and high levels of scrutiny at everything. Your team's bandwidth is not going to be infinite. You need to make

sure that you're applying good governance and quantitative testing and um effective mitigations to use cases where it's needed, where it's high risk. Low-risk ones you should be able to

mitigate away. You should be able to have pass through mechanisms, but that will allow you to achieve something that is um an innovation driver, not a checkbox exercise. It's something that

allows you to use governance as an accelerator, assurance as an accelerator to realize value. So I think that's kind of the foundational framework that I'd like to see um other or general

industries applying. &gt;&gt; That's a great way of thinking about this Raj in terms of the value. And Natasha, I'd love to come to you and your experience because we're talking

about how do you you know how do we help organizations bridge that gap between okay I'm doing cutting edge AI development and I'm really excited about what I'm doing and the research or the

product I'm developing and then the kind of practical governance frameworks and practical assurance frameworks and just thinking following on from Raj's talking about how do we see it as a driver you

know um how do you help or how do companies bridge that gap is it about create you know showing how this can create tangible business value or prevent risk as well as well. What are

you seeing from you know how how companies and organizations are addressing this or you've addressed this in your your own organization Microsoft? &gt;&gt; Yes indeed. So when we started doing our

responsible AI work at Microsoft almost a decade ago now um initi been that long. &gt;&gt; Yes. &gt;&gt; Yes. Even the office of responsible AI

that um I led I have led from the very beginning um that will have existed for seven years uh by the middle of this year. So at the beginning of our journey at Microsoft, we had um exactly what Raj

mentioned. We had a set of six highlevel principles. So we said AI systems that Microsoft is going to build are going to be fair. They'll be reliable and safe. They'll be private and secure,

inclusive, accountable and transparent. Now those principles have been very um important guiding north stars for our work but they are not sufficient by themselves. Um and that's simply because

they're stated at such a high level that they don't answer sort of fundamental questions that our uh product building teams, our engineering teams have on the ground. So nobody argues with me when we

say look we want to make sure that AI systems are fair. But what our engineering teams want to know is what does that mean for the data that I need to collect um in order to train this

model? What type of testing do I need to do before releasing the system and also on an ongoing basis? What documentation do I need to make available to our customers? So over the past um uh almost

decade now we have been answering those questions at Microsoft. So taking a highle set of principles and operationalizing them and making sure that we've got the receipts to show that

we've done that work. So to come to bring things forward to you know what does this assurance actually really look like in practice. Let me give you the example of uh M365 C-Pilot which is one

of our flagship AI products. Some of you might even use it. It takes um all of our Office uh products like Word and Outlook and Excel etc. uh that are well used around the world and really

supercharges them with AI features. Now for us it was important um that not long after the international standard ISO 4201 became available this is a management

system standard. So it looks at the governance process around how you build um a system like M365. We went and got certified against that standard and that delivers real business value for us. Um,

Microsoft has many highly regulated financial services customers and health care customers and defense customers. Our customer base asks for and expects us to have these types of

certifications. I think one of our insurance customers, it's global in nature, put it really well, which is to say, you know, unless you have the receipts in the form of, you know,

certification against an international standard. It's like saying that you're a you're a car manufacturing company. You've got safety engineers, but no one actually proves that the car has brakes

and the car has airbags and both of those things function in all the anticipated sort of and foreseeable operational circumstances in which they will be operated. So um I think to

finish on Sue's core point um assurance at this point is not just a nice to have. it is you know demanded in procurement processes um and it's a way of building trust across the supply

chain so that if we can offer um you know our certifications forward it means it empowers all of the many people who build off Microsoft's platform make available applications in their context

to actually leverage the work that we've done to help supercharge um your work building applications as well. Thank you Natasha great examples and Tim come to you talk about AI assurance and practice

let's let's let's go back into the kind of the tools in the tool box I suppose and ISO 4201 is really becoming a reference standard be interested in your view of where do

you think we are with that what does successful certification actually require and also perhaps are there common misconceptions organizations have around implementing it you know if

that's the the good place to start how Do organizations how do organizations need to think about it? Does that make sense? &gt;&gt; Yeah. Probably best way to start where

we're at. So particularly we're seeing in terms of the certification side it is massively picked up in recent months. It was already growing a lot. Um and it's really quite interesting where it's been

driven from. So there are certain in terms of certain countries and sectors that normally pick up certification but for 2001 is really driven by where AI is sitting. So financial services, ICT,

professional services. In terms of countries, um, India is actually second in the world in terms of accredited certification. So &gt;&gt; that's great. Very good.

&gt;&gt; Well done everyone. &gt;&gt; UK is number four. Still good but not as good. Um, &gt;&gt; what's number one? &gt;&gt; Uh, US and China's number three

surprisingly, but &gt;&gt; so India's really up there. Huge. Um so in terms of some of the uh misconceptions so cast mentioned about 27,01

and all these management systems follow the same structure which is deliberate so they're easy to pick up and use but so there is some some views that 20 that 421 is just 27,0001 with a bit extra.

It's not it's something that's new. You have to work work all the way through it to get it in place as well. Um akin to what's been mentioned already. It's about certifying the organization and

their approach to AI governance not a particular product. Carson also mentioned earlier on as well. Um and there's also there is kind of this view about the link to regulation. So

particularly um say in the UK there is a push towards using standards and assurance including 42,0001 to be demonstrate good governance. But really as was said the pull is coming through

supply chains. companies want to do this, their customers want it. It's not because they've been forced to. It's because the market's really driving them to do it.

&gt;&gt; So in that case, Tim, perhaps I come on to you and I want to move kind of perhaps just thinking about the strategic opportunity for India before we talk about how India and the UK

because it seems like we're on similar paths in terms of assurance, how we could potentially work together in partnership on this. But thinking about the strategic opportunity for in for

Indian organizations what should they be prioritizing then to capture this kind of AI assurance opportunity you know in the next 3 to 5 years is it is it that working with your partners working with

your supply chain say look if you you you know you're going to need to do this I can demonstrate that I can do this too is that is that the way to do it &gt;&gt; I think it's there's two sides one it's

you know 42,0001 is here you know whether it's in terms of taking uptake or certification that's thing that really demonstrates that you're a leader And also getting involved is sort of

cast mentioned the standard system as well. Um yeah and I think I mean one thing I was going to mention so uh we recently announced that we' certified Axis Bank which is you know it's the

first as far as I'm aware the first bank in the world that's got 42,000 certification. So you know India is really a leader in this already. &gt;&gt; Yes that's great to hear. Natasha would

love to what your advice would be to for Indian companies thinking about if they haven't started on this kind of AI insurance I hate that word but journey you know what should they be

prioritizing and then Raj I'll come to you as well so I think in um here in the Indian context it's a really great moment to lean into the role that assurance can play recognizing Ken's

important point that um you know there's not just one type of assurance that applies in every circumstance stance um but rather it's a range of tools and and critically you need to sort of match the

right tool to the right use case but with with the India AI impact summit um the Indian AI governance guidelines have also been published and there's um a number of important recommendations that

are coming out of that that I think will help pave a sensible course forward. So for example, there will be an AI governance group that's established and a technology and policy expert

committee. One very concrete thing that I think those uh groups could do is to develop what's called um crosswalks um between international standards and other mechanisms of assurance and some

of the specific requirements in India. And what a crossbook does is it shows how you can meet the say specific existing Indian law on the books um in a way that also acrru to meeting the

international standards. So it helps basically provide a map or a path that you can follow in order to see how if you take a step like making sure you've got a valid incident response process,

you can see how implementing those controls to meeting your obligations under Indian law as well as um demonstrating a control that will be assessed in the

context of um [clears throat] a a governance audit that might um be scoped to a particular part of your business. So I think just trying to make sure in this moment that you really are

connecting in all of the excellent activity in India to some of these broader frameworks that are crossborder. This is going to help not just um more rapidly um adapt and localize um tech

that's developed outside of India in India but you're also going to export to the world too and so that's why you want to make sure that you're using this moment to align and map wherever you can

um so that you can get the benefit of these emerging uh global or crossber standards. &gt;&gt; Yeah, thank you. It's this really exciting conversation. I might be being

a bit of a geek here, but we've been talking at tech about AI assurance for, you know, it'll be 10 years, our digital ethics summit, which you spoke at really at the beginning of be our 10th year

this year and now it actually feels like this is actually happening, right? It's actually having real world impact, which which is amazing. Absolutely. Um but thank you for setting me up because Raj

I wanted to ask you and your given your experience and your knowledge a bit about frameworks and policy frameworks that can help c um c um um drive forward the AI assurance market particularly in

India thinking about you know as you touched on deployment in financial services but also as healthcare and agriculture public services government services you know are there policy

frameworks that you think could really support or that are needed to support those you know critical use cases and adoption and diffusion of AI and AI assurance at the same time. What would

you say is is key? &gt;&gt; I think um I want to build on something that Tim was talking about which is um integration to the supply chain. Um starting off with your procurement

process. Um while in a previous answer I said that governance should never be a stifling um factor to innovation and moving forward. There has to be a point at which um the economic buyer or the

procurement process needs to have a certain standardized pack and I don't use those words lightly because it's difficult to standardize this but as an ecosystem as a uh as a country if you

align on a certain requirement set of the uh AI providers that are going to deploy AI use cases into your organizations there should be a minimum baseline that aligns with both the

company level expectation as well as country level expectation. I think we as a technology company we see this we're in we are integrating with Indian companies at the moment and

some of that procurement process is very well aligned to AI systems and we get through and we're able to showcase the good work that we're doing and provide evidence where it's needed and it's a

smooth process and then there are there are others that it's a very cumbersome process. It slows down AI adoption because they're trying to get through this with a not fitforpurpose set. So I

would definitely start at a policy level which is procurement um across the board. Um next and I will always champion this is risk have a risk based approach. You need to have a a policy

pack that's in place where you are identifying critical infrastructure and critical AI use cases that require the most evidence against them and then you should prioritize in that manner and

then you can move forward quickly with high impact low-risk use cases and do the effective due diligence on high-risk high impact use cases. So I think those are the two things I' I'd probably start

with as levers to move quickly in terms of policy. Thanks Raj and and Tim just thinking then turning it into okay the UK we've been you know leading the charge in AI assurance for for a

number of years now uh our government check it out published an AI assurance roadmap um only last year in terms of how we're going to drive forward the AI assurance marketing industry she said

India number two for you know actually implementing the standards which is great but so what could the UK and India do together what could we learn from each other in regards to AI assurance

and standards you know is how do we help each other? What what would you say would be key there in terms of you know going forward?

&gt;&gt; I mean I think sort of taking it more of geopolitical level. So if we were having a kind of conversation about where regulation standards and assurance were going last year it was quite clear the

direction everything was going in the world and literally in the last year everything's kind of gone in multiple directions it has to be said. Um, and I really think in terms of what the UK and

India can do, it's trying to get more harmonization around it across the board because it's just going to make things really difficult. Particular to the point earlier on about importers and

exporters and so many rules around the world and &gt;&gt; just the complexity &gt;&gt; the complexity of the way things are going because there is you know there's

always been this tension between the need for regulation to let innovation flourish but it's just got much more complicated in the last few years and trying to get you know regulation is

probably coming but trying to make sure there is that alignment around the similar sort of approach to regulation whether it's light touch or not I think it's something we need to all do

together. &gt;&gt; Um Raj would love any views from your side on that as well and perhaps what does what could or does success look like in terms of collaboration between

the UK and India on AI assurance and are there concrete steps you think organizations or policy makers need to think about in terms of the opportunity here to because it sounds like it feels

like we're at a similar kind of point in time if that makes sense. &gt;&gt; Yeah, definitely. I think um my answer is going to be a little bit biased towards a technology provider that's

looking to to deploy effectively in this area, but &gt;&gt; I think that's allowed. &gt;&gt; It's allowed. Okay, fine. So, what I would love to see is a lot more

collaboration in terms of sharing um best practice when it comes to actually um governing and assuring AI use cases. There's a lot of work that we're doing with multinational companies um UK based

companies that we get a lot of learnings from and we are happy to share those learnings in terms of best practice with organizations that are starting on their governance journey, organizations that

have established um ecosystem in India that are looking to export and what is best practice. The idea being that governance should be again the accelerator to your deployment. It

should answer a lot of questions that your stakeholders have by your quantifiable evidence that you're providing to them based on these kind of governance pathways. The second thing

I'd love to see is um more collaboration again in terms of like a a sort of partner swap almost. So we have people that are working in the ecosystem in the UK to spend some time in India and vice

versa to make sure that we're learning from both ecosystems. both have unique challenges that um each ecosystem will face at some point whether it's first or later or vice versa. I think that would

be an an extremely valuable um cross collaboration opportunity. And then the final one is a potential shared sandbox environment where certain use cases could be tested and um different

benchmarks could be collaborated upon with visibility into the actual use cases that we were testing. Yeah, Tim, I see you nodding away. Just before I come to you this, sandboxes [clears throat]

we've found in the UK, right, to have a really really important role to really flesh out how these things work. Back to our theme of like AI insurance and practice, but also help develop

trustworthy and trust trust between partners, right? Um because we're talking about is this is really key in terms of supply chains. Do you want to touch on that in terms of the experience

of the sandboxes? &gt;&gt; Yeah, I mean there's there's two sides. I mean, as you say, the UK led this 15 20 years ago. services. So &gt;&gt; FDA started the sandboxes, right?

Originally, &gt;&gt; so so basically these are areas where you can work with the regulator and try something that's new and not be worried about the regulations there and the sort

of talk in the UK is about taking this forward particularly if the regulations aren't right then changing them after the pace as well. So that's one side. The other thing we're also involved in

which I haven't mentioned yet is around the sort of EU AI act and so we will be a notified body and certain organizations we need to work with notified body to get their products onto

the market so medical devices toys etc &gt;&gt; to get their accreditation basically &gt;&gt; they have to basically get um designated to get it on the market and around that there's a similar structure around um

sandboxes as well. So in our role as a notified body, we'll probably be involved in those as well to sort of oversee what's happening. But from a non-regulatory perspective, but yes,

sandboxes, I mean, particularly given the pace of change in in AI, which is frankly bonkers, you know, it's um you need something like this. &gt;&gt; Bonkers, it's a very technical term in

the UK. um and and and also check out the UK's approach um in terms of governance in terms of the AI growth labs that that's now being developed which is a bit like a sandbox approach

but looking at actual the legislation the regulations the rules of the road and whether in a sandbox environment any of those need to change or need to shift because we are also looking at you know

AI is moving as we all know incredibly quickly and laws and regulations don't move incredibly quickly so how do you keep pace but but Sasha any view on that but also just wanted to come to you on

this kind of point about collaboration because from what I see um uh India is deploying AI rapidly right and scaling the deployment so rapidly which is amazing to see UK we've had that

pioneering practical AI assurance approach so there must be specific collaboration opportunities here um which could create mutual value and I'd love your ether um views from where

you've seen other things around the world that could work here or where do you think the opportunity is for collaboration? &gt;&gt; Question I know.

&gt;&gt; Yeah. Yeah. I've I've got some ideas. Um uh so I I agree with what Raj said earlier around you know I think ultimately the opportunity space for collaboration between the UK and India

crosses three areas. Ideally you want shared standards. You want shared skills and then you want shared like evidence evidence of meeting those standards. And if that is the overall frame then what

are a couple of specific problems that I think India is really well placed to help um chart the path forward for India but also for the rest of the world. The first is about trying to get clear about

responsibilities across the supply chain. Now I think in India it's entirely possible to have a use case that involves for example bad art GPT that is uh outputs from that are

integrated by Infosys into a system that's deployed in an agricultural context across India. So in that type of use case, it's really important to understand who needs to do what across

that supply chain and what is the evidence that needs to pass from one actor to the next to help them do the things that they uniquely need to do. Now actually globally there have been

you know initial attempts to try and define what a developer of a model needs to do versus a deployer of a finished application. Um but there are some really important open questions

especially kind of in the what I would call the messy middle. um you know what does um Infosys in that example need to do relative to the model developer relative to the system deployer who

needs to monitor the system in practice. So I think India because of its very um broad and deep um uh uh ecosystem in the tech space is is going to be really really well placed to help define with

clarity who needs to do what. The second opportunity in India I think is really making sure that we master the art of not just testing in the lab prior to release but testing in the real world um

on an ongoing basis. It has to be efficient and effective to do at scale. that India has such beautiful diversity in uh linguistic dimensions in cultural dimensions that it it really is the case

that you know the agricultural system deployment um in northern India is going to have quite different issues in practice than what it's going to have in southern India and so helping to find

ways to um effectively do that real world testing that post deployment um monitoring at a scale that is efficient and effective I think is a real challenge that uh India can help lead

the way on. So, we're going to come to some audience questions, but I'm just going to quickly ask my panel um for just some very closing thoughts from their side. And I'm going to give them,

you know, 30 seconds or maybe I'll give them a minute each, but um given everything you said, one piece of advice or one area that organizations should really focus on uh if they're starting

or thinking about their AI assurance. Natasha, can I start with you based on, you know, what you just said? &gt;&gt; Sure. So, I'm sure we've got many builders of AI systems in in the room.

And what I'd encourage you to do is to really think about assurance about how you create the evidence that people should trust your system as a product capability. You build it in from the

very beginning. Assurance, sometimes people think it's just a paperwork exercise at the end of the day. It's not. The best systems that deliver assurance are ones that have it designed

and from the very beginning and you can use AI to help too. &gt;&gt; Um, so I think really thinking about assurance as a product capability from the very beginning.

&gt;&gt; Yeah, we we've talked about security by design. We've talked about privacy by design. This is the age of assurance by design. There you go. Um, and you you can quote me on that. Uh, Raj piece of

advice. Um, I'm going to talk about Natasha mentioned a car earlier about airbags and brakes. And when I think about AI governance, I think about your company is the car and AI governance is

is the brakes in that. And a car can only go quickly because it has brakes. So when you're designing your governance deployment, you need to think about how are you going to materialize that in

reality in a tangible way. The companies that we see best moving fastest with AI are not the ones with the most sophisticated use case. It's the ones that have the most sophisticated or most

tangible AI governance workflow. If you go to somebody in your organization, you ask them, you have a great AI use case idea. How would you move that into production? That should be knowledge

across the entire organization. Identify the use case, identify the risk, mitigate it, and deploy at scale and continuously monitor it. &gt;&gt; To use the cup analogy, maybe it's it's

your headlights as well. It's knowing where you're going. Right. There you go. You can use that Raj if you need to. And then Tim um piece of advice and then we'll open it up for questions. So

please um put your hands up for questions. &gt;&gt; So the one thing I'll say is everything's moving very quickly but ourselves and others are putting a lot

of things out there for free to help people. So in terms of work that needs to be done around the EUA act for 42,0001 we've got guides, self- assessment tools, training. There's lots

there. So please look look to that. And also we're on the UK pavilion in exhibition hall 14. So come and have a chat to us as well. Yeah you are as well.

&gt;&gt; That's a great plug Tim. I'm also going to plug um the lovely Tess Buckley. Please wave your hand. So, she's um the mastermind at Tech UK um and with Lawrence as well, but Tess has been

writing a number of reports at Tech UK um particularly one that came out last year on AI assurance looking at specific markets and industries. It's a brilliant paper. Please go and check it out. It

should be available to download. Um but TechUK, we've got loads of material as well. So, we're really keen to help. Okay, questions, questions, questions. I'm going to ask you to Wow. Okay. I'm

going to for those online, you can't see all the hands up. We're going to go take a few at a time and we're going to try and do it quite um quickly. We did start a bit late though, so forgive us

organizers if we just go over a little bit. So um okay, Tess, let's do the best. Let's take these one. Okay, one, two, three, four. So can we take four at a time? Is that all right? Keep your

questions really tight if that's okay. &gt;&gt; One side only. &gt;&gt; I'm going to come to that side. Don't worry. Don't worry. Don't worry, I'm fair. Don't worry, I'll be fair. Okay,

go. &gt;&gt; Thank you. Mine's a very quick one. &gt;&gt; Okay, the microphone's not on. Could we turn the mic on? &gt;&gt; Can I take one of the microphones here?

&gt;&gt; Okay. &gt;&gt; Thanks for a great panel. Uh, very quick one for me. Uh, can we do 420001 using AI? &gt;&gt; Okay. Can you do 420001 using AI? Next

question, please. &gt;&gt; Hi, I'm Goautam. I'm part of Salesforce basically. So just a quick one on skills basically Nasha you touched upon very important pillar and then you mentioned

Raj about uh brakes and cars right and if someone basically who doesn't even understand what AI is and doesn't even understand the entire landscape it's very important for them to understand

which one is brake which is accelerator right so what exactly is tech largely maybe Sue can answer that largely is doing in terms of filling in that skill gap u and I have an nu as well which

works around alongside this uh particular thing so I'll probably want to touch upon later as well. &gt;&gt; Brilliant. Okay, let's come um Okay, let's go to these two here and then

we'll don't worry, we'll try and get through as many as we can. Thank you for keeping them brief though, sir. &gt;&gt; Yeah. Uh so I'm a research scientist. Uh and I think assurance is directly linked

with cyber security. Uh one of the key aspects of cyber security is that no model is going to last forever like they deteriorate. So when do the asurances deterate and how is there any policy

framework that can help us like you know have a sustained assurance metric some something like That's that's a great question and next please and then I'll take a few answers and then we'll go to

this side of the room. &gt;&gt; Uh so uh we actually implement uh use cases automation for SMBs. So uh we try to install brakes and headlights in the system before uh deploying the use case.

But uh I want if you can in uh talk in realities for example uh if I am implementing uh for a car washing center uh calling AI who will call after the service to the person how was the

service after 2 days and taking the feedback. This is a regular repetitive work we automate it for them as a deployment. So how we should uh approach we try to make it safe and reliable. uh

but from you guys I want to know if we can get any advice. Yeah. &gt;&gt; Okay. So any advice on how you do this in reality assurance and cyber security so deterioration of models how do we

deal with that skills? How do we understand the difference between the break and accelerator? Um and then can you use for um can you use AI for the standard? Tim should we go quickly and

then we'll go quickly Dan. We'll come over here and then we'll have to wrap it up. &gt;&gt; I'll be very quick. So in terms of um can you use AI for 2001? No, it's really

about trying to understand your organization, build it to your own risk profile, your own government. Did &gt;&gt; you just Oh. Oh yeah. Sorry. &gt;&gt; Sorry. So it's really about building it

to your own organization and governance approach. What is coming is a smart standards approach which means in the future when the standards will update it will update into the systems but that's

to come. Um in terms of the other question about cyber security so within firstly within the management system the approaches adapts to your organization and changes that's one side but equally

with the assurance infra infrastructure it means that you're regularly checked as well so it's not just a case of you get a certificate and that's it for life it has to be continual. Yeah, great.

Thank you. Raj, do you want to take any of the other questions that haven't been &gt;&gt; um I'll quickly touch on the skills piece and uh the the model visibility piece as well. Um in terms of skill, uh

your first line of defense is always your people. &gt;&gt; Yeah. &gt;&gt; And so that's the side of the coin that is the um pessimist, something's going

to go wrong. Your people need to understand the limitations of each use case that you put out there and know what is right and what is wrong. The other side of that is through effective

upskilling of your organization, you will realize AI benefits quicker and also identify areas where AI can be deployed effectively. So having that skills-based training in place, whether

it's internally driven or um externally is valuable for multiple reasons and every company should be doing that as a baseline. Um to the question on uh model retirement, model drift, um the way that

we approach it holistic AI is understanding the inherent risk of that use case. what are you trying to achieve the technology using to achieve it the data that goes into it and you bas you

benchmark your repetitive monitoring based on that. So there's email autocomplete. It's something that's not super high risk. You don't need to revalidate that system maybe once every

12 months. There'll be things that you want to monitor continuously. There's items you want to reassess every 3 months. that is should be formed part of your governance framework at an

organization level so that you understand what you're trying to achieve and everybody knows what they're trying to baseline against. &gt;&gt; Great. Thanks Tasha. Anything you wanted

to add on any of those very quickly. &gt;&gt; I think they covered them well. [laughter] I don't I don't know if there's one question from the side. &gt;&gt; Let's see what Let's see what's coming

up over here. Okay. I've got Okay, we'll start with a gentleman here and then um let's go. Okay. To So &gt;&gt; I think we're only &gt;&gt; one, two, three. Okay. So this gentleman

and then can we go with the lady here? &gt;&gt; Question. &gt;&gt; Pass on this to you. &gt;&gt; Okay. Very quickly. Thank you. &gt;&gt; Is my question my voice audible?

&gt;&gt; Yeah. I'm Subaraju here. My question is specifically for Microsoft. Uh as the quantum has become reality now do we require a paradigm different kind of a approach for AI assurance?

&gt;&gt; Okay. Different approach for AI assurance in quantum. We'll come to that in a minute if that's okay. &gt;&gt; But it's a good question and it's something we're actually exploring at

TechUK already. Go ahead. &gt;&gt; So I uh I identify high impact processes for SMBs uh US and UK and my question is with claude board and modbot you know uh you're talking about certification

you're talking about compliance and I uh like when the business owners want the high impact processes to be implemented and the technology is changing every day. you cannot control the guardrails.

Uh these boards are easily able to break that. So how do we propose something to them and implement when the compliance is also you know growing every day &gt;&gt; because it will take a hell lot of time

to use the use case wisely and make money out of it. So how do we do it? &gt;&gt; Okay, thank you for all your question. I'm going to have to hold it there. I'm really sorry. Um

&gt;&gt; we just have to hold the questions now. I love that everyone's curious but just for timing sake. Thank you. &gt;&gt; Sorry. Um so actually um that's probably for Raj but we'll start with Natasha on

the quantum. It's a great question and something in the UK we've been working with the national quantum computing center on responsible quantum and what we can learn from AI insurance into the

quantum world as well but please answer answer &gt;&gt; and look I think it is a fantastic question and there are going to be elements of our sort of AI governance

and assurance program that will very much carry across and there'll be new things that need to be added. Yes. and and some of the governance processes as well. And there will also need to be new

uh techniques and approaches built on top particularly as we you know um confront you know a sort of a a need to address you know whole new sort of cryptographic errors and challenges in

that space. So what I would say is that um while it it is potentially a pretty significant paradigm shift, we've had to navigate these waves already and we have to apply the same skill sets that we

used to move from traditional AI and ML to generative AI and now agentic AI systems. Actually all of these waves have required um new and different approaches. And so I think of I I think

of the um impacts of quantum as along a spectrum. In some areas they will be very very significant and whole new approaches will be needed but actually there will also be many elements that we

will just be able to strengthen and build upon as well. Um uh to our uh uh this lady's question in in the front row. Look, what I would say is that um it is the case that um you know unless

you have a baseline mandated by the law um uh not everyone is going to follow all of the responsible practices. We know that from past waves of technology that continues to apply here. Um but my

experience within Microsoft tells me that actually um you know good hygiene when it comes to upfront risk management is doesn't just response uh result in more responsible product. It actually

just results in a better product overall. So I would encourage you as you do this work to really find the business case champions of where the product has been both you know well designed to meet

user needs and responsibly designed and use those champions to help build broader awareness of why we do this work because the business value is very real. Um and while there might be, you know,

there might be instances in the ecosystem where um you know things are pretty fast and loose, I think you have to look over longer time horizons to see what is actually sustainable and

valuable in the in the medium and long term. &gt;&gt; Thank you, Natasha. We're going to leave it there. We've run out of time, but thank you so much for all the hands and

all the questions. Please can we thank the panel for Tim TJ and Natasha in the normal way and thank you all for being here. It's a real pleasure. Thank you so much.

Enjoy the rest of your day. &gt;&gt; Thank you.
