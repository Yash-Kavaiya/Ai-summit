# Digital Public Goods for Global AI Equity

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/70_734Iehvs?feature=share) |

## üé§ Speakers

- Mr. John Dickerson, Mozilla.ai
- Ms. Chenai Chair, Masakhane African Languages Hub
- Ms. Lea Gimpel, Digital Public Goods Alliance
- Ms. Urvashi Aneja, Digital Futures Lab

## ü§ù Knowledge Partners

- Digital Public Goods Alliance

## üìù Summary

This session examines the role of Digital Public Goods (DPGs) in advancing global AI equity, aligned with the AI Impact Summit 2026 focus on inclusive and responsible AI. As AI accelerates, access to AI resources and capabilities is becoming an important public-policy consideration. The discussion explores how open data and open-source tools enable context-sensitive AI ecosystems, drawing on relevant initiatives to identify pathways for expanding access to AI.

## üîë Key Takeaways

1. This session examines the role of Digital Public Goods (DPGs) in advancing global AI equity, aligned with the AI Impact Summit 2026 focus on inclusive and responsible AI.
2. As AI accelerates, access to AI resources and capabilities is becoming an important public-policy consideration.
3. The discussion explores how open data and open-source tools enable context-sensitive AI ecosystems, drawing on relevant initiatives to identify pathways for expanding access to AI.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/70_734Iehvs/maxresdefault.jpg)](https://youtube.com/live/70_734Iehvs?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

you know to just be discussing such an important topic at at a very timely timely moment when we're talking about AI through the lens of uh impact. Um so let me let me try and address your

question in two parts. One on the data desert and then what it means for uh how we democrat or how what it means for the kind of power um power dynamics and and for and for smaller players. I think one

of the big challenges in the Indian context is that a lot of the public data that we have um you know it sits in silos. Uh we don't have the provenence of that data recorded. We don't have

metadata for it. It's it's in different formats. It's in different uh languages and there isn't really any mechanism yet to bring all of that together. Um I think we also need to remember that you

know data is not the same like the data has to be collected for a particular purpose to be useful for that purpose. So if data has been collect if we have a lot of data from around transaction data

or social media data that data in itself is not going to necessarily be helpful for building an application in healthcare for an example or building an application in agriculture. So when we

when we're collecting data or when we have when the data that we have has not necessarily been collected or put together from the perspective of what we want to use it for and that's a huge

challenge also in terms of how that data has been recorded and and so on so forth. So that's one big piece of the uh of the problem and the second obviously is that you know we have a lot of data

that sits with private platforms um and uh again and they have collected it for a certain purpose with a certain kind of uh use case or a certain kind of end use in mind uh and that reduces the uh

usability of that data but this is also proprietary data and it's kind of locked away with private platforms and so there isn't easy access um to that to that data um so even though you know when we

think about India And we talk about India being a really datari country. When it actually comes down to a high quality usable data, there really isn't very much. So recently for an example,

we have the new national data sets platform something called AI Kosh. Uh but when you actually look closer, you see that uh there's very few data sets on there and the one that has been used

the most is you know been downloaded like 400 times or something which is nothing, right, for a for a country this size. and the the scale of the the startup ecosystem. So there's a huge

number of problems there and definitely having ways to open up data to have if if startups and other small entrepreneurs had access to uh highquality data that could be uh that

could be a very important step in kind of shifting that balance and creating new opportunities for innovation. um it would allow them uh to also build products that are culturally aligned

that are appropriate for the context that speak to the needs of the Indian population. Um but before I close I mean I just want to also caution like that alone in it in itself of course is not

going to be enough right when we we've seen time and time again that open systems are prone to capture and uh actors with more in with more resources more compute capacity more talent and

also just tech companies that have data sets across very different domains and are able to kind of collectivize that into a into a form of intelligence uh are at a in a much much better position.

So you know unless we think about the kind of political economy of that ecosystem while we're thinking about how to make data open I think there is actually a risk that we undermine the

very objectives that uh for which we're trying to make uh data more publicly available and uh accessible. So I think it's important that we do these things together and we don't think about the

kind of guard rails or the the issues around kind of misuse and capture as a afterthought. All right. Or something that we do as a next step. Um because that I think will uh undermine what

we're trying to do. &gt;&gt; Thank you so much. You already made a point that I wanted to make as well here on the panel. Namely that openness in itself is not an end um and we need to

complement it um with guard rails with governance structures um and so on. So happy to dive into this um also further along the panel. Um I would like to pass it on to Chennai. um you do work on

language data and one of the topics that uh comes up again and again is benchmarking um for African languages. Um if you look at evaluations I mean they are used uh to determine the impact

and usefulness of AI systems but for African languages specifically those benchmarks basically don't exist. Um what is the practical impact um on people in the global majority when AI

systems can't be properly evaluated because benchmark data is missing? Thanks so much, Leah. Um, so when it comes to benchmark data, I think there's from what is accepted as a standard if

you're looking at Helm or ML, MMLU, they are not reflective of the context and nuance of the African context. So in on the African continent, there are over 2,000 plus languages and these are the

ones we've counted so far, which means there may be more. And then also the fact that in those languages there's diversity and nuance by region by context. So the I speak Shauna the

Shauna that's spoken in Harare is not the same Shauna that's spoken in Mutare which is another town because there's a sub dialect and also African languages are quite emotive. So one word can have

several meanings and that is only captured by the way in which someone speaks that word and I think most of us can relate to this. So that's often missing in the um existing language

benchmarks. There have been efforts um on the continent particularly looking at Sahara for African languages and that's been started as a way to then benchmark um some of the languages that are out

there and then for us as Masakani African languages hub what we've actually done to respond to this is launch a request for proposals which was this year in January where we've been

trying to find people to benchmark 40 languages and they're looking at it from a speech perspective as well as a voice as a text perspective and in this way what we're trying to understand is which

bench benchmark approaches work and which don't and why don't they work because it's also trying to create evaluation solutions that understand context and nuance and also cultural

issues involved but as Uvashi mentioned the political economy around those um data sets creation or the evaluating work and so for us it's also that whoever is going to be doing this work

um will actually make these benchmarks reusable so that we don't always have to reinvent the will we build on top of what other people have already done and then so in that way we want the data set

the work to be openly resourced so that people can make use of it and also open for improvement because from a doing the work on African languages and generally global majority languages we have to

think about it from a sustainability perspective at the current moment everyone is interested in having tools developed in um global languages because you can't just have very there are over

7,000 languages in the world you can't just have a few of those represented um if you're going to have a product that actually works in market. And so then it's important that as we're thinking

about this, we it's actually led by the people from those regions rather than it being a solution that's transported to that region because then it'll always not work.

&gt;&gt; Thank you so much uh Chennai. And building on top of what is already existing that is exactly the essence uh of being open source and also of digital public goods. Um so um I think this this

part resonates quite well with us and of course the sustainability question and community-led um initiatives as well. Let's um pass it on to ya and um we are here at the AI impact summit. Current AI

is an outcome of the AI action summit last year uh in Paris and it was founded on the premise that the future of AI cannot be left uh alone to a handful of corporations. So it needs to be

communityled. need to have people on board um to do this um to realize the benefits of AI for everyone and um so I would like to ask you from your perspective what are the specific

structure problems that current AI is trying to address in the AI market and how can openness and digital public goods be helpful in this regard. &gt;&gt; Um thank you for having me Leah. Um so

yes uh current AI was launched uh almost exactly one year ago at the French AI summit at the AI action summit in Paris. Um and this was an important um uh feature because the summit didn't result

in just kind of charters and conversations. An actual entity was formed. uh and the goal of current AI is to uh champion and help build a vision for AI that is collective and that is

collaborative [music] and doesn't just represent one country or one company. And the reason that's important is multiple folds. So, you know, there's the obvious um reason that we don't want

all uh monetary gain to go to a handful of companies in the world. That's sort of like a a really obvious thing. But also there are issues around what direction is the world taking. So I

don't know if uh people have heard over the past few days there's been uh kind of a you could cherrypick a few scandals. So, uh, Ring, the the company, uh, the the the doorbell the connected

doorbell company, uh, put out an ad, uh, in the Super Bowl where they basically showed that their product was a surveillance camera, uh, surveilling every neighborhood in America and

basically recording you when you're on the street walking around. Uh not uh not a couple days, not even a couple days later uh we hear that Meta basically has decided that Meta Glasses um are uh

going to start doing facial recognition on every person that the wearer will encounter. Um you know a few weeks before that uh Amazon announced that Alexa is just going to start turning on

for whoever has it. So they just and you know no no decision you have to make the device that you have is suddenly uh um listening to you and sending uh data back. So the the problem with these um

with market concentration is that you have these companies that just have large swaths of people that use their products and they just get to decide uh uh to turn on a feature and change

behavior and are really affecting societies at large. And so we want to create kind of a different uh vision for AI, one where um people can create AI that works for them that that that is in

their language, that works for their community, that works for their needs. But in order to do that and in order to withstand the you know amount of money and uh honestly the lead that some of

these companies have, we we look at the fact that we have to all collaborate to make that happen. That means countries have to collaborate among each other. Uh governments have to collaborate among

each other. That means communities around the world have to collaborate among each other. That means that we have to really come together as public sector, private sector and philanthropic

sector to be able to build this sort of like collective uh movement towards a better vision for AI. So you know where does open source fits in? Uh obviously open source as um you know is is sort of

how we make the goods available and open and transparent and auditable. But for me the more interesting part of open source is uh open source as an ideology and open source as a methodology for

collaboration. uh open source as a way for very large groups of people to collaborate together on a common goal and to be able to see their own contribution within that

project to be able to make progress on that contribution to avoid duplication of work uh and to be able to share learnings that is the essence and the ideology of open source that's for me

what really inspires me so you know as an example I just took the role of CEO at current AI I uh not even you know a little over a month ago. Uh I come from Beirut, from Lebanon. Uh a country that

will never afford to have a data center. We don't have the physical space uh to be able to have data centers. We don't have uh electricity. The country constantly has power outages. We

absolutely don't have enough water for people. How are we going to have water for data centers? And so what does AI mean for a country like Lebanon? likely there's a lot for me for our country to

learn from countries for example like some of the ones that Chennai is working on uh with um uh in Africa who also are resource constraints. So how do we enable this collaboration where we can

think about what is common what is different what we can learn from each other so that the outcome can be better for all and our efforts can go farther. Thank you so much and I love your point

about uh collaboration. Yes, please. So yeah, collaboration that is really at the heart of the digital public goods alliance as well. Um because we are an alliance we have more than 50 members.

Uh Mozilla is a member, the government of France is a member uh and uh many others. So that really speaks uh uh to to the heart of of what we do and what we would like to see achieved by digital

public goods. Um in addition we also have the product owner community for example where product owners themselves also collaborate and um yeah with this I already mentioned the Mozilla

Commonwealth data set is one of the DPGs uh that is on the DPG registry it's there since 2022 um so for quite a while already and um so I look at you John um because Mozilla has been a champion of

um yeah for advocating for healthy internet uh for for many years now and we now talked about AI development but I also would like to uh quickly check in with you to see about AI deployment and

challenges around um how people can then actually make yeah use cases with existing AI systems, existing AI models and what is maybe needed there to close a gap. So

&gt;&gt; the very last part &gt;&gt; no I I um I would like to ask you about the deployment uh challenges of AI um that you see with um and that you address with Mozilla uhai.

&gt;&gt; Yeah. So uh at Mozilla AI we are trying to do basically what Mosilla did for the open internet 20 years ago now for AI. So, one of the things that keeps me up at night is, well, what happens if we

have this concentration of power? What happens if all of our data is flowing through just some small number of frontier labs? You know, do we have a world where the open internet as we know

it now just disappears? And some of this is also touching on what I was mentioning, which is, you know, we we like to build open source communities uh because these communities then allow us

to uh create projects in grass grassroots ways uh from various communities. Um and then we you know at Mozilla can help support those projects uh either monetarily or by you know

trying to bring the community together to push on new things. Um but at the end of the day uh it's all about uh the community building and then owning what they built. And so that's maintaining

open data that's maintaining open source AI dev tools that's maintaining open source AI models. uh you know one of my thesis for this year is that we're going to start seeing a lot more small

language models mattering again which means that we don't need you know orders of magnitude more capital than most people have anymore necessarily for some of these small models and I think the

community can come together and really build toward that now the question was about uh AI deployment and deployment is tricky um you know we have deployment using cloud-based services most of which

are blackboxes uh run by well a lot of the CEOs who are at this summit right now right we have I think Sam Alman from OpenAI here. Um that is easy to deploy with an API call, right? Um I actually I

often give a talk where um I basically make the case that open source AI needs to be easy to use if it's going to win. It's not just about model parity, it's ease of use. I have to be able to like

default to using an open potentially local model as opposed to going to chatgbt.com or to going to perplexity or one of these. And I find myself doing this even right I'm an open source

advocate but I still go to these closed source model providers from time to time because they're so much easier to use in terms of like user experience than open source models and so when it comes to

deploying you know there's the cloud-based approaches there's also local or on-rem and those have their own engineering uh issues you know for those of us who have been engineers here in

the room we know how much of a pain that can be that also means you need to have the knowhow to stand up your own infrastructure things like that but again I the the key point that I'd

really like to hammer home here is like if you're hearing people talk about deployment issues when it comes to AI, if you're hearing about people talking about not wanting to use closed AI

solutions, then the thing that we should all be doing as an open source sort of uh friendly community, right? Open source AI um in general is we should be working on sort of doing the boring

things as well. Not just model parity, but also like making it dead dead simple to be able to deploy things in practice, to be able to use them and so on. And so that's part of our mission at mozo.ai I

right now is really trying to push for this to be the easy default to do the safe thing which is using open source which is when you can using local models so you don't have Alexa turning on

randomly right I can I can run my own local model on my own local hardware and I control it that's my data that's not anyone else's we need to push for that to be easy to do

&gt;&gt; thank you so much John and [applause] um so we touched up on a few things market concentration the data desert um but also the well difficulty of deploying models and you you mentioned

um a few good things here around that it needs to be easy um that everyone can use it uh easily also localized um and um yeah fit for context uh let's say um you also mentioned owning data owning

your own infrastructure um could you just quickly walk us through about how this owning things connects to digital serenity and why this is so relevant for developers but also foreign nations for

instance at the moment. &gt;&gt; Awesome. Yeah. So I'll get to the sovereignty pitch here. Uh in fact I I don't think anyone has said that yet which is surprising for a panel that is

now about 20 minutes in. But when it comes to like a sovereign AI stack, when it comes to a sovereign open-source AI stack, ideally you would want that to go all the way down to the hardware level,

right? You would want to be able to compete against an ASML, a TSMC, a Nvidia, right? You want to be able to like go all the way from from hardware up into the application layer. Now

that's really really hard to do, right? There is only one of ASML. There is only one of TSMC frankly and you know every country is not going to be able to build that out. Every country shouldn't build

that out. So we do need to make sure that our governments are collaborating that our corporations are collaborating because you know I I don't think any country can be truly truly truly

sovereign in the sense from hardware all the way up to the app app layer right now. we have a we have a globally integrated society right now and these are very complicated companies. Now that

said, I think once you start playing around at the software layer, um, sovereignty becomes more doable, I would say, for coalitions of countries, right? India

certainly has the capital ability and the data ability and the skills to be able to compete at the frontier lab level. Something like the UK though isn't going

to have the capital expenditure to be able to do that. And so, you know, I think the quote is something like the entire R&amp;D budget for the UK is like half of what Amazon spends on R&amp;D in a

year, something like that, right? Um, so the UK, a country like that is going to have to partner with other countries if they want to be able to compete in that way.

&gt;&gt; I would maybe um agree with everything that John said, but I would say also uh the other side of the spectrum of sovereignty is individual sovereignty. So at the individual level, what does it

mean for you to have sovereign AI? Um I'm really interested in what in in how we can enable people to have their own individual versions of AI where the data stays with them, never goes on the

internet, is not compromised, is not surveilling them. Um we just heard a few days ago uh the US government is asking uh Reddit, Meta, Instagram, um uh Discord uh to release data on their

users and you know specifically who's criticizing ICE. So like you know you're you're you're compromised when you're using some of these big uh tools and services. So how do we enable

individuals to have their own uh their own devices? Um I spent 15 years of my life in the open source hardware space. Uh and so that's a frontier that uh current AI is going into. Um and uh and

our contribution to the space is trying to um be able to direct energy and resources towards uh you know engineering and technical projects that are not financially viable that a

company is never going to take on because they'll never make the money back or a country doesn't want to take on because there's not necessarily remuner remuneration uh for their people

but that we believe need to exist in the stack and so hardware as John said is a is a piece of it and an individual version of that uh is something that becomes important.

&gt;&gt; Thank you so much for complimenting this perspective. Um so digital sority for room actually. Um so when we speak about it we often mean nations but it can be much mean much more actually and it

should mean uh much more and this also provides an excellent bridge actually back uh to the data discussion and to how community get involved in collecting data um and also what they grapple with.

Um so tonight the work that Masakhan is supporting is communitydriven. It's rooted in community engagement and um we discussed openness already as a way of collaborating of mobilizing resource of

tapping into skills. Um and at the same time we also already noted that openness in itself shouldn't it shouldn't be an end in itself. So looking at the work that you do and also the DPG standard

which requires open licensing for instance of the resources that are vetted as DPGs. Um what are your thoughts around how communities can actually solve this tension I would say

between openness cultural soenity or community serenity if you want um and also compensation for creators. &gt;&gt; Thanks Leah. Um so uh yesterday we were on a panel and tension was used and

initially people were like ah tension is bad but one of the points that was mentioned by the speaker was how tension actually surfaces what needs to be done right. So if everyone is getting along

we're not going to put effort where there are gaps and where there's there's marginalization. So masakane actually means we build together in Isuzulu. So that is the premise of how we approach

openness. It's communitydriven on the values of uh Ubuntu which actually translates to my humanity is dependent on you or I am because you are and that's an African practice, African

philosophy that a lot of people have been applying to the way in which they approach social issues. I'm a sociologist by training. And so then this is something that when we're

thinking about openness and how community is involved, it's seeing the shared value of trying to build up on a resource that's missing because no one, you know, you can't wait for someone to

come and build it for you or the fact that you see the value in trust, trying to have your language represented. So I think starting off with how community can be involved. The story of Masakanya

is actually that there were people NLP researchers, machine learners who got together because they were being rejected from international conferences when they were applying for um work and

papers that tracked African languages. So they basically decided you know what we are going to come together and have our conversations and this was 2019 and so 2019 one of the language largest uh

African lang languages space didn't have as much African representation now because the masakan community has come together there is lots there are lots of papers co-written by people so that's

from a research perspective of actually then putting out the knowledge and challenging how people understand African languages so that's the first part And then the second part is also

determining what issue do we want to address. So you can't take a top- down approach with community engagement. You can't say you have to build X because uh I think it's important but you actually

have to consult with community to understand what is a priority and what needs to be built. So the approach then in that work is actually what we have an open platform. We actually even

currently have an open survey right now where we ask people what is it that you're curious about and what is it that you want to see being done by the masakana community and to emphasize that

the masakana community is just not technical builders it's sociologists it's um academics it's policy makers it's anyone who's curious and it's not just Africans it's open to the to

everyone so we have 3,000 people on our platform who are not just um from the continent but are also doing knowledge exchange particularly championing south to south collaboration. So that approach

of openness in terms of shared learning and shared knowledge is quite significant in how you get community involved in these processes. And then I think lastly it's the collaborative um

approach. I think Masakane has contributed to Mozilla Common Voice in terms of the different entities there who are actually then creating the language data sets and then the the

[clears throat] point around value contribution and paying people back because that's often a big thing is actually addressed by ensuring that um end users are part of the creation

process throughout. One of the things that we used to do when I used to work with uh Misilla on the common voice East African languages work was trying to figure out how do you

honor people's time which may not necessarily always mean paying them hard cash for contributing hours which some people then do but it has to have a data set standard um a set pricing standard

but it's also thinking what is the community need of so I often like to share this project where we had a we needed to have representation of women in the data sets which is often the most

significant challenge in that as much as you talk about community. There's often marginalized groups who are never part of the initiative unless someone is intentional about ensuring that they're

there. So women are often left out and so one of the things that we did was actually to work with the local social justice entity uh in Kenya that was supporting women with sanitary wear and

they simply said we'll contribute to the platform if you supply or help us buy sanitary wear that we distribute um boxes that we distribute to the women in this area every month. Now when we were

telling our funer that hey we are running a sanitary way project as part of our uh voice campaign they were like how does that connect right and we're like it connects because at the end of

the day this is what matters to the people who we are claiming to build the technology for but when you build with them you are actually building on the lines of value that they have and so

that's how you actually capture community and understanding what is important to them right now and then how do I meet them where they are? &gt;&gt; Thank you. I love this example.

&gt;&gt; No, it's it's such a fantastic point to really think about what the community needs and build on top of that build with them. Really one aspect that I would also tackle here Oashi is how

communities can work with tech companies. um because that is what you are doing and um Chennai talked about um the protection of women in data sets and bringing these perspectives in as well

and you do something similar in a way I would say with your work on uh gender bias and agricultural large language models. So um from a DPG perspective digital public goods they need to adhere

to privacy and laws they should be designed uh to do no harm. they must be designed to do no harm and um safeguards need to be built in to mitigate them. How is the work that you do um with

communities but also with the tech um uh tech companies um how is this informing safety and transparency and trust of AI systems? &gt;&gt; Thanks Leia. Um you know I think civil

society organizations play such an important role in kind of being that connective tissue between uh tech companies, global governance architectures and the communities for

whom we are eventually trying to create value for. [snorts] Um and you know and and the reason for that I think is that civil society organizations have a really unique vantage point in

understanding what is actually happening on the ground in understanding what that impact of that technology is and not just from a use case perspective not just in terms of does this product do

what it's supposed to do but also situating that impact in the longer kind of arc of that community the longer kind of arc of development initiative atives in that space and the longer and and and

a larger kind of discussion around what the broader kind of structural impacts are. So I think civil society plays a really really important role and and some of the work that we are doing is

trying to strengthen what that kind of connective tissue looks like and one piece that I think is really important which is some work that you know we're going to be doing with Chennai as well

is to be doing contextual evaluations of AI. uh you know we can't we don't think it's enough to be doing lab-based evaluations. We need to do evaluations of AI systems in real world contexts uh

and really ask the question that is this serving the purpose for which uh is is this serving the end the end goal for the community for the end user. So you know if we're building a chatbot for a

farmer is that useful for that farmer and what does usefulness look like for that farmer? So what we're trying to do is do these contextual evaluations and through these contextual and and build

through these evaluations the benchmarks uh to be able to evaluate these models and have the communities involved involved in building those benchmarks. have the communities involved in

building those benchmark data sets and I think part of um part of that is you know building these benchmarks for whether uh around questions around kind of usefulness or relevance and so on so

forth and then of course also around issues like safety um and safety is I don't think is something we can again understand in a lab lab context right safety is something that is very

contextual there's a lot of work happening now in the safety ecosystem around um you know testing models against malicious attack or malicious use and so on so forth. But in our work,

we've really seen that the biggest risks actually come from deploying these systems in low resource context among vulnerable populations where there isn't alternatives and there where choice is

not really meaningful and we don't have the institutional guardrails in place. So the safety risks actually come from use, not necessarily from malicious attack, right? They come they come from

the everyday kind of interaction. And so how do we embed that kind of understanding into the safety architecture that we're building and I think you know when we think about

safety you can think about safety from a kind of engineering lens but then you can also think about safety in terms of functional safety right so if you think about a car there is the engineering of

that car which maybe is the same model that is deployed everywhere but the functional safety of that car has to do with you know what is what is uh um what are the existing rules in in that

particular context so I think civil society organizations ations play a really important role in bringing that that kind of contextual um contextual knowledge. And so to bring it back to

the DPG conversation, I think that um this kind of evaluation work can help establish some of the baselines before we actually release before we actually scale and can provide that feedback on

how these DPGs are actually performing on the ground uh over a period of time and where the work needs to be done where that kind of maintenance work needs to be done or the the re

re-engineering of these DPGs needs to be done so that they're still serving the communities in a way that is reliable. and useful and safe for them. &gt;&gt; Thank you so much. Yes, lost, please.

[laughter] [gasps] So, um yes, thank you. Um I think this was really helpful to understand um how you work um with the communities and with uh the tech uh

scene as well. um looking at how to support these structures, how do we scale the work that you're doing and how do we make sure that we collectively are able not only to develop this

alternative vision for AI but also to implement it to deploy uh this kind of vision in in a real world uh context. I would like to ask you a how is current AI supporting these things? How is

currently II supporting public interest AI products, communitydriven AI products, open source maybe and digital public goods that yeah really cater to this idea of an alternative scenario for

AI. &gt;&gt; Um um so current AI is going to engage in three different um modalities. Uh the first one, the first pillar we call

fund. Um and that's a grant making function. We're going to uh give out uh grants to people who are already doing the work. So uh developers, uh nonprofits, small organizations, uh even

forprofits that are doing um uh work, shipping technology, uh that is open source and that is auditable. uh that uh that um attach us to the themes that we uh care about. Um the second thing is

second pillar is called build. So we're going to build our own uh tech. We're going to have a small team that's going to co-create and co-uild with some grantees and other partners uh so that

we can uh a uh invest outside resources in areas where like I said before there is no financial incentive for anyone to go uh but we can and b uh to be able to stitch together efforts that exist uh

outside in the world like whether in the stack or in the community and kind of like fill in gaps in between uh and then the third uh pillar is called invest and that's investment in architect in

infrastructure. So investing in infrastructure for the movement. So this this doesn't refer to infrastructure technical infrastructure um well it is some of it is technical but it's really

kind of community infrastructure more than anything uh so that we can enable this kind of cross-pollination of um of work um across uh across countries. So the example that I gave before uh you

know between uh thinking about what AI looks like in Lebanon versus uh in a community in Africa like that that's where that would work would would sit. Thank you so much for for sharing these

insights and I think currently I is such a great outcome of the Paris uh action summit and I hope that the um impact summit here will have similar great deliverables um that we can work towards

to together and my understanding is that they are working towards an impact comments which I think connects quite nicely to the DBG and openness discussion that we are having here on

the panel. Um being a bit mindful about time, I would like to make a little stop here and change gears. Um so I plan for a rapid fire session um uh with you for here. So basically one question and

short answer 30 seconds um if possible and um I will just ask you one question and um basically connecting and yeah feel free to connect a few things you said in a very uh concise manner. So

what is the onebold move or partnership we need to initiate this year um that would most effectively scale digital public goods and public interest AI for the global majority and I will leave it

open who wants to go first. &gt;&gt; Can I get 60 seconds instead of 30? &gt;&gt; Sure. &gt;&gt; So &gt;&gt; I'll donate my This is collaboration.

I'm going to donate my 30 seconds. &gt;&gt; Good. Good. Good. This is collaboration. Look at that. Um, two things. One is Mozilla likes to talk about forming a rebel alliance amongst nonprofits,

governments, communities, for-profits to build out the open source AI world that we want to see. That's one. That's not the alliance that I'm going to submit here, though. I would love to

see a new alliance which is every frontier lab across the world. Not just the US, not just China, the entire world commits to when they come out with like the nth generation of a closed model,

they commit to open sourcing the previous generation. So the N minus first. So for example, if GPT whatever uh gets upgraded to GPD whatever plus one, we see GPD whatever get open

sourced. And we would work as a community as well to put in appropriate guardrails to put an appropriate understanding of evaluation around that. But I think this is one way that we keep

open source models or at least open weight models coming out and that allows us to support uh sovereignty when it comes to open source AI and that's at the community level that's at the

corporate level that's at the individual level to Io's point that's at the national level as well. So I would love to see that second alliance of closed source frontier labs worldwide

committing to open sourcing. &gt;&gt; I have something. Can I take my 30 seconds back? Okay. &gt;&gt; Um I would like to call for people individuals not to uh fall into the trap

of the iPhoneification of AI. Uh so early so last year um Open AI announced that they were acquiring Johnny Ives company who created the iPhone because they wanted to create the iPhone for AI.

Uh and I think that uh we as a society are still kind of paying the price of uh uh of that um um that opaque um uh product that is finished and that we are all consuming and is consuming

us. Uh and so we get a chance and we get an a vote uh not to uh participate in the iPhoneification of AI uh by just not purchasing it when it comes out. And so uh vote with your money and uh don't

participate is my call. &gt;&gt; Yeah. So 30 seconds rapid fire. Um so for thing for me the biggest thing is and that's is our pillars of work at Masak is actually enabling a sustainable

ecosystem with southto south collaboration. The honest truth is that [clears throat] we can't do this on our own and it's important that we have sustainable nonp parachuting initiators

into these regions and also thinking about how do we have ownership of the way in which we are creating our own technologies and when we choose not to participate what else can we participate

in that still enables us to communicate and address the challenges that we have. Uh just a plus one to what uh Chennai said and also just to highlight that Chennai and I are both part of a global

south network for trust toward the AI that will be launched on Friday and would invite all of you to join us for the launch and help us build this alliance uh together because you know we

cannot we cannot do it alone for sure. Um, and I think, you know, just on on the other side of it, uh, while we invest in the open source AI ecosystem, I think we also have to ensure that

we're doing enough to kind of dismantle the existing structures of power because representation without shifting the balance of power can actually be more harmful and more exploitative. And so to

that end, I think we really need to draw attention to the frontier labs and ask them to have transparency about what their business models are. We made the mistake with social media. Let's not do

it again. And we really need to address the vertical integration of the AI marketplace. Otherwise, again, all these good efforts risk being consumed by um the existing dominant players.

&gt;&gt; Thank you. Thank you so much for sharing these points. And I as a moderator also have the pleasure of wrapping up here. And just maybe a few highlights uh from what

I have heard here um before we close it. Um first uh thing communityled trust and infrastructure. So it's uh really about openness as an enabler of access of safety and transparency and localization

of AI systems complemented by greas by infrastructure and by developments that are really rooted in communities. I think that was a very important uh point uh that we heard here. Secondly, to

fundamentally shift power, we need to take people on board. So, um shifting power just with technology with making things open is not going to work. We really need to uh look at how

communities are getting involved in these kind of developments and um bringing together different people to share learnings to build on each other's work. Um but also maybe to start new

alliances of even people that are not always working together, civil society, the big AI labs for instance, um but also policy makers and really help to scale up these efforts that you are all

doing uh here on stage to move basically from yeah technology access to technology agency and serenity for states but also for people. And lastly, digital public goods of course uh can

play a role in here. they provide an alternative pathway for these developments um whether it's through Mozilla's language data um with the Mozilla common voice data set or the

packaging tools that John um mentioned or Mazak and digital futures lab on benchmarking um these um initiatives are really demonstrating how we can collectively build um to make an AI

future that is not only serving a few but the many. Thank you so much for this conversation and yeah &gt;&gt; I mean shall we take [music]

&gt;&gt; [music]
