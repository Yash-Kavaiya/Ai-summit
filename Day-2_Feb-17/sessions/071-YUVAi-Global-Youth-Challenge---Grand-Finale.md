# YUVAi: Global Youth Challenge - Grand Finale

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:55 |
| üìç **Venue** | Bharat Mandapam | Meeting Room 7, Level 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/NjALPWUfI08?feature=share) |

## üé§ Speakers

- Sh. Mohammed Y. Safirulla K, Director, IndiaAI Mission, Ministry of Electronics & Information Technology
- Deepak Bagla, Mission Director, Atal Innovation Mission (AIM)
- Ivana Bartoletti, Vice-President, Global Chief Privacy and  AI Governance Officer, Wipro (TBC)
- Apurv Agrawal, CEO & Co-Founder, SquadStack.ai (TBC)
- Kirthiga Reddy, CEO & Co-Founder, Verix
- Jeet Wagh, Co-founder, Ideabaaz 
- Shradha Sharma, Founder & CEO, YourStory (TBC) 
- Kartik Suri, General Manager, IndiaAI Mission

## üìù Summary

This session will feature presentations by selected teams across three panels, showcasing their ideas and solutions. Each segment will be followed by jury interactions and questions, enabling deeper evaluation, feedback, and discussion.


## üîë Key Takeaways

1. This session will feature presentations by selected teams across three panels, showcasing their ideas and solutions.
2. Each segment will be followed by jury interactions and questions, enabling deeper evaluation, feedback, and discussion.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/NjALPWUfI08/maxresdefault.jpg)](https://youtube.com/live/NjALPWUfI08?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

and manage. Uh we are glad to support this initiative by helping define evaluation criteria and participating in the assessment uh with a focus on real world outcomes and usability. Let me

close by briefly speaking about another initiative that we have taken under the uh CAGS initiative. It's called A4I AI innovation and inclusion initiative. It's a collaboration between Microsoft

and uh triple IT Bangalore and the charter is to translate and build cutting edge AI technologies aimed at inclusion and then scale them up for at a population scale and be released as

digital public goods for everybody's use and one of the um there are many solutions that we are working on but one of them which is very apt to be quoted here is the work we do with one of our

NGO partners vision empower and that is creating AI solution for blind blind children. It is not just brain accessibility. We are enabling them to become proficient in stems education and

there is no content uh there is content there's hardly any content there is no methodology which is mature enough there is no pedagogy that is mature enough and we are working together with the NGO

partners and bringing AI into the whole mix so that a blind children not just is able to read those are the basic things which are anyway required but it can hope to become a graduate and an

engineer and be able to contribute from the STEM side of things. So we are getting good things and hopefully if that succeeds next year that case study will also be part of this case uh this

this compendium version two. Thanks a lot once again for uh uh having us here. Uh thank you. &gt;&gt; Thank you sir. Bringing together 18 deployed and scalable AI solutions. This

case book focuses on real world impact of AI enabling inclusivity and accessibility. The featured use cases demonstrate tangible improvements in autonomy, participation and quality of

life for people's with for persons with limitations. I request all accessibility companion partners and dignitaries on stage to kindly come on stage to join the uh to join the dignitaries for

launch of the case book. Uh after that we will proceed with the keynote address by Mr. Rajiv Sharma, joint secretary of DPWD. Could we play the video? Thank you dignitaries. Uh I would now

like to invite Mr. Raji Sharma, Joint Secretary, Department of Empowerment of People with Disabilities. Numerous. Namaskar, Jahind, Watram and to all the international uh

dingaries present over here. If any a very warm greetings from my country Bat. Ladies and gentlemen, this department for empowerment of person with disabilities was created in 2012. Is a

very young department of government of India and it has got many units out of which one is Alimco and we have got about 10 to 12 other units which are dealing with one or the other aspects of

persons with disabilities. So whatever I'm going to say here in the context of accessibility uh shall be construed in the larger context of disability. Friends,

um on 13th of December 2006, the United Nations General Assembly, they adopted the United Nations Convention for for the rights of person with disabilities and India uh became a

signary to this convention on 1st of October 2007. uh to give effect uh to to implement uh the status of being a senator to this convention. Government of India it uh

the parliament of India it enacted a masterpiece of legislation in the disability sector known as RPWD act 2016 and uh the UNCRPD uh has got eight general principles all

of which are mentioned in inter in the preamble to this RPWD act and out of these eight general principles two are accessibility and inclusion. So this conveys the weight which these two words

carry accessibility and inclusion and one leads to other and two are in that sense the two sides of the same coin. Ladies and gentlemen, when it comes to accessibility,

uh the department has been dealing with accessibility in the builtup environment that is buildings, the transport including the air transport, train transport and the road transport and the

accessibility in information and communication technology. Friends, artificial intelligence has a vast role to play in all these subdomains of accessibility.

Nowadays we are having apps. We wish to have more apps, more softwares which at the face value of it are able to tell you which comp which building is accessible or not

or which component of a given building is accessible or not. Whether it is the title ties or whether it is the slope of the ram or it is the condition of the handrailing or whether it is the

location and positioning of of the young toilet etc etc. uh the government's uh the uh government of India's resolve to this effect is also reflected

by a recent budget announcement by the honorable finance minister on 1st of February where uh the honorable minister was kind enough to launch one Sahara Yosna where the scale of production of

assisted devices was to be multiplied by a factor at least 10x times maybe analytics times. This uh scheme is going to uh encourage research and development and integration of advanced and uh

advanced and artificial intelligence enabled technologies. uh like when I made a mention of RBW act uh it is it is a right based act and uh although it's not a it's not a law class

but I'm telling you the rights means rights right to diagnosis right to rehabilitation and right to assisted device so here comes the role of artificial intelligence ladies and

gentlemen the uh when we are talking about inclusion we are concerned about the education employment, health, mobility, communication and independent living of

our the young brothers and sisters and artificial intelligence helps in each of these. Uh uh when when I said uh you must be remembering when I said right to diagnosis, right to rehabilitation and

right to assisted device. Friends, this RPWD act of government of India as a result of vision of honorable prime minister, it it increased the number of disabilities from 7 to 21 and uh there

are right now technologies developing and uh existing as a result of previous development which are able to screen which are able to uh give very early diagnosis of person with disabilities

who are suffering from one or the other disability including at the very early stage. age of childhood. Examples are like we have computer vision for navigation. We have speech

and language technology for realtime communication. We have got now adaptive learning tools for specific learning disability and neurodedevelopmental disabilities.

Technology friends may alone not suffice. So we need uh artificial intelligence which is able to uh which is um which can enable the univers the universal design of learning also for

the sake of education of person disabilities a design of learning uh which is educational framework for optimized teaching through flexible goals methods materials and assignments.

I'm happy to observe today that one of our unit Aleno uh that was a party to development of the case book uh the real world impact of AI in accessibility along with the other partners like

triple it Bangalore India emission and changing foundation we are right now finding the use of huge use of artificial intelligence in orthosis where we are using some

supporting uh equipment like splints for a person with disability having vehicle links Yeah, my second is there and processes where we are having we are where we are

able to develop artificial limbs by the use of technology including artificial intelligence. Uh ladies and gentlemen we have uh a group of disabilities which is on the rise as we are moving ahead on

the time scale and these group of disabilities are known as neurodedevelopmental disorders. It includes autism spectrum disorder, autism.

Another is attention deficit hyperactivity disorder. Okay. Attention deficit hyperactivity disorder. So like a very cool example I can give that if you are not listening to me properly, if

you are not paying attention to me, suddenly I start singing a song. Attention deficit hyperactivity disorder. Okay. We have got intellectual disability. We have got specific

learning disability. Somebody is weak in mathematics or English. Somebody uh reads 464 or does mistakes in spelling. We are right now having machine learning algorithms where whereby we are able to

analyze behavior patterns, speech profile, eye tracking and facial expressions to give the early signs to give the early diagnosis of a given disability. Indian initiatives including

mobile applications are there where screening is uh accessible not only to the uh professionals but also to the parents and the healthare workers in remote areas where which are normally

lacking the professionals. So that way artificial intelligence is uh not only uh leading to early diagnosis or early diagnosis but it is also leading to effective intervention

effective delivery of the rehab services that includes the personalized learning path and structured therapeutic activities. Uh we have got many of our national institutes as I told and

includes one of the part of one of the many components of the department. We have got very vious tools which are working day and uh day and night day in and day out with body like CDC where we

are developing uh to AI tools where the videos of children are used to identify the atypical patterns. The result is that the age of diagnosis has come down from 4 to 5 years down to 80 to 24

months. So that way early intervention we are able to do during the most neuroplastic period of the brain. Similarly, our national institutes are also working

with bodies like Detect for the cause of special learning disability with Gisha and the product is the product is uh one product is Gisha for special learning disability. We are also working with uh

bodies like infill where we are developing a platform for mental health diagnosis including early diagnosis or real time diagnosis of uh conditions like anxiety and depression. uh our

nursing students are also they have also been able to develop a platform known as eardia which is adaptable accessible e-learning software for children with autism and mild cases of intellectual

disability. Mild cases means the IQ is not that low. Okay. So and uh to uh to uh wrap it up uh I want to just uh place a word of question that whenever we are developing a software uh or artificial

intelligence tool whether it is India or in any other country of the world developed country or developing country we need to be cautious about the social cultural value of that country. Number

one, we need to be cautious about the ethical considerations like informed consent and we also need to be cautious about data privacy. So um uh before I leave the mic I just want to say

accessibility as I told earlier accessibility means I want to say that Thank you so much sir. With this we come to an end of the launch of six thematic

AI impact compendance. Before that I would like to welcome uh Vidar Ma who is the secretary of department of empower empowerment of persons with disability for her presence today. Uh

welcome ma'am. Uh thank you again to all of our dignitaries partners authors and guests for gracing this occasion. I would also really like to acknowledge uh Muhan G ak Pandi sir here uh a prajata

from changing foundation uh as well as panker zidi sir Amit pakage g from triple ITB for all of their very valued uh contribution that they've been doing uh you know behind the curtains uh we

sincerely appreciate the efforts and guidance of our partners in the development of these case books and we invite you to really engage with these publications digital copies of these uh

case books are now available online. We request that all the authors who have been featured in these case books can collect their physical copies to Ministry of Electronics and Information

Technology after the India AI impact summit uh commences. We will not be distributing any physical copies right now. Thank you so much. Uh with this we come we conclude the uh launch of all

the six case books on the real world impact of AI. Thank you. &gt;&gt; Sorry, sorry, sorry. Just uh just uh we have to give the entrance to the dignitaries. Please stay back on the

stage. And we work with the ministry six ministries after government. and information technology the government of India. I welcome you all

to the grand finale of UI global youth challenge. We are honored to have with us Mr. Deep Bagla who's the mission director at the util innovation mission. Dr. Anish John Paul program lead at the

utel innovation mission. Mr. Ranjit Goos, global chief marketing officer at Vipro. Miss Shraha Sharma, CEO and founder your story. Miss Kitika Reddi, CEO, Optimize GEO and founder AI Kirin.

And Mr. Gitwak, co-founder idea. I request all the jury members to please uh come on stage. &gt;&gt; Uh so Sha ma'am will be coming in another 10 minutes. She's just wrapping

up her previous session. &gt;&gt; Dr. I'll request you to please not. &gt;&gt; I would request our jury members to

please uh step up for the group photograph which will be a part of the momento of the AI impact summit. Should we wait for her to join? &gt;&gt; So, she may take like 20 30 minutes.

&gt;&gt; Should we do it towards the end? &gt;&gt; Uh, we can do that. It's a 3-hour session. Okay, we can do that and we'll do it later. While we wait for Miss Radha Sharma to join, I would also

like to welcome all the other esteemed dignitaries, stakeholders, and students who have been a critical component of UI and have been working towards shaping the future of AI. Launched in October

2025 in partnership with Nillet and Mayharat, UI is one of the three flagship global impact challenges that have been launched in the series of the AI impact summit. This challenge invited

youth innovators in the age group of 13 to 21 years old to submit their innovative AI solutions for empowering people and communities. We received over 2400 submissions and with the support of

our partners at Intel India as well as evaluation support from top industry experts, a rigorous multi-stage evaluation process was concluded. And today we have with us the top 20

finalist teams including students from as far as United States, Thailand and Indonesia. I would now like to invite Dr. Mr. Deeper Bagla, mission director at

Innovation Mission to deliver the opening address. Thank you. Morning. This is the most exciting session of the day and it's not about my keynote. It's about the people.

What you will see and hear the ideas today. These are the ideas which are making India and making the world. So thank you everyone for being with us and I have really have to thank the entire

judges who have taken time to be with us. I think Shreddha is going to be joining us shortly. But truly you know just imagine started in October 2500 plus applications and ideas and frankly

to my mind each one of them each one of them is a winner. We will actually be following up with all of them to see how we can work with them. There are certain aspects on which I think the jury will

be looking at it. Keep me out. This is going to be the most difficult job today. But uh it's not just the 20 who will be today looked at in a different manner where the numbers are given out.

But I think we would look to work with each one of you in this effort. And what we are now witnessing is a new beginning of a new world in many ways. and the makers of that new world are

sitting in this room today and we'll be presenting to you. So I will be short today the day belongs to all of you. So we'll be waiting to see and learn from all the ideas which you're bringing to

us. Thank you. &gt;&gt; Thank you sir for your motivational address. On that note we would now proceed to the finale presentations without much ado. The 20 themes that

we'll be presenting today have been organized in six panels of three to four teams per panel. These panels have been curated according to the themes of the solution ranging from healthcare

assisted technology to uh road safety. Each team will have only 5 minutes to present. Teams, please note a buzzer will be played at the end of your 5-minut timeline. We request you to

adhere to the timing guidelines. Exceeding time limits may attract penalties. I would now like to invite the first team of panel 1 UI 14258 to please come

forward and make their presentation. I hope audio is working in the presentation. You'll have a photo. Yes.

Uh tech team please can provide support. Audio text check could be ready for you. &gt;&gt; It's here. It's not present. Okay, it's here. Take &gt;&gt; audio.

Thank you. &gt;&gt; I can take the mic. Okay. &gt;&gt; Um, I'll just speak like this. I can start. &gt;&gt; Okay. Hello everyone. I'm Tri, founder

of Paris speak. Listen carefully. Okay. So, the audio was only on the laptop in this case or &gt;&gt; we'll wait. Don't worry. &gt;&gt; We'll wait.

&gt;&gt; Thank you. &gt;&gt; Just fix this for &gt;&gt; Thank you so much. &gt;&gt; closer to the speaker. &gt;&gt; Understood.

&gt;&gt; Move the mic. with this. The PBT has closed. This price also &gt;&gt; that's all right. I also brought some uh speakers in case that would be

&gt;&gt; there's no rush. Our kids are very different. &gt;&gt; Did you understand? Anyone? Neither did I one and a half years ago. Over 650 million people

worldwide face voice and speech disorders caused by conditions like stroke, paralysis, Parkinson's and more. I started with disatria and tresbonia conditions that remain largely

underserved. The question is can we enable a full range of communication for these people by converting their impaired speech into clear speech. Introducing uh sorry existing solutions

are speaker dependent English only and inaccessible to those who need them most in both cost and form factor. Introducing Paris, a pocket-siz device that can convert impaired speech into

clear speech on a real-time basis. Remember the voice in the beginning? That person had disadria, a devastating motor speech disorder causing slurred speech. Let's hear what they were

actually trying to say. It feels incredible to see someone so happy to hear their voice back in a way everyone can understand. So how does it work? Press the button and speak. The

speech is then processed by advanced cloud-based AI models. Building these models was a long journey from collecting the largest database of Hindi desertic or slur speech to creating a

high accuracy framework that works even with limited data. Then clear speech is played back on a near realtime basis. This framework is patent pending and PAS speak is trademark pending. But there's

more. My goal is to scale PASE across many kinds of voice and speech disorders. Here's another demo with the same tech. This time a patient with press bifonia where the voice weakens

with age. Hallelujah. Paris Peak is portable, affordable, India first, accessible and designed to improve quality of life. My journey

started one and a half years ago in grade 10 when I went to a care center and met people who could speak but could not be understood. Then I got to work work that won both national and

international science awards representing team India supported by the government. Paris speak made the national news soon after in October I was selected to present at IIT Delhi's

empower assiste research conference as the only high school researcher and and recently perspe was named the national winner of Samsung sol for tomorrow with received grant from Samsung as well as

an incubation at fit I Delhi ps currently stands at technology deadless level 7 with extensive demos completed now we have already launched a larger data collection program and are

currently developing veloping a market ready version of Paris speak software and hardware by mid to late 2026. A clinical trial for um CDSU certification and other regulatory approvals will

begin and by early 2027 devices are planned to reach the market. I'm on a mission bringing PE to those who need it most. Revenue will come from device sales rupees 2,000 per per unit plus a

rupees 200 monthly subscription. Paris speak can also power public communication counters and other assisted devices through an API so that they can also understand impaired speech

commands. Institutions including government ones can sign multi-year install and support deals. All right. I have completed data I have completed data collection and testing at

two associated care centers and I hold letters of interest from more institutions and neurologists including over 100 people who signed up on the weight list on their website. What

Paspig needs is clinical partnerships, resources, and funding, and a motivated team. I'm ready to bring back the voice of those whose voice can't be understood. Let's embark on this journey

together. Thank you. for the entire panel post three presentations. I now invite uh UI 9405 team to make the second presentation. &gt;&gt; This is a place to keep our laptops.

I don't need that. You need I just keep it here. I would need it for the Ready? &gt;&gt; Yeah. &gt;&gt; Good.

&gt;&gt; Right. &gt;&gt; Okay. We've all seen elevator buttons with these random dots at the bottom. We know it's real and we know it's used by the visual impair to read and write. But

the one question we ask is how do they read it? The same question my partner man and I've been asking each other is perfect because there's more than enough teaching force present in India teaching

the visually impaired bra. This is India's biggest education and market gap that we notice and we are here to fill in. Judges we are V stands for variable assistant for your vision and we bring

learning to simple gestures. We are the first and only once in the entire variable assistant in uh India and we are the first and only ones in the entire global market segment of hearty

braille. Over here as you can see we use is a pair of variable gloves which has six flex sensors in total to mimic a traditional brail cell. This is our

first prototype and our latest prototype is as shown here. Show &gt;&gt; this is our latest prototype here. &gt;&gt; This is our latest prototype. It's ready

to market and as you can see in the images here it's the faces are blurred out for ethical reasons but we are already testing with multiple brand institutes not just in Delhi but also in

Kolkata lighthouse Kolkata and DRU as you can see here wave has six flex sensors to mimic a traditional brail cell and when I f my finger when I flex my

finger the voltage on these sensors fluctuates this fluctuation is recognized as a gesture which maps to my database of my alphabets the database then moves to my website that teaches

you entire braille as I mentioned the biggest problem right now is the lack of teaching assets for normal students a teacher can use lot of assets like YouTube video or other teaching assets

but for learning braille it's a lot more difficult of course reading brail is like so but learning brail requires a lot of onetoone attention which is not easy to pay for a class size of 30 and

that is why we built wave that takes over the entire learning process of brail not just that but it also scales to a corporate setting right now we'll give a quick demo I request one of the

jury members to volunteer for the demo. &gt;&gt; Yes, of course. &gt;&gt; Okay. And what are we going to do? We are going to use

&gt;&gt; as we prepare our uh ST jury member for the demo. I'd like to add that we have successfully filed our design and utility patent for India and we are also building a Japanese rail prototype with

collaboration with the Japanese government for Japanese rail and this marks a significant landmark because we want to scale not just in India but overseas man and I we both come from a

Middle Eastern background she's from UAE and I'm from so we have a very solid network already built for Middle East we are spread into the Southeast Asia starting with Japan but our first motive

is to start with India and as you mentioned we are we are made for Bhat and we are made in Bharat. So our first point of action is to build into Bharti Bale and right now our prototype

features Hindi, Tamil, Hindi, Tamil and Malaram for Bharti Bale. Right now we'll quickly show here show the demo here. &gt;&gt; Yes. All right.

&gt;&gt; All you have to do is listen to the interface and do what is the going to talk to you and you have to just listen to what

No problem. &gt;&gt; Just keep it. &gt;&gt; Can you flip the volume? Can you show the screen to the people?

&gt;&gt; That won't be possible. &gt;&gt; Oh, yeah. That's the demo here. Okay. I I'll just wrap up. &gt;&gt; Please select your language. Say English or Hindi.

&gt;&gt; English. &gt;&gt; So, our website features two modes in total. There's learning mode and practice mode. In learning mode, the user learns alphabets from A to Z and

numbers from 1 to 100. For every incorrect input, my website says, "Hold on, you're not exactly wrong, but if you make these changes, you'll be absolutely correct." This is very crucial because

the we are building something liber. Your input will only be recorded after the two trigger beeps. We'll start with learning mode for letters A. &gt;&gt; I just want you to exactly

hold both of them together. Okay, let's see what happens if she does it wrong. This only time is over. &gt;&gt; But finish your demonstration. &gt;&gt; Okay, so now when she did it wrong, when

she did it wrong, we're going to do it again. So &gt;&gt; let's say what's the second? Let's go to practice mode. &gt;&gt; Switching to practice mode.

Your word is cattle 4 C both one and four. &gt;&gt; Now just &gt;&gt; so now we showing a quick demo of our product here. Uh Miss Ready is trying it

out and you can see she's in practice mode. She's learning Braille right now and we'll quickly show what the reports are if she needs some improvement in any of the finger mappings which is very

important for a instructor to know. The biggest gap in education right now is the teaching assets which is what we cover. A a supervisor or an instructor just needs to click a single button and

we take over from there onwards. We teach, we give feedback and the entire model is voice control. So you can give a voice command saying stop, start or how am I doing and it gives you a

complete feedback of how you're doing and where exactly can you improve. Not just that, but it generates a complete comprehensive review of how you performed, where your mistakes lie and

where can you actually improve for the instructor to tell. This is the best feature so far for the teachers perspective and we received a very good response from the teachers

around the PU and the lighthouse in Kolkata. They are very eager to use our product and we are already receiving orders for them and I think Yeah, just to show the other you also

added. So you add the so there's learning and practice. &gt;&gt; When one senses sabotage, your other senses are enhanced. When your sense of vision is sabotaged, your sense of

hearing, your sense of touch, and your ability of speech is enhanced. The same is utilized here as well. Your sense of hearing is utilized by adding a buzzer and an interface that talks to you

constantly. Your sense of touch is utilized by adding a glove that gives you complete authority of control and button vibrators that beep through naturally using haptics. And lastly,

your ability of speech is utilized by giving you a complete freedom of speech with interface. You can speak in your mother tongue and it responds back to you. So this was wave and we are happy

to announce that we have already filed our patent successfully and we are building a prototype in Japanese whale as well. Thank you. Oh, sorry. Yeah,

&gt;&gt; thank you teamasm. Please uh we shall all try to stick to the timeline so that all the 20 teams have a fair chance to present. Uh Julie members, our third team is UI

3536. Uh unfortunately, they're still stuck in the security process. So we'll be moving to the fourth team for the next presentation which is UI378. Technical team please play the fourth

presentation 1378 please. &gt;&gt; Hello Am I audible? Yeah.

Okay. Good afternoon all. Uh myself Anikit Kilikar and this is my teammate Nik. Imagine a consultation with your doctor where doctor is focusing directly on

your patient. He's chatting with you. He's talking to you. He's reasoning well and not going through all the documents that are that you are presenting to him looking for the information that is

specific to you. It's not just about imagination. That's what Ara little enables. So before understanding how it really works, let's understand the problem and

the gap that is there. Today the clinical expertise in the uh India is heavily concentrated in the metro cities. what remains in rural India is just a single single doctor clinic where

he has to manage everything from taking the notes to uh prescribing the medicines but that creates multiple challenges that doctor to ratio in the rural India

is very high and that gives us very less time for the doctor to talk with the patient it's about 1 to 2 minutes so what happens is patient doctor has to just react to whatever the patient is

telling And this problem cannot be really solved by adding more of healthare workers because healthare workers with with time move tend to move towards retire cities

only for better pay and better lifestyle. So the only solution to this problem is how do we really empower the ones that are really on ground in the rural India and to solve that thing we

are creating AI but in this uh India's digital infrastructure digital public infrastructure as well as the policies are very interesting and they are very aligned at this time right now India has

built ABDM the Aishman direct digital mission which really has digitalized around 80 uh 80 A raha health IDs and digitalize 67 crores of health records and with time in 1 to 1.5 years in

states like Maharashtra or Tamil Nadu the adoption of these health records uh digital abha will be very high but there is still a gap the slide

there are solutions like akab which are really doing digitization of the documents but the gap is if we just digitize all those documents and dump it to them on laptop firstly they don't

tend to use new tools and if we give them that in digital form instead of paper there is no use so there is a gap then there is a need of a system that can reason over all of this data and

present to the doctor and exactly that system is during our discussions with the doctors we noticed something really interesting specialist setups there are juniors and

assistant that are helping the doctors so before even you enter the given of the patient. You have already gone through two to three cable of juniors where you have been done the preliminary

assessment and everything and on paper the specialist just sees whole case and the thing uh that is suggested by the juniors he just revises some things and suggest them. Our vision with Aragi is

that one doctor plus the system that we are building with Aragi should be really equivalent to the reasoning capacity of entire specialist setup. Let's just see that in action.

out before the consultation even begins. AI before the consultation AI captures the patient's concern in natural language and structures it

automatically so the doctor's time is spent on decisions data collection within seconds the doctor sees a clear overview of the case every traceable sources

The doctor interacts naturally, asking questions, exploring context, and guiding the system. Prescriptions and investigations are generated instantly and delivered

securely to the patient through AD. At first when we showed this idea to the doctors, they were really skeptical and they thought, will this really work? But after showing this UI demonstration they

were like if implemented correctly then this can really solve a lot of problem that this face every single day. So RA is built on three primary pillars that is ABDM native SLMs and evidence based

fact. So our system is already a has ABDM integrations and based on the consent of the patient we plug in the data into our systems. We have specialized SLM models so that we can

scale to to across the country uh in to also to the rural places of country. So evidence- based right helps the system to answer based on the facts and not just on the based knowledge.

So early diagnosis becomes the default not a privilege. If preventable deaths become treatable conditions because every doctor everywhere reasons with special intelligence. Hence we work for

welfare for all happiness for all. Thank you. &gt;&gt; Thank you deans. Uh Judy members we are open for the query. &gt;&gt; Where are you from? I am from

Maharashtra. Can you just speak? &gt;&gt; Do you guys have a demo? Do you have a demo? &gt;&gt; Yeah, we have a demonstration but we

avoided it because of the time &gt;&gt; uh jury members we are open for queries. So for the three teams that have presented in case there are any further questions to the teams please feel free

&gt;&gt; testing. Yeah. Um so one phenomenal just phenomenal phenomenal to see the clarity of um both the problem identification as well as the innovation that you're applying. I guess my question is for me

starting with the first presentation Paris Paris &gt;&gt; Paris you know so I guess two things one is there is a little bit I know you said it's real time translation but there is

a bit of a actually there was a timeline I'm curious how you think about closing that timeline that's one two what was the hardest challenge in solving the problem

&gt;&gt; so um for number one uh currently the AI solver which I like the model I built is running on my laptop as a so the hardware device communicates with my laptop which then clifies the patient

sends it back but in um in a future deployment and as most professional AI models are deployed uh it'll be put on the cloud um I've already tested it on AWS and Google cloud in both cases the

lag time has been reduced around 5 seconds to uh 2 to 3 seconds um so once I deploy it over there finally then even the device will be able to translate pretty quickly uh so the latency will be

reduced uh the second question um the hardest challenge I would say was uh thank so the hardest challenge I would say came um with the hardware. So when I went to the care centers and repeatedly

tested my prototypes uh the feedback I got from the patients again and again took me through all of my prototyping iterations. So I definitely spent a lot of time on that trying to create it in a

very accessible manner so that patients even if their half their body is paralyzed they can still use the device properly. I have a question for

&gt;&gt; I have a question for 13788. Yeah. Just tell me about um while I understand that this is um those you know more equipped for doctors who are in remote

areas likely right that's that's the proposition that you've made. um when they are transferring data back what kind of associations do they have with urban centers the interpretation of the

data so what are the what are there any particular urban centers they're sending it back to are there any um healthcare networks that you are trying to tap into and uh what is the what is the specific

connection or understanding between them because what I'm really talking about is how do you bridge a connection gap if at all one exists. So ma'am this specific question we don't

need to tackle. Government of India by NSA has already tackled this problem. They have built a full opensource digital highway for the data of medical records by EBDM Aishman digital mission.

&gt;&gt; Okay. So they are providing us the whole data and whole data travels to their APIs to us and it is based on the consent like how we do in Diatra or DY locker 7 days we get the access of the

data same way it will be implemented in the system and when pushing back to the patient it goes back to again the ABDM where it is logged into patients ABDM account and if he even goes to chains

like Apollo if Apollo is registered with ABDM they can access that data and if a primary clinic is there they can also access the same data that is pushed by Apollo to the EVDA but it depends that

if Apollo will give that data or not that's a different okay and this also should ensure uh patient privacy yeah for patient privacy ABDM has already done something like red access and name

and all what you get is just the primary pointers like a and and it's like same like a case study a textbook case study that you will get the AI will process it as by SLM locally only. So what we are

planning is using frameworks like ARM and all those things it can be done on device like this if government provides uh good type of infrastructure in the hospitals that government hospitals it

can really be deployed fully locally so data never comes to us. &gt;&gt; All right thank you. &gt;&gt; Thank you and great presentation all of you all the three. Thank you.

Hi, I had one question for Paris speak. What is the acc how varied and deep your data set is right now? What you're training it on and how accurate is it right now?

So currently um over the past year what I've been able to personally collect is about 45 minutes of data from 28 patients and these patients have varied conditions from Parkinson's to paralysis

to CP congenital disorders and more. uh the insilico accuracy rate of my model is about 96.7%. I also conducted a real life pilot test with around 11 patients and the accuracy

in that pilot test varied between 80 to 95% depending on how severe their speech disorder is. &gt;&gt; Yeah. Thank you. &gt;&gt; And I have the exact same question for

the for one no the second 9405 &gt;&gt; on the on the accuracy. Raise your hand please. Mom,

&gt;&gt; could you repeat the question once? &gt;&gt; No, it's the same question about the accuracy accuracy of the M. &gt;&gt; So we we tested with around more than 120 students not just in Delhi but also

in Kolkata and we recorded above 80% of retention rates compared to traditional braille using braille devices. Our accuracy right now stands at a 97.3%ish because the sensors which we use are

very cumbersome. If we buy high grade sensors, it's definitely improvable. But right now, the biggest bottleneck we are facing is the funding. So any funding we get from here will be directly supplied

into the supply chain and production level uh you know uh production &gt;&gt; and do you think monetization or like how is it that you're going to take it to market?

&gt;&gt; Yes. Yes, definitely. So the currently our competitions are the traditional braille keyboards which have six prongs in total like a traditional braille cell and they starts from uh they start from

45,000 onwards and you can search it up. Our product right here it cost us 99 9,700 and if I build it in bulk I can create it within 7,200 to the dot. So it's a landslide price. You compare it

with 45,000 to 7.2k. It's a landslide price and we really believe we can uh you know scale over there. There's a huge gap in variable haptics and we are fixing that. Thank youelcome

members if we have your permission we can move to the next panel. Uh I'll also request for the ease of logistics that the students who are uh presenting and are applicable for the

query round please come forward uh at the time of jury questions. We move to UI1036 uh presentation number five. Just

&gt;&gt; hello. Hello. &gt;&gt; Uh I would also like to thank uh Deepak S for his valuable time and for sitting through the first panel of presentations.

So it's unfortunately tied to another panel but we have Dr. Anish with us who will be representing the adult innovation mission. &gt;&gt; Yes. Uh

uh photography team can you request for a group picture please? Join us. Join us. Join us for the picture. &gt;&gt; That's you. Happy birthday.

Yeah. No, no problem. They're doing such a nice job and you want to Yes sir.

&gt;&gt; Hello. Good afternoon everyone. Um let me begin. There are about 910 million population in India living in rural areas. Out of which 65%age of the people have lacks lack of access towards the

healthcare. These people faces shortage of specialist and so they need to travel long distance and also uh they they need to sacrifice their daily wages and also they don't have proper awareness about

which doctor to consult and whether the doctor will be available at the location or not. In order to uh provide in order to provide this information several tele medicine platforms has been introduced

but it doesn't adopted among the rural areas to uh and this is the exact problem we are trying to solve with our solution. Hey, Medicare is a voice enabled AI powered tele medicine

infrastructure platform. You for this you don't need to install any apps or you don't need to open any website. You just need a basic feature phone. From that you can able to call our agent and

our agent will handles perform an A2 and gives awareness about whether you whether the patient needs a doctor consultation or not and also and also it says which doctor to consult and it also

calculates an agency score. Based upon it, the doctor can able to easily prioritize the patient with high medical emergency and also it books an appointment uh for the patient in the

nearby location. Let's let us see how our solution works. First of all, the patient needs to visit the nearby public healthare centers ories to make a call to our toll-free number. From there our

voice interactions are captured from Twilio and a fast websockets and those audio streams are sent to text to speech speech to text transcription and those transcription are sent to our manager

agent which is powered by langraph which orchestrates symptom analysis agent and booking agent. The symptom analysis agent works like it it first extract the symptoms from the user query using name

entity recognition which is done by bioclinical bird and from that symptoms a semantic search is made into a recctor database to uh ask uh relevant symptoms as a questions and based up these

questions are repeated these questions are asked until and conference in the emergency score is reached. Once the agency score is calculated properly, the queries are redirected to the booking

agent and our booking agent will uh easily segregate the users whether they are having a life-threatening situation. If they are having life-threatening situation, their queries are handled to

the ambulance and uh for not life-threatening situation uh it is handled in a smart priority queue in which the patients are arranged in a uh arranged in the order of their medical

severity and to uh then for booking based upon the the agent will ask an pin code from the user and based upon the pin code it fetches the nearby hospitals and it uh tells the patient and from

that the patient can able to easily book the appointment. We used the MCP servers so that we can able to easily scale new tools into our infrastructure. Let me explain the implemented plan of

our solution and for pilot deployment which was semi- urban area with 10,000 users. Our estimation cost is around 40 to 45,000 per month in in rural area.

Our expected revenue streams are governmental partnerships, CS CSR funings and the hospital subscriptions. In rural areas multilinguality provide a major impact for providing that

multilinguality call it cost us around 2 rupees per minute. We assume that every patient will speak 3 to 5 minutes in that call making it highly affordable. While expanding it

across villages we store the patients conversation with their concerns and we we fine tune our model to make it more accurate. We we designed our architecture to handle multiple calls

concurrently. Let me show you a quick demo. You can remove. &gt;&gt; Hi, I would like to book an appointment with the doctor.

&gt;&gt; Please provide your sixdigit 61 04. Please let your hospital looking Hospital 2602. Appointment successfully

standing 2026 2 item 747 ft 3 ft. As you can see that the patient can able

to easily book the appointment and it is reflected into the doctor dashboard. Uh tech team, I request for mic access on the podium. Thank you, Anit. Do you remember

members? We now move to the next presentation uh UI 2326. This is our young team from Thailand. How do you feel? &gt;&gt; Right. So, first of all, I would you can

use the clicker model, right? You don't touch. Sure. This is your presentation, right? &gt;&gt; Yep. How do you feel if your loved on is

diagnosed with cancer, a completelyable disease? It's so sad that globally over 300,000 women die each year. related to cancer. Yes, because cancer

cytoke is the first innovation that protects your mother, sister, and the loved ones from cable cancer. That was a short video of the summary of our problem and solution.

So, we tested our system at two cancer centers in Thailand, which works in three simple steps. First of all, our takes a picture of all the cells in the slide and uploads them into a into

the website and the AI to do the analysis. Now, the results are the process ends immediately. Here is a video of us interviewing uh a negative patient. Now

if the case is abnormal the case will be forwarded to a pathologist who then completes the diagnosis. Right? So as you can see here uh our system has already completed the

diagnosis but the old system uh the case still hasn't reached the first psychologist yet. Within 6 months of waiting, women can receive their results in one day, which means they can have a

chance to start treatment immediately. Right? So, Psycho Scanzee is fully scalable to uh over 162 countries because it uses an international data set and we have also tested our system

at two cancer centers in Thailand. And our workflow aligns with the WH's uh goals and standards. Right now, our system has been copyrighted and patented and has received support from both

government institutions and businesses. And next, we plan to scale our system to be able to diagnose HPV related cancers other than cervical cancer. And we also uh have a business plan that

was created by discussing with the Northern Cancer Center in Thailand in order to reach 162 countries. And here's a video that shows our full expansion plan.

First, we went to the northern cancer center system. Next, we went to the southern cancer and tested our system there.

Then we will plan to expand our system to five more cancer centers and the National Cancer Institute in Thailand to protect 4 million lives. And finally, we will expand to 160 countries and 1.4

billion lives all around the world. Cytoscanzi can reduce the waiting time from for cervical cancer from 6 months to just one day and reduces the cost of equipment from

uh by 5,000 times making it accessible to most countries. And next we will create the first cervical cancer data center to increase our AI's accuracy and uh teach future specialists. And

cytoskanzi is sustain is environmentally sustainable because it is able to reduce transportation and is socially sustainable because it can be used in all local hospitals. Finally, CYOS scan

aligns with the WHO's policies and uh is supported by government institutions making it easily scalable. And next is our demonstration. As you can see, this is our Sigma eyepiece, the

automate microscope by just add three pieces into the standard microscope that worldwide are using right now. Now, our m the standard microscope will turn to a million dollar slice scanners. As you

can see, we have two two functions. First the autofocus. Our algorithm will automatically focus. It will analyze the image and now it will send a signal to the motors and

next is capture. By just one click our sigma IPS will automat automatically capture all the entire slice with our operator

from it will capture for more than 360,000 image and all the image will be sent into our web application. And here is our web application. As you

can see, we can now upload the file analysis and then the specialist can now easily uh diagnosis. That's it for our Thank you.

Thank you. Thank you. Thank you team. I Our next presentation is Yubai 22634. He's a 14-year-old young student from

the United States and he wasn't able to travel due to his midterm exam. So, he sent a pre-recorded presentation for the jury. Vidi, please play presentation 7. Hello, I'm Sarat Mandiala. I'm 15 years

old and I'm an entrepreneur here in Dallas, Texas. I'll start off with a little introduction about myself. I am 15 years old and I'm currently in my first year engineering at the UT Dallas

14 years old. So currently circadian where we use cardiovascular oscillation to detect diseases early essentially just by placing your phone on your heart in 7 seconds we can detect

over 40 types of cardiovascular abnormalities. As we all know cardiovascular diseases are the leading cause of death globally accounting for uh onethird of all deaths many of which

could have been prevented if they were detected early. So what we do is we're essentially bridging that gap in identifying cardiovascular abnormalities efficiently and effectively by using a

simple heart screening app. So we've recently conducted clinical trials on about 3,500 patients in government hospitals in Pradesh, GGH, GGH vigil and also GGH room. And we did a double

blinded study where patients were randomly sent who were uh high risk who were normal patients, healthy patients and also patients who were previously diagnosed with cardiovascular

abnormalities and we screened them all. Whoever was flying as normal were immediately sent for a protocol designed by the department uh of medical education where they were sent for ECG

to echo and then also cardiologist review and also a random sample of healthy patients also went through the same protocol to evaluate the efficacy and the accuracy of the tool

efficiently. So this led to us understanding how impactful this would be in low resource environments and also in extremely high volume environments. So in our testing we found that this

tool would be extremely useful in doing it in primary healthcare centers or providing it to nurses and government hospitals or in high volume settings because just in 7 seconds using an

iPhone we can detect various types of cardiovascular abnormalities. So this tool is incredibly scalable in what it is because it's just a software that's running on an iPhone. And the only

technology that it needs to run is an iPhone itself and a microphone on an iPhone. So it's incred incredibly scalable and it's incredibly useful in being able to identify cardiovascular

abnormalities early, which is what we're really trying to do here at Circadian AI. So here's a quick demo of the app on iPhone. So all you do is you take it and

you place it on your chest like this and then you record it for 7 seconds. Perfect. And it's just given an audio recording that you'll be able to hear like that of the heartbeat sound. And

then you click the analyze button and then you'll get the result. in this case, healthy heart. Finally, I wanted to thank you for your time and consideration of Circadian AI,

rebuilding the future of heart health technology, one heartbeat at a time. Before I end off my presentation, I wanted to give my sincere thankfulness for the jury and their consideration of

circadian AI, I wanted to apologize for not being able to be there in New Delhi right now today presenting live in front of you. Unfortunately, because I am in college at just 15 years old, it does

come with its own unique constraints and challenges. Currently, I am in the process of studying and doing my midterm exams in my college. So, it becomes a little bit difficult to travel to New

Delhi at this time. However, I am very happy that I've had an opportunity to participate in this challenge and you know I hope to bring circadian AI into the use case of innovations and

integrations in hospitals, primary healthcare centers around the globe. Uh jury members we have UI 3536. Rishi uh is team 3536 in the hall.

Are you ready to present or would you like to present later? &gt;&gt; Okay, no worries. Uh members, we're open for Q&amp;A round to the teams that have presented so far. 136

2326. So that unfortunately won't be available for the Q&amp;A round. Um okay, I can go first. So um for the team that was doing the cyto scan I guess my big question that I did not

really understand through your presentation is what is your innovation right like what are you doing differently than others in the space so basically we have uh a completely

full system while uh other commercial scanners or alternatives they just merely scan slides. But for us, we have a system uh from image collection and cell imaging to AI analysis and uh

sending it and transportation, right? So yes, &gt;&gt; what how what prevents the others who are in the space and already solving it from doing the same thing that you are

doing? Uh so uh with our AI so normal AI that uh globally uh worldwide are using it right now. So they are just uh put data set in the AI and the AI app.

&gt;&gt; Sure. Sure. &gt;&gt; All right. So the the images are just inputed into the AI and it just analyzes that's all. But for us we have multiple uh we use a multimodel AI system which

uh has like an entire process through in its analysis. First it is it does some object detections and then crops out the individual cells and then it's segmented by a unit segmentation model and then

the pixels in the each in each oral or counted and or calculated in a mathematical formula which that formula is what we use to classify the abnormalities.

Okay. Yeah. So I have a question to this uh 17036 uh you're here. Okay. So the question is so who are your target uh this customers or beneficiaries and do you think how

feasible is is it for the the rural people to adopt this technology? &gt;&gt; Yes sir. This is for actually rural patients and um rural patients we I I have brought up in rural areas. So I saw

many rural peoples can't able to access the modern platforms. So my idea is to uh using their tech itself they whatever the technology they are using from to it we are bridging into modern uh modern

infrastructure so that they can able to easily access our services through mobile phone. But the question is how how do you think is it feasible for them to adopt this

technology? &gt;&gt; They just need to call and our agent will take care of their queries and they can able to it's like a communication with uh a health worker like that only.

&gt;&gt; Are there any language barriers you are anticipating? &gt;&gt; Yes ma'am. Currently we have created for English only and also we are adopting for multilingual support so that the

rural patient can able to easily access. So basically see when when we talk about rural India and we talk about reach in rural India um we are talking about a massive

country many dialects many languages right so that's an added complexity in this so keeping that in mind if I were to compare it with let's say Manipal hospital they use a app for booking it's

a very simple app all you need is you download the app and you you know they ask for an OTP you do that That's about it and you choose the doctor that you want to meet. So the question is would

that interactivity be easier or would this be easier? Uh both might come with their challenges but at this point in time which interactivity would be easier that would

be better if they have smartphones but in several rural areas they don't have smartphone and needed access. So that our our uh using our uh platform they can able to easily call and book their

appointments so that uh many people can able to avail the medical services. &gt;&gt; Got that. But your language consideration still remains and that's the scalability aspect that you need to

think about. So for that uh we will be while we are scaling we will store the conversation of the patient with their concern and we will retrain the speechto text and text to speech models so that

the language and dialects will scale while we uh uh expand across villages. &gt;&gt; Sure. Thank you. &gt;&gt; My question was the same about data privacy. when you're speaking to someone

on the phone taking their information their data how do you think you can mitigate that risk because data privacy laws are being stricter and stricter now as we go ahead

&gt;&gt; so um can you repeat the question please &gt;&gt; so when you're taking personal patients data so when they're telling you what symptoms they have you you are basically uh mediating appointment for them as

well so you're taking their data as well like you said you will actually store the data and try to learn on that data as how do you then actually uh comply with the data privacy for the patients

as well. So uh first of all we will be isolating each uh users conversation and also uh we want we are storing with their uh concern but we don't store their personal details like um their

name, ages or phone number. we will be allocating a stream ID for each call there will be an ID and for that ID those conversation will be recorded so that those uh those data won't be

explicitly given to anybody thank you thank you jewel members thank you team we now move to third panel for the day it's the eighth presentation UI22861 one.

&gt;&gt; Do we have this? It's also working this. &gt;&gt; Hi judges. Do you ever hear about malaria? Malaria is a disease that kill

one life every 50 seconds. Why? Why can we eliminate malaria yet? It's a questions in my head. The problem is one right now we always react instead of prevent

example mass system they're using statistic data they're not real time with the big scale of province scale that's made the uh system of preventing is not accurate and cannot produce in

the real real the first ever forecasting that is solution one that forecast before the epidemic And two, the problem of right now because in rural area we

have only this two team test kit that can only assess the rural area but the problem is mia is the resist that have different species all five species and all five species have a difference of

treatment. So that's why the positive or negative result it's not it's not have any meaning in there. So that's why we have TO CREATE THE FIRST particle microscope with diagnosis AI code site 2

with malasite will change and break through this and this is the uh video of our innovation solution &gt;&gt; the end to end malaria elimination system

&gt;&gt; the audio respond audio &gt;&gt; audio So this is the video showing our system

using in the real place. No this one. Uh yes this &gt;&gt; uh tech. &gt;&gt; What do you want &gt;&gt; the sound of video of this video?

&gt;&gt; Play the video on the slide. &gt;&gt; Malaria X. &gt;&gt; Okay. So this video will talk about the mother XR system that already used and deploy in the real growth field test.

Right now in the video I will show that &gt;&gt; yes our malware X system is my we we have three part before we predict the the risk area that will upgrade in the our website there and after that when

you know that outbreak took place we will go into the field in just two hours and during we getting into the uh field test into the field rural area. We will use our escope weapon site all our

system to diagnose malaria and give a patient correct treatment. And after that this is the patient that using all our system and next right now we already

scalability around three three centers in Thailand. First at the northern disease control center in Shennai we deploy the scope rapid site venala site and next two week we go to tins Thailand

to test all our system there and after THAT WE WE GO TO THE SOUTHERN part of Thailand to diagnose and test our system with a special case of malaria there. So that's why right now

we already deploy to around 10 centers in Thailand. In three months we already take care about 260 cases of patient and for sustainable mo X it's not it's not just the best innovation because Mal

X not no need to use experts or the specialist because all our system can use by just normal people like you all of you guys can use our system by just training in one day you can be like

specialist in the rural area that's why people in the rural area can get the correct treatment and like having the experts in their place and can access all of the gold standard treatment. And

next is our demonstrator. I will show you our website of using our Matt attack system. In this you will see that this is the screen of our officers centers. Okay, we'll see

the first step one when when uh when when the place in the map have the outbreaks, it will alert to the system. When it alerts, it will show the screen that uh how to adjust at that place

because our simulations will uh recommend how to adjust the place upgrade by by if if you if you click one scenario one. If you click the outs outbreak and it's not working, they will

not recommend another HS way for the best method to prevent malware before the outbreaks epidemic. Right. And next is our demonstration of site

and power to present the escore. Heat. We have to privacy immediately. And finally, Maria X, don't leave someone behind. We did it take to

protect zero. Maria, start now. &gt;&gt; Can I just take one? &gt;&gt; Thank you team for your enthusiastic presentation. We move to the ninth presentation for the day. UI 13482.

Jury members. This is UI 13482. Can you hear &gt;&gt; Good afternoon judges. My name is Chiroshi and I am the co-founder of Vauxet which is basically voice based

observation using explainable AI for daertia. At first let's understand what is daia. Disarthuria is basically a neurological speech disorder which is caused when the important parts of brain

such as motor cortex cerebum and the brain stem got damaged. As a result, the speak muscles becomes very weak and the speech become very slurred and the people are unable to talk.

Then the it is not only a neurological speech disorder but also an early sign for serious diseases such as stroke and Parkinson's disease which can cause a lifetime burden for a person.

If you see the worldwide daert affected rate in the world, it is about 0.1 to 0.5 percentage of the total population and in India it is about 0.5 to 0.6%. The long-term effects of daia can be

permanent speech loss and the swelling effects and can cause a lifelong medical burden for a person. The main problem of the daertia detection is the early detection. It cannot be early detected

because the early symptoms of daertia is very much unclear and unnoticed is very much subtle. The people cannot understand they they are suffering from daertia and mainly the rural people

can't get access to the costly tools and the specialist help. As a result they remain undiagnosed or get diagnosed at a very large stage when they are unable to cure themselves. So we are building an

easily accessible affordable AI powered screening tool for dicartha detection. At first let's understand then what is voxid? Voxid is basically an AI powered screening tool that enables early

detection of daiserta by analyzing the speech patterns and generating an explainable report medical report within seconds. At first we have trained our model using 2,000 open-source voice

samples among which 500 male daisertic and 500 male non-disertic. Same for female 500 mil daisertic and non-ertic. Then we have sampled the voice at 16 kohz in order to extract the

important features such as MSCC, ZCR, zero crossing ray and the delta and delta 2 in order to extract the most important features that are responsible for dicertia. Then we have passed it to

the CNN model in order to analyze and predict the speech patterns. Then the most important innovative part of a project is that we are not just predicting we also explaining for which

features it is daisarthic and we also showing the feature level analysis that's why the model is predicting it dice and our model accuracy is about 94% or above and with low latency and this

is our design software design we have made this is a very working model where the user can login themselves and then they can record their record or upload a short

voice sample. Then the voice will be analyzed and the result will be shown. If it is daisarthic or normal then a automatic PDF generation report option will be there which will tell them for

which reason it is daisertic or if it is normal then okay and if it is daic then it will tell them for which reason it is darthic and what precautions they should take.

At first the the real and the market impact of our project is that we are aiming to collaborate with the hospitals old age homes for the early and the regular screening of the person. Then

the user can sell uh screen themselves through their mobile phones from anywhere throughout the world and the people we can also use this in NGI health for the early screening and the

most important focus of our project is the rural people. rural people can't get access to the costly tools and the specialist help. As a result, we are focusing on them and want to build our

main support is the Aishwan Bharat which mainly focuses on the development of the rural people healthcare. So we are aiming to uh affordable hardware which will be available at the rural

diagnostic centers for their easy and affordable screening. People can usually go there at an affordable rate. they can screen themselves and understand whether they are diarrheartic or not. If they

are diarctic then they can perform further screening and go to the cities for the further help. And the most important thing the rural people cannot give doctor visit every time. It is very

much expensive. So they left the omit the suspicious as a result they cured themselves at a very large but it is not at all curable. And we also building an smart reference system. If a person is

detected dice then it will the app will suggest them at what they should do and what hospitals they should visit and what specialist help they should take. Our business model is

B2B. We want to collaborate with the NOS's hospitals and the rural development program for the uh development of the rural people. We also aiming for the multi-reure activity

which is not available in India and our project is different from the other projects because it is very much affordable and early screening detection is done and the people can easily access

themselves through the phone also. We also tells that boxer doesn't replace doctors it helps the people to reach doctors at the right time. Thank you. Julie.

&gt;&gt; Thank you team. Uh we now move to the 10th presentation for the day. UI 21582. &gt;&gt; Oh is that okay? &gt;&gt; Okay. I will start with Okay. first

uh so okay never mind that so in our world there will be one decade that everybody and everyone should care about is about Alzheimer so imagine you wake up one day

but you can father your father your mother forgotten you this is not because they stop loving you but because of Alzheimer disease and you know what Alzheimer disease is already kill 1.8 8

million euro a year that a big number and this come with two major problem. One is Alzheimer disease will be 139 million by 2015 and two lack of doctor one need have to carry about 36 375

patient and three for diagnosment is called over 10,000 oh 100,000 so as have different state and each step confidence teamman. So as you can see in early cell our didn't show up and can be

seen. So index create the first ever AI model to convert video to skinning and in the first step into middle set index create the first ever sol

VR headset that you can buy a bit under $50 US and that's simulate the VR that help you and last you going to be die absolutely so we want you to have a happy memory before you die.

So what make you index unique? So in that it's in all one solution can be preventment and also scanning and this can be sold that it can be access anywhere anywhere

in the world and two it have personalized AI and three is only 50 of 2,000% oh 2,000% cheaper

so what made this visibility so we didn't change how to work but we implement them make them work easily and you can see that we also implement on open cloud the new thing that's just

come out like two week ago then we also have a copy when you do it out ah so here is our copy and also we do it under human article and also we in the

king user So how do we we distribute this? So first of all the main target of my project is doctor and partner. So they will get uh sharing coffee from their uh

putting in clinic or nursing home and then in the uh secondary target is the department of health. So they will get meal in hospital in Thailand. So we using the V and task clinic

playbook. So we will pilot in one one to two pilot clinic and then if this work if this study work we will implement it into other client clinic and we will do it in this phase. So in

fact when we will validate it first then test it with some small cate and then we will go over here is uh scale it and what make it scalable. So we have two layer of architecture. So one is

auto balance. So it can handle 10 or thousand people and two data layer all data and incubate and and we all private and three we using all third party uh platform so anyone can access it.

So this uh is a architecture. So when some uh some some Hian has do and then we will get more user. More user mean more data. More data mean more accuracy. So

more accuracy than getting more user again and we get our ecosystem and community. Okay. Now how we win? This is my four win. So

first of all, so first of all customer will get all in one headphone with the cheaper high at only 50 US and two hospital will get customer from us and then they will get

the ching profit when they uh bring their customer to us. And three government government will reduce financial burden reduce daily and increase uh quality of life in the

country. and lastly index in the we get more user and also more money. So here is demo. So this is the demo of uh skinning to video to skinning. So I upload the video

of footage. This is about 5 minute and this will analyze uh as the video and show that what part of the video are dangerous and have a list of sinner. this activate 97% and one is uh this via

also generate uh a map and a form patient individually. Okay, I think that's all for me. Thank you. Thank you teams. Uh judges we are open for queries for UI 2261

13482 and 2582. The teams are seated on the right. Yeah, I have a question for this 13 482. Okay, so you have developed that technology, right? So, how accurate

is it and how do you validate that accuracy? So we have tested it with many peoples and uh since we are students we have tested among many friends among around 100 people we have tested with

their voice and since we don't have any dicertic people we are uploading of daertic voice and if you're recording a normal voice it is showing normal and with confidence score is also showing.

So you haven't tested with the real affected people or &gt;&gt; no sir uh we have tested it with the opensource voices we have downloaded which are available easily from some uh

hospital websites or which are easily available we have tested with that only &gt;&gt; okay fine &gt;&gt; my comment would be u paraspeak and wage should possibly collaborate to build on

this further that's my comment but thank you I I really like the problem statement that both of you took up. &gt;&gt; We also have you want to take a break for 5 minutes or you

&gt;&gt; and thank you to all the three teams who presented. &gt;&gt; Uh teams uh we'll be taking a 5m minute break for the jury members and then we'll be back again for the 11th

I'll request all the guests who are uh keen to see more student presentations to stay in the room and uh please be back in the next 5 minutes. So I

basically not allowed to inside the hall. This is a bit of a challenge and uh let me just something. &gt;&gt; Oh my god. This is going to be a hard

challenge. That was my last show. Sorry part of the country after time after the event. I just want to

talk &gt;&gt; I just could run to another event but catch me up on LinkedIn or somewhere. &gt;&gt; Okay, I'm on I'm on class 11. I'm making an AI startup but I don't have the time

at that time to invest in this. I'm not public welfare startup. I'm trying to make a AI startup on automation business on online and marketing terms and we are trying to build our custom algorithm and

airlines and it's B2B type not public for B2B it's B2B &gt;&gt; for for which area which segment &gt;&gt; online and marketing &gt;&gt; automation

&gt;&gt; marketing I'll be curious to hear what you're doing &gt;&gt; yes we are your guidance and we are on MVP

&gt;&gt; send send me to connect and &gt;&gt; okay thank you &gt;&gt; thank you all very well &gt;&gt; thank you

&gt;&gt; where are you from &gt;&gt; I mean I am in I'm from &gt;&gt; nearab Keep building. I don't

&gt;&gt; who's Yeah. Yeah. come here. So, &gt;&gt; I have to work. Can you send me your Um,

you know, so I guess students are solving a big problem. So on the side I think you know questions

and thank you for the demo given that one I really enjoy. Maybe just Yeah, sure. &gt;&gt; You don't know. I think this product is

this person right so I think that it's cumbersome but I I found it very cumbersome but what I should do is I think an organization called dialog and we should get connected to that

I serve you. I'm sorry. This one. That's amazing. season. Absolutely. Started. Should

we stop? &gt;&gt; Hello everyone. I request all of you to settle down. We'll begin with the 11th presentation for the day. And moving on to the second

half of this finale, we have UI 3858. Technical team, please pray. Presentation number 11. &gt;&gt; This is your clicker. &gt;&gt; We can operate it from this as well.

&gt;&gt; Which number? &gt;&gt; 3858. Greetings to the arena and dear Jes. So we would like to start our presentation with a small video.

&gt;&gt; I'm at the corner of Rampal AND M. SO THE PROBLEM THAT WE saw that according to a who survey around 1.3 million annual road accident deaths occur and a whooping 20 to 50 million

peoples are injured or disabled each year somewhat and the risk increases at night and with bad weather. So this is the uh statistic statistical data published by MTH. So this shows that

around 30 to 35% of these are actually occurring at the T-bone and curves. So many factors are contributing to this. So why exactly are T-bones and curves accident so dangerous? Well,

because blind turns have zero visibility for both the cars that are coming as you can see in this image. And the car that is coming from one side is not able to uh predict the position of the another

car that is coming. And what usually happens they collide into each other which can be fatal as well. So these are the perspective of the individual cars. So to tackle all these problem

presenting our solution safe AI where artificial intelligence means the road for safer intersections. So safe panel as you can see this is safe panel. Safe contains two display panels

each facing uh each having three LED strips like red, yellow and green and a camera facing each row. So now I want you to imagine a scenario of a cross road having a blind turn like that like

here say will be placed like that on the blind curve. So uh there's a car coming from this road and then the car comes from this road. Uh each camera will be facing each car. So accord this camera

will detect the speed of the car passing over from uh this road and according to the speed it will turn the opposite panels uh LED which would be green yellow red uh on or off like if the

speed of this car comes from this road very high then it would turn red LED on the opposite perpendicular panel and if the speed is like uh like serious speed like below 10 like this which is not a

dangerous speed then it would turn green. to alert the uh the driver and the other perpendicular approaching turn like the visual representation. So now let me show you how it would work. So

this is a demo representation of like the view of the camera. So as you can see uh our model is detecting the car like this is as you can see the car the speed is detected 9.2 22 km per hour

which is not a fatal speed like a safe speed like so it is uh turning green but in the different scenario uh let's yeah so as you can see the speed of the car is 17.3 per hour so which is

moderately dangerous speed like so to alert the other driver the safe car has yellow reading so to alert the driver so now a more worst case uh so So yeah,

now you can see uh the speed of the car detected is 40 mph. So it it has turned the red LED. So uh this will alert the drivers like you can see uh the speed has been constantly detected using a

roller model or speed detection and it's so like currently so now uh let me show you a very more important feature like in the worst scenario like even after safe path a collision did happen like

maybe the uh the driver was drunk or something of the scenario then safe path has a feature like it can uh just a Right. It can detect the collision like you can

see the boxes have been tracking of the cars and it can detect the collision and both will be glow. So now the collision will be detected and the nearby authority will also be formed. So this

is how straight car will prevent both tone accident and in case of if any team accident happen then also it's a like a very problem solving thing. So our accuracy of the model was 98%. And in

case we might get confused with concave mirrors, safe actually gives active warning. It is effective in almost all weather condition. It uses night vision camera

and gives collision alert beforehand only. So we have tested it under multiple condition at night and in rainy weather in our city itself only and uh so our future expansion also includes

integrating it with upcoming AI cars. So such that we are calling it infrastructure to vehicle communications such that the AI cars will not only depend upon their in their sensors but

what will happen they will be able to communicate with safe traffic such that in case there is traffic ahead or what whatever is the condition the AI car will already know what is happening over

there and they can save time and they can reroute the travel plan. So yes this was all from our side. Thank you so much. &gt;&gt; Thank you team.

We now move to 12th presentation of the day. UI7465. Do you need this or you need? &gt;&gt; No, I'm sorry. This is a clicker. You can move your

slides. &gt;&gt; It's working, I think. &gt;&gt; No, no, don't. &gt;&gt; Also connected to this. &gt;&gt; Uh first of all, uh good afternoon all

of you and thank you so much for this opportunity. My name is Goravas. I'm from Bihar but country has to that IIT Madas my background is a data science and actually sir uh we are discussing

the problem whatever problem you are solving urban traffic management and emergency systems are fragmented reactive and out system because there are no real time coition between all the

existing data sources I mean CCTV data to sources or traffic signals emergency system they are currently working as a manual system second problem in in India 90% of traffic is working on fixed timer

basis There are no any AI that corridor for ambulance or emergency vehicles. Fourth, third system, no any predictive AI that can prevent or forecast the accidents and traffic obsession before

it will be happening and deduce that. And fourth, there are no any integrated AI solution that can track and classify all the vehicles in real time with uh historical data and real time data. Now

we are discussing our solution the jet tax. Jet tax is an air powered a smart traffic management and emergency uh platform that can integrate all the existing data sources and make realtime

decisions. They are predict make driving grid code adapt signals and many more thing also. So we have built our innovation in three layer in first layer we have develops our own AI and ML

models for this thing. First actually we have developed our AI gador. Here I have spent about $20,000 US dollar to making this uh models. After that adaptive signals optimization, traffic prediction

and forecasting models and there are tracking and classification models. Here you we are using multiple data sources for making these models. I mean CCTV data, weather data, radio data, uh

weekend data and all three type of data. Second is our uh age hardware devices. Actually I apply this hardware devices on even dictions in Chennai. Actually our P is going in Chennai and it's

completed and there is a benefits of this hardware it's a processing only data all locally there are remove the dependency of clouds latency problem and there also remove the data trust and

data leakage problems and from here we can also cost optimization reduce the bandwidths and third is our unified centralized command software from these softares government person can control

our hardware and our air models according to his genius second he can so all the alerts alerts analytics violations on this software and from this software they can also give the

multiple access I mean key IM officers I am there are some worker who are working on some levels I the traffic police they are giving multiple access actually I make multiple models multiple software

for this our system uh is working it will take CCTV all the data after that our AI model is running on hardware after that it can optimize signals and from here you can also to control all

the things. And third is actually we can saw this is our existing uh video currently this is deploying in Chennai government actually pilot is completed and Chennai government adapt our uh

software and all the things and uh currently uh currently in UP government also approved for this innovation and uh in Mad Pradesh uh police is also invite our team to deploy the uh software in

four area in Mad Pradesh. Apart of this uh key uh uh we can sell our hardware devices to also other other sections I mean key details industry this type of section and we can also sell our AI

models by API to deliver delivering parting platform company I mean JTO JTO for faster and better use actually I saw the measurement impact you know it will be reduce the 10 to 15% reduction in

every average time it will make 30 to 40% faster after emergency uh rules. After that he can also reduce the manual intervention by traffic and police. Then there are more thing also our system is

as scalable and sustainable because we are using exist exist existing data sources. Second government government can deploy on projection or full city. It depends on government. And third is

we have developed self- learning AI algorithm. From this algorithm our model will automatically learn. There are no need to learn multiple times. It will automatically learn and improve

accuracy. We can also as key increase in tire second and tire three and global seat also. Here three IP for this innovation. Two are completed, one is in pending. I think he'll be also completed

in uh 1 minute. Thank you. &gt;&gt; Thank you team. Our next presenter is UI 23165. This is presentation number 13. So may I start?

&gt;&gt; So uh myself Shaman and this is Pratam. So we will be presenting a platform which is trust race which is uh combating the solution uh which is a solution to combat uh different kinds of

misinformation potential fraud and manipulated content which is generated by using a IML. Okay. And so currently in this day and age we have seen that ML and AI has been liberalized to the

masses. And therefore because of these powerful models are in the you know hands of other sorts of you know miscreants or bad actors. Then any sort of misinformation or uh you know

criminal proceedings like uh uh child sexual abuse material, revenge pornography, they all can take place and they can roam in the free media anywhere. So we need to put a watchdog

somewhere to see and verify the particular authenticity of the image before it is shared to the masses. &gt;&gt; So uh so these are the results generated by each type of deep fake analyzed by a

website. So on the left we can see uh it is the result generated for the audio defects. Below are two graphs. The graphs are MSCC. Uh so the male frequency graphs the coefficients they

indicate whether the media was synthetic or real uh in order to compare we have provided two images below labeled as real and fake. The real ones the real MFCC does not have elongations laterally

in uh higher and lower frequency whereas the fake ones do have errors and sound uh noises in it. Currently we are uh completely deployed onto the public internet and as well as we are running

our own infrastructure we have not migrated to cloud as well. So our models are super fine tuned and they are also you know made in specifically to combat uh res uh resource constraints which are

generally used seen when AI huge AI deployments are done. The core engine behind trust is a set of six ML models running in ensemble. So four of these ML models I will name them MF which is uh

uh CNN efficient net B4 and B7 and res next are used for image and video based detection and as well as we are using MFCC classifier and an SVM model for our audio models for uh and also currently

we are beta testing our newest uh text misinformation uh detection model. Uh we have been recognized by Delhi police uh national commission for women as well as uh we have uh patent uh granted and

published Indian patent and uh we have uh also done a lot of academic work regarding this ML development and we have published uh nine research papers on these models and the entire platform

in peer-reviewed scopex journals. Uh we used to show a live demonstration of the website. Also one more point I needed to add that we are totally data compliant. We adhere

to GDPR and TPTPR policies according to the Indian government and we do not collect any PI data from our users. Also, our solution is very modular and we can cater it to all sorts of

enterprises which is corporate, governance and public sector as well. Currently, it is open to the public and uh we have been developing models specifically for police and we have

pilot tested this during the election season where a lot of misinformation regarding political parties and figures were spread out into the internet. So it was reliably detecting uh in our control

data set testing we are getting around 90 to 95% accuracy and in the wild when we are detecting deep fakes according to the classification of what type of deep fake it is it is GAN based or it is in

sort of you know face swap uh we are getting around 80 to 85% in wild uh in the wild testing cases. Uh so this is how we it is a very simple process for creating the case details in form every

single case has a unique hash identifier. So if something goes into legal proceedings, so this particular can be used as evidence in court because it is tagged and marked and uh this is

how you get the entire and this is all same for all those three forensic mediums. Uh we'll be very soon integrating our text model into the portal once it is very finished.

&gt;&gt; Okay, &gt;&gt; that's it from our side. &gt;&gt; Yeah, the website is live. &gt;&gt; It's live. I'd like to see your &gt;&gt; please.

&gt;&gt; Yeah. Yeah. Phone is my phone because internet constraints are over there. &gt;&gt; This is yours. This is mine. &gt;&gt; Currently our hardware is the biggest issue because you're not running on

cloud. We use only two single stack GPUs. So we are chunk our models like that. So audio models will only run for some hours and then it will cycle back to video and cycle back to image. Uh so

that is the reason uh there is no constant processing. So we are currently working on that issue to get make it concurrent and to process a sort of live streams and then secondly also we are

trying to bring this technology to directly on the phone itself so that there is no data getting out. &gt;&gt; Tell me have you collected case details etc.

&gt;&gt; We only use emails OTB based verification from emails and there can be throwaway emails. So even even that how effectively comfortable communicating your cases anyways we'll

take this up in the queue. &gt;&gt; Sure. &gt;&gt; You can have a seat here for the Q&amp;A round. &gt;&gt; Jury members we begin with the Q&amp;A round

for this panel. The three teams which have just presented UI 3858 7465 and 23165 are here with us. We're open for questions. I'm just going to continue the question

that I just started. My question was uh when you're asking people to input case details, um what level of information are you expecting in that case detail? And how

are you interpreting what's written as a case? Because the case would be a a text or a photograph or something that they would have given, right? So the user may or may not be educated. So

how are they communicating is broadly the question. &gt;&gt; So firstly when it comes to PII data we are only taking emails because we need to have OTB based verification because

uh we are trying to protect from DOS or you know spamming attacks on the website itself. So that is the reason we have put two factor email authentication onto it. Other than that the user need not

put any other thing except the location because we are also take the metrics from like a like a heat map. So if there is some sort of political uh you know moment or demographic thing going on. So

we need to see the heat map from where these kind of data is getting generated in the first place. So that could be reported to the authorities or the cyber cell to know take action on it. So that

is the only two things that we are taking from the user and we also ask for context and from what platform did the user find this media in the first place. So that if it is shared on Twitter so we

can you know ask them to give a Twitter handle which shared the data and then all that details could be you know collaborated into one single object and then sent out to law enforcement. We are

trying to work on that uh with our counterparts in law enforcement to you know give them a steady stream of data uh which can be you know interpreted as what you asked as case details. So that

is &gt;&gt; okay thank you. &gt;&gt; Okay question to this 3858 the safe path. So actually when you demonstrated this uh uh this prototype so I have one

query that is you have done with one model that is maybe in India if you see the accidents mainly happen also due to overtake overtaking of vehicles right. So if uh in a in a scenario that if

another vehicle overtakes in that how do the system that calculate the the speed of the another vehicle and how the it allows the uh the other side of uh thing. Uh so so what happens is you uh

we are using yellow model. So yellow model will track both the cars and if like if a car if a car speed is like below 10 like it's a safe speed and if a car speed is like uh above 40 like is it

dangerous speed. So uh the to the other way to the other side perpendicular blind turn it would show red only it will go for the higher speed only. Yeah fine that is for one vehicle maybe

in the one side if you have another vehicle coming the same speed suddenly if it increases uh suddenly the fraction of second how uh fast your system detects so so uh our system accuracy is

like 10 millconds like it can detect the speed of uh of the cars very fast uh because the yolo the speed calculation like the headb detection of yolo the latency is very low and uh it with 99%

accuracy So uh it will it &gt;&gt; okay fine you can also work on that there fine &gt;&gt; to add on to sir's point actually I wanted to ask what all test cases have

you guys uh tested on the product right now because as sir rightly mentioned there can be two cars there the pedestrian which is coming on the other side also so is the product actually

being able to detect all those things as well &gt;&gt; so we come from Vanci And the most uh congested area was a Lanka. So we it it is in front of IIT VHU. So we asked

permission from the director. So he permitted us. And we actually took sample for 10 hours only. So it it included all the cars and pedestrian that were coming. And since it includes

object segmentation. So all the pedestrian that were also coming were also treated in the case and their speed were also maintained in it. Um so I love all the innovation that we

just saw and having been in a crash myself where someone ran a red and crash into me I truly appreciate um some of the solutions that you have shown. Now let's go to the the content the defect

detector. Uh and my question there is um what is your innovation right because there's so many players including Vic tech that's working on it like how are you doing this differently and better

that's one and then also I mean there's also so many standards like the C2PA uh etc. So around content how does that play into what you're doing? uh regarding the innovation I would say

currently what we think is that ensemble that we are using is it comprises of four different models and sub varieties of those models so we are not just looking at the image from one single

perspective we're also converting into a different channels so one of our models is looking at a attention based uh span and then it is one of it is looking for the chromatic opberations that are

happening in the video then there are also technical parameters of the image that we are also taking in consideration so there's lot of processing that is happening together parallelly and then

we are coming on to one single uh you know output which is you know once again ratified by our classifier model so we're using all these in stages so we get a more better predictive outcome uh

right maybe one followup right I mean because models are getting better as well right so even during your development are you finding that it's a race that you know you are not able to

race &gt;&gt; so how are you keeping ahead I will one more uh like innovation that we like we thought it's like because there is lot of you know like uh inconsistency in the

data sets that are found for DFA for Indian specific users. So there are not a lot of data sets that contain cater for Indian audiences. So what we did we created our own data set for Indian uh

you know figures and you know kind of Indian facial features and Indian voice maybe and then we did contrastive learning on those all of those data sets so that the models are able to properly

you know differentiate between uh the use audience currently which is in India only for our partners and law enforcement and different so that is something that we are trying to tackle

over here and with the data regulations the currently the main objective was DPDPA because uh we were developing India specific solutions so we went to DPDP And then afterwards the GDPR has

come. So if you want to scale upwards you know go global in our reach then uh we have know adhered to the standards in DPDP they stand. &gt;&gt; I look at C2PA as well.

&gt;&gt; Yes. Yes definitely ma'am. &gt;&gt; Thank you jury. Uh we have eight presentations left and 40 minutes for this session. So we'll request all the teams to please be seated in the forward

area for smoother logistics. Moving on to the next presentation, we have UI5012, presentation 14. This is 1512.

You can use this clipper to move left and right. Yeah. Yeah. &gt;&gt; Namaste all greetings to all. So especially to the guest also. So one

thing I will ask a question to the jury as well as to the delegates who came here. We your AI will work without network. We your AI will work in the key platforms. Is it possible? And also I

will ask another question. Is AI only meant for urban and metropolitan cities? Not just for rural, tribal and forest areas. Here you come. We are introducing the wild track 360 where it can be

accessible to anyone and anywhere of this world. Especially we are focusing on the themes of the forest tribal already. It is implemented in the south part of the India. Especially in the

Andhra Pradesh basically I'm from Andhra Pradesh. So there are the two major parts we are covering on forest itself meant for the smuggling and to capture all these areas the forces of the nation

like police forest as well as the fire to help to safeguard the nation we are implementing this factor thing called two AI systems called threshold AI and AI meant for the three eyes. So we are

forecasting forest, fire and police. We are helping them and we are introducing the wild pack 360. Uh this is implemented in the last year also in the Andhra Pradesh segment. So here we we

are capturing the animal traffing as well as the smuggling areas. So these all kinds can be captured which will be very helpful for the forces uh like in the defensive system of the government

and also not only for the government we are also implemented our solution for the public also right in the uh in the initial ter I I said a word called we are uh innovating our solution for both

officers like government as well as the public for public who is staying in the tribal areas or rural areas they are not more aware about the mobile phones of smartphones. That's where we came up

with the solution of the technology called yeah we have came up with the technology called Lora technology many of you know that so that lora technology is an

connecting bridge between the terms here you can see how it will be connected without any internet you can transfer the artificial intelligence in your mobile phones just you can plug and

connect the artificial intelligence and where it can be easily uh uh where it can be easily used For example, in your forest you got a snake bite. You are a tourist. You went to a our area Andhra

Pradesh. You got a snake bite. At that time what you will do? You don't have any proper network there. And at that time this Lora technology will define you what what are the steps you need to

take it out. So there we are reducing the trinetra AI our AI co-pilot assistance which will be a commanding for both government as well as the public who is uh affected in near of

that forest area directly connect to the hospitals forest service and the police also along with that if anybody is caught like someone is smuggling any sandal most of you know push right so

many of the things will be happening in our area at that time no also see all these things can be captured a single thing and you can transfer your photos and you can have a communication between

the Laura technology. So here I am saying that AI is not only just for the smart cities or smart places. AI should be accessible to everywhere of this world. So already we collaborate with

the government of Andhra Pradesh and government of police also. Now we are implementing in a large scale mixer and also we have executed our drone technologies

which is supported for the police people and the forest people easily they can recognize through the sensing cameras within the uh range of 30 kilometers. Our pilot test were completed for the 30

km and in the area of alluralamu district area already completed. Now we are going to the extent level forecasting the nala forest range highest tiger reserve forest areas there

will be so much of smuggling and all these type of threats also there. So the end point is AI in every domain should be near to every domain but this AI is a single solution for each and everyone.

So this is what sir we are concluding with this factor product and uh ready to uh connecting with the other states also and making the vixit bar by the youth of India. Thank you.

Thank you team. Our next presentation is UI408 presentation number 15. &gt;&gt; Okay. Thank you ma'am. &gt;&gt; This is 14.

Good afternoon. Before I begin with my presentation, I want you all to take a moment to visualize the sheer scale of a catastrophe that burned silently until it's too late. In the Utilan

crisis of 2025 to 6 alone, we didn't just lose trees. We lost 15,13 cr rupees in economic value. We saw operational resources getting exhausted and ecosystems getting wiped out. During

the Australian black summer, about 3 billion animals were impacted. And what is the real tragedy about this? We knew it was happening, but we couldn't trust our data. Current solutions are failing

us. Satellite systems are extremely slow and expensive. Manual watchtowers are leaving human lives at risk. And the worst part about them all, the false alarm rate. About

93.25% of alerts raised in the Utan crisis were false. We were spending resources chasing fires that never existed while the real ones

were raging. We asked ourselves the real question. How do we stop guessing and how do we start knowing? That answer is ana. Anisha is not just a sensor. It is an

intelligent ecosystem. We have built an AIdriven forest fire detection system that combines environmental sensing with a realtime image verification. We solve the three biggest problems that exist in

the market today. Delayed detection, high costs and false alarms. Let us move into the methodology. how we have implemented our work to understand why Agnes works

where other prototypes and methods are failing. I want you to imagine a forest guard who is constantly keeping watch. He smells smoke. He looks for the fire and then he radios for help. Current

technology creates a massive gap. Satellite systems are too far away to smell the start of a fire. Meanwhile, manual watchtowers are too slow to watch everywhere at once. This is where Agnisa

comes into play. We are using a sense verify alert loop. First we sense lies deep inside the forest sensing for specific gas and thermal signatures. Instead of uploading data to the cloud

which is really slow and expensive, we're using an ondevice processor. This is our first line of defense against those 93% false alarm rates. Second, when a threat is detected, we

look around. We activate the camera and then run the images captured by the camera through our compact deep learning model. This deep learning model has been trained in

such a way such that it can distinguish between a harmless sunrise or fog or between an actual devastating fire. Then third, we alert the people. Once we have sensed the smoke, we have verified that

the fire is real. We use our low frequency long range radio protocol so that we can cut through the dense canopy of the forest where cellular networks and Wi-Fi zones are unavailable. Man,

with this we caught cut down the existing solutions which are really expensive. Let us compare the existing solutions with our solution. Draws about three lakh rupees compared to what we'd

be selling about 16,000 INRA per unit. Satellites are extremely expensive and they are slow in detecting fires. By the time they have detected a fire, it is already too late.

For the business model, we are planning for business to government B2G. We are planning to sell our prototypes directly to government uh agencies like wildlife wildlife sanctuaries and forest

departments and private uh businesses as well. B2B we are targeting private timber and tea plantations. Now we are currently at the functional field test prototype stage. We are ready for

pilot deployments in uh control zones. We have also applied for a patron panel. Our road maps includes moving to custom PCB architectures to further miniaturaturize the device and lower

costs even more. We are building an plug-and-play solution for the world's most vulnerable ecosystems. And we are also integrating new features into a computer vision model so that we can not

just look out for fires but for illegal activity as well. investors, you're not just looking at a fire alarm. You're looking at the internet of forests. We are asking you

to join us to help deploy Agnifa. &gt;&gt; Thank you team. We move to the 16th presentation. UI 10591. Good afternoon. We are team climate. In the last year, India have seen more

than 50 black cloud west and flash flood event and more than 400 people lost their lives just due to presence of no early warning system at all. also leading to economic loss of around 2,000

cr rupees in this techy word 75% of the Indian district are still at the verge of being flooded the outdated technology like gorgees they uh get either washed away during

the time of flood or they are not accurate so to solve all this problem here we are with our product called the rusty so the rusty is a patented AI powered

flood monitoring system. It is a non-cont based sensor that can be mounted on any of the bridge available or any of the pole available over the river and it keep track for the very

suspect of the river like what is the river depth, what is the river velocity and other uh discharge and other climate data. Here we use a sensor fusion technology where the radar plus vision

based where radar can keep continuously monitoring for the very suspect and if there is any uh like if there is any abnormality in the data then uh the AI uh we use our AI based models for the

visual verification so that we can reduce the number of false positive or false negative alarms so that we can have the trust of the people on our Now coming to the AI forecasting, we do

our forecasting in a hybrid domain uh version where we use a domain one, domain two and domain three of different resolution of 9 km, 3 km and 1 km. In the domain one, we use a satellite data

to capture the highle topological uh features. In the domain two, we use local weather models and then in domain three we use our own devices model. These domain provide feedback to each

other in order to increase the accuracy of our alerts. Uh now let us uh talk about one of our major success in the last one year. Uh we are testing our system from the last monsoon and uh in

the last uh 11th September 2025 we were able to exactly pinpoint one of the major site of a cloud bust that happened in blasphemal Pradesh before 24 hours and it actually turned out to be a cloud

bust on the same spot in on 12th September 2025 and uh we were able to capture around 75% of the major event that happened in 2025 monsoon and we are expecting the same with more accuracy in

this monsoon. Now I would like to show some our digital twin. The the data from our sensor goes into our digital twin model. This is a 3D replica of uh Delhi near

our campus. Uh the data here is currently coming live from our sensor. &gt;&gt; Now I would like to show you also &gt;&gt; that's basically 3D coming

from the sensor and here you can sit next hour 6 hours next 12 hours during the time of flood so that the disaster relief team can plan their evacuation plan more efficiently so that they know

communities is has the highest probability of being submerged in the water so that there is no casualties. As you can see now we will simulate it. Now we are simulating the situation in

the next 3 hours. Uh also uh you can also see in the VR technology here this is what sir is able to see in the VR. We will be able to see all the data and uh all the what will the

situation what is the AI forecasting and for the next 3 hours is it a high alert and what will the river level in the next 3 hours which community will get effective and this is how it looks I

guess &gt;&gt; team you have 30 seconds to wrap up your message &gt;&gt; uh now for the impact we are able to reduce the alert latency by 70% and also

improve the lead which communities never had in Himachel since we both are from Himachel and we have seen the whole communities getting biped away by the flood. So we are able

to provide them a lead time of around 60 minutes to around 1 day. So that is a very major change in their life and uh for now in our pilot testing we are providing early warning to more than

10,000 people in the command valley in IIT uh in Mandi district. Thank you. We believe that minute warning can save generation of life and climate tech is the first step toward that vision.

1059. Thank you teams. I'll invite UI one triple 28. Now for the 17th presentation this is 1le 28. For India, AI is not a luxury but a

necessity and it must be inclusive for For India. AI is not a luxury but a us all. Farmer constitutes about 65% of population and are a major contributor to our economy. Yet they largely remain

untouched by ongoing AI revolution. This is the gap we are here to fill today. So today I Vidan Gupta along with my team Shakum Shabla are here to present a solution agit pro which is an AIdriven

crop health management solution designed specifically for farmers. So every year as you can see around 20 to 25% of crop yield is lost due to unprecedented conditions like pests, famines, droughts

or epidemices which constitutes in monetary value around 8 lakh 60,000 kores of rupees rupees lost every year. This is exactly where we step in. So let me start with the live demo. Uh

where can I start the video with? Uh it's next. &gt;&gt; So this is the live web app of Agrete Pro which helps farmer to know about their future crop risk 10 to 14 days

before it's visible to human eye. Let's go into the sign in workflow. So let's see the website from a farmer's perspective. When a farmer signs up, it's redirected to add a new field page

where he adds his fields with the basic field details like field name, area, crop type can be auto detected via model description and the use by live location to map out to the current location or

the other GPS based uh advisories. Then he's redirected to the dashboard where we have four cards crop health index, soil moisture, temperature and humidity. Crop health index is coming

from Sentinel 2 Lancet satellite which helps us give us ND NDVI and NDMI through hyperspectral imagery which helps us predict crop health index. Soil moisture is coming from NDMI indices

from the same satellite and temperature and humidity are coming from the weather API. Then the next card is crop health and yield trends. It gives us how the crop yield is varying over time. How the

health is deteriorating. So farmer can have the next action plan. Let's move on to the health map uh page. What health maps does? Health maps let us know where exactly on the field is

the danger zone and where we need to act to get to get a better cre crop yield. The next module is 3D terrain which is the future scope of of our model. So basically through IoT sensor we would

map 3D we would map out the 3D terrain of the farmer to set up an uh irrigation channel. So as you can see uh my bad. So it's &gt;&gt; you want

the video from where it was. Uh you can go ahead to the 3D terrain feature. Move ahead. Little bit more.

Yeah. So basically basically it helps to map out the irrigation plan where as you can see the uh blue area is lowland. So basically if a heavy rain occurs there would be water logging and it would lead

to around 100% crop yield loss in that area. Let's move on to the spectral analysis page. So basically every tech is not basically for farmers it's also for AI

analyst. So, so it helps us give us the reflectance versus the wavelength data to help map out NDVI, GNDVI for the researchers. Farming is collaborative for large

farmers. It's a team of multiple members which works on their particular fields. So basically with the RBSC system we can give field permission to a particular delegate and they can see that

particular field and act according to Then it's the setting page for the UX of the website uh along with the privacy. It's 2FA enabled with passwords and 2FA apps.

Let's move on to the kisan our AI chatbot which bilingual for now English and Hindi which helps farmer to know about what to do to map out to their crop leads.

We have website in more than 17 languages. So, so language would not be an barrier. So this is the demo of the uh WhatsApp based chatbot. Basically we can connect

to the web app through the WhatsApp model only where an additional feature that when a farmer spots that there are some disease in the leaves or there is some discoloration they can add to that

chatboard and ask for the organic solutions. It's fine tuned from the agriculture institutions data which is very cost effective. It's also available in 17 plus

languages. &gt;&gt; Yeah. With your support, we aim to scale this solution nationwide and contribute to a driven food security for India. Thank you from team hyperscalers.

Thank you team. Uh jury members we are open for questions now. For the last four presentations we have UI5012 148 10591 and lasting 1028. &gt;&gt; So my question to this last group is

agree. Yeah. So you are focusing on the health of the soil and also the crop &gt;&gt; Crop. Okay. So here you focusing only on this uh irrigation or maybe the soil quality that is MPK uh the quality of

the soil. So basically what we are doing we are taking the we are taking satellite data known as sentinel 2 in basic in basic multisspectral bands RGB uh NDVI and DMI SWIR to map out the crop

health index for basically a healthy crop reflects at a particular rate a particular percentage of light to for this and an unhealthy crop gives it below that region. So basically we have

for soil crop health and uh everything related to the farmer. &gt;&gt; Yeah. For the the question is the for the soil health that is NPK is a very important parameter but it before based

on the various field how you get the data is it uh because every for for every region is also this uh the soil health varies. Okay. NPK v the parameters varies. So how to detect the

parameter and how we will uh based on that how we will map with the the crop. &gt;&gt; So for the soil moisture the multisspectral bands gives us with enough accuracy the exact soil moisture

of the ground but if we want even more higher accuracy like it gives around 5 to 10% of error not more than that but if you want more we can definitely integrate IoT sensors to monitor the

soil health. &gt;&gt; Yeah fine for me multisspectral is more than enough. Yeah, thank you. &gt;&gt; What do you guys think are the adoption barriers that come with your like from

farmers? &gt;&gt; Yeah, so basically the adoption barriers that farmer would come with is the UI interface of the web app. So basically to overcome that we have created a

WhatsApp chatbot. So uh because the farmer would not log through the website they can definitely generate a one-time account and then they won't uh be more than be techy to log into that every day

and see their help. So basically then we give the notification through our WhatsApp chatbot. So that barrier would be tackled in that way &gt;&gt; and our WhatsApp chatbot is also

multilingual. One more question to this 1408 is that a forest fire. Okay. You uh the your device will be deployed in the forest.

&gt;&gt; So we have decided to deploy it in high altitude regions like the canopies of trees so that we can cover maximum area. &gt;&gt; What if your device gets uh the fire it's get fire affected by fire? We are

creating uh a grid mass grid deployment so that uh we can create a peer-to-peer network of devices so that even if one device is put down the other devices will replace that and send continue

sending data to us. &gt;&gt; The questions thank you jury members. Thank you teams. We now move to the last four presentations of the day. Uh our next

team is UI 3624. Uh we have an finalist from Indonesia. This is presentation number eight 362. Okay. Yeah.

You can change your slides left and right. You want All right, good afternoon everyone and honorable judges. My name is Anipamongas. I'm founder and CEO of UA

apps innovation to create a modern lifestyle towards a better world in the future. I come from Indonesia and nice to meet you all. Um first of all I grew up in the

rural Salan area of Chhattima village Indonesia living in the village where every day I help my parents take care of the cows meeting where the livestock sector always be considered petty and

continue to be traditional because it's only of animals every year the demand for livestock grows serial part of the livestock industry contribution to the economic growth. However, the question

arises, why is the price of rice sold to Berlin always concerned every year? Even though the price of meat on the market continues to increase. In April 2021, a business struck my village and operate a

disease that killed hundreds of animals causing millions making us think. How is it possible that the livestock that we have looked after since that we have killed for years die in such a tragic

condition in just a few months. Since that incident me and other young people took the initiative to create an innovation called maps. Maps is a model life innovation with four superior

features. The first feature is a monitoring system with a physical component like a sensor equipment cost attached to the livestock. This sensor detect the animal health status and

sense the updates that can be accessed by smartphone. The second is a marketplace features where our customer such as breeder breer and the public can buy and sell the livestock of the rest

of need. And the third is the educational teacher. We provide educational services via chat and also video caller to solve the problem in the file. And the last is consultation

features becoming performer to communicate problem in the field to veterinarians with the AI chart and also integrated to doctor with only $5. We will get all the benefit and service in

term of application and innovation through strong determination. Since 2022, we have reached most of Indonesia area and we want to improve our technology and expand in India also that

uh apps also reduce the number of livestock debt by monitoring features and integrated technology by up to 80% and save the over revenue more than $10,000 on the first year of my season.

Not only that, Europe has also decreased pricing by introducing a market procedures that connect vendor and customer with a fair price agreements. And currently the marketers had gener

profit of $50,000 from the first year of my SS. Not only that, seeing the lowest hope of informal education. We provide educational services with a success rate of 100,000 of the topic in livestock

sector and also having more than 100 general public participation in our application. And the last is consultation features become performer to communicate problem in file to

veterinarians with a success rate of 100 veterinarians partner that uh join in our company and also we integrated the AI chat board for the improving our technology that's why we hope to expand

our impact and connecting with this event because we believe that if the you are from the outside of the country that you have to push yourself to make an innovation to solve the real problem in

the society and uh in the future we want to improve our technology by make it simply into a chip and we want to many holding to many sector to improving our country also and the collaboration

between India and Indonesia and the last one I want to share how the technology is Oh, so the judges we also have the product is just like a necklace and then they

will put on the uh this the lifestyle and it can be detecting like a disase or something like that especially internal dishes inside of the box they having a lot of the sensor like a temperature,

body pressure and something like that. It could be a sensor could be detect the real uh the real life of the livestock. And then what they what we going to do that we

that the sensor will be will be able to see on the AI that the AI will be able to integrating the technology. So as you can see in this website, so this is our Yeah,

like I said, like I said before, we have P for main Twitter and the farmer can check the information about the livestock from here. Yeah, from here just like this. So the

farmer get the information and they won't be worried about about the kind of disease that attack for the livestock. And we actually We actually expand in the across Asia,

South Asia countries like Indonesia is our main um main office but we also tries to to expand our impact in the Malaysia and Vietnam also and we doing our assistant who app has won award like

this one. So there are so many so many award and the experience that we've got since 2022 and the total of our team is 27 including me as the founder. I would like to say thank you so much. So in the

future let's create a modern lifestyle based on digital technology towards Indonesia and India better once in the future. Thank you. &gt;&gt; Thank you team. Our next presentation is

UI 14163. Can use this over. Um, greetings. I'm Tulina Bus and this is Danchi Shastav and today we are going to do a presentation for using uh deep

learn using deep learning for enhancing tourism in uh Bishnapra which is in West Bengal. So um our problem statement is that for centuries there have been many um heritage sites that have been built

in India and its legacies have been passed down for generations even till this date and because of that most of the popular uh popular heritage sites today are been visited by the tourists

and uh even after uh all this uh there are some hated sites that date back to the same time these popular hated sites have been built that are still not being able to attract many tourists and

because of that uh we have done a fruitful uh survey and reports to classify the types of hated sites that there are in India and uh our first type of hated sites comes uh under the

category of the most highly recognized uh hated sites. uh for example Taj Mahal which attracts a lot of tourists uh every year and our uh second type of heritage sites include the moderately

recognized heritage sites for example the Punak temples and last but not least our least recognized type of heritage sites for example Bishnapur attracts the lowest amount of tourists every year. So

this is why uh we have decided uh that uh this is creating a digital gap between the posts and this uh and these least recognized hate sites in India. So uh for this we have decided to come up

with an AI approach which is um we have decided that uh first the users are uh going to um input an image and from that it is going to detect um and that from that it is going to detect the

classmates and from that uh we are going to be provided with all the information and uh the location of those detected heritage sites and along with that a recommendation system is also being

provided which recommends us the nearest heritage sites that they are available for the tourists to visit next. So uh this AI approach uh so this AI approach that we have followed has given us an

accuracy of around 92.77% accuracy and uh we have also implemented this in our website which have been live predicted and it is also giving us the detected uh temple names along with its

location all the information regarding those regarding those heritage sites and along with that uh all the other architectural sites that are located near that location like the most nearest

with the uh further locations uh providing a choice to the users for where they would like to travel next. And uh for this we have decided on how to promote this product. And uh for

promoting this product uh we have decided like we have planned on collaborating uh with our tourist guides and um also with the heritage nos and for the government so that uh we can

expand our data set that data set that we have locally created uh by visiting the by visiting the least recognized hated sites on site. So uh if uh once we are being able to make this very

scalable, we are being able to promote these least recognized hated sites of most of the uh architectural sites that are present in India. So we are not only making this focused only in Vishnapur

but we are also making this focus to most of the least recognized hated sites that there are in India. So we are promoting this hated sites to the people because these hated sites deserve the

same recognition as those most popular hated sites like Taj Mahal, like Kutum already deserve. And because of that we are also going to add uh we have a plan for uh implementing in our future work

which is uh as I mentioned before the recommendation system that um as per the radius as per the location of the detected temple we are providing with the nearest uh heritage sites that they

are available so that the user can decide where they want to travel next. So we are providing a choice to the user as like a free will for where they would like to travel next. And also uh we are

also uh planning not only planning we have even started working on a 3D reconstruction of the uh almost demolished architectural sites uh in India. Uh for now uh our prototype is

focused on Vishnu. So as I mentioned before for scalable expansion we are going to make it more generic uh focusing on all the underrepresented sites in India. So uh what we are going

to do is in our already implemented website the user is going to take an image of the detected temple and with the live camera prediction while they are moving around the 3D reconstruction

is going to provide a structure of the demolished temples. So they will provide an idea of how they can be reconstructed again in the future. So uh before I conclude my presentation, I would like

to share some of the achievements that uh we have come uh come with for our project and that is the data set that we have locally uh gathered on site has been applied for copyright as well as

the research paper or based on this project have been published by it e as well. Thank you. We move to the last second presentation of the day. UI498

tech team. This is presentation number 20. &gt;&gt; Access to quality education is still a privilege. not a right. Quality education resources remain inaccessible

to millions of students due to extensive private tutoring, lack of personalized content in local languages and the urban rural divide. According to government data, out of all the students who reach

IIT, only 35% of them are from the rural India. This is not because of the lack talent. This is because they do not have access to quality learning resources. Hi, my name is Zakaj and I'm the creator

of Kovu. My mission is to democratize education by using the power of AI in creating rich educational resources at a very low cost and making it accessible to anyone who needs it. I'm inspired by

the goal of Vixs Bhaga 2047 by honorable prime minister Paraga India Taba India. So meet Kawiri a grader from rural Andhra Pradesh who turns to a phone for study help because a family cannot

afford expensive tition. Coaching centers like Baiju and Allen are very expensive and there's no local language support. Whereas Khan Academy requires high bandwidth for playing videos and

again there's no local language support. Tools like charge GPD and notebook LM lack a structured learning experience and most of the features are paid. So what's the solution for Kiri? The

solution is Kido. Kiri got to know about Kido from a school teacher. She then logs on to ww.kidoo.com. She has access to rich educational resources such as chapter notes which

provides a detailed explanation. She has access to chapter notes in eight Indian languages which include Marathi, Telugu, Canada, Gujarati etc. She has access to practice questions to rest her

knowledge, flashcards to revise her topics and NCERT textbook solution. One of one of most unique feature is its contextual a tutor. So for example, if a question like what is parameium is asked

by an eighth grader and an 11th grader, the answers would differ and would be different as compared to the eighth grader. The answer for the eighth grader is much more simpler and different as

compared to the 11th grader. This is because the AI tutor understands that each child is different and un answers on the basis of the child's class, subject and the curriculum of it. So how

is this content being generated? This is being generated by a ragdriven AI content generation system. This has the capability to generate highquality structured curriculum aligned content at

a scale at a very very low cost. So how does it work? This works by first uploading base reference material like NCRT PDFs and then converting into a more readable source for AI which

includes markdown or latex. This then generates variety of resources such as flashcards, practice questions etc. This is grounded in factual accuracy because hence our base reference material is

NCERTT. We have also implemented a quality check system implemented by AI models to check if the generated content follows certain parameters like language appropriateness and cultural

sensitivity. We have also established instructional design and bloom taxonomy principles to ensure that the content generated can be easily understood by the children. So the content that we uh

so the content that we generated has been tested on these key parameters. The grounded accuracy is more than 95.5%, hallucination rates are almost 0%, answer correctness is 96.3%, language

appropriateness which is very important for kids is more than 100%, content coverage is also 100%. Till now we have generated around 50,000 highquality content resources and it has only costed

us around 2500 rupees. We are collecting minimum data which only includes email name and class and there's data anominization and no third party data sharing. So right now Kovu is live with

class 6 to 12 CBC board. If the judges you want you can try the app on your phone by searching kiddov.com on the browser. And our future plan includes adding other state boards, adding

features like a study plan creator, sample paper maker and building a completely indigenous air model for our own educational content. We also plan to add content for competitive exam

preparations like J or NEAT. KO has the potential impact on the lives of more than 170 million students. If we target 40 million rural students and if they pay on an average 7,000 rupees annually,

they're paying more than 28,000 K rupees. With Kovo, they're saving that. They're saving more than 28,000 K rupees annually. Kov uses the power of AI in creating rich educational resources,

making quality education a right rather than a privilege. Thank you. Thank you, Ash. Uh Julie members, we have the last presentation of the day. Now I invite UI 3536

technical team. This is presentation number three. You can once the presentation opens you can move left, right? &gt;&gt; Yes. But you just 4 minutes now. 4

minutes. Namaste. Today we know that uh blind and visually impaired people they rely mostly on some caregiver or some assisted devices uh later such as meta

some blind man take some uh more technologies which have been recently built but is that enough that's the question so the thing is uh they may sense obstacles and they may sense some

he may send some haptic feedback but there is no contextual environment sensing and No. Uh what do you say the whatever is happening in front of him is not uh alerted to him. So uh so here the

third eye comes into the picture. So uh globally around 2.2 billion people are blind. That's a huge number. This is just a report uh this is just a reported number. But as you can see the

unreported may be more and in India alone there's a 70 million people who are visually impaired. So uh also due to this uh there is economic social loss and mineral loss too. So we stepped into

the field uh we attended the international disability event in Punjab where we interacted with 40 to 50 million visual impact. We tested this with them and took the inputs and

refined it uh according to their needs and their daily experiences. So as you can see um so this is the development process which we have done. So what is actually now let's uh deep

dive. So uh basically uh as you can see uh this is the uh tof sensors which is known as time off sensor. There's ultrasonic sensor and al also below um there is a IR sensor. So

this five sensor works calibratory like uh it will work simultaneously and give different datas. Now uh the IR sensor basically for depth estimation. Now if uh there is a uh some potholes or stairs

so that will be detected by the depth estimation. It will throw the IR radiations and according to that if there's a spike certain spike then we'll know that oh there's a depth uh or some

stairs or portals and this signals will trigger the computer vision uh computer vision uh models which we have trained and then if there's a portal or stairs it will confirm and then send a voice

navigation. So yeah &gt;&gt; uh so about the computer vision we have made our own model called disha model. So basically visha model is a is a model it comprises of more than

eight preced models uh basically models we take all the data all the objects we make them as a priority list let's assume you are in a you are in a class uh you are a blind person and you are a

third let's assume you are in a class it will express to the environments what is in the class where is the blackboard it will it will basically act as a Yeah. Yeah. Uh so so he talked about the dika

model basically our own build model. So now you may be thinking why there's a phone here. If you have built everything then uh you may have a question why there's a phone here. So this is

basically uh for the advanced AI processing. Now uh all blind people or visually impaired may not have the access to the phone. So all blind people may not have access

to the phone. So we already have a um the hardware build uh which has many sensor as you can see. Uh we have integrated a GPS GSM um all the offline voice modules as well and the ESP32 is

the main onboard processing also the Raspberry Pi camera as you can see. So we have used this basically. So this will uh detect obstacles both online and offline. Maybe offline will detect some

few obstacles. So mostly that will depend on the haptic feedback given by the sensors. And here there is a vibration uh sensor integrated near the hand and also there is a arm clunch over

here. So the for the weight distribution also um so now will talk about the battery part. So about the battery part we have designed such algorithm where our ESP32

and Raspberry Pi communicates with each other and gives a limited amount of power to the sensors and to the required part. So now what about the safety of the blind people so there's a care you

must have basically if if so there is a button over here which is in so if you press it twice or if you say uh emergency emergency twice so we have a wake up word. So basically then it will

send the live location to the caregivers's app. Uh so so the caregiver can really track his live location also the multiple uh and there's offline prediction map which we have used using

dio and IMU sensors and uh how the blind people will uh know basically how to operate this. So we have a bra manual as well or there's a voice uh embedded uh what you say the

navigation manual in the stick as well. So you can basically associate this learning mode uh and various modes as well. Um this is the AI matrix. Thank you.

Thank you teams. That brings us to the end of all the 20 UI presentations. I would like to invite Mr. Karthik Suri GM future skills at the India AI mission to present a token of appreciation to our

jury for their patience and time with us. And while you can all give a huge round of applause for all of these entrepreneurs you presented what an incredible incredible show

you certainly left the jury with a very tough job of deciding the winner. So thank you and congratulations. Yes. Dr. Anish Shan Paul program lead at our innovation mission.

Miss Kithika Reddi CEO optimized G and founder AI Miss Ranjit Goos global chief marketing officer VITRO and Mr. Jeep WA co-founder IDAS

the winners for this challenge will be announced today itself we have the awards ceremony at the ample theater in the south pavilion Bharat mandakam I invite the jury members teams and all

the guests to please attend the award ceremony at 6 p.m. to know the winners for the finale. Thank you for your time. &gt;&gt; We should take a photo with all the participants.

&gt;&gt; Oh, we want a photo with all the Can we get a photo with all the participants? &gt;&gt; Come, come. &gt;&gt; Wait, wait, wait.

Take one on this one. Next session. I would like to take a second. &gt;&gt; Yeah. Yeah. Thank you so much. &gt;&gt; I have to

Hi, I would request the participants from the previous session to please vacate the room immediately so that the next session can start in time. Thank you so much. You may use that gate for

exit please. And I have &gt;&gt; requesting all participants from the previous session to kindly vacate the hall

and I had much like the final step. Good afternoon everyone. Um uh room full and uh so much energy for us. So thank you very much for staying.

It's a very busy day and I hope we have a interesting session for you. Uh my name is Amir Banifetani. I'm chief responsibility officer at Cockresent. I'm delighted to be here today and we

have a wonderful panel to present to you on a very exciting topic called governing autonomy and uh the infrastructure for trust. We're going to talk about it a little more. We have a

demo for you as well. So my co-odderator Pravin Tanduri which is head of the AI lab in Bangalore uh is going to be doing couple of demos and as he's preparing this we're going to ask the uh the

audience to be presented themselves the I'm not going to do justice to present them fully but uh I'm going to name them and then uh have them to say probably a few words about what they do. Uh I'm

sorry but Elisa from Google uh go ahead Ellie. Hi everyone, I'm Eddie Safay. Um I am policy manager working on AI and emerging tech. Uh particularly agentic

AI and robotics. &gt;&gt; Uh hello and good afternoon. Uh this is Mahesh. Uh thank you all. Uh and thanks to Anir and Provin for having us here. Um and also they are generous enough to

put my younger version in the picture. And so I'm from project Nanda. uh we are pioneering the uh building a foundational infrastructure uh for a internet of AI agents you know like it's

a new kind of internet is born or getting born from last year onwards and u yeah and and one of the most uh foundational issues uh the way I say that trust that is me you know like

that's my photo the same thing you know like how we are going to solve uh this problem you know like using in this internet of AI agents and those primitives needs to be solved at a

foundational layer. It's not like after the fact or after the thought uh solutioning it has to happen as a first principle. Yeah. &gt;&gt; Thank you Alash.

&gt;&gt; Uh hello I'm Al Pash Sha. I am the managing director of the IT standards association uh and a member of the management council at le Thank you. &gt;&gt; Thank you Apua.

&gt;&gt; Hey guys. Hi. Um my name is Apu Goyel. I'm a principal at Insight Partners. I help lead a lot of our US India investing efforts. Just as context, we're one of the leading global

technology investment funds. We manage close to $90 billion in AUM investing out of a 12.5 billion fund into leading global software companies around the world including a bunch of companies

based out of India. &gt;&gt; Wonderful. Thank you so much. Uh let's be getting to uh Pravin is my co-odderator. probably is the head of a lab uh uh uh cockpit in Bangalore. But

before we start talking about it that as of raise of hand, how many of you have built an agent or play with an agent? How many of you are scared of what's going to happen with agents

when it's probably like 5% 10%. So it thinks that 90 80 or 90% of you don't feel that agents are going to be dangerous or anything else. Have you followed what happened with open cloud

recently on notebook? Do you feel this is cool or exciting or energizing or fun? Who is excited about what happened? It's a beautiful experiment, right? So, we're

learning about all these things. And as we talk about agentic world, the concept of autonomy scares a lot of people. Why? Because we don't fully know how they're built. We don't fully know how they're

going to react. If they're objective going to be changing, if they're going to be mixing with each other and creating new babies, we don't know what's going to happen. And they got rid

of autonomy a lot of decisions that enterprises take and society's functioning may not be able to put to be put in the hands of agents. So the concept of governance which is a concept

which is very encompassing about how we control the outcome of systems and procedures and ownership and risk management becomes central again uh in the world of agent which was not the

case about even a year ago. So today we're going to be talking about this concept of governing autonomy. How we can actually make sure that this world this future world going to be fully

autonomous. Not only is our hand to some extent but we can somehow trust it and we're going to extend. So to get started um maybe we can quick demo uh what do you think pin?

&gt;&gt; Let's start with the uh questions happening with autonomy and then &gt;&gt; okay perfect that's a good thing. So maybe I can start with Ellie. Um Eddie, in your vantage point, can you help us

understand what's different uh be between multi- aentic environment and systems and traditional AI that we've been used to? How should we think about it?

&gt;&gt; Yes. Um so with the raise of hand that I saw in this room, um I think we are u talking with a group of experts. So um from my perspective uh and you many of you have already worked with uh Mosbug

and uh have seen openclaw and have built agents. So you know better than me that the way that we think about agents it's not a specific line or a specific point in time that like this group of things

are agentic and this group of things are non-aggentic. rather thinking about them as a spectrum of agency or autonomy uh going from basic chat bots that can do a little bit of research and at the end

present the uh result. For example, uh Google deep research uh does a research um uh given your prompt and finds the information and presents that

information that has some agentic features but it doesn't take actions uh compared to let's say going all the way towards the end of the autonomy that is uh for example uh autonomous cars that

are completely end to end and they take action in the real world. So um I think seeing agents as uh a spectrum or a continuum of autonomy across different uh dimensions uh including memory

including planning and long-term planning short-term planning uh uh planning horizon that they can uh plan and execute things and where and also uh autonomy itself. So what I'm trying to

say is that um we can't say we don't want to say agents are the ones that take actions. We want to say agents live on a continuum from uh very basic autonomy all the way to um things like

autonomous vehicles that are fully end to end times. &gt;&gt; Um Mah uh you started talking about interesting uh issues but let's follow what Ellie said. What? How do we know it

just could make an error? How can you visually even know? Yeah. So, uh she used a very nice word. It's a continuum, right? So, it's not like a single point responses that you

can keep monitoring, you know, like after the agent took an action and she another thing that she mentioned they become a network actors. they will be acting at every single stage uh visibly

or invisibly and that makes it mandatory for us to make it uh I would say that it has to be a runtime governance rather than you know like wait for uh like let it happen and then we'll reverse so the

traditional uh governance models uh that we have or exist were very much evolved from our understanding of uh machine to machine interaction then it evolved into a SAS model and a cloud model. Uh then

we evolved to the microservices uh architecture and we kind of assumed that you know like somebody else is taking care of those uh governance after uh we reach uh at a scale you know like

so when autonomy will reach at a scale uh then we cannot think of like okay we need to solve this problem now now we are thinking of like agent as like oh okay charg is one of the agents I'm just

looking for the search answers uh rather than uh and slowly We say that okay it can just go and do some action it can crawl some web pages okay then we say that okay then there will be multi- aent

systems agent to agent interaction collaboration that will happen uh and just we are adopting it without addressing the foundational issue that the safety and the governance uh has to

be addressed uh that's one that along with the trust but also to make it u like how it can become a deployable across the enterprises uh or a public services or a civil

society uh without sacrificing this is very important factor without sacrificing the openness of this execution and the accountability. So those are the two points I would like to

mention. So you give us more information than I ask for. &gt;&gt; Yeah. Thank you. Uh when you talk about incident that happens of course remove bad actors right people that are using

agents for bad purposes. We're not talking about that which is a different issue security cyber security or control. We talk about agent themselves making an error or having a mistake. Uh

some of you know that we're talking recently about aic identity as a way to make sure that who the agents where they're coming from what's their training what data have been used who

created them who they belong they have a passport how they going to talk what language they speak can we talk with each other same language and so forth which brings now the concept of

certifying agents I'm going to ask to push the question because our push in in uh E stands working a lot in many many uh concept even ahead of his time on energetic. How do you think about

certifying agents in a world of autonomy? How how should we think about that? &gt;&gt; So I think this works

I guess that's one of the most important points, right? Knowing when it's on and when it's not. I I say that in just but this is also part of when we're thinking about these

various models and how they interact with each other. Not not having the ability to understand what is the end result or what good looks like creates a difficulty in understanding the

parameters by which you can state this is working as it should. Which means that very much and and already we we've seen this done quite successfully in a number of um uh the use cases we've been

involved in in prototypes and uh implementations around this that we've done is that first making sure you have a very strong governance structure in place is

critical. Second is making sure that you have um a very clear process by which you are determining what does and doesn't go out or is ready to go into the sandbox or

what you're ready to even put into that runtime state as you were sharing earlier. It also requires ensuring that you have an iterative approach to it. uh these

are not one-time exercises because you won't know necessarily when there might be a shift or where things may go in a different direction, right? And so this requires sort of a constant monitoring

approach. Adding to this is also the need to contextualize a lot of what you're looking at. Some of the reasons why you may see the behaviors of uh the multi-

aents may be because there was a trigger that you typically do not see or are unaware of which means that the bounds that you currently had in mind may not be the right bounds

and therefore it's important to also ensure that you have transparent accountable not only logging but people in that process ultimately at the end what it is that

you can evaluate let's a at a much um more level of confidence is the means by which it achieves the output. You won't know 100% if the thing that is out there is perfect

but over iterative series you begin to clearly understand right this out of the whe it's a Monte Carlo sim simulation or whatever model you choose to apply here at some point you have enough data to

know what what good should be right um so our certified program uh allows for this at the same I'm we have a series of standards uh that air uh was was instrumental in being involved and a

number of folks in the front row here as well uh which are focused on uh data transparency, focused on uh age appropriate design uh focused on also the critical elements around what does

it mean to be accountable, transparent, what does data privacy mean in the context of systems that we don't know what they were to be right and what we found the greatest power in is people.

It was the community of people that worked on this. They were heavily representative of a mix of lawyers, doctors, artists were even involved with engineers and technical people that

really understood the contextual problem so well that it allowed for us to better understand and appreciate what some of those variances might have been. Thank you Aash.

Okay. You invest in many many startups and companies and you are uh in the first line to evaluate them and and and see if the company is going to have solid technical background and the teams

is right. But because Aish mentioned the concept of governance, we're talking about governance and governing AI. How do you imagine a stack? Because we talk about a technical stack. We're all

familiar with the technical stack. What would be a governance stack look like when everything is autonomous? &gt;&gt; Yep. I think the way we think about governance stack in this AI world is a

5k clear model. Um if I kind of go first is like the build time around the build time the idea is okay how is the company architected around the idea of data governance model versioning. Um you know

when you kind of come to the next stack which is basically deploy time how do you think about the idea of policy uh tracking permissioning secrets management um when we come to the third

piece of it we think about this whole idea of runtime how are you ensuring that your your architecture allows for realtime observability how do you ensure that there is an idea of kill switch if

things go bad how do you ensure that you're able to cut it off at the right point of time then we think about the whole idea of How do you drive remediation? So do you

have the right audit trades to be able to do a postmortem? Do you have the right incident response architecture to be able to attack that? And then how can you drive and know whole accountability

lay which is around the whole idea of who drives accountability? How how do you have the right reporting structures? How can you conduct right postmortm? Do you have the right set of tools to be

able to do a compliance mapping there? So I think we think of governance stack in today's world in a holistic 5k clear model and anybody who thinks about this holistically is where we feel

comfortable about the fact that okay this is the team that is truly thinking about governance in a holistic way and as you think about the best AI native teams governance is becoming less of a

compliance issue but more of like an issue which is more product and GTM because you know whoever is embedding governance into product is truly winning on the GTM side um and that is becoming

a competitive advantage and so it's becoming a key part of how we evaluate a lot of the companies. &gt;&gt; Some people jokingly said we uh a few years ago 10 years ago we talk about

internet inside when the PCO was that now we talk about governance inside would you agree with that? Oh 100%. I feel like uh with so much of uncertainty I feel like every enterprise that is

procuring today like the upfront conversation before they take on any business through multiple layers of you know evaluation is talking through a bunch of questions around what is your

auditability? What's your traceability? What's your data handling practices? Are the kill switches in place? because the costs of things going wrong are so high that people are willing to spend

millions of dollars in ensuring the right governance while even buying a half a million ACV contract. Uh so I feel like it's becoming a core part of so how startup sorry this is a question

I didn't ask plan to ask but how startups that don't have all the fundings and all the resources necessary could comply with this level of scrutiny or requirement. I think the way I think

about it is when you're starting an agentic AI business in today's world, I call it like you need to have a minimal viable trust tag, you need to be at a high level, you need to be able to tell

what is this agent supposed to do. Uh is it actually doing what it's supposed to do? And if not, can you actually have someone stop doing what it's supposed to do on a real-time basis? uh and that

becomes critical and for that you basically need to have what you call as a clearly defined agent identity registry. You need to have the right set of guardrails at the orchestration

layer. You need to have a clear realtime observability architecture. And lastly, you need to have very clear set of defined oversight. I think if you don't have any of this, I don't think you

should be launching an agentic ecosystem into production because you're bound to meet more failures than success. And it's not that expensive to do these four basic things. And of course, as you

scale, you'll have a lot of compliance, start building into your product. But this is the minimal viable thing that any startup that's looking to start in the agentic AI needs to do to be able to

go into production. I think you should write an article about that because a lot of us would need that little four stack layer to to get started. You you use the term orchestration. Uh I would

like to pass on to Pravin uh as we as we talk about orchestration and coordination because as we define multi- aent systems they need to be coordinated in some ways to do certain things but

also to not do certain things. So um uh Previne um &gt;&gt; is you ready for the for a demo quick demo? I think it's very tiny. So maybe you can explain uh

&gt;&gt; so uh we have truly believe that the next phase of is going to be called the agent system. Am I audible? &gt;&gt; Sorry about that. I thought these was

working. Yeah. So uh we at Cognizant and Cognizant AI truly believe that the next frontier is going to be multi-agent systems and uh in that endeavor uh sometime in May 2025 we sort of open

sourced our multi- aent uh framework uh which is called Neuro AI multi-agent accelerator which you can see on the screen here. The uh it's a low code no code framework that's designed to

accelerate uh the prototype development to scaling. It's a production grade environment. Currently it's available uh under Apache 2.0 license on GitHub. Um there's an active community that is sort

of uh working on building and enhancing this framework uh as we speak. The the some of the features and the capabilities of this accelerator is that it's LLM agnostic right uh it's uh it's

cloud agnostic. So you have you as a user will have the control over which LLMs that you want sort of the the agent network to talk to. uh you have a control on which environment that you

want to deploy on that and it's interoperable. I mean currently you know we support multiple protocols from an agent to agent communication our own uh our protocol as well as A2N MCP server

uh and most importantly as we as we heard about the you know governance autonomy and you know the guardrails security is built into it. So we built this from security at the core of it not

not as an afterthought. So in the next one minute and and most importantly we've made it so simple that even a seasoned uh an a IML engineer to a CXO who has minimal or no coding experience

can start building their agent network in a matter of minutes and that's that's the whole our reason is that we want to make this as a de facto standard and we want everyone sort of adopt it and sort

of you know not just experiment it actually build this agent networks at scale and deploy them. Right? So, let me just do a quick demonstration. And today, what I'm going to do is quickly

white code an agent network in front of you guys. So, this is our uh uh vibing environment. So, let me just quickly anybody wants to give me a prompt. Anybody?

&gt;&gt; Anything? Anything you want prompted? Yeah. Uh AI submit schedule manager. &gt;&gt; All right. &gt;&gt; Can you read because it's not easy to read.

&gt;&gt; Yeah. I'm I'm saying create a multi- aent. &gt;&gt; Can you the microphone? I'm saying create a multi- aent network. for India AI summit New Delhi, right?

It's working now. It's working. Okay. So, what you can really see is just give it a few more seconds. What you see is that there's there's a multi- aent architect and a designer which is

working behind just to understand the intent and the intent that I gave us is create a multi- aent network for India AI summit New Delhi that's currently happening. First thing that you will see

is that the large language model understood my requirement and it created set of agents. It's defined the agents. Now what it's actually doing is that it's actually connecting those agents to

an orchestrator. It's still building through it and as a next step what will happen really is that basically now every agent needs to def uh be defined. It needs to

have its own roles responsibilities and what it should do and what it should not do. So currently that's a step that we are actually going through it where you can see that you know uh in a matter of

moment all these agent network uh agent individual agents will be populated with descriptors you can see that right so those descriptions are nothing but its definitions what it should be doing at

the end of the day right and it's still finalizing the agent network the two things that you need to see at this year is that there are agents which have been specifically created for that agent

network and then there are there are few of them which under the leaf nodes orange in color. So basically what the designers uh understood that there are certain agents which were already

created and they were available in my environment. So it just connected them directly. So instead of rebuilding them, reinvesting in creating the agent network, it just connected them. So you

could use it. So it also allows as a designer of agent network is that you have a control auditability and traceability of it. At any point you think that that leaf node is not

required in that agent, you can just delete it and save it. the server understand the changes and your new agent network is ready to be played around with. So now that the agent

network is ready, what I'm really going to do is that launch it you can see that the agent network is uh made available again just let me blow it up a little bit here and before I sort of fire a

query uh just to sort of and again this is a development environment. The reason we are showing a development environment is just to showcase a couple of capabilities. What you see on the uh the

right hand side panel is basically your chat window and then you have an internal chat which is basically shows in real time the communication between the agents what kind of information is

being uh transmitted what the nature of it. So you as a designer have the control over it as well. So you can take a dump of it later on and you can sort of go through it review it to see if any

confidential data is being leaked through a large language model got access to it right and then you have the logs. The logs are pretty granular in nature in the sense that it gives you to

details to a level of the token usage and the cost associated with each of that communication. And last but not the least uh I mean most of the folks here are pro ESD metrics right so you you

also get a score of energy usage carbon footprint and the cost associated with each of the uh prom that you are firing so let me just so so I'm asking the agent it was so can

you provide a schedule for the keynote speeches at the India AI summit right so I think it's okay let me see if I can get so currently it's not grounded is just talking to a large language model

behind. So every agent network that we create here uh by default it talks to uh GPT4 but you as a user have a control as I said is LLM agnostic. So if you in your organization have a qualified large

language model that you want this agent network to we can. So globally each and every agent network has access to one uh large language model but the framework has has the uh coolest capability where

every leaf node agent also can be empowered with two specialized or a general purpose agents uh LLM as well. So they act as a fallback and and if you have a specialized agent like for

auditing or governance or compliance right you want higher accuracy you can sort of connect a specific large language model just to that uh leaf node agent as well. So that's sort of the and

and today it's al uh it's available on GitHub uh it's been there for last 5 months now we have an active community uh the GitHub repository gives you access to the code base under the Apache

2.0 license and this framework has met the highest standard of GitHub uh security as well today right so that's an example of a

you have no queries to run &gt;&gt; yeah so that's an example of a coordination which basically takes into account all the consideration that was discussed and you said it's open source

right plugin &gt;&gt; yes it's open source &gt;&gt; open source so everyone can use and play So here's the QR code and if you need more so here's the QR

code that you can sort of scan it will directly take you to the uh the GitHub repository that we have uh you know we encourage you to fork it clone it and if you like it give us a start and if you

don't like it let us know why and we are here to uh sort of work with you on that. Yeah, &gt;&gt; sorry to interject. Uh, I just had a question. If you have multiple agents

running at the same time, all of them have different contexts and different memory. How do you manage that in a single platform? &gt;&gt; I mean, some time. Let's come back to it

offline, but we'll get into that. We'll get into it. All right. &gt;&gt; Great question. So, that was just a demo to basically because the audiences they were assumed what what these things look

like, but this has been certified as for compared with this framework as well. So there's a lot of that behind the scene what Abua was talking about has been taken into account in terms of

observability monitoring and so forth. Um going back to the um the issues of incident and tracking incident and and danger that could happen. There are examples in other areas such as

aviation, nuclear power etc. uh maybe Eddie can give us a uh a view of how the other industries have dealt with these issues because this issue is today we talk about agentic autonomy we have this

issues before in other sectors how have we dealt with them &gt;&gt; yes um absolutely so the technology may be new but the concept of safety especially in safety critical uh

industries is not new we have seen that before and we've solved for it um uh let's take the example of uh aviations and uh drones for example example. So drones are kind of newer technology and

um a lot of um regulatory bodies are looking at regulating drones. Um and the interesting thing about looking at drones and comparing them with agents is that um when you look at let's say uh

the regulations that uh at least in the US uh aviation industry is uh considering for drones it was originally based on what uh FAA uh or federal aviation administration calls uh VLOOs

meaning um visual line of sight meaning that a pilot has always uh is in command and they have to keep visual line of sight with the drone. So uh and that is how they they are accountable for

managing that drone. However, as the safety and as the system safety based on using AR technology develops, uh now the vloss regulation is moving to beyond visual line of sight and that

means that now the safety of an AI uh detect and avoid system has gone above what a human can do. And based on this advantage of say advantage of detect and avoid based on AI system now the

regulation is moving from a pilot has to always keep visual line of sight to beyond visual visual line of sight and um using that as as a way to maintain safety. So drawing a comparison to

agents um if you think of uh when we talk about human in the loop human in the loop we basically talking about wheel loss human has to keep approving every step of the way that agents are

taking however that undermines the utility of the agent right so as agents become safer and more reliable similar to what detect and avoid in the aviation industry got better and better over time

we we have to be moving from human in the loop to pilot in command in aviation industry. In this case would be human in command. So human will be uh doing the

supervision but not in the loop approving everything that agent is supposed to do. So drawing this kind of parallels with respect to other uh industries that are moving from safety

of human making those decisions make a lot of sense to apply to agentic AI because uh similar to um aviation in this case we see that human maybe keeping the human always in the loop is

not the best thing. um similar to detect and avoid there must there could be better safety systems that AI can provide that keeps agents even safer but I'm not saying that that

applies today I'm saying similar to other industries that moved from one side to the other agentic AI would also move now we are in human in the loop and then we have to move towards human in

command &gt;&gt; thank you very much &gt;&gt; thank you very much as you talked about the similarity between drones agents and FAA regulation. I'm going back to the

rest of the audience, the two of you to ask a question is that in your opinion, what's the balance between engineering guidelines and technical design at the core versus regulations and norms and

standards, right? Because both of them are media. We're not discussing that. But today with what's going on with agents in what's the balance of that should be 80% engineer design and good

practices like observability measurement etc or should be probably little bit less controlled engine let innovation go but also providing framework of um certification and standards how do you

balance these two &gt;&gt; yeah so um so I'm I'm analogy with the early days of internet you know like how internet even evolved at first place uh they make sure that it's not owned by uh

individual player or anything you know like so it was all inclusive and they very much focused on uh solving the uh the foundational primitives you know like identity discovery uh trust and

that was in a federated system it was never uh a centralized system so in this uh context you know like when you said uh okay so compliance uh It should be uh heavy compliance will kind of uh

sabotage the innovation you know like how the tear off uh uh we will do uh and my uh uh my opinion on that is you know like we should be uh keep the innovation open you know like and that remains uh

as a data plane okay but the governance has to be the control plane so they has to uh built in parallel we cannot choose one versus other so yeah that's that's my But yeah, I'm curious to hear Pisha's

and Pua's opinion on that as well. &gt;&gt; Yeah. I I mean I I I think the air if we took some real world examples right there's some policies regionally uh that some have claimed were too too early in

the days and have led to uh unnecessary regulation and the effects of that unnecessary regulation have compromised perhaps the innovation that could have emerged as a

result. I'm not so sure whether or not I agree with that. I think you know I'll I'll let time uh you know claim claim that one. But what I would say is that it

really just depends what you're trying to do. If you're early days, you're just trying to understand what is possible and the bounds within your own sandbox. You should be able to test it out and

understand you. You need the chance to even observe it before you can jump to a conclusion that's something that's ready to go to market. Uh at the same time when you get to the

proper maturation point as as uh my colleagues have shared you know this is when regulation starts to make a little bit more sense right from a requirements standpoint.

Policy can also function though in an earlier stage to begin framing and the framing is important to know just so you have a sense of where is too far right but framing is different than

and at a certain point as as uh I'm sure provin knows as well is that there there comes a point where there's a market acceptance of what is normalized And at that point in time, that's when

the market differentiation really starts to play a role. That's when you see the major uptick. Prior to that, you're not necessarily going to see everyone buy into paying $100,000 or $150,000 to get

something certified, right? The costs become a barrier to entry. But this also means that there is perhaps a different way of approaching

this. You know, I go back to the comment air and uh we're were speaking to earlier of the mini trust stack. Uh you know, in many ways, we can also consider this the economic problem of

how do you make it easier for startups to come into play. And one of those ways could be let's say theoretically but maybe some of us are working on this uh is the integration of the required

standards and policies baked into the fabric from the get- go. And then as you build and stage stage gate beyond that what you've already done is you've bought time for those

startups. You've also given a level of trust for the governments as they're playing here and you've given regulators at least something much clearer to measure against. It's very very

difficult to ask someone to measure something and hold you accountable when they don't know what they're supposed to hold you accountable against. And it's the same problem for companies. They

don't want to waste time on something that makes no sense and all this market play. So uh air I hope that helps answer your question but that that's my take on it. Thank you.

&gt;&gt; Can I ask a followup? &gt;&gt; Please go ahead. I'm the ones to answer too. &gt;&gt; Actually in your experience &gt;&gt; captured most of what I said so I would

save the time. &gt;&gt; Yeah actually I wanted to get your perspective on how you see founders actually balancing this.

I again I I feel like the idea is everybody's working with the certain idea of what that framework looks like and I feel like there is not a lot of mutual tension between deploying

responsibly AI and what leads to high commercial deployment you know it's like if you need to be a half a billion AR business today you need to be able to sell into enterprises in mid-market and

those mid-market solutions are selling into either government institutions, large scale enterprises and all of them today have a much larger business to prot protect and so if you're

experimenting with a new technology that is evolving very very fast and if you're not able to provide for certain frameworks of those responsible guidelines it's like hey I want to make

sure my data is being handled well I want to make sure my secrets are being managed in the right way the agents have the right set of permissions and policies these those guidelines are

being and and I think today those frameworks are very individual are localized to the company that you're trying to serve but if you kind of distill that those will broadly come

down to like 15 20 large principles and most of the innovation that is happening is happening within the bound of those 20 25 frameworks I think to Alisha's point that is going to start solidifying

a lot more as a technology matures Uh but I think people always try and frame being responsible and commercial innovation as a trade-off. I feel like with the way the world is moving, it's

it's not a tension. It's actually very very aligned. Uh and that's how even most of the board conversations happen is because if you can't do that, you would not be able to scale.

&gt;&gt; So on that note, staying with you Aurora, right? You you talked about the trade-offs, you talked about the investment, right? If we switch gears into the economics of it, right? Uh

so when when do you see the governance actually becoming a competitive advantage and not a a cost burden to the organization? To be very honest in very early stages

of the company we have a lot of our portfolio companies at seed series A stage start selling into enterprises day one. So if you are selling into the cognizance of the world or if you're

selling into uh the Googles of the world and all of that a bunch of these companies today and just how innovative they are and how fast they're moving like day one they sell into you know a

half a million a million AR contract into a very large enterprise and when you're doing that you can't do that without uh governance like sock 2 used to be that version uh so to compliance

for like your old age SAS framework there so I feel like most of these conversations become pretty much very very embedded in your seed series like the moment the company's about to sell

if governance is not an embedded conversation in your product it will not be a competitive edge for you in the GTM uh and and to be honest I meet 100 AI companies a month the best AI native

teams today have actually embedded it so deeply that you know like security it's part of their weekly operating cadence they'll talk about the idea around evals you know how solid are your eval

reviews. Are you doing it on a weekly basis? Are you making sure they're like meeting the standards that you want to espouse serving into enterprise customer? They're thinking about red

teaming in a very solid way. They're doing very high quality postmortem reviews if things don't work the way they are supposed to work. So, I feel like governance is like security today

and those start playing out pretty much in a seed series A conversation. If you're selling into uh an enterprise, I feel like that conversation becomes later if you are if you're a PLG

business that is serve serving like individual creators, individual designers. I don't think if you are like trying to buy a $50 per month contract as a designer and using that to create

videos, you're thinking as much about like, hey, is this meeting those governance standards that I need to? But anyone selling into a mid-market enterprise solution, this becomes a very

early on conversation. I have just uh a follow thought on that right. So uh our India's digital bullet infrastructure story like when we built Aadhaar we built uh UPI payment system we solve

identity problem we solve the the payment problem then we were like okay what about the data privacy then we have the dig locker then we have uh OCD and then uh now what what is happening

that's a very important success story and very much aligned with this agentic AI because the government uh took a stand saying that hey we are going to standardize as the interfaces. Okay. And

what we really want to do rest of the people or the companies they can do any applications that they want on top of it so that government plays a very important role in this uh agent

evolution I would say. Thank you. &gt;&gt; Thank you. Uh at the beginning we talked about governing autonomy and we discuss about autonomy discuss about governance to some extent I think. Um what could be

in your opinion um well there's two aspect to that question. when is it if we can't about trust what is infrastructure for trust because it's so so fragmented between different pieces

and then how should we think about um the one single thing that would enable us to go to the right direction because we talked about again many things but in your opinion what be the one single

thing that we have to do today given what you expect what you mentioned it's just that we need to leave innovation open we need to experiment we need to have some general guides and framing Of

course, but besides that, what would be one little thing that we need to really be pushing collectively, not as individuals, but collectively to to to make everybody progress besides open

sourcing it? Of course. &gt;&gt; Ellie, do you want to start? &gt;&gt; Uh yeah, I can start. Um maybe one of the things that we can think about today is how can we evolve um testing methods

and evaluation benchmarks for multi-agent systems. And the reason I say that is that um uh we have a paper uh called distribution distributional AGI safety meaning that um the paper

discusses the fact that AGI may not emerge as one monolithic big powerful system but it may actually emerge as a lot of sub AGI agents specialized agents working with each other in a multi-agent

system. So we may be talking about multi-agent systems that reach AGI level capabilities and for that to be successful what we what should we be thinking about today um when it arrives.

So um in that paper we discussed like four different categories of um safety uh including market design including baseline safety for each agent itself including inter agent communication etc

etc uh please feel free to refer to that agent but um refer to that paper but um I think what we need to do today is making sure that we built evaluation benchmarks that are relevant to multi-

aent systems and for Frontier Labs that are developing these um models that are core to the agents. It's important for them to and by them I mean Google leave mine being one of them um to report test

against these benchmarks report transparently about the limitations report transparently about the capabilities um and I think that's that is uh one of the goals that Google lip

mine has been pursuing and a lot of that information is available on the website please feel free to uh read our frameworks on um on AGI safety as well I stop

Um so I just uh again follow on that right uh one of the important factors that we're missing in a multi- aentic system there we are assuming that it's a single model agent right across the

multi- aent system I'm using one model but when we extend that thought that what will happen when I'm using uh models provided by different players open source uh or nonopen source you

know like all of those models will try to uh so single responses are easy to verify. You can have the matrix or all the telemetry associated with it to verify the uh whatever the agent is

claiming. But when it goes across those boundaries and it becomes like a multimodal system, multi- aentic system and every single uh company saying that hey trust us you know like because we

are uh so the one of the thought experiments or the way we try to solve it is like get every voice heard meaning that let's hear from all the academia how they think about this problem uh get

all the uh LLM uh or the big uh companies get involved in this discussion. uh the same thing with the system integrators and hyperscalers also

participate in it and not just them but including policy makers as well as the the younger generation who is going to be the uh Asian AI native you know like so how are we preparing uh for that

that's very important uh so the problem doesn't uh get solved uh with the single model uh responses so the only solution that we kind of move towards to make it enough decentralized or enough federated

system so that we can have those uh uh trust monitors across every single thing. Yeah. Thank you. upper run. &gt;&gt; I think for me largely

the thing which I think can solve a lot of it because that kind of distills enough information to people start working from is the idea around auditability and traceability to be able

to capture and accurate reporting in an immutable way of a lot of what is happening. And as long as there are more open-source platforms that allow for a lot of those, you know, anonymized way

of auditability and traceability and the incidents that's coming uh to come up, I think it drives for more collective learning at a more global platform level. I I don't know if there are and

this is a conversation where when we meet a lot of startups they're actually learning a lot from talking to each other and they keep ruing about the fact that there not a lot of global platforms

that just talk about just learnings around audit auditable trails or what is happening how is it happening where do systems fail at what scale uh and level of infrastructure and I think something

that solves for just a collective platform to learn from uh will go a long way it's it's a very innovative environment ment what's in around the world and what's happening. So as long

as you provide the right infrastructure for even knowing what's going wrong um you know I think there's a lot that can actually accelerate the learning and development there.

&gt;&gt; That's a cue for our session. &gt;&gt; I'll finish closing. &gt;&gt; Oh I thought that was where you programmed the AI to do. &gt;&gt; Yeah. So I

I I think there's two two key points. Um I I'd like to just leave everyone with you know uh the first Amir runs a very uh innovative uh organization called uh AI commons that many of us have been a

part of over the years and really the the the critical nature of what they have been looking at which very much aligned with uh a lot of what we were looking at as well was uh the idea of

having these technologies treated it as a commons public utility because if you don't do that you can't do exactly what everyone here is speaking to only those that have access

to that can do that and the point on education is very critical uh but the point I I would just bleed into this then is the thing to do today we have to spend a lot more time

getting rid of the jargon even the title of today's session isn't something that's accessible readily to the same people we're asking to make use of these technologies,

right? And so a lot of the effort needs to be spent on demystifying what we're talking about and show the value of it because if we don't do that then you're going to have a lot of fear and a lot of

the fear is unnecessary and I think the these would be the critical things. Um I would also love to use your app to turn off that alarm. Uh so maybe you can teach us later about

that. Thanks. &gt;&gt; Thank you very much. Thank you. Thank you everyone for coming. very special set of uh speakers here with us this afternoon. I'm going to

keep the introductions very brief. I'll let them do the talking and let them introduce themselves to you. Without further ado as we talk about global capital, the local advantage India in

the AI race. Please join me in welcoming Shriram Bishwanatan of Celestea Capital. Sham can we have you up here also with us Nibuti Ray of Invest India. Nibruti thanks very much for joining us.

Dibinder Saluja of Capricorn Investment Group. Sanjay Tugnet uh of Fairfax Digital and Abhishek Shukla Prosperity 7 Ventures. Thank you very much to my panel for joining me here this

afternoon. Let me just set the context of what we are going to be talking about and I would imagine that you've had plenty of conversations centered around AI in general and India in specific and

where India finds itself. Let me just throw some developments that have taken place in the last 48 hours uh or perhaps the last 72 hours when we talk about capital uh and we talk about what's

happening globally. Anthropic just raising $30 billion as a $350 billion valuation. That's the kind of capital that is slloshing around globally. Can India uh try and veer some of that

capital to our shores is the big question. Other developments and it doesn't necessarily only have to be money. It could be collaboration. It could be partnerships. Just this morning

we've seen anthropic and emphasis in uh inca partnership join hands together. We've seen AMD join hands with TCS. So there is a collaboration that is taking place, an ecosystem of partnerships

that's also building out and that is also going to be an important aspect to look at when we talk about how foreign investors are looking at India. Where does India find itself uh in the AI

race? Uh I think the question being asked at Nauseium is who is India's AI story? Uh I think at this point in time it is a developing story. It's a work in progress. You will of course see the

launch from Saram the frontier model that Saram is going to launch tomorrow here uh and that is going to be the start of India's uh LLM story in a way but uh there is plenty else that's

happening of course the Indian IT services sector uh and their their claim at this point in time is don't write us off we are here to play even in an AI era and that's going to be a big one for

India to make the transition and pivot to in an AI world because that is a sector that has generated jobs. It's a sector that's generated significant forex earnings for India. How does that

make the pivot and what role can foreign capital play in that is also the question. So I'm going to now step uh step two towards my panel and and get things started. But very quickly uh in a

minute if each one of you could introduce yourselves take us through the kind of portfolio investments that you're making the assets under management at this point in time so that

this audience gets a glimpse of what interests you the bets that you're making and then we'll talk about the future bets on India Shriram I'll give you the first word.

&gt;&gt; Yeah. Hi my I'm Sri Ram I I'm one of the founding partners of Celestea Capital. We are a Silicon Valley based uh deep tech investor but we are very active in India. We actually have a India fund. So

uh you know we were investing in chips and deep tech uh probably all of our career. Um the the founders of the firm have extensive experience in in deep tech. One of my partners is actually the

CEO of Intel. The other partner is the guy who built Flexronics. So we come from a hardware background and uh we're super excited about what's happening in India and we have over 100 companies in

the portfolio. We have about 20% of our our activities in India and uh and yeah so we're like we couldn't be in a better place better time than right now right here.

&gt;&gt; Better place better time than India right now right here. Sanjay uh a minute to you to start with. Fairfax digital how bullish are you on India and also explain to us what the bets are that

you've made so far. &gt;&gt; Uh thank you first of all and thank you Shira for curating this panel and you'll have to switch the mic on I think. Yeah, I'll start again. Thank you Shin

for the question and uh thank you Shiran for curating this panel. Uh very glad to be here. So Fairfax Financial is a company which is headquartered in Toronto and uh that's where I come from.

Uh this company was started 40 years ago by a chairman and CEO who is a founder of the company Mr. Primatza. He's also known as the Warren Buffet of Canada. And uh there are two things common

between him and uh Prime Minister Modi. They both turned 75 last year uh and they're still growing. And the second thing is that both are extremely bullish on the India growth story. Uh India

Fairfax has been uh a very very long-term investor uh and we have done our first investment as company called IC Lombard. So Lombard was uh Fairfax. we came in that was in the early 2000s

and since then uh we have had a lot of success with companies both on the physical infrastructure. Uh Bangalore airport is one of our uh crown jewels. Then we have Thomas Cook. Uh go digit

was the first uh digital insurance uh company which got IPOed uh and that was a 3.7 billion IPO. So we are very very bullish on India and uh as uh when we interviewed Larry Frink he said the

India era is now and uh that's what Fairfax and P believe in. Thank you. &gt;&gt; The India era is now is what Larry Pink did say. Whether it's going to be an AI era or not is the question that

hopefully this panel will address. Liberty at Invest India you've been trying to draw foreign investors into India at a gross level. We've seen FDI go up of course uh we've seen a lot of

outward movement of money as well which has impacted the numbers but how confident do you feel about the numbers picking up on FDI? Uh so I'm very very confident and just like my name suggests

invest India but that's only half the story. My job is to not just bring investment into India but to ensure that the return of investment to the investor is enabled because that's why you know

some handholding some avoiding bumps has to happen and that's why the government has instituted this charter in West India. on the FBI. I just want to say just this last year or the year that we

finished in uh April uh he said you know pays turn 75. I have with my team enabled 75 industries to invest in India and by the way by the time April comes it will amount to $6 billion. $6 billion

75 companies more than one per week is what we have enabled. Now these are only industrial investors and if you look at India's investment about 50 billion is the new equity that came in last year of

which half was industry half was institutional. So invest India enabled six out of 25 from if you look at last year's metric but this year I can assure you it's going to be much more because

last year we enabled only $2 billion. Now the remainder 25 is institutional investors and what I'm trying to do now is FOR ALL THE COMPANIES out here if you have aspirations to become local

suppliers to global investors amp up roll up your sleeves because we are trying to bring a program called scale up India where I'm partnering with you know guys like this on this on this dire

very you know large aum kind of guys to look at a fixed demand of a company like a Swedish company coming into India to build machinery but needs local suppliers doesn't want to import. I am

trying to bring investment into this Indian company. On the last one, outward FBI. I think that's a good problem to have because our companies are investing abroad. Just last year when I talked

about uh you know 80 billion uh FBI coming into India, 30 billion went out. It was double of the last 5 years average. And why? Because we were getting manufacturing capability. We

were adding IPS, we were growing TAMs, we were growing products. So it's a good problem. So net FDI needs to not be looked as the only metric. What did India uh you know gain? What is the

wealth distribution? I'm looking at all of that. &gt;&gt; Okay. Thank you very much for that. I'll come back &gt;&gt; called Capricorn based in Palo Alto and

in New York. We've been investing in deep tech for over 20 years. And uh as Shiran was joking, we were kind of the early Silicon Valley Silicon crowd really the Silicon and Silicon Valley.

Um uh we started investing in the energy transition about 20 years ago. So a lot around power, electronics and the electrification of everything. Our second investment 20 years ago was

Tesla. Um we went on to do uh a whole bunch of ecosystem investments in the EV ecosystem. Moved on to electric airplanes and then aerospace um rockets and satellites. Uh one of our uh

investments along the way was SpaceX and Planet Labs which has done a lot of work here in India. And then over the last 10 years, we've been focused a lot on semiconductors, chips for computing,

chips for networking, chips for power, uh more recently optical chips and next generation dataccom and AI hardware infrastructure. We really think that is where uh the next wave of innovation has

to happen as often the software jumps ahead of the hardware infrastructure and then the hardware infrastructure has to catch up. uh we've also invested in India over the years primarily around

the energy infrastructure and are now starting to look at um uh the semiconductor and other associated spaces. Looking forward to a good &gt;&gt; We look forward to listening to you and

uh what you have to say about some of those trends and the innovations that you talked about also the the big emerging trend the possible emerging trend of data centers in space which is

which is the big uh buzzword at this point in time. Abishek to you first uh with a quick preview of your India plans and then we'll we'll take the conversation forward.

&gt;&gt; Absolutely. Uh hi everyone, my name is Abhishek Shukla. I'm the managing director for Prosperity 7. We are a single LP fund backed by Saudi Aramco. Uh Aramco ventures overall is $7.5

billion worldwide with offices across Palo Alto, China, uh Europe and now shortly in India and Bangalore. uh so uh and we invest prosperity 7 I'm based in PaloAlto we invest a lot of the things

which uh which depend around uh silicon networking infrastructure because there's a lot of AI buildout happening of course in the valley around the region but then also in the kingdom of

Saudi Arabia with uh with the given the energy as well as the as the infrastructure needs there uh in terms of India we we we have an office uh in Bangalore we are opening up uh adding

more people and uh looking to invest uh you know this would be our third and third and the fourth office worldwide uh but we are looking to uh to come in strong obviously we've been looking at

India for some time but in terms of deep tech in terms of AI in terms of infrastructure uh you know that story wasn't obvious wasn't real up until now

which is why we feel it's a confident time for us to step in &gt;&gt; so I'm going to ask you when You're going to write your first India check, but I'll come back to that in just a

second. Before we talk about India, let's get the global picture out of the way and Shiramama and Depender, I'm going to get both of you to address this issue. You know, there's jaw-dropping

numbers in terms of the AI infrastructure buildout, $600 billion and counting. Uh, you know, the question though is what is going to be the return on investment? Are we overbuilding? Are

we heading into bubble territory? Are we already in bubble territory? Are we close to correction? Let's get the global picture out of the way and then we'll talk about what that means for

India. Shr starting with you. &gt;&gt; Yeah. So you look at I think in any uh huge momentum in the market over the last 30 40 years you would see that the market actually gets ahead of itself. I

mean it corrects itself and then continues to you know move forward and I think this time it is probably quite significant because this is uh you know if you take the if you take the telecom

revolution or if you take the enterprise software revolution each one of those waves as it were impacted one segment of the overall market. Now here you have a technology in the in the ways of

artificial intelligence and deep learning and all of that which has a potential to affect every industry in every aspect of our lives whether it's work play you know uh commerce you know

all of it so this time it's different &gt;&gt; but that's is really &gt;&gt; in terms of the I was going to the second part of the question was where I was going to get to where it's not that

different in terms of what to expect from the market but in terms of the core technology itself it is very very different. Um you know there was this whole discussion around you know do you

build narrow AI or general AI uh and as you know the difference between what China is doing and what the US is doing the US is really focusing on general AI. So if you can actually build

intelligence then any problem that requires intelligence by definition everything does you have a mechanism by which you can disrupt that problem whether it's industrial you know

manufacturing any of it but China didn't take that approach that China is taking a slightly different approach anyway going back to the real core of your question which is is this a bubble I

think you will find that there are certain parts of the overall ecosystem that are in the bubble territory &gt;&gt; uh already of But you know remember in the dotcom days

90% of the market uh players in that time died but out of that came multiple trillion dollar companies. So I think this time you will see pockets of the market which will be ahead of itself and

will take some correction but core technology at the lower end of the stack where you're building disruptive whether it's frontier models whether it's new generation chipsets or you know depend

and I are actually involved in a company that's actually looking at we can't tell you what the company is uh but they're looking at a fundamentally disruptive model to how the LLMs are built. today.

&gt;&gt; So, you know, you probably know about the one New Woman architecture. They're architecturally looking at something completely different, right? So, there are things that are happening which are

going to be very disruptive and I think you will see that play out over the next 5 10 years. &gt;&gt; And that's the perfect segue to come to you Depender because you know the kind

of money that is being thrown at the buildout at this point in time going by the way that LLMs are being developed and the uh uh layers around that and China is taking a very different

approach and a very different cost structure as well. what are the lessons to be learned there for India because as we get into the race and we're not in the race yet as we get into the race

what do we prioritize so I think um I don't think there's anything unique that you have to worry about in India but just to add to Sriram's point one of the differences from the last time assuming

you know we're talking about 25 years ago is that this time around we are talking about reinventing practically everything that is done in the world practically everything we do. So it

isn't anywhere near as narrow as the dot beginnings. Um and we haven't even scratched the surface on the entire physical world yet. Everybody's been focused on the models, the software side

of it. Um, in fact, almost everybody when you meet them in San Francisco is focused heavily on coding as the first frontier because that's what everybody loves and does over there. So just

imagine if you were to go from coding all the way to human activity outside whether it's medicine or education or uh you know any of those large industries and then start on the industrial side

and manufacturing and the whole physical AI side. I think you know autonomous vehicles are a tiny front to that but if you can bring that to everything else that is uh industrial and physical

there's a huge huge opportunity set out there. So the TAM is almost you know limitless right now from where we sit. The question is are there localized bubbles? Are there too many people doing

the same thing and what the fallout there will be. But that's not different than any other opport situation in which people compete and the best ones will win. And yes, there will be a lot of

people who don't make it, but in the end, the consumer &gt;&gt; and the and uh and the benefactors will be many. &gt;&gt; Well, the the consumer Yeah, absolutely.

Abishek, go ahead and your point. The consumer is benefiting at this point in time. You've got everybody selling their stuff to Indian consumers virtually for free and and YOU KNOW AND THAT BEGS the

question of monetization as well. But go ahead Abishek. &gt;&gt; Yeah sorry I just wanted to add to that then dialing up the contrast a little bit 25 years ago you know uh when when

the buildout was happening there was one assumption the assumption was we're going to build out the network and they will come. We are we were living at a time when there was no Uber there was no

Door Dash no nothing. the iPhone moment hadn't arrived and the network was built for next 20 year capacity. Contrast this with now there is not a single GPU which stays unutilized today even if it's the

H100s or even going before that. So you know while uh uh while we might be talking about infrastructure buildout and is there a bubble we are still ears away from people even uh you know having

enough which is needed today. We have portfolio companies such as together AI and others like the demand they they cannot get hold of the demand uh of the of the demand. It's all limited by the

supply. Um, and maybe just to your last point, &gt;&gt; this this doesn't mean there won't be um a lot of pain. This doesn't mean there won't be a lot of losers. Um, take

the example of the whole smartphone market. &gt;&gt; All the incumbents felt a lot of pain because they did not build the product that the world wanted or needed. That

did not mean there was a bubble at large. it meant there was less room for mediocrity &gt;&gt; and so I think you'll see the same cycle where mediocrity won't get rewarded

beyond a point and uh that will feel like a bubble to to to many but in the larger scheme of things um scheme of things um there's still a lot of lot of blue sky out there

&gt;&gt; a lot of blue sky a lot of headroom for growth Sanjay go ahead &gt;&gt; uh thank you I think just taking on for from some of the things which were mentioned by uh by my panelists out

As we think about what Deependra just said right now, we are the last generation of managers in this room managing humans. We are the last generation of managers

in this room managing humans. The next generation of managers will manage a hybrid workforce which will be humans as well as digital workers and that's what we're seeing in our companies. Now if

you take that then the capital gets repriced and you mentioned about ROI in the industrial revolution ROI meant return on investment

&gt;&gt; but in the intelligence revolution means return on intelligence. M &gt;&gt; and I think there are three major forces which India can benefit of when you said about global trends and I call them the

three Bs. The first one is decarbonization. The second one is digitization and the third one is decoupling. So if you look at starting from below what

said it's the revival of the middle order which is where India will benefit you signed five treaties in the last few months and you're

looking at just in the EU 100 billion coming in for the next 15 years right so if you look at that is one major trend the second is decarbonization India is absolutely on the 7

there there will be a lot of investments coming in and all of these three are AI enabled and the third one is digitization. If you look at digitization, we are much

ahead of the curve. We already have the digital pack, you know, we have NPC, UPI. We also build the physical infrastructure, you know, the road and all that. Now the third as Jensen

said AI is the new infrastructure because data is the new oil and I think that's where if you look at institutionalizing intelligence in India will be the key and that's where because

intelligence density is there that's where the global capital flow that's the global trends are thank you &gt;&gt; I'll come back to you in just a second let me get nitri in on this niu you know

when we talk about digital infrastructure and the government has an AI mission in place a budget has been put aside as far as the AI mission is concerned and it's running in parallel

with the semiconductor mission and you know Shriram and uh his team have been partnering with the government on that is that going to be enough is the question you know we talk about just a

single company in the US spending $200 billion is the kind of money that the Indian government is putting forward the Indian private sector you know is is not in the game so to speak at this point in

time is it going to require the government to do much more by way of investment if we are going to be in this race. &gt;&gt; See, I'm not going to say government is

going to do required to do more, but yes, we need to do do a lot more. I'll just start with here's some context setting. I want I was like so itching to say some numbers that you know when

these guys were speaking today India has women to come up with the numbers uh today India has 1.4 4 gawatt of data centers and if multiply I mean divide by the population 1 watt per person. May I

tell you China has 20 watt per person. United States has 150 watts per person and we are talking about digitalization journey. You absolutely need the data centers. So that is a done deal for me

that we need to grow our data centers significantly. Now if we grow our data centers to 6.6 6 gawatt by 2030 which is you know more than 3xing we will need $17 billion a year to drive that and

this is regardless of the fact that you look at the data center infrastructure buildout for 1 gawatt India will need close to um you know 7 to8 billion versus US will need something like a 12

to$13 billion minus the chips so we are cheaper but we need to build more. Having said that the current plans and I've looked at most top regions today world has about 89 let's say 90 gawatt

and the next 3 to four years we will double if we DOUBLE TO ALL THE INVESTORS and the companies out here I want to tell you 50 million CPUs will be required and THIS IS HYPERSCALERS I'M

NOT TALKING AI hyperscalers are 15% AI compute 50 million CPU use 7 million GPUs. Now wait for the third number. 3 billion memory devices. 3 billion memory devices. The world is already short off.

I want to tell you how many fabs are in 1 billion storage devices. Now if I look at the capacity to meet my CPU GPU needs for hyperscalers, I need two complete uh fabs to be working on data centers

alone. AND IF I LOOK AT THE SUMMATION capability of less than three nanometers, we have five uh you know fabs uh generating uh you know 40,000

wafers per month. two are used up for data centers remainder we'll have to you know take away from desktop this that now I want to tell you how many fads do we have for memory worldwide

for HBL high bandwidth memory that uh servers and the GPUs need five 40,000 capacity of wafers and by the way I'm calculating yield in it good wafers us we have five fabs 200,000

capacity need of the HOUR ALREADY WE'RE JUST doubling is I need 10 fabs so out there if you are looking at investing please invest in memory fabs and I'm really happy that micron has already

decided I'm looking at skhinx to COME AND DOUBLE UP THEIR capacity because that's the need of already today and even if I'm taking 15% kind of uh you know workload which is AI where US is

already 50%, 2030 it will go to 71 and you know that GPU and AI workloads need tremendous amount of memory. So that's last thing. &gt;&gt; Yes,

&gt;&gt; India does everything in a biodal fashion. So yes, we will need sovereign and there are companies. I don't want to be the first. LET THE FIRST BE someone else. Our serums and other will follow.

But the other part that a lot of you don't see is many of the GCC's and I'm positive many of these companies also their AI work is happening in India. when Pakistan India issue happened the

GCC's were more worried about internet stops who will do my AI work so we are doing both &gt;&gt; you know that and that is that is a reality the GCC story is a recognized

and acknowledged reality all companies all global companies have got GCC's here in India last count 2000 a lot of the AI work is happening out of India but Shiram going back to Nutri's point and

since we're talking about global capital and we're talking about local advantages uh you know link this back to your experience For instance, with semicon and with the semiconductor mission, uh

the government has just announced in the budget a 20-year tax holiday for data centers because ostensibly, as NRI pointed out, that's the big opportunity that the government wants to leverage

on. You've got Google that's committed $15 billion to set up uh in in Pradesh and many others are likely to follow. As you look at this ecosystem building out, what's the experience that you have from

Semicon that you now believe we need to amplify and accelerate? Well, I mean look at I think the government is already doing that with the AI mission. So uh the amazing thing about this

government is that they seem to have u figured out that the velocity of uh of commitment to a sector and the investment that goes to support that sector they've seem to have gotten to

the same cadence of that velocity in their commitment. So case in point um if you look at roads you know arguably the US and the rest of the world the developed world had fantastic

infrastructure you know 60 years ago and we're now barely catching up to that um electrification you know it was shorter broadband it was further shorter adoption of PCs further shorter so what

you're seeing is that the country is now starting to recognize some of these key trends and infrastructure development requires substantial commitment you know federal commitment the difference this

time is that the government is actually starting to recognize that you cannot do it by yourself and that's why I think what uh Nutri is talking about in terms of public private partnership is crucial

so the government doing RDI is really a catalyst it's almost like an ignition but the car has to have enough fuel to run and that fuel has to come from private sector yeah

&gt;&gt; so that's ideally I think if Ask Ashwini, he will tell you this 10 billion should be able to attract another 90 billion from the private industry which I think it will it just

will take time but you know these are all things that &gt;&gt; how much time because you know we we are in a fairly competitive environment a fairly competitive market how much time

will it take for the private sector to put fuel into the tank &gt;&gt; well listen I I I I think you know capital is like water it'll go to the place where it's lowest gravity lowest

friction and assures highest return. So if India is able to assure the Indian market is able to assure nobody's showing up here because you know of course our cultural heritage and

everything is fantastic but the capitalists are not coming here for that they are looking for a return give me meaningful tangible return now here's the challenge nobody has figured out I

mean there's this one giant company under sucking sound in Santa Clara that's making all the margins nobody else has made the margin you know and video you know kudos to Jensen fantastic

margin every other participant is not making the same margin as he's making including OpenAI, including Anthropic. Anthropic is, you know, 10xing the revenues year on year. You know, kudos

to Dario. Let me see the P&amp;L. Let me see the you know, how are you making the profits? It's not happening. So, the challenge for India in being able to attract investors like us is to be able

to show tax policy, you know, listing, you know, bankruptcy laws, all of those things have to happen. It's just by throwing capital you can't solve the problem. This is why my my dear friend

here Nisha Desai uh who's actually working on a lot of you know policy matters you have to walk and chew gum at the same time. The Indian government has to deploy capital has to remove

bottlenecks remove you know like for instance you can't say I'm going to only fund TRL4 with my money. you know what happens to the the uh incubator uh you know the coming out of incubator in IAT

Madras it's not TRL 4 it's barely starting how you incentivize that these are challenges the government has got to do the good news is this government is incredibly astute in listening to

industry and I'm hopeful that they will do the right things &gt;&gt; well speaking of doing the right things Abishek what is it going to take for you to write your first check for India what

are we talking about in terms of the size of the check. Uh and are you looking specifically at only AI stories? What kind of AI stories from India are you looking for?

You know, looking that capital is a is a tool productivity and employment and all of that is a completely different thing. So I think

the the last thing that I would say is that before the Indian entrepreneur had numerous constraints to succeed. lack of capital, lack of infrastructure, lack of skilled labor, all of that. And today,

you can truly build a oneperson billion dollar company if you come up with the right idea. And we've got, you know, 1.4 billion people. There are lots and lots of very creative, innovative people. And

this is the opportunity for them to actually become true entrepreneurs to create and really think of capital as a means to that. and not everybody talks about you India is committing so much

but nobody's talking about how are they going to actually build more entrepreneurs and all of that so &gt;&gt; no we we do need to build many many more entrepreneurs you know there are a lot

of open questions at this point in time what is going to be the actual productivity uplift that we see on account of AI what is going to be the deflationary impact of AI across

different sectors what happens to margins are we going to see margins expand are we going to see margins compress for IT services what happens to billable hours for you know lawyers to

accountants to to consultants I think these are all open questions at this point in time that uh that we're all grappling for answers for but as as you look ahead what would you say would be

the biggest opportunity and and the biggest risk for India so I know that we're running short of time that was that we're out of time two sentences I really loved what he said

today we have 6 million programmers software guys you know working uh GCC's doing AI I for global companies tomorrow 30% is what people are saying productivity increase I believe 3x we

will have 80 million people because they'll be agents India will be an agentic marketplace and I really believe that's one opportunity because the one line that I want to give to you Shireen

for AI is I believe AI will be pivotal for economic productivity military power and information control and we are working on all three of them how to make India lead in that. Well,

that is the perfect note to close this conversation. NRI and gentlemen, many many thanks for joining us here uh this evening FOR GIVING US A GLIMPSE OF WHAT GLOBAL CAPITAL is looking at when we

talk about the India AI story and the India AI market but more importantly uh the opportunities that we must leverage to build out the AI uh story here. Thank you very much for joining us this

evening. Appreciate your time. photograph. Oh, sorry. &gt;&gt; One second. We need We need to give you We need to give you momentum. &gt;&gt; You take a picture of

Uh the center for responsible AI at it is a multi-disiplinary nonprofit research center position in the global majority. We are a few we are one among the few global institution that

specializes in both technical and policy research to ensure and enable the responsible development and deployment of AI systems. The center aims to pursue research in ethical and responsible AI

and become the standard body in the country to recommend guidelines and policies to make deployable AI models and systems more accountable, explainable and responsible. Uh through

its work, CI which is the center for responsible AI uh brings together research, researchers, policy makers, industry leaders and sales society to build AI systems that are not only in

innovative but also trustworthy and align with societal goals. Uh a quick shout out to our co-organiz co-organizer Vadani AI. Vadani AI is a nonprofit applied AI institute focused on driving

so social impact across the global south. Since 2018 uh Vadani AI have uh developed over 25 AI solutions reaching 20 plus million users across healthcare, education, agriculture and AI skilling.

Today's session is on multistakeholder collaboration to foster uh AI adoption in the global south. And it's my pleasure to welcome and introduce Mr. Hmon Pandi who's the CEO of center for

responsible item address and he's also going to be writing the moderator moderator's hat today. Over to you sir. &gt;&gt; Thank you Satan. It's it's a it's a privilege to be here

uh representing Sai as well as Vani AI. Um this reminds me of uh an instance uh in Seattle when 15 minutes before the session I was told that I was going to be one of the

panelists because somebody didn't show up. It's not that short a notice but I am the host today. However, the Alpan who was supposed to be the moderator today uh has been called out of town. So

I'm going to be the moderator as well today. Okay. Uh I hope that that day it did go well. I hope with your support with your support today's session I'm pretty sure it will go well. Let's

collaborate on this one. Uh so first let me introduce our eminent panel. Okay. So we have my friend Professor Dame Wendy Hall. She she tells me or she tells everyone that even

though Dame is a pretty coveted title, professor comes first. &gt;&gt; Because that's the noble profession. &gt;&gt; No, that's not right. &gt;&gt; Dave title goes with your first name. So

I'm &gt;&gt; so it's closely associated with the first name, right? &gt;&gt; So um since again this is kind of last moment I'm going to use a cheat sheet to

introduce people. Okay. Um so Wendy um she is DBE FRS. uh this regious professor regious

professor of computer science associate vice president of international engagements and the director of web science institute at the university of Southampton.

Uh she became the dame of British Empire in 2009 in the New Year's honors list. It's actually commander. &gt;&gt; Dame commander.

&gt;&gt; It's actually Dame commander just in case. &gt;&gt; There's a little bit of the British Empire that I command &gt;&gt; and um as we don't have the empire

anymore, I don't know it really exists, but I'm a dame commander. &gt;&gt; But nevertheless, she does have a commanding presence. So um well, I know her from my and her ACM

days as well. Um Association for Computing Machinery. uh she's the adviser to the UK government and also uh other governments as well as United Nations. Welcome.

&gt;&gt; Dr. Aisha Wal Bryant. Uh she's senior staff research scientist and head of head of Google research Africa with sites in Acra that's Ghana uh and Nairobi Kenya.

She has over a decade of experience uh working in Africa and uh she leads teams to develop innovative uh technologies that leverage AI and u computing to address Africa's most uh well Africa's

challenges um and she drives uh Google research Africa food security and agricultural research um and they are developing AI technology and tools that address food

insecurity in Africa and also extending it globally. Welcome to the panel. Professor Vukosi

very fate. Uh Vikosi is professor of computer science and holds uh ABSA up chair of data science at the University of Pritoria. Um he specializes in developing machine

learning ML and AI uh methods to extract insights from data with a particular focus on the intersection of A IML and NLP natural language processing. uh his research is dedicated to improving the

methods, tools and availability of data uh for local and low resource languages. As the leader of data science for social impact research group in computer science department, uh VUK is interested

in using data science to solve social challenges which is very relevant for our session. Thank you for being with us. Safia Hussein. Uh she is the chief

impact officer and co-founder of uh Karia. She grew up in uh central Asia and has a background of humanitarian work and research. Before Ken before Kar co-founded two companies in India and

worked as a research consultant for 3IIE and United Nations later at Stir Education I hope I'm say pronouncing it right. uh and she led the monitoring and evaluation with design of some big

impact uh research um research projects. Thank you very much for being here. Makaran Makran Tapasi. Dr. Makran Tapasui is the principal uh ML uh scientist at Vadrani AI which is our

partner for this uh this panel discussion. uh and and focuses on using AI for social good. Uh he's also an assistant professor at CVIT, the computer visual

group at triple it Hyderabad. And at Wani he's developing and deploying AI solutions that create social impact in education, health and agriculture. And finally, Dr. Nati Chaya. uh she

currently leads AI and um and co-founder at uh Hyperbots Inc. She spent a decade at Adobe Research before starting up Hyperbots as a part of their research team focused on NLP and multimodel

content uh content understanding. In addition to her industry career, she has been teaching at triple IT Hyderabad and ISB as a junct faculty and holds several patents and publications to her credit.

So as you can see we have a very eminent panel and before I also give the context I'll show you why I'm saying that this is eminent and also relevant uh panel for our panel discussion today on

multistakeholder collaboration because as you can see from the description we have rep if not representative but advisor to multiple governments so working with

government people from industry there is one person who's with industry as well as academia so wearing double hats people from academia and also nonprofit organizations so we

do have a very good sample here and also another thing is that they are obviously consumers not only creators but consumers of product of AI I right now okay AI itself has become a product now

so some of them are parents I mean various roles a person is student all the time so anyway so what I wanted to bring out is that uh opportunity the potential of collaborating right there

in our panel itself okay again welcome uh welcome to this panel uh they also represent uh potential for collaboration ation across geographies cuz as we said uh Africa, South Africa um UK, India

okay so uh that again represents a lot of global south &gt;&gt; I don't &gt;&gt; except you know perhaps England's move we've

moved away from Europe &gt;&gt; and yeah Benny is used to being the diversity person from the gender perspective now you're diversity from geography

&gt;&gt; Okay. So, um &gt;&gt; I'll see you. &gt;&gt; So, uh yesterday in one of yesterday's panels, people that was in the context of education. So, people talked about um

how everybody has a responsibility when it comes to um AI. That may not be accountability or liability. The liability may lie with somebody some with the

institution or rather some the entity which institutionalizes it. But the responsibility of moral accountability lies with everybody. Okay. Now with that again from the

beginning there is need for collaboration. There is need for multiple stakeholders coming together. so that from the design development up to deployment we have collaboration

which is inherent to it. Okay. So anyway with this context I'm going to launch into our our panel and um I'm going to um ask a common question. Okay I'm going to

throw a common question to all of you and we'll go in the roundrobin fashion. Okay. Um so and that question is going to be please tell us in 2 to 3 minutes each

uh by the way the timer hasn't started here so is it because this is the last session &gt;&gt; starting &gt;&gt; so can the timer be started lean

&gt;&gt; into it come on &gt;&gt; yeah so time stands still really for this panel okay so the question that I'm going to have and each one answers in their own way in short is that can you

briefly summarize uh your work for our audience today uh especially highlighting how disparate stakeholders play an integral part in developing AI solutions responsibly

and what are the challenges inherent to it. So we'll start with Wendy. &gt;&gt; Okay, thank you HT. Hello everybody. Hello. &gt;&gt; Hi.

&gt;&gt; Um, so I think I I could talk about a lot of things. Um, but I think I should talk about the work of the UN advisory board because um, it was a huge um, my background is

I'm a I'm a computer scientist. um most well known for the web and the internet work I've done and the um I've always used AI though throughout and but I was catapulted into AI policy by

Theresa May when she was prime minister and I wrote co-wrote an AI review for the UK. So it sort of developed our national strategy for AI back in 2017. This was before the chat GPT moment and

uh but we all knew the m you know it was coming that the generative AI machine learning was coming but we didn't know how it was going to arrive. Um and then uh in uh just there was chat GPT moment

November 22 and that led to effectively the first one of these summits at Wel Park which I was much much smaller than this and I was privileged to attend that. Um and we launched the AI safety

institute there but also just at that time um it was October 23 the UN announced their high level advisory board um the AI advisory board and I was hugely privileged beyond that there were

40 of us from around the world I mean you can you can't represent the whole world with 40 people but they it was very u multiddisciplinary um mixed gender diverse but it was also

So um very um I would say maybe half of the people there were from the global south on I can't remember exactly but it was it was very um geographically diverse. We had people from China as

well which is so important. I know it's um I mean if this conference was in China there'd be a lot of Chinese people there obviously but it is Chinese New Year and I don't think there are that

many of the Chinese people here. But um to me it's so important if we're going to talk about global governance of AI and how we get people to adopt AI, we have to have China in the conversation

as much as we have to have clearly the US and and and everywhere else in the world. But the US and China, China's got to be at the table. So the UN board had two Chinese people on it and it was very

very um well set up in that sense. uh we produced our report called governing um AI for humanity in September 24 um and that was at the UN General

Assembly and in that we focused a lot on AI for everybody. I love the phrase by the way we keep seeing around in India AI stands for all inclusive. Is that what it is? Have you seen the phrase all

inclusive? Um, so the report was very much about and you're seeing the implementation of that report now. It was very much about how we get global governance of of AI in a way that is all

inclusive for the whole world and not just the rich west or the rich south of China. And um at just week ago they announced um one of our first recommendations was

for a global scientific um board and I Ravi is on it. I don't know if there's anyone else here. Are you on it? &gt;&gt; But so guys you got to do great service

on this. Okay. There's a lot riding on it. Lot of responsibility. I It's hard work by the way and um because but you know it's f There's there's a lot writing on this

this panel and then there's supposed to be another one of our recommendations was a global dialogue about um AI and I think we meant that to be policy makers I believe that will be launched if it

goes well at the AI for good conference in um in July. I'm going to more or less finish there because I can we could talk more about it if you want to, but to me um the UN although potentially these

days a flawed organization, an organization that doesn't have a lot of money, it is the only game in town when we're talking about global and inclusive of the global south and China. Um

talking about how we make AI safe, how we make it good for humanity, right? And so I would urge you all to follow what's going on there. Thank you very much. &gt;&gt; Thank you. Thank you for the background.

Aisha. &gt;&gt; Hello. Hi everyone. Thank you uh for coming out today for for this great panel in the evening just before dinner. Uh I'm Aisha. Um so I lead our Google

research Africa team. Uh the work that we primarily do is um pioneering AI for Africa from Africa to the world. A lot of our solutions that we develop um are by African

scientists and researchers or collaborators across uh Google research broadly that are wanting to impact the continent. But what we've seen is much of this work has scaled. Uh so we cover

domains in climate, sustainability, health, education and others. Um much of what we do is this stakeholder partnership. Uh I always say for me personally, I'm thinking about my

community, children, um and what's the future of AI given our demographic dividend both in Africa and in India, India. Um so we're building that future and I think a lot of this

spirit comes out in our research team. Um some of the core uh interesting aspects of the work that we do is it's kind of uh research innovation to product innovation to impact and we're

very very rigorous and serious around measuring impact. It's a lot. If you are a scientist, you like to play on this side, do something really creative, but if we're not able to get a path to

impact, this is not the right project for us. So, picking that right project is very important around scale uh not just for the continent but for the world. I'll give two examples of this

multistakeholder collaboration and how we work. One in weather and the other in African languages which we just launched. Um so our weather work our teams work with the local Met agencies

across the continent and for many of you all uh you may know that in North America and Europe there's about 300 radar stations uh for for weather and in Africa there's an order of magnitude

less about 37 and you know we can fit North America Europe and many other places uh inside of Africa. So you can imagine the dir of of data that we have in that space. So our team was able to

work uh and to create an innovation that leveraged satellite data and a global model that enabled us to launch a global weather now casting that if you land in Africa you'll now find on search and

you'll get precipitation estimations for 5 kilometer radius. So this is where your unique context just like in India this is not a challenge or a barrier this is a breakthrough or innovation

this is something that you guys can bring to the world the second example I'll do is working with collaborators on more on the data collection side so if you think about it uh languages across

India across Africa thousands and the way to reach AI doesn't always have to be from a keyboard and it can't we have literacy barriers we have various uh uh barriers to entry and so

what is an inclusive approach speech so we created a data set well actually through partnerships with Marera University in Uganda with digital um and a number of other partners where it's

partnership-led they uh collect the language speech and language data in order to make it open and available to the communities. They own the data as

well. What we've done is launch it as open-source 11,000 hours of ASR that's automated speech recognition and text to speech uh on hugging face for you developers and it's called Wahal NLP.

Wahal is Woolof in Sagal for speak. So this is one way that it's completely partnership driven and led and we're using technology as a as a layer to amplify and reach the ecosystem in the

community especially for languages. So those are some examples of the work in collaboration. &gt;&gt; Thank you. Um we'll pick up on some of the points that you said later in the

question and answer. &gt;&gt; Yeah. Okay. Uh nice to be here and good evening. Um yeah I I I wear a number of hats but uh for today I highlight two. Um so on one being at at the university

uh my my big interest is on African languages and how how we deal uh with that being represented in a lot of uh machine learning on natural language processing. Uh but a thing I wanted to

high like maybe uh give as a way for people to appreciate this um is on one side you might ask and say like where's the data for all these languages? Africa has 2,000 3,000 languages and and many

of them um like you know we would take them as being low resource. It doesn't mean they don't have many many speakers. They do uh but there might not be just this digital presence that then makes it

like you know easier for developers or other people to be able to use. Um if you only look at that as a technical problem uh you are going to very quickly kind of run out of of of railway track.

Uh so you then have to look at kind of the social technical and this is where now thinking about the community the partnerships as Aisha um has actually said and even how uh people actually see

languages becomes very important. Uh so one of the challenges that you have in in normally small languages or uh or like maybe the political nature of working with language is then uh what

happens in terms of what the community people are expecting on the use of a language in society if they're not expecting it to be used in math or physics or astronomy. It limits then

some of its kind of wider applicability when you think about where you're going to now build up systems. So you you now have to think who's the user at the end of the day, what is it that they're

expecting and those things. So a lot of our researcher at at at the university is trying to figure this out. So had to break out just not being in just the computer science department but working

with African languages, working with law on how then you can think about equitable licensing uh as a way to give power to kind of communities. On the other side, it's been great also sitting

next to Kia here. Um, I'm one of the co-founders of Laba AI, an AI startup company u that works and now building these uh kind of language technologies uh but then at the end being uh

available to businesses to enable that they can reach uh their stakeholders in a much better way. So there are a lot even there in working and saying how you're going to improve those systems.

you have to then think about partnerships and these multistakeholder u kind of relationships and that's where I will then hand it over uh to to thank you

okay thank you thank you so much um so I mean I think maybe some of some of the work that Kadia does has been introduced but um just to give a brief overview we're an impact focused AI and digital

services company and we work all the way from the data set by data set collection to annotation all the way to evaluations and I think I'm actually quite lucky to be flanked by two of the stakeholders

that that we do work with uh both Lalapa and Vwani AI um so I think for us because we actually sit at a very interesting place we sit almost as an intermediary between this extremely vast

workforce of data collectors that I think Aisha mentioned as well as on the other side model builders and big tech companies and a lot of the work that we have to do is creating a little bit of

translation between these two. On the one end, because we work with a lot of low-income communities, we have to create value for the types of data that they can create and we have to connect

directly to, you know, ecosystem and model players to say, hey, you actually need to involve these people. Um, so I think for us, you know, and I think when I talk about collaboration, I'm going to

speak a little bit at the worker level because I think we need to increase not only the representation, but also I think the knowledge that people have about this industry and what

your individual human so everyone in this room, you have some sort of value that you can bring to AI. But I think the question for us is as we're working together, how do you actually make sure

that you engage in that responsibly across the entire value chain? And I think the only way that we can actually crack a value chain that becomes ethical that becomes something that we all want

to participate in is through some sort of multistakeholder collaboration because we do have a situation where I mean and thankfully we do have you know Radwani we have Lapa they are building

more in the south but right now we do have this unequal divide of so much on the model side coming from the global north and not and so much from the building side from the data side coming

from the global majority. Can we either flip that or just create a little bit of a more uh equitable playing uh playing field for for all of us. So I think for us the key challenge really is power

dynamics. How can we change that and how can we use systems like this right where we're actually able to come together to create more equity and I think yeah a little bit of representation and

inclusion at every level. Thank you. So you talked about equity representation which is very fortuitous because the question that I'm going to ask of you later this

right um hello everyone thank you again for joining us uh and it's lovely to kind of hear from everyone before about the importance of multi multistakeholder collaboration um I think uh so I'm an ML

scientist I like to build models uh there's a lot joy in seeing models first fail and then eventually start working. Um I think one of the things that I learned by joining Madwani AI which was

briefly introduced uh before was if you really want to deploy solutions for the benefit of humanity it cannot happen with ML scientists just sitting in one place and trying to do their thing right

so that's just does not work um so AI we are a nonprofit organization applied AI institute that we uh we build develop and deploy solutions in education health and agriculture um I've been working

there for over a little five five years and um it's been a phenomenal journey where you get to see your models actually now go out in the world and um get used by people and then they'll give

you interesting feedback in terms of um not necessarily model performance because performance is not the only thing that matters which is what you would typically expect for a machine

learning scientist uh but also usability whether it's integrated well into the program itself self um whether as as language barriers are addressed um is it a voice interface or is it does it

require some form of literacy and all of these kind of factors come into play while making sure that a product actually um gets used. So stop there and can take this next.

&gt;&gt; Thank you. Hi everyone. Uh let me bring in a very complimentary view. So I lead a finance AI startup. Everything I put out there needs to work. It needs to make my stakeholder who is a CFO a very

conservative persona actually use AI. So if I look at someone who is not only trying to measure impact every day uh ensure that the AI is responsible also ensure that it is working for all my

customers and then finally ensure that they're going to trust it and actually pay me money. Right? So here my stakeholders are not only your model builders or the data that is creating

all of this but it is very much this whole trust building mechanism that not the obviously the marketing and the sales need to bring in but the AI builders need to actually establish. So

part of my stakeholders are these AI agents which will ensure that the customer data is safe. Um the second thing is I actually need data or every startup or everyone who is in a

sensitive uh B2B kind of vertical space needs data to actually build the AI that works right like I can't always go out to close source models. I I'm definitely don't have the money to build large uh

pre-trained models. So how do I make sure that I am able to convince my customer, give me good data, um kind of gift wrap it and anonymize it or make it ethical to use for training and

then further train it and actually think of it in terms of monetization. I want to all the way take it to the infraox and ensure that hey give me something secure that a extremely conservative

persona is going to use. So everything that everyone on this uh panel has been talking about uh impact collaboration data uh model training all of that is something where uh you are in a very at

a very small organization level is something that you kind of need to do every day. Um and this has direct uh impact in terms of whether as organization I will survive tomorrow or

not. Um the last thing I would like to comment on in in this context is that what uh is important is how do we ensure that organizations like startups collaborate with other governance

organizations and have a say in building those policies right because be it healthcare or fintech or education or any other or defense for that matter all of us are talking about AI in these

fields um having a space on the table where all the big players are actually bringing in the policy. Uh ensuring that it is eminable to those small organizations who are trying to take

this to their f uh end customer is is a kind of uh collaboration that I think we must nurture. &gt;&gt; Thank you Nati. Um us well I said round robin but if I go

by roundroin fashion then again you will be the last and right now you have the microphone so why don't I do this in the reverse order now okay so you talked about

AI responsible AI in in finance finance industry was one of the very early adopters So in the '90s and things like that, but they all the models, ML, model, they were developed by the

finance industry itself. So uh you alluded to some of those things, but perhaps let's drill down. What has changed now uh in the finance uh industry? How exactly are they

collaborating? How we are assimilating? I mean examples of collaboration. That's what I would like to drill down on. &gt;&gt; Sure. So I think you nailed it. Math, finance, ta existed. Uh they have built

their quant models and they still exist. But what is new is with u agent with NLP getting useful or usable what has happened is that the unstructured or the financial operation side. So

transactional data in finance has become aminable to uh models using it, models generating it, models interpreting it. Um and that is the same data like those bills and the invoices and the simple

transactional heavy manual tasks that uh while ' 90s automated uh planning and budgeting to some extent or quant modeling no one touched these very dirty shabby scans which which have no

regulation and they're all over the place. So, so that is that's one kind of large open space where there are even today like hundreds of people manually doing that data entry and and that is

the space where your office of the CFO is starting to open up and say that hey can I instead of having 200 people process 10,000 invoices for me monthly can I have an AI agent do that for me so

that if tomorrow I have 20,000 invoices can can can we handle it with the same workforce. Obviously, there is cost optimization as well. One one other aspect still remains is that this

transactional or semi-structured finance data is still very mathematical in nature or semiructured in nature. So, it's it's not only the OCR and LLM on top of it. It is still very much going

into those terms that accountants understand or charted accountants understand or CPA understands to further drill down and say how can I save cost and that is where a lot of

multistakeholder understanding or even on the science side bringing in math reasoning or or bringing in a non-aggentic uh AI kind of very traditional stoastic model is important.

So, so it's it's it's very interesting that while agents are taking over um it seems OCR is solved but even then your best OCR in the world will not get any invoice right or always. So it's there

are these nuances that where you go deeper and deeper within a domain you learn that unless I start thinking like an accountant I won't be able to build AI for them. So the stakeholder there

becomes these non- tech professionals who are my actually customers. &gt;&gt; Great. &gt;&gt; so thank you for bringing out the importance of nontech and non finance

stakeholders into the collaboration fold. Makan um you've been again involved in uh working in healthcare in education in agriculture and things like that. uh but the proliferation of AI has

generally depended on internet bandwidth and pre prevalence of internet in some of these domains internet may not be that well uh fast let's say agriculture the consumers and

things like that so what's your view on how we circumvent that challenge &gt;&gt; yeah I think it's an important question um much of the progress we've made since the last 5 years I believe is primarily

because the data has been out there for everyone to scrape and build large models on um if that data doesn't exist online I think uh we spoke about this with the thousand African languages if

that data is not on the internet you will have to go and collect that data to build something for that society right so there's from both the building perspective which is um where do you

source the data from if it doesn't exist And then from the deployment perspective where the the end user may not have access to a stable or a fast enough internet to perhaps um kind of have your

models run and interface with the uh tool. So I think both of these problems are important to address. Um I think the first one there's a question of do we need to build necessarily very large

models for every language out there? Maybe not, right? could we use um multilingual LLMs essentially and then fine-tune them with some hopefully lesser data uh which is sourced

purposefully for that community which we can then use um to to get that LLM or other models to benefit that community right so I think that is one way of perhaps looking at it essentially if

you're trying to build for a particular community probably helps to get data from that um source the second aspect is uh I think my my team from the whole anthropometry project is sitting here.

Um so so I started out with uh with this project on newborn anthropometry at Vadwani which the goal is can we take a video of a baby and then try and estimate what the weight is. Now you

would think weight from vision images that that seems a little unrealistic. Turns out you can do it or you can try and estimate it at least um and you can talk with all of my multiple

stakeholders right who are collaborating of course to get that data sourced to us. The way this works is it's not necessarily a large model that needs to kind of run on the internet uh or on

some cloud server. We are able to compress these models, put them in the lowcost smartphones, not just not even iPhones or like high-end phones, just phones of 8 to 10,000 rupees. Um, and

have those models run offline, right? So that serves the other purpose of even if you're disconnected from the internet, you're able to make use of AI models that have been developed which can then

provide outputs real time and then assist in the process that would other that the frontline worker would otherwise do. And this can naturally extend to other domains like agriculture

and education as well. &gt;&gt; Thank you for a road map of addressing the challenge of what I posed to you. Okay. uh Safia um across the world the data set

building that you're talking about um has been done by people from the global south but the data has generally been coming from across the world especially from global north. You talked

about the need for representation equity. How can this fact that the people who are collecting the data that's they are working from global south how can we bring in their their

inputs how we can enable them? &gt;&gt; Excellent question. Thank you so much Hmon. So I mean I think as as you very much called out there are four countries that are kind of powerhouses of doing

this type of data work. uh it is India, Kenya, Uganda and the Philippines. Um and the reason why these countries have been the powerhouses is because English, right? Uh these are all countries that

are able to speak English. They're able to decipher the types of data that the that the global north needs to have deciphered. Um and unfortunately there are mechanisms to unfairly pay people.

And that is something that is uh something that is wanted sometimes in the AI value chain because there are a lot of uh I guess models that are chasing profit. But what I think we've

really seen in the past few years that I find to be very exciting is that I think the divide is closing. And I think it's specifically because of language. I think we are realizing that if you want

to have AI work in the global majority, you cannot take an English view to it. you not only have to take a linguistically appropriate view but you also have to take a culturally and

contextually relevant piece of view right so I think you know when I see the world and what we're doing uh sorry when I see this type of work in the world there's definitely a shift into English

being more of an area where expertise is needed right I think that will always be something that you know the global south will probably contribute to right doctor annotations annot annotations etc. But I

think what we've really seen and I will speak especially I think for for for India is a real growth in a desire to build foundational models uh a desire to create inclusion through speech. I think

this is something we're seeing not only from the government which I mean I think this year there's been an unprecedented amount of budget allocation specifically for local language data collection which

is something that's extremely exciting. There's also been budget allocation for stress testing and evaluations which I think is something that is very new because we are realizing that if we

don't make sure that models actually fit the realities of the people that are going to use them then there's actually no point in deploying that model. You actually won't see very high pickup,

very high retention. There actually won't be safety and trust, right? Um so I think what's going to change and I I really do see this growing and I think you know the is a really great example

of that is that we are actually seeing so much demand growing for what does I mean in some ways I'll use this term very loosely but what does sovereign AI mean for each of these countries? How do

we create two true products that actually help people? So I think evaluations are going to be something that are very critical and I think building the proper data sets but in

both of these things what is very important I think for all of us to remember and that's why we need to have good collaboration and safeguards is that we don't become extractive because

what I wouldn't want to happen is in this big uh you know desire to collect so much data it shouldn't be that the people who are contributing to this either a don't get to benefit from the

technologies or B don't have some way to see that data as their own asset. And so I actually would like and encourage all of us as we're thinking about

collaboration, let's also think about ownership and how we can redefine that within the global south because I think we have the ability and we're so many countries we have so much power

together. Can we change that narrative to say what is data ownership? What is model ownership? and who actually gets to be in the room to decide how and what we build.

&gt;&gt; Thank you. With that thought, I would like to ask you for um you talked of of course talked about specific challenges of Africa, specific problems and things like that. So

as a leader in developing AI for for Africa Africans what lessons have you have you gathered and how do we address the lesson expand those things to address the problems of overall global

south. Yeah, that that's a very tall order. Uh in this case that I I do see myself as a servant as opposed to a leader in in in that area. um in in terms of just trying

to understand um also as a researcher uh I think um yeah on on one has has been after spending a number of years building models collecting data uh was we spent uh the

last year or so now working on analyzing what were some of the practices that were being done uh across um uh uh like natural language processing and African language community uh specifically

through Masakhani uh Masakani is is a a kind of distributed research uh network uh for African languages and uh not like on one part not surprisingly uh one of the things that came out was uh if we

are being extractive you limit your long-term impact because it closes doors it breaks trust people don't want to interact whether Sure, there might be the data side, but

the part I'm also very um interested in, especially this year, I'm on on my sabbatical year, just working on some research on thinking about evaluation. What are these uh kind of practices that

we're doing in evaluation and how do they really connect to what's happening kind of on the ground? So, that's one of the extractive is like, you know, being extractive and just thinking of let's go

fast. It does have an impact. And I know it's visceral, but if you're a researcher, it's like this thing where you're now questioning the decisions that you're making. I think it's

worthwhile to make those the those questions and feel a little bit um out of it in that in in that way. That one just to to to to uh to finish was a a a leap that people

kind of took on saying how do we get to creating tools that again not computational to assist either communities or people in keeping uh some way of control or or or like you know of

choosing how whether their data their models are going to be used. So yes, equitable licensing conversations have to happen. They are not going to be one sizefits-all. They're going to be very

different for different communities, but we can't block them. Uh just because we're saying we're just rushing towards there has to be an LLM in every language. That doesn't necessarily need

to be true. It doesn't need to be big. It doesn't need to be and some communities won't want that at all. How do we get that to be part of our practice? Thank you for giving a

researchers's view for the solutions to be really applicable for the community. And talking about community, you also mentioned community in your opening

remark. U so uh there seems to be a fundamental conflict in marrying cuttingedge large scale uh technology to highly localized problems in in Africa. Okay. Uh so do

you do you see this as a conflict or you have a more positive view optimistic view of that? &gt;&gt; I've been known to be very optimistic. &gt;&gt; Let's hear the optimistic

&gt;&gt; and I I I appreciate my own energy. It fuels me. Uh so I definitely don't see this as a conflict. I think complimentary to what many folks uh discussed on stage, I'll give uh an an

example to kind of highlight that. So um you know with my Google hat on we have we have models like uh Jimma which is an openw weight model. We have MedJimma which is actually more positive like

more downloads than Jimma itself which is trained on medical uh text and imagery. And then we were looking at the challenge from a healthc care perspective of how how do we make that

medical reality relevant to the continent of Africa? our burdens of disease are not equally distributed around the world. Uh and so this is actually at the hallmark of this you

know this collaboration. It's a we made this data set called Afromed QA. It is a pan-African Q&amp;A data set from medical institutions uh more than 16 countries across Africa

about I think it's 32 different uh disciplines but most importantly it's 25,000 question and answers from the African context from those who are medically trained and so what's key

about that is as you use these types of models you're now being able to okay first you you might benchmark with this type of data data set but also you know evaluate how these large language models

are representing your context. Uh further down the line it could be fine-tuning or you know leveraging some of the open models with this data set. So that allows us to bring in our

reality and our context into the technologies that are there. So that's one way that I think you know there is a power in leveraging those models that are openly available.

&gt;&gt; Sounds like my time's up. &gt;&gt; Could you stop that? I'm actually tracking time. UH WE we are well in time. I noticed that when we started it

started with 35 instead of 55. I'm not going to take that long, but I think we certainly do have at least 10 minutes. Yeah. Uh so you have two minutes though. Uh so Wendy as a pioneering computer

scientist um as the AI revolution is unfolding how do you uh address the digital divide that exists even within the global south? Your uh thoughts on that.

Uh I'm sorry I don't um I'm going to say I don't understand the question because you said as a computer explain ask me again. Yeah, you've done pioneering. What's the digital

&gt;&gt; computer science and the digital divide? What's what's &gt;&gt; Oh, uh as but okay, let me rephrase that. As a leader, as a thought leader, &gt;&gt; right?

&gt;&gt; So, &gt;&gt; uh there is a divide right now. I mean there are various u challenges which are unique and there is a digital divide. Some of them are more enabled even

within uh global south. Uh so what are your views on um uh bridging that divide? &gt;&gt; I still don't understand the question. I'm sorry because what are you talking

about? Are you saying um every country has problems where &gt;&gt; correct &gt;&gt; people some people are &gt;&gt; so any any okay any commonality that you

see any commonality that you see &gt;&gt; it's not just a global south thing is it &gt;&gt; we have people I mean we have a huge problem every well in Europe certainly in the UK about people who have no world

most of the people in the world do not understand AI right at all is that the digital divide you're talking about what &gt;&gt; sure that's one of the things that deployment of AI really becomes a

challenge right now. Okay. So, your thoughts on on that? I mean, u collaboration is one example of that. &gt;&gt; No, it does. So, I don't get does anyone want to answer this question?

&gt;&gt; Anybody else who would like to help out here with this question? Anyway, um &gt;&gt; well, let me just say right the whole the key thing for me is that um we are we are there's currently a huge contract

going on, right? We are being conned. I'm going to talk about this in my keynote tomorrow by the big tech companies, right? We're all being conned. They're saying, "Oh, SORRY.

ACTUALLY, I'LL TELL YOU, GOOGLE'S MY FAVORITE, RIGHT? There are humans in there. &gt;&gt; Google's my favorite." But there's this huge thing about we're going to reach

AGI by the end of the year, right? That's what um Dario said at Davos. We're going to reach AGI by the end of the year. Demis slowed him down a bit, okay, and said five to 10 years. What

does AGI mean? You know, it's a meaningless term. And this um so and and the world out there thinks AI is going to take their job and thinks that we're all going to be overrun by AI and is and

it gets very scary because people don't understand. So the key to this and and it's true for for politicians and the media as well as your average person in the street or the farm or wherever is

education, education, education. You've absolutely got to help people understand what it is we're dealing with here so that they can um I mean lobby is maybe not the right word. local politicians or

their local schools or their local universities or &gt;&gt; no good stuff &gt;&gt; to um to help people understand what this technology is and what it might do

to their lives, how it might change their careers or their careers their children might aspire to. What do teachers make of it? um and these people are not going to ever understand how

this technology really works in terms of um the mathematics behind it in that sort of detail. So we have to explain to people uh when the you know this whole I mean

the taxi driver taking me to Heather airport yesterday said how do I tell the difference between a deep fake and a I don't know what's truth anymore and we're really coming in you know we've

got AI slop everywhere I'll just &gt;&gt; thank you u so education is one of the uh ways of u uh along with collaboration educating

people on AI and it's again we talking about multistake collaboration getting everybody's views while developing deploying uh AI solutions

okay we do have time for a couple of questions from the audience we yeah go ahead uh microphone or I can give my microphone Thank you so much for such a wonderful

panel. Um I had a simple question on evaluation because a lot of you brought it up. How would you structure that evaluation? Should it be different in different contexts? Should it be

different um in different countries? What baseline would be would we follow across the world? And I asked this mainly because I'm very interested in participatory approaches to building

deployment and evaluation. Um where you actually bring the lived experience of the end beneficiaries into the equation. So how would you structure evaluation and monitoring? Um this could be for

Safia or anyone else on the panel. Thank &gt;&gt; Can I just ask what are you evaluating? &gt;&gt; The impact of the technology. &gt;&gt; The impact of the technology &gt;&gt; is working for them. So sorry just to

clarify you mean impact evaluation and not AI evaluation. &gt;&gt; Understood. Yeah. No because that does make quite a big difference. &gt;&gt; Art I mean I think the

well I mean from a very impact measurement perspective it would be very difficult given how much AI is infused to find a counterfactual. So I think that is actually quite a big question

that even as an impact measurement specialist I have as well. Um and and just like you have in many evaluations, impact evaluations, I don't think that there is a one-sizefits-all approach, I

think it really depends on what is the causal relationship you're trying to understand, right? I think already today we do see a lot of evaluations happening at the expert level, right? Is the

output exactly what we want? But I think if you want to ask the social question, you have to first decide on what parameters. And I don't think you can have a mega evaluation um because that's

going to give you a lot of confounding answers. Right? So I think we are not at a place where there should be where there is a baseline framework and I'm also not sure that that is the future

that we should be pursuing because each technology will will have its nuance and if we don't you know evaluate impact in the way that picks on those nuances then we're actually you know risking perhaps

not understanding what true impact that intervention or that technology would have. &gt;&gt; Anyone else wants to add? Yeah, I I think uh

uh one big thing is going to be uh not completing the two &gt;&gt; and no from the perspective on the other side as well that when we do have big claims of how AI now the way we've

evaluated AI is going to now change all of these sectors and everything because now we're getting whatever humanity's last exam or or the and now saying that that means on the other tide like you

know the tide will lift all boats and everybody's going to benefit in the same way. These are not the same kind uh kind of thing and making the point is on on one side making those big claims because

of maybe the ecosystem in terms of where money flows or or resources are going to flow. It does have it it does have impact in in terms and it does hurt uh because in some places then people then

say we are not going to make uh the education um investments because it's fine somebody else has taken care of this but actually that's not the reality in in in in on the social on the social

side. Uh but then now yeah nobody is now going to invest in in solving some of these things. So let's not it is a very good question in terms of let's not conflate the two but sometimes it looks

like on on in public that oh it's the same thing and it's it's not &gt;&gt; uh we have time for one more question &gt;&gt; um thank you thank you for the panel uh wonderful comments mine um one is a

reflection around I think impact if you think about it from medical diagnostics for example like simple things like radiology a simple small model that could fit on a cell phone that a nurse

could use. If the output is to catch more, you know, infections, maybe it would be much faster. But then if the outcome you're looking for is people getting the the help they need once they

figure it out, that's a that's another dimension to it. But my question um you know to anybody on the panel is for our future generation. So I I I'm a professor and I teach undergraduates and

I feel like a lot of students are not ready or are not evolving uh as the world is evolving um really quickly and so in terms of preparation like what kind of from your leadership perspective

what do you see is the the shift in terms of being ready for you know the unknown Right. Um if you think about computer science students graduating right now,

they're graduating in the millions. I'm making that up in the US for example. So the question is um what does it look like uh for an undergraduate or graduate student who's finishing right now in the

current in the current environment? &gt;&gt; No jobs. I think it's ironic that the industry that's creating all this is the one that's destroying jobs for programmers.

Um but actually I say that quite glibly because I don't think that is the case. I but I we've already seen and I think it's a true in the US a fall in the numbers of people applying for computer

science because the because the rhetoric is you we don't need programmers in the future. actually was talking. &gt;&gt; It's a love alert.

&gt;&gt; But we Yeah, &gt;&gt; we will need we will need because at the moment I mean this is this is another bit of the comm which is that it's not AI that's doing this. People do this

with AI at the moment and I don't know for how long but at the moment AI doesn't decide what it's going to do, what programs it's going to build. I mean that could come in the future but

it's not here now and so we are going to need these types but the rhetoric that gets out there very quickly is no we don't need any programmers. Um so okay sorry I'll shut up let someone else say

something I'll add to add to your points. Uh I think what's really important actually uh you're training undergraduates is uh teaching them early as early as possible to question

everything and that means that you need to as a a computer scientist or any any field that you're in you you need to separate yourself from your work. So, you know, maybe you're going through the

PhD. I was in robotics. You love your robot. You know, it's capturing elements about the world. You really have to separate yourself from your work and think about what are the thousand ways

this can go wrong. The interesting thing about being in robotics is that I had to think about safety first because for all sorts of reasons. So, that's kind of baked into the set of algorithms that

you learn first. But in general I think there's and and it's not just for undergrad also your children uh in the similar similar way you talked about deep fakes question everything separate

yourself from the tools and techniques that you build and start to think about what are the ramifications positive negative what could be some uh you know downstream impacts and don't do it by

yourself do it collaboratively with different people &gt;&gt; thank you very much for bringing in students uh I think you they are going to be here for some time at least SO

you you can connect with them later unless they are feeling or everybody's feeling very very hungry but what happened towards the end is that students and fresh graduates were

brought in as one big community as a stakeholder in this but I would like to thank all panelists for giving their views on the need for collaboration for

responsible Thank you very much. &gt;&gt; It doesn't have my name. &gt;&gt; Okay. Yeah, &gt;&gt; thank you. &gt;&gt; We have a to of appreciation.
