# Scaling Trusted AI: Global Practices, Local Impact

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:25 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 18 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/ppx6gBSTniQ?feature=share) |

## üé§ Speakers

- Akanksha Ray, Credo AI
- Candice Anderson, Credo AI
- Caroline Louveaux, Mastercard
- Fabrice Ciais, G42
- Magesh Bagavathi, PepsiCo
- Navrina Singh, Credo AI
- Rajiv Gupta, PB Fintech Ltd

## ü§ù Knowledge Partners

- Credo AI

## üìù Summary

Join senior industry leaders as they showcase enterprise-scale trusted AI adapted for diverse regulatory and market contexts. Moderated by an AI governance expert, the panel will share real-world governance use cases, metrics for measuring trust across geographies, and cross-sector insights. The discussion will highlight practical tools aligned with frameworks such as India's AI Governance Guidelines and explore how proven governance approaches can be localised to scale trusted AI innovation across emerging markets and varied operational contexts.

## üîë Key Takeaways

1. Join senior industry leaders as they showcase enterprise-scale trusted AI adapted for diverse regulatory and market contexts.
2. Moderated by an AI governance expert, the panel will share real-world governance use cases, metrics for measuring trust across geographies, and cross-sector insights.
3. The discussion will highlight practical tools aligned with frameworks such as India's AI Governance Guidelines and explore how proven governance approaches can be localised to scale trusted AI innovation across emerging markets and varied operational contexts.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/ppx6gBSTniQ/maxresdefault.jpg)](https://youtube.com/live/ppx6gBSTniQ?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

is projected to add 15.7 trillion to the global economy by 2030. Here in India, that number could reach as large as 500 billion in the GDP contribution. 47% of Indian enterprises already have

multiple AI use cases not in pilots but in production and 74% just over the last two years have accelerated their AI rollout from precision agriculture

to uh fraud detection in banking to AI powered diagnostics in rural healthcare the deployment in AI is real and it is accelerating so I truly believe that it is an amazing time to build. But I think

what is even more exciting is it is time to build responsibly with trust and confidence. Because the question that will define the next wave of AI is not who builds the fastest or the best

performing model in the world, but it is who builds with measurable trust. who gives people, enterprises, institutions and nations genuine confidence that this AI technology will deliver prosperity

and progress for everybody. The next wave of AI will not be defined by capability alone. And this is a core belief we've had since founding the company. It will be defined by trust

that you can define, measure and prove. And that is why the framing of the impact AI India summit is so critical. Congratulations to the Indian government for convening the summit around the

imperative of impact. India is not just asking the question should we build AI? I think the exciting thing is India is asking the question which is a hard one. How do we build AI

that works for 1.4 4 billion people and how do we prove it that it can be trusted and how do we make sure that it is impactful and there's a reason that this question is being asked here you

know India built Aadhaar enrolling 1.3 billion people into digital identity identity system that now underpins everything from banking to healthcare access India also built UPI processing

over 13 billion transactions a month making peer-to-peer payments seamless for hundreds and millions of Indians built on the India AI stack. Now these are not just technology achievements. I

think these are really trust achievements. The you know these work because people trust them institution that institutional memory building systems that billion people can rely on

is rare and that is what this moment in AI really demands. Now with the release of the AI governance guidelines, India has done some really important work in

establishing the foundation which is really underpinning the AI ecosystem in India. Now the guidelines represent the framework around the seven sutras that translate responsible AI principle into

actionable pathways for builders, enterprises and institutions. But most importantly as this technology and sector specific need evolves across India the framework can be built upon

and augmented and this is something that we've been actively working with the Indian government on over the past couple of months. Now this is emblematic of what good effective governance by

design looks like and we really commend the Indian government for their leadership here. Last month I had the opportunity to visit with professor Sud uh who is leading the office of the

principal scientific uh adviser to prime minister Modi and they've recently published the technolleal framework for AI governance. Now for those unfamiliar with this term which is technolal it

just means that governance is not just written in policies but it is embedded throughout the AI life cycles. It is measured scientifically and you are constantly making sure that the trust

can be proven. So it is compliance by design, governance by design, not as an afterthought. And the framework basically maps governance across the full AI life cycle from how data is

collected to how models are trained to how AI systems are making decisions to how autonomous agents are going to be operating with full agency. and critically it is built for India

purpose-built institutions calibrated to India's sectoral diversity and digital infrastructure. Now this is the kind of thinking that excites us and that really matters in this age of AI. The next step

is really the hard part making it real and that means translating this policy into operational standards that enterprises can actually follow. It means investing in AI governance as a

professional discipline, not just as AI literacy, but the specific skills needed to assess AI risks, verify AI trustworthiness, and manage AI systems continuously.

It also means that venture capital flowing into trustworthy AI startups and governance tooling. It also means incentivizing all the builders in this room with measurable trust from day one.

Defining the framework we believe is necessary but operationalizing it is the bigger challenge and it will require a lot of deep work in investment in scaling in incentives and in policy to

determine what it changes next. Now CTOAI has spent past five years building software that helps organizations worldwide to operationalize AI governance. And what that means is we

take trustworthy AI principles and we turn them into daily workflows, measurable outcomes, measurable checks and organizational alignment. We work with Fortune 500 companies, many of uh

those that you're going to hear from today on the panel. And there are a few things that we've learned. The first thing that we've learned is context is so important because the same AI system

that can be helpful or harmful depending upon where and how it is used. A simple example, if you have a large language model that works well for answering employee questions inside a company

becomes a very serious risk when it is giving financial advice to a retail customer who may act on that advice. A facial recognition system that is accurate in one country might fail in

another just because of demographic disparities. Now this is why you can't govern AI in abstract and that's why co you know context really matters. Second is governance really needs to be across

the full AI life cycle. Now most uh I I would say organizations treat AI governance as airport security you know it's like the worst thing ever but it's a a single checkpoint before deployment

and we've seen those companies are actually not successful and the reason for that is you have to really think from your designing to your implementation to putting it in

production how do you actually in uh in that system define that measurable trust and make sure that those systems are holistically governed. The third thing which I do want to

underscore because this was a very interesting set of conversations yesterday at the summit is many assume governance is all about regulation and I actually think that is uh that is a

framework or mindset we need to shift. AI governance actually is a competitive advantage. This is one of the biggest opportunities knowing the risk that you are having in your AI systems that

you're either building or buying aligning your teams and deploying that with confidence. So I I think as we increasingly think about governance uh governance is becoming a market access

requirement. Enterprises know want to know can I trust the AI? Governments want to know does it meet our standards. Trading partners want to know, can I rely on this AI across borders? And the

organizations that can answer yes with evidence are the ones that are winning contracts. And so we really see governance as a steering wheel and not a break that is going to guide AI to be

useful across not only India but also global south. And you know something that we've been working very extensively with across the globe with standard setting bodies with regulators with

policy makers is really thinking about how trust needs to be embedded across standards institutions and procurement. Trust is not just a product feature. It has to be woven into the entire

ecosystem. Standard bodies need interoperable AI governance benchmarks so that an AI system can be assessed as trustworthy in India is recognized in Europe is recognized in Middle East in

Africa institutions, banks, hospitals, government agencies near really need clear definition of what trust in AI means and not wake principles but specific measurable requirements. And

this is the work that we've been doing over the past five years making sure that for every application we can define what that trust means and can we measure it and so trust is uh you know how we

standardize and how we inst instit institutionalize how we buy and sell AI. So um I also want to quickly address before we bring on the panel a couple of few things that

there is this big conversation happening globally around AI taking jobs and I would like to offer a very different lens AI governance actually is creating a whole new category of professional

jobs that didn't even exist like one year ago or two years ago and these are require these roles require distinctly human skills judgment contextual reasoning

ethical analysis, stakeholder communication that AI in itself cannot replace. AI evaluators, professionals who test and stress test AI systems for safety, fairness, and accuracy before

and after deployment. AI governors, people who design and manage the policy frameworks and the workflows that keep AI aligned with organizational and regulatory requirements. Managers of AI

agents. I mean, you know, if clawbot was any indication over the past 10 days, we know that we need humans to really think through what does, you know, automated governance look like, but at the at the

same time be able to manage this massive army of agents. And so, trust and verification specialists are also becoming a core role. It's it's a professional who audits AI systems,

produces the evidence that enterprises and regulators need uh to have confidence. So, these are not speculative roles. These are happening right now, right here across the globe.

For anyone in the room who's early in their career or even starting a startup, I would certainly suggest that AI governance is going to be that next frontier of job creation that humans are

going to be critical for. The future of work in AI is not just about building AI. It is about verifying, governing, and earning trust in AI. And that's where some of the most

important careers uh for the next decades will be. So everything that I've shared just now is uh is coming from practice. It's not coming from theory. As I said, for the past five years,

we've been working extensively with governments and enterprises to really define what trust looks like and to embed that in their software development, in their AI development

processes. And so today we are so excited uh to one launch the global compendium of contextual AI use cases with some of our customers and partners. Some of those will be on the panel in

just a bit and you'll get to hear a little bit more about them. But I think this is really important because as we are thinking about what does context mean in terms of AI governance, you

can't have a peanut butter approach to AI governance. It really needs to be grounded in impact that each and every AI application is going to have whether it's in healthcare, whether it is in

lending, whether it is in facial recognition systems, whether it is in defense. And so certainly, you know, if you have your phones out, please check out the compendium. I am so grateful for

our partners uh and customers Mastercard, Autodesk, G42, AP and Cisco for contributing some really exciting use cases so that as you go on into your organizations you can bring these uh use

cases to bear. Now we are all here because we all believe in potential of AI or we are afraid of what it's going to create. But for whatever reason you're all here, let's be honest where

things stand. Um, you know, AI governance feels super overwhelming. You know, everyone I speak with around AI governance doesn't really know how to dissect this complex challenge challen

u, you know, uh, topic. New rules every week. We have 72 countries with over thousand policy initiatives. the EU AI act, the AI governance guidelines in India, South Korea's basic AI act,

sector specific frameworks from RBI to SEC, risks are expanding fast and so are the opportunities. So whether you're a startup founder building your first product or an enterprise leader scaling

across market, the question really is where do I begin? And five years of building uh AI governance software has taught us that there is no single credible source of truth in AI

governance. Everyone means different things when they talk about AI governance and it's actually as a a company that has created this category. It's painful to watch. So today I am

really excited to be solving that challenge because today we are also launching the first global AI governance insights hub and this is a really monumental thing and I'll share a little

bit more about what this hub is uh hopes to do but it is a comprehensive continuously updated single source of truth um single source of truth for AI policies for AI risk controls models,

models and also vendors. As you're buying a lot of third party AI systems, how do you know which ones to trust? How do you know which ones to buy? How do you unpack the very complex AI supply

chain? Our hope is that Credo AI's AI governance hub is the answer to that solution. It is not just augmented by our governance AI agents but also by Credo Aai's human intelligence through

our team at uh at Credo AAI. The exciting thing is this is not a static document. It is actually tailored to your need. As I mentioned, context is so important in governing these AI systems

and your input, your industry, your regions, your specific risk profiles, your use cases in plain language. This hub takes in that information and with Credo AAI's governance intelligence

gives you an AI powered snapshot of your governance posture and a plan how you can get started. I also want to just quickly focus on the three pillars that this hub really tries to address right

now and then where we are augmenting it. So the first pillar is the policy tracker. Again, as I mentioned, you know, regulation is just one teenytiny component of governance, but we just

want to make sure that Credo AI can provide you the single system of record for what truth looks like in even regulations. So, right now the regulatory landscape, as you know, is

exploding. We have aggregated all the major regulations globally and translated them into plain language so that you all can understand what this means for your businesses. But this is

also where we actually work with the policy makers and regulators to make sure all the implementation that is shared here actually is validated by them. The second is the risk taxonomy.

Uh you know again one of the key things when we talk about AI risk is what is the harm to your brand to your revenue to the people that it serves. So this risk taxonomy provides 16 distinct risk

types mapped from pol policy violations to bias to security vulnerabilities, hallucinations so that you can see exactly where you're exposed. And then the third thing is risk and policies are

kind of futile without the right controls in place. And this is we believe is the bridge between the knowing and the doing. and a specific mitigation strategy for every risk, not

just the diagnosis uh but from human in the loop oversight to technical stress tests. And what is really exciting is obviously you know we do have a platform but we are making this available for

free to everyone in global south because what is really important to us is that it improves with your contributions. So I'll share the QR code in just a bit, but this hub lets you lets [snorts] the

community vote on risk control mappings and the rate of impact of policies, the severity of these risk and this is a collective effort governance intelligence as a shared responsibility.

So I really hope that all of you would you know join us. I'll leave this on for just a second so that you can and we'll be sharing this after the session as well. your contributions are going to be

really critical to make sure that global south continues to lead in trusted AI because without that we are just going to be beholdened to models um that might not work in context that means that is

required for global south and so um you know I do want to now switch to uh going back to something I started with which is it is a really exciting time to build uh with AI and

today we are uh so excited to bring um some extraordinary folks to the panel. Um these are the builders who are not only defining what the next era of AI is going to be, but these are the builders

who are defining what responsible and trustworthy AI looks like. They are the ones who understand that trust is truly the unlock across technology, across standards, across institutions, across

procurement, across borders. And what really gets built with trust uh doesn't just serve India. We believe that it's going to serve the entire global south. And these builders uh that I'm going to

be inviting are actually making that happen across enterprises from financial sector to retail to frontier model to healthcare. So with that um Magesh Bwati who is the senior vice president and

global head of data and analytics at uh and AI at PepsiCo. Please welcome to the stage [applause] Caroline Lvu who's the chief privacy AI

and data responsibility officer at Mastercard. Fabris CS who is the group head of responsible AI at G42. G42 is [cheering] leading some really exciting work at the

frontier of AI building their own models for the global south. So really excited to have you here for Breeze. And lastly, Rajiv Gupta, who is the president at PB Fintech. Rajie, welcome. So, we are now

going to kick into a very exciting panel conversation because everything that we've shared today, these builders are operationalizing that at scale across their businesses.

&gt;&gt; Great. &gt;&gt; Hello. How's everyone doing? &gt;&gt; Wonderful. Thank you. &gt;&gt; Awesome. &gt;&gt; Okay. So, um all of you have a very

important response. All of you have a very important responsibility in your organizations not only to lead in AI but to build responsible AI. So maybe Fris I'll start

with you. What does that role mean and why is it important to G42? &gt;&gt; Mike is that working? &gt;&gt; Yes. &gt;&gt; Brilliant. Yeah. In G42 we are a global

as you say technology company based in Abu Dhabi and we bring the full AI infrastructure. So we build data center at scale. We build the biggest data center capability and capacity outside

of the US. We bring the digital infrastructure which is safe sovereign to create tokens of intelligence and then we develop AI models across a lot of industry in healthcare in geospatial

activities in smart cities. We bring frontier model to bear. Frontier model we develop in Hindi and English in Arabic and English in Kazak and English. So for us we need to bring responsible

AI at national scale and regional scale and to do that responsible AI as you said Navina is a no-brainer has to be part of the strategy because what we develop has to be really secure data

have to be protected. the handling of data has to be sovereign but we need trust to develop AI at government level and really at scale across the region. So as you say responsible AI is not an

airport security check is really really embedded as a strategic imperative in everything we do. &gt;&gt; Thank you Fabris and you know Caroline you and I have worked for a very very

long time together. Mastercard was our second customer when we had we were just getting started and you've made this a core part of your strategy but you've implemented this across the entire

financial inclusion for all the financial products. So tell me a little bit more about where is Mastercard today? How are you making responsible AI real especially or across some of the

agents that you've developed recently as well. Thank you so much Navina. So happy to be here with all of you today. So let me first say a quick word about Mastercard and AI because it may not be

obvious to all of you. So AI is nothing new for Mastercard. We have been leveraging AI for decades to make our network safer and more secure. So for example, we use AI to make sure that you

are who you say you are when you make a a payment or to detect legitimate from fraudulent spending behaviors. And then more recently we are leveraging genai techniques that help us increase the

speed and the accuracy of our fraud detection tools by up to 300%. So it's a real gamecher and as you said nrina for us the only AI is responsible AI it is all about trust way beyond regulations

to your point because for innovation to scale people have to trust it right so we have been investing in AI governance for way before it was a hot topic um now to be honest our customers have

also been very explicit that's what they expect and they are very clear that one One of the key reasons why they select us is because they trust us more. As simple as that. And we've learned early

on that actually responsible AI is not a friction. It actually provides a business with clarity, with confidence, with guards that they can embed into the design of their innovations from day one

throughout their life cycle. And so if done well, it can really accelerate innovation. I'm going to keep it that. No, I I think you just hit on something which is so

important like the the trust is how your customers really believe in Mastercard and I think there's such a great validation for Mag for you guys PepsiCo where brand is so critical to making

sure that any AI that is used is actually bolstering that customer trust that you know PepsiCo's reputation and you play a very important role leading the entire AI portfolio and data

strategy at PepsiCo. So tell us a little bit more about concretely maybe an example of where responsible AI has sort of helped shape a lot of your PepsiCo's work.

&gt;&gt; Well, thank you. Thanks for having me. It's good to see everyone here. Uh we've got a full crowd here. So thank you all for coming. Uh by the way, I was actually 30 years back. I was just in

your backyard. I was uh working in a place before I ended up uh here. So uh u well thank you. [laughter] Um but uh yes local makes a difference. Um

with with regards to PepsiCo on a daily basis we serve around 1.4 billion consumers. So that's uh sips and byes every day. So for us it's really about serving the community. It's about uh

ensuring that truly the prime minister's vision of vasadeva kurumbam really comes to life and what that really means is really it's welfare for all it's it's happiness for all as well and so when we

talk about that we when we talk about AI we almost switch very easily switch to okay there's benefits for me but there could also be harmful uh for me or for us or for the collective overall planet

itself. So it's something that we've got to really walk the fine line because we are focused on two things. One is we want to all innovate at speed but we also want to ensure that we are not

taking undue risk as well as we're innovating at speed. So that's that's a fine line that we're uh walking. So um I'll give you an example. Um we were actually doing a campaign for Mountain

Dew. The marketing team was doing a campaign for Mountain Dew and uh the responsible AI team got involved in the campaign and very quickly one of the things we noticed was taking pictures of

mountains. Well, certain mountains could be copyright infringement. So very quickly we uh the team got together, worked with the marketing team and we ensured that we had the right marketing

campaign go out and also made changes to the applications as well. the app itself that was doing that made sure that we are not only launching the capability with the right

mechanics but we're also launching the right capability for the right consumers with the right guardrails in place so I think responsible AI is not a back office function like you mentioned but

it's really a front office function because it truly is welfare for all &gt;&gt; thank you so much Magesh and I think uh you know as a big fan of PepsiCo product the sips and bites really resonates with

me and that goes to healthcare because Rajie you and I were just talking backstage about PB fintech uh is one of the largest provider of insurance lending software but also they're foring

into healthcare so maybe would love to understand like why is trust important to you Rajie and how are you embedding that across your AI life cycle &gt;&gt; as you know PB fintech

&gt;&gt; hi u hello everyone uh good afternoon to all of you and thank you for having me here. As we spoke you know a little while before the session PB fintech represents largely the BFSI

segment and banking and financial services without trust is not innovation right it is liability we are accountable to the regulators we

are accountable to the customers we are accountable you know for long-term brand equity as well when BB fintech was launched we started policy bazar first and to answer your question we deal with

about close to 1 million customers every day, you know, uh and over 200 million customers, you know, a a year. I mean, leaving aside some of the holidays. So, up to 200 250 million customers.

Many years later, we launched Pesa Bazar, which is a lending platform. So, we are today one of the largest lenders. So, who gets an insurance policy? Who gets uh the loan sanctioned?

Who you know uh at the end of the day is trying to do a fraud with us. Since we connect with so many people every day, how do we summarize the conversations we've had during the day is all thanks

to AI, you know, and and governance for us is upfront because everything we do is regulated. You know, RBI is one of the largest regulators here in the country. We have IRDA which is regulates

the insurance sector. On the health side of obviously there's no regulator, but there are responsibilities we have. You know, we've just launched PB Health where we setting up, you know, hospitals

across the country. uh we launched this company this year for the first five hospitals we have chosen Delhi NCR as a pilot the whole objective is how do we deal with India

as a country you know uh keeping in mind the the whole uniqueness of this country right we have 140 cr people living in this country of which 30 40 cr people live below the poverty line generally

get covered by social security schemes unlike the US and Europe where social security scheme is available for everybody we also have the top 20 cr 30 cr people who manage things on their own

because they are either you know earning enough to be able to manage things. But the larger challenge we have in this country is those 60 70 cr people who live in middle class and lower middle

class. For them affordability is a big challenge right and in this country the two big areas we will need to obviously work very closely is how do we improve financial literacy and how do we build

that trust and AI is the biggest platform for us to use that and that's what we have done we adapted AI way back in 2019 and today thanks to AI we are able to handle volumes and our ability

to reach to every pin code of the country you know and educate people on Why understanding finance is important? Leave alone buying insurance, leave alone, you know, uh buying and secondly,

you know, how do this people living in the middle class decide what is important for them and their families? If they buy a health insurance, can health be affordable for them?

&gt;&gt; You know, if I go to a hospital, can I afford that cost? If I don't have a health insurance and if I have a health insurance, is it enough for me to cover my, you know, uh challenges? So I think

AI for us will do everything in an hospital scenario where the customer enters as a patient till the time he gets discharged if he gets you know hospitalized everything is going to be

managed through AI. Absolutely Rajie and you know this is something we were just discussing yesterday with Matey and others is the culturally sensitive profile in India the large population

base also the need for inclusivity and making sure these AI systems work for all is so critical so Fabric would love to hear from you because something that has been really exciting to watch is how

G42 is not just building frontier models but they're actually building models that work for global south so tell us a little bit more about you know obviously all the innovation on frontier models

but why is global south important to you? &gt;&gt; Yeah know it's very important I I give you an example uh we are very proud we are launching a pilot for digital

schools in Azerbaien and the intention is to bring basically the knowledge in all the schools and also accelerate uh what teachers can do so we can be you know more efficient and share the

knowledge more effectively. To do that we develop language models that are based on the local language and you know due to scarcity of data of resource or skills it took a lot of effort to be

very very contextual in the way we developed the model to do a lot of testing in the model and when you develop something at national level and for schools where you have to build a

lot of security and you have to build a lot of trust and for us it's very very important to bring all the skills we have developed internally in the global south to to to benefit that and we do

the same for in the English languages Arabic you know large language models as well we we we are developing so for us the global south is part of the con construct of all what we do

&gt;&gt; no thank you for breeze maybe Caroline I'll just go to you know you're based in Europe obviously Mastercard is multinational so tell me a little bit more about when you're building AI

products how do you take into account the context especially for India and weave that into products so that it actually is inclusive and working for all.

&gt;&gt; Yes, absolutely. I think it's important to understand that um the principles remain the same. So I think it's really important for companies to be driven by a set of global principles that act as

your north star and that guide everything that you do with AI. But then to your point, you may need to localize the controls and the guard will so that they fit for purpose to take into

account the local regulations, the digital maturity, the cultural differences, societal expectations and of course global south is something that has to be um top of mind. So for

example, transparency, how do you make sure that your AI innovations are very clear and understandable by everyone? And I think for India it's particularly relevant given the scale, the diversity,

the multiple languages that are at play here. Same for fairness. How are you sure that your training data reflect the diversity of the population so that the outcomes are fair? Now the good news is

that at Masacat we have our AI garage that is based here in India in Pune and uh we have 6,000 technologies that are really working day in day out to develop the next generation of our innovations

with the global south in mind and they conduct also all our research and developments and so that is totally top of mind for us and then on top of that we are also working with uh academic

institutions to bring that alterine perspective which is really really important so that you don't actually you know work in eco chamber you um you get expertise from outside and then given

the the pace of change of the technology I think this is absolutely critical to keep everyone in mind so that AI works for everyone including here &gt;&gt; so Caroline like I just very curious is

agent pay now available in India or is it only &gt;&gt; it is and we just announced it today &gt;&gt; so fresh hot off the press &gt;&gt; I I think when you think about AI agents

and everything that's coming uh in the future. Maybe just very quickly on agentic AI governance, how are you thinking about it? Yes, agents uh agentic commands brings a whole lot of

exciting opportunities but also you know it brings some anxieties to some some of us um uh and look we're going to be driven again by the same principles. I think our mission at Mascat is to make

sure that agent le uh transactions are equally safe and secure and to bring everyone along the journey to set the standard so that um it works at scale uh in a trusted manner and so we're going

to bring our capabilities in terms of fraud protection cyber security building standards um but that's very exciting uh certainly is and you know we look forward to sharing more about agentic AI

governance frameworks we are thinking about for global south and potentially an opportunity to collaborate there as well. &gt;&gt; Happy to partner in every uh Mages, I'm

very curious. I won't go into retail because like you know that in and out but are there things from other sectors that have either surprised you in responsible AI or excited you that you

want to bring into retail so that your AI is more trusted whether you are buying third party AI or developing your own? Uh I mean it's a great question um because we're still in the early innings

of AI right so we're all collectively learning so one of the things I truly believe is uh AI is an equal opportunity leveler right um organizations are going to be flattened industries are going to

be also having a lot more seamless interconnectedness unlike kind of the walls we actually have today so what um and when you think about PepsiCo we're not just limited to certain components

of maybe a brand that you think about. We're through the entire food chain or value chain all the way from farm to uh to manufacturing to supply chain to go to market to shelves to eventually to

the consumers and the consumer's homes and the pallets, right? And brands as well and and associated marketing. So we through the full value chain and they're part of the value chain. We're connected

with almost every aspect of most industries. And let me share an example of kind of what we've leveraged from the tech world is um uh uh uh we're actually I mean some of the favorite brands here

at least that actually started in India is Kury right and but at the same time there's other brands as well like Lays or Doritos and uh these brands we a lot of the innovation for these brands

actually come because we've actually got local ingredients in them. So we've got local farmers embedded engaged with us as it actually as we're actually building these brands. The freshness of

the food, the high quality of the food. That's one. So there's also another piece as well that we're actually collaborating right now is with uh Meta in terms of really WhatsApp ordering. So

you can actually go into a Canara store and we actually have customers in Canara stores that can actually now start ordering via voice, via image, via video or just native ordering. And so it

integrates the food uh the the full chain with uh and you talked about earlier you've got Aadar, you've got UPI, you've got Mastercard. So we're integrating across the full chain with

all the best practices that we have but with still affordability of the market. Rajiv like you talked about uh because that's a very key component for this market here

&gt;&gt; and Magesh as you are like using facial recognition voice recognition I mean governance becomes so central to making sure that you're protecting every citizen their biometrics so I'm very

curious could you talk a little bit more about how you're thinking about you know maybe doing more for India in responsible AI and governance uh so that these systems not only work but are

going to be trusted &gt;&gt; see this is where it's the coalition of the willing and the coalition coalition of the partnership. I mean I'll I'll give a plug for Navina and her team

right credto.ai is a very critical part of how we run the entire governance life cycle. So as we're actually building these systems we're actually using the software development life cycle. Now

we're calling it AI development life cycle and through the full uh life cycle it's not only responsible AI typically gets invoked or involved or cyber teams towards the end of the process but

through the full life cycle and in that process we're actually embedding uh how do we think about consumer protection legal involved way in the beginning rather than later in the processes and

the the point is as more and more consumer consumer ecosystems really comes into our consumer data platform, we've got to be that much more responsible uh as we execute uh our our

our game going forward. &gt;&gt; Absolutely. And we are excited to continuing collaborating with you and making responsible AI more operational across PepsiCo. Uh Rajie, you mentioned

something which really I've been thinking deeply about is, you know, it's not just about tooling and just building trust and magically it happens. It's a lot about education and AI literacy. So

I would love for you to like maybe talk a little bit more about within PB Fintech, how are you making your employees not only understand AI but also responsible AI because again AI

skilling is one thing it's really understanding how do you put governance guardrails in place. So talk to us a little bit more about your AI literacy initiatives.

So I mean straight away to answer your questioned first of all we have now started monitoring AI usage across levels of employees. So we are encouraging that if you don't adopt AI

now you will have a problem in future. So if I have to be 3x or 4x from where I am today uh adopting AI is very very crucial. First of all getting the right skilled people today you know who

understand AI it continues to be a big challenge in a country like ours. Right. So while we have a lot of people uh we are training people to use AI very effectively and AI to us is all about

fairness right today we live in a country where we are we have other big challenges right today we are not an online country talk technically we we've done many things uh we we've created

UPIR those are obviously you know facilitators for people to start coming online but if you look at this country very significant portion today still

believes that people should come and meet them face to face, you know, and do transactions. To move from that scenario, you know, to ask people to trust online uh requires a lot of

responsibility, requires to ensure that we remain accountable to everything we do, you know, uh on on on online. Uh we also want to ensure that our

accountability towards the regulators is very high because we are under very strict regulations. you know any any challenges we face there will could could also I mean completely close our

business down you know and so to us not only adoption of AI using AI effectively what can AI do for us for example I'll just tell you one small story on which we are working today we believe while

India is moving towards Vixit bat in 2047 today there is a population who are 60 plus and that's about 10 crore Now if you study this number is going to

be 60 cr people in 2047 which means a significant rise in senior citizen population which also means today's 40 year olds are tomorrow's citizens senior citizens. So how do we

identify two customized products for today's 40y old so that they safeguard their interest when they grow old they don't have an income plan there'll be a

problem because with longevity increasing how will they survive so AI is going to help us to identify such people customize products for them and at the same time reach out to every pin

code as I mentioned to you in the country keeping in mind diversity multiple languages that we have in this country because people will not understand English or Hindi we'll have

also adopt you know multi- language training programs to be able to use AI effectively. So when in 2047 when we have 60 cr people can they live a life with respect because 80% of those people

today don't have an income plan don't have a health insurance plan now imagine what impact it will have on the country which doesn't have a social security scheme if this is not addressed today

and that is where EI is helping us &gt;&gt; absolutely Rajie we're going to go to the last question I think this is a really important question because we all are gathered here to really think about

what do we want from this India AI impact summit. So maybe you know quickly maybe Magesh we can start from you. What are your hopes uh and what does success look like for you and for PepsiCo uh

coming out of this India summit like one actionable thing that you would like to see and we'll make sure that the answers are limited to less than a minute. So we can round it up.

&gt;&gt; Sure. One of the things I'm super uh excited about what India is doing is really associated with sovereign AI and building the necessary infrastructure at a governmental level, at a policy level,

uh at educational institutions, uh for enterprises and for industries and really also trying to make sure it flows all the way down to its uh citizenry. So for us as uh uh serving you know 1.4

four billion consumers every day. Leveraging this kind of capability is a huge advantage for us because we can piggyback off all of the digital capabilities, the AI capabilities that a

country like India is offering and thereby ensuring that we are able to have the necessary fairness, equity, equality, but most importantly welfare and happiness for all.

&gt;&gt; Thank you so much Mesh Caroline. So quickly, one thing that we haven't really spoken about is, of course, we speak a lot about the huge opportunities of AI. But let's be clear, AI also

lowers the barrier to entry for cyber crime. Think of how easy it has become now to generate deep fakes. Anyone can do that in their garage, right? Or in the bedroom. And then how easy it has

become to trick people into sending money or data to farters. And the threat is only amplified now with aic and new developments in AI. So if we want to stay one step ahead of cyber criminals,

we must join forces. We must act together and we must be able to share data intelligence across borders and across the public and private sector. That is absolutely mission critical. And

so if we want AI to continue to be safe, we must combat fragmentation of standards and data silos because it only benefits cyber criminals. And so that's what I hope to achieve.

&gt;&gt; Well, thank you so much, Rajie. And then Freeze, bring us home. Yeah. So as I mentioned to you in fintech and insure tech you know for us AI risks are amplified because decisions affect

financial futures right outcomes are you know obviously asymmetric. You know errors compound socially. So for us you know ensuring that responsible AI with highest governance standards is very

crucial. It it is early days for India but India is is growing fast as far as AI is concerned. Today we use a mix of open AI and and you know local AI uh to be able to build what we are trying to

build across our businesses. To conclude I would say financial services taught us to be cautious. AI first companies taught us to be systematic. &gt;&gt; Thank you so much Rajie Fris.

&gt;&gt; Yeah for me that is blueprint adoption and leadership. So if we could define a blueprint for responsible AI in the global south taking into account all the contextual challenges that we need to

address making making is safe. Making sure he's trusted, but making sure we respect basically all the you know all the local um all the local culture and requirements is very important to define

this blueprint adoption because if we don't adopt AI we don't get enough you know data points to improve AI and we we we we don't make AI safer and more trusted. So that's very very important

and leadership on the global stage where we see a need for leadership in responsible AI. So if we could wish that this place and India could be a leading place for the global s this would be

great. &gt;&gt; Wow Fabreze that was exactly what I was going to say but I'm just kidding. Uh but I I think that's a really good summary like blueprint what is

trustworthy AI in India but global south really mean. I think this summit has such a great opportunity to make that happen. What does adoption at scale look like? because it will need all of us to

make sure responsible AI is embedded and I think leadership also is responsibility. So how are we making sure to Caroline's point we have the right standards and right guardrails

becomes really critical to make sure that our builders are not just building with AI but they are doing so with trust and responsibility central to it. So with that please give a big round of

applause to all the panelists. Thank you so much. &gt;&gt; Thanks. Thank you. Hello. Okay. Thank you so much to all of our panelists and Nina for such an

insightful discussion. It was great to hear about how global practices are being employed here for local impact in India and across the global south. Um, we heard some really great examples of

AI use across the value chain and we hope that we've left this audience with insights that you can take with you as you drive the AI transformation journey in your enterprises. Now, we're going to

do a quick ceremony of momentos for each of our speakers. So, if we could just one by one have each of you. So, Fabric, we can start with you.

Not me. &gt;&gt; Caroline. Mash &gt;&gt; and Rajie. Thank you all so much for joining.
