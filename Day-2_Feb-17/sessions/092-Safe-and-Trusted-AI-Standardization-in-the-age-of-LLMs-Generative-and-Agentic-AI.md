# Safe and Trusted AI: Standardization in the age of LLMs, Generative and Agentic AI

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/Q2gGs8qruwo?feature=share) |

## üé§ Speakers

- Mr. Abhishek Aggarwal, Ministry of Electronics & IT, GoI
- Mr. Ashish Tewari, Infosys
- Mr. Rohit Israni, INCITS/AI
- Mr. Sridhar Chimalakonda, IIT (IIT) Tirupati, India; Adjunct Faculty, University of Waterloo, Canada
- Mr. Tim McGarr, British Standards Institution (BSI)
- Mrs Reena Garg, Bureau of Indian Standards
- Ms. Gayathri Ekambaram, Tata Consultancy Services

## ü§ù Knowledge Partners

- Bureau of Indian Standards

## üìù Summary

The rapid deployment of LLMs, Generative, and Agentic AI offers immense productivity gains alongside significant concerns. This panel identifies opportunities and challenges in AI adoption, highlighting how standardization enables responsible innovation. Featuring experts from industry, academia, and policy, the session explores the current status of AI standards and the urgent need for further frameworks. The goal is to ensure AI's responsible use for positive societal impact through a collaborative, standardized approach.

## üîë Key Takeaways

1. The rapid deployment of LLMs, Generative, and Agentic AI offers immense productivity gains alongside significant concerns.
2. This panel identifies opportunities and challenges in AI adoption, highlighting how standardization enables responsible innovation.
3. Featuring experts from industry, academia, and policy, the session explores the current status of AI standards and the urgent need for further frameworks.
4. The goal is to ensure AI's responsible use for positive societal impact through a collaborative, standardized approach.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/Q2gGs8qruwo/maxresdefault.jpg)](https://youtube.com/live/Q2gGs8qruwo?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

It's done. It is my privilege to welcome you all to this panel discussion at the AI impact summit 2026 here at Bharat Mandraam New Delhi. As AI systems increasingly shape

economies, governance, research and daily life, conversations around responsible development and deployment have never been more critical. Today's panel discussion focuses on a theme that

sits at the very heart of this transformation. safe and trusted AI standardization in the age of LLMs, generative AI and agentic AI. The rapid deployment of LLM's generative AI and

agentic AI systems are unlocking unprecedented productivity and innovation across sectors. At the same time, it raises significant concerns around safety, trust, transparency,

accountability, and societal impact. This session will explore the opportunities and challenges emerging from widespread AI adoption, the role and current status of AI standards

globally, how standardization can enable responsible innovation, and what more needs to be done to ensure AI delivers positive societal impact. We are privileged to have experts representing

standard bodies, industry leaders, academia and policy makers truly reflecting the multistakeholder approach required for trusted AI ecosystem. Without further delay, I request Mrs.

Sina G to take the decision discussion forward. Thank you and over to you ma'am. Thank you distinguished panelist all the participants present over here. A very good afternoon to all of you and

it is my privilege to be here amongst the eminent panelist and all the participants to moderate the discussion on safe and uh trusted AI especially the standardization aspect

and as artificial intelligence moves rapidly from research labs and into our governance systems industry operation healthare, finance and even in everyday

decisions we make. So the question in front of us is no longer whether AI will shape the future or not. The more important question is whether it will do it responsibly.

That is the important question in today's context. So the standardization plays a very critical role here. ensuring that AI systems are safe, reliable, transparent, interoperable and

aligned with human values. So today uh the discussion this discussion is an opportunity to explore how technical standards and regulatory framework and ethical principle can work together to

create AI systems that are for that the citizens uh we are here are very confident and we can rely on those systems. So uh I would like to uh start with the

question answer sessions like I will be asking one questions for each panelist and the my first question is for Dr. Shrihar Chamal Gunda from IIT uh Tirupati. So you have been working very

closely with the AI domain relating to standardization and uh you you were also chairing the group on AI assisted software development in JDC1 SE7. So my question

for you is how do you define trusted AI in today's um era of large language model and agentic systems and where do current governance and responsibility framework really fall short?

uh firstly you know uh thanks uh uh everyone for joining the session. I think we are discussing a very critical topic. So you asked me about trusted AI and if I say that let's say you know if

the audience here how many of you you already use let's say HR GPT or any you know model and do you trust it? So so the question here is like you know trust has is a multi-dimensional and

multifaceted thing. So it's very hard to sort of define that you know this is how you trust. So uh my uh perspective on this is that uh of course you know we have already you know a couple of

standards in SC42 on artificial intelligence where uh you know trust has been defined uh you know in various properties like 12 properties in terms of reliability, safety and so on and

also you know a lot more characteristics right in terms of when when do you trust a system when do you not trust a system but the point that I would like to bring here is that uh the trust essentially

varies based on the domain based on the stakeholders based on uh you know the autonomy of the system that we are in trust in in uh you know let's say web browser versus trust in a diff different

system could be very different so I think uh we still have to go deeper in terms of defining trust for a range of scenarios which I think is still evolving so on the on the second part of

the question I think like I already mentioned that know There are a couple of standards and technical reports on defining trust but the challenge really is that they're still at a policy level

or at a principled level. So what uh I see or or what I envision is that uh there is a need to provide uh you know uh sector specific guidance go deeper into this how you can define trust how

you can measure trust for several sectors. So the current system they're largely you know focused on principles but we need the next level of you know guidance so that uh the vendors who are

making uh you know AI products as well as who are following AI process. So for example if I am like you know a simple question would be if a software is generated using multiple agents and now

if the software fails who will take responsibility for it let's say if there are 20 agents which agent will take responsibility for it or should the software engineer take responsibility

for it so at this point of time the questions the answers for these questions are still unclear so I would say that know there is a need to evolve in this direction

&gt;&gt; thank you Srarther very well explained and uh I I think standards have to some extent some answer to these definitions but it's a dynamic process of laying standards. So it keeps on evolving. So

but whatever so far is there on our plate. So for the benefit of the participants they can maybe go through those websites like where the whatever standards are actually in place the

Indian standards the international standard JTC1 SC42 ISO standards on AI. So uh we can share the links of all those uh things with all of you later and uh we have a very uh like relevant

and very knowledgeable person Mr. Rohit with us today and he's the chair of insits AI the national mirror committee of US who is uh making uh responsible for making I AI standards and Rohit like

my question to you is what roles do international standardization bodies like ISOIC JDC1 SE42 and national standards body like NC uh play in defining trustworthy AI frameworks

Thank you Reina G and it's a real honor to be here in Delhi and first of all thank you to BIS Chhattish and Reina G for organizing a panel on this very important topic. So

the question about standardization in AI actually started coming up in 2015 and 16 time frame and in 2017 uh there was a discussion between ISO and ICE and a decision was taken to

start a subcommittee focused on AI standardization and I have been a part of this subcommittee right from the inception and India has been a member right from day one as Well, so ISO and

IC as many of you may be familiar are international standardization organizations and a combination of them has a committee known as joint technical

committee 1 JTC1 in which a lot of the information technology standards are created like cyber security privacy and within that the work on AI standards started in 2018 early 2018

And uh the good news is that we've been through several years uh we've built uh the foundation of AI standards and again uh Shrther mentioned a need for vertical standards sector specific standards.

What SC42 is it's a horizontal committee across verticals. Uh first of all there is a need for common vocabulary. So everybody's speaking the same language. So that's among one of the work products

of SC42. Thereafter there have been standards developed on data. Uh there have been you know standards and reports developed on testing and a variety of foundational

standards for AI and this has been done within SC42. Uh I may also mention uh within SC42 there's also now a certifiable standard that got released a year and a half ago. uh some of you may

be familiar with it's the first certifiable uh standard for management systems for AI called ISOIC 4201 and uh to answer Reina G's question that's the first kind of trusted

framework it's a beginning it's not the end we're on a journey the journey's already come uh since 2018 it's been 8 years but this is going to be a multi-deade journey cuz AI is rapidly

expanding capabilities are changing you know within it's not a question of a year it's a question of a quarter the model you used a quarter ago versus the model you use today there is a huge

difference in capability and standards need to keep up and that is the biggest challenge because technology is moving very fast and as standardization bodies we have to find ways to keep pace with

it I'll stop there for now &gt;&gt; thank you Rohit that was lot of information very useful full one. So since you talked about 420,0001, we already have a certification expert

amongst us. Uh Tim, so uh Tim, my question is like what are the unique challenges in the certification of AI system especially with respect to 4201 and other relevant standards.

&gt;&gt; Thank you. Thank you very much for hosting today. Um I think as has been mentioned the real issue that everyone faces with AI just as Rohit just said is the pace of change.

um and but nevertheless the standard system and the associated assurance is very well aligned for that. So 42,0001 as was mentioned is a framework that adapts the organization adapts the

change. So even today what we're seeing is that all the big uh general purpose AI providers have for 2001 certification and we also have with some of the emerging challenges some of the

standards that were mentioned so the stat the big standard for the AI management alongside the AI management system standard is the standard for cyber security so 27,0001

27701 around data privacy and the those those standards have been around for 10 or 20 years and very established used by hundreds of thousands of organizations

around the world and some of those things we already know we can bring those same statements into the emerging AI area because the importance of data protection the importance of cyber

security is still there we can look to that now &gt;&gt; thank you Tim uh like my next question is for Gaitri uh from TCS uh so you've been working a lot on agentic AI and

other models of AI so what new risks and respons responsibilities have emerged with the rise of these new generative AI and AI agents and the in the whole of this AI ecosystem. what are

the actual new risks which have been &gt;&gt; absolutely good afternoon all um it's it's a real pleasure and honor to be part of uh India AI impact summit I think it's rightly named as impact

summit so coming to your question Reina G what are the risks new risks and responsibilities which have come across along the way in Genai and agentic AI well a risks are not new right we have

been dealing with them for over a decade. I think Mr. Rohit also mentioned about we having standards for about 80 years and uh traditional AI so-called. So when we thought we have stabilized

it, we have known the ways to see the inaccuracies or model drifts um and how do we train them, how do we manage them, then came geni about 2 three years back. Uh which which paradigm there is a

paradigm shift in the way GNAI introduced risks, right? Uh it it led to deep fakes, it led to IP infringements which have not been thought so far before. And uh hallucination is not just

about inaccuracy but uh the confident fabrication of the facts it it it's giving right. So that has uh broughten a lot different angle on how these risks have to be managed how these risk has to

be prevented. So when we thought we have some ways of you know grounding the models into non-h hallogenating and having stringent governance then came agentic AI which don't uh only generate

but also act on this risk they execute uh they call APIs they access systems they execute irreversible transactions so I think the risks are like the the capabilities are also exploding the

risks are also exploding marina and responsibilities is I would say it's everybody's pie. Um I think from the model providers, deployers, distributors, implementers, it's

everybody's responsibility to have these responsible AI practices. Uh in TCS we have a responsible A framework and what we call as safety tenants, responsible tenants. Um it's an acronym. S stands

for secure and reliable A systems. A stands for accountable. Who is accountable at the end of the day? Right? and F is fair and ethical at the end of it. Is it whatever gains we are

gaining because of the AI? Is it fair and ethical and um transparent? Is it transparent and explainable and is it also giving you the identity and privacy protection the much needed one so I

think responsible AI is everybody's pie everybody should uh be taking that very seriously. &gt;&gt; Thank you. I think the standards also come in there playing a very important

role. &gt;&gt; Absolutely. Absolutely. &gt;&gt; And uh like you need to have some initial guidance to identify those risk and how to behave responsibly. So the

initial guidance will of course come from the standards and over and above like the organization like yours will build up your own system to follow those kinds of uh responsible AI ecosystem.

&gt;&gt; Absolutely the standards coming to the standards part we are as Mr. Rohit also said SC42 I think is a subcommittee which has most number of standards and many standards

are being built as well. The focus is currently on the agentic AI. How do we standardize the agent AA practices and what are the different dimensions how agents are going to interoperate how how

they are going to orchestrate and how can they be standardized uh so many things are in progress many exciting times to come. &gt;&gt; Thank you. Thank you Gaitri. And uh

coming to the governance like uh I we all know that uh recently like uh in the earlier this year government of India released AI uh India AI governance framework which is available for

everyone to have a look at the uh website and also on the website of office of PSA. So uh this is a very important document and defining and it is talking a lot about standards. So in

this reference I would like to ask uh Abhishek who is here from uh Ministry of Electronics and IT like how do AI standards support governance, transparency and accountability and risk

management. So how do standards help in all these uh addressing all these aspects? &gt;&gt; Sure ma'am. First of all, I would like to thank uh EIS for this uh session and

inviting me here and also being from the ministry of electronics and IT, I welcome all of you in this India AI impact summit and making it successful. It's a collaborative effort of you, us

BIS and everyone and since starting we always want to be uh inclusive in this manner so that we can feel it's like a batka summit. as far as the role of standards in the govern AI governance,

transparency, accountability etc is concerned. So the AI standards are like the operational backbone of the safe and trusted AI. So like policies and the strategies etc the governance frameworks

they articulate the intent but these are standards are the ones which uh define which translate this intent into implementable technical and procedural processes

as like the from the governance perspective we see these uh standards introduce consistency and comparability where the like they established the structure processes for the data sets um

like data set documentation uh model validation and and and across the life cycle and they also talk about the life cycle approach. The standards define transparency also

in the system how means standards are the ones which show which defines how AI system designer build the transparency into the system. So like standards guide uh how model should be explained how uh

like how the limitation should be disclosed and the these transparency are very much important in the high impact sector such as healthcare agriculture which where we cannot afford any risks.

Further uh as far as accountability is concerned as Shar mentioned that right now we are struggling who who is responsible. So standards are the do is the one document who defines who will be

the responsible in the across the AI value chain starting from the development developer deployer uh after that the management and then the post audit reports etc and further to what

should be the as ma'am already mentioned about the governance guidelines what should be the approach of India's India approach towards the AI regulation AI AI adoption etc we have India government of

India has come out with the AI India AI governance guidelines last year on the 5th of March uh sorry 5th of November 2025 it was released by our principal scientific adviser along with our

secretary Mitti so it talks about what is the vision of government of India we are promoting we are pro- innovation but we are also not compromising on the user harm so in short if we say that the

standards are the one which reduce ambiguity and operationalize and build trust towards the deployment responsible and safe deployment of AI at global I means at the scale at at the scale in

India. Thank you ma'am. &gt;&gt; Thank you Abhishek. Uh so uh back to you Shrar again uh like we have been uh witnessing LLM agentic AI and uh so and we have already start started discussing

related to embroidered AI. So what could what could come next and how must governance framework and standards co-evolve to ensure this responsible and trustworthy AI

&gt;&gt; right uh I think again like I was you know like all of us have been saying right like AI is already here right you know it's not just one domain from education to healthcare across like you

know even defense so the question the critical question next is if it is already here and uh if people start using it which we are already doing. So the next thing next critical thing would

be to ensure that these AI solutions are safe to ensure that they are trustworthy and responsible. Now the current way uh I mean like you know the way I would see is that we do not have uh established

mechanisms to say that yes I use if I use a particular AI solution let's say no GPT or cloud any any of this how do I know that it is trustworthy how do I know that I can rely on this so at this

point of time the next critical thing that I would say is like you know one is definitely the proliferation of lot more you know proliferation of AI across the domains but at the same time how do we

ensure that these systems are responsible now it is here I see that uh again you know going back to you know the government of India's approach on the the governance guidelines again you

know guidelines as such are not prescriptive in nature so if there is an AI provider and if they say that yes you know we are you know we are in line with the guidelines but if there is no

enforcement then there is definitely a risk you know for the general public on good. So I think we are at a pivotal point where the proliferation is happening at a you know lot more

exponential rate of AI across domains and on the other hand the governance guidelines are are at this point of time uh suggestive in nature. So what I see next is uh for how long can this nature

of suggestive be there is the question. So a critical thing for us and for you know for the standardization community and for the government of India is to look at how do we cross this line

without uh uh hampering innovation. So I see that there is a need for a stepbystep or a step stage wise approach where we could say that uh the guidelines could be enforced in certain

domains whereas the guidelines could be of suggestive nature in other domains. So to me this is critical uh pivotal point where uh the standardization community as well as MIT and all other

academic and industry bodies should uh think and deliberate on what are those sectors where we are okay with the guidelines to be suggestive where it is not okay and it should be enforced as a

regulatory thing. Now just to add one more quick thing on this is even if we assume and if we say that okay we want to enforce so for example like you know how do we know that our data is is not

compromised when we are using an AI tool today from a DPDP act perspective or a privacy perspective right now we don't have answer but as I see uh uh it uh you know as I envision it I see that there

will be novel approaches right both from academia as well as industry to come come up with ways to verify if a particular privacy policy of an AI provider would adhere to some of the

guidelines given by the mighty. So what next to me is if I have to summarize one is of course lot more proliferation of AI across domains. The other is a stage-wise approach where we definitely

need approaches and tools to guard uh like you know and ensure that these solutions are responsible. I would stop here. Thanks. &gt;&gt; Thank you. Thank you Srita. very well

explained and I think uh like what you meant is that the government is giving us some specific guidelines but what actually the users have to do what actually the citizens have to do that

has to be more prescriptive in nature and more detailed more comprehensive sort of documentation maybe in terms of standards and so lot of responsibility again on standards community to work

tirelessly and to keep on evolving to keep on um modifying to keep on revising those existing standards. So thank you for that and uh my next question I'm coming back to Rohit again. So lot of

responsibility on JTC1 SC42 for evolving international standards and uh like they have a comp overall structure of involving national standards bodies from various countries various consortia

and uh various other entities as well. So that the standardization process is inclusive and so in this reference I think you are licened between SE42 and organization for economic corporation

and development OECD and ML commons. So what role do such forums and consortia play when the international standards are being developed in these areas? &gt;&gt; It's a excellent that's an excellent

question. That's an excellent question Reina G and to what Shrida was mentioning and also what Abhishek alluded to where you know he's also involved in G GPAI

uh there are several conversations that need to occur and they sometimes can be informative conversations for standardization and among the two organizations both of them play an

interesting role and uh OECD was the first organization to come up with a set of rules for AI I guidelines for AI and there is a certain amount of activity that is what is called

pre-standardization which is a discussion among stakeholders among countries um among various uh constituents and that informs then a standard as it is being developed. In

the case of OECD they actually did an AI incident monitoring framework. This was ratified by I think all the OECD countries and that was brought in the Delhi plenary which was hosted by BIS

last April. It was brought in as a new work item proposal for standardization. So something that was already kind of baked done well and it's required by every country. We have to monitor AI

incidents now is a work item proposal in SE42. And that's one example of how a forum like OECD u you know is kind of impacting standardization. Uh the other organization that I'm privileged to also

be a leisur to is ML commons. Um, one of the things we notice about AI particularly, right, it's not a technology in which you do what is very structured testing

standards talk about red teaming or prompts where you're asking a series of questions and you're looking at the response and you're identifying toxic behavior, behavior that's not

acceptable, biased behavior. But then to actually do this in practice, you need benchmarks and that's a very important area where ML Commons is a consortia. It has a large number of companies across

the world. Most of the large US companies are participating in it. They've come up with a set of questions, a benchmark called AI illuminate and now they have one for jailbreak. These are

very critical and important elements because a standard can say do red teaming but how you need a benchmark and that's where an organization like ML commons comes in and uh besides that you

know I am a layer software too uh it's to the credit of SC42 chair while DAB he has spent he's been the chair from the inception we have 89 or 90 uh leons with several organizations like this so It's

it's like all of us coming together and actually helping move the ecosystem further. Stop there. &gt;&gt; Thank you Rohit. That was quite

comprehensively addressed. And uh uh next I'm coming back to Tim. Uh so as a AI market development lead at uh British Standards Institution. What are your views on like how standards uh can keep

pace with rapid innovation in LLM and generative AI? Yeah, it it's definitely a subject of interest to me because as you mentioned we do assurance of systems and to do assurance you need to have

standards and accepted best practice in place. So getting that in place is important for us. I think as as mentioned we are in a good position because the standard system started

working on AI over 10 years ago now. I think it's 2015. So we're quite far down the line in terms of that system and the important parts are there. So terminology, risk management, governance

and those have been adapted as we get new um so general purpose AI is coming through and there are new standards starting in there and there's also work coming through and I think it's very

important that the standards community continues to work at pace and work with liaison as well who can bring in sort of new ideas and build this system out to meet the needs of all stakeholders

around the world. &gt;&gt; Thank you. Uh coming to Gaitri uh again uh like how do you uh think like whether these existing standards are sufficient to address the complexities of LLM and

uh generative AI where exactly should the standardization community should focus on to address these two areas? Well, I would say the existing standards definitely have given a strong

foundation right uh for the GIA and a lot of adoption we are seeing from the industry perspective. Lot of our clients different organizations from various sectors are adopting for 2001 the AI

management system standard and for 2005 for a system impact assessments. lot of standards are already existing and being adopted and they lay a very good foundation but are they enough uh seeing

the nature of AI the nuances coming through genai and agentic AI the existing standards also have to be uh evolved developed new standards are definitely needed right in in in just to

throw a small light on that area in SC42 we are focusing as I said more on agentic standards there is a lot focus focus has been given on resilience of an A system, reliability of an A system,

robustness of AI system and Rohit mentioned about the incidents, how the AA incidents are going to be addressed. So I think um um the standards are also have to keep pace with the technology.

It's going to be the co-creation of standards with the technology. Currently technology is kind of outpacing the standards but we are also gearing up. We will also have the standards rapidly

built and uh to ensure that the technology is um uh in in indeed giving benefit to the mankind. &gt;&gt; Thank you Gri. Uh again u moving to Abhishek again. uh so like uh you've

already uh talked about uh this but what are the other uh ways uh uh on how AI can standards uh AI standards can complement AI regulations and national AI strategies

uh from the government perspective &gt;&gt; in my view the AI reg AI regulation or the national strategies and the standards mean both are complement to each other

uh Both are required to support each other. Uh national strategies or like AI regulation they define what should be done but standards are the things which

define the process how it should be done or how it should objectives of these national strategies should be achieved also uh like AI is very evolving. So the standards are the mean standards are

provide the adaptive technical guidance so that we which means which supports the uh innovative life cycle changes but also remain intact and aligned with the national regulatory goals. Further as

for a country like India where we are pursuing a pro- innovation approach these standards support us and help us in uh ensuring that the domestic EI systems are compet competitive and

comparable with the others globally also ensuring and reflecting the national priorities in the India governance guidelines it talks about the accountability it it emphasizes the

account uh explanability access to data, access to compute and these standards are help operationalizing to achieve these priorities. They define the path how to achieve these priorities

uh across the sectors and without compromising and stling the innovation. &gt;&gt; Thank you. So as I understand standards are the tools uh to implement regulations brought out by the

government. So the standards will be uh actually used for implementing whatever government is prescribing. So uh like uh we have completed two rounds of uh questions and answers uh

within a very like uh stipulated time frame. So there's uh little bit time left. I would like to utilize that with one common question to all of you uh all the panelists. So what is that one

concrete action and suggestion you would recommend for organizations to ensure deployment and uses of safe, trusted and responsible AI solutions as well as to integrate AI governance with national

and international standards. So uh maybe we can start from uh Tim and then go around all the panelists. &gt;&gt; Yeah. And just one thing I'd also in terms of the last question reference out

around the link between standards and regulation. So taking two other examples and there are various different ways that countries are approaching um regulation of AI. So for example in the

UK where I'm from the government is pushing towards um standards and assurance as a way of demonstrating good AI governance but not pushing regulation. And the other thing sort of

close to where I am from is also the EU AI act which sets out which the first comprehensive piece of AI regulation in the world which sets out you know the what but there the standards that

provide the detail and that's where certain organizations will need to have um to work with a notified body to get their products onto the market that the standards are very closely linked to the

way that the regulation is going to work in the EU in terms of what you can do I mentioned earlier on that around 42,0001 and India is already a lead in this space. So in terms of number of

accredited certifications in the world it's number two and also leading through. So Axis bank recently got certified and that's the first bank in the world to be certified to 420001. So

sort of real leadership that's there and there's a lot of materials around to help with 4201 to understand what it is, how you put it in place. So take a look at that sort of build out through from

the standard forward because that's the main framework that's used around the world for AI. So I think one concrete action is to adapt these standards rein um not to see

standards as alien or an outside thing the organizations should adapt standards and organically throughout the life cycle of their business. Right? And as Tim also said for 2001 is gaining

prominence and we are also hearing and seeing in the industry and I would also say more focus on the upcoming technology and standards which are going to come in that space. I think standards

we need to take very very seriously. So I will I will echo the same point and you will hear this number a lot 42,0001 but I will also add one more number adding six to it which is a standard

called 427 we haven't released this yet it's in development but as Srther alluded to a lot of the current like 40201 as well it's a standard that talks about process

these are the things you should do. These are the elements of governance. You should have a committee that looks at it. You should identify the risks. You should mitigate the risks. That's

what 4201 does. But as we get sector specific, there perhaps is a need for doing product level testing, right? There may be for a for a certain high-risk application. You know, there

may be a need for you to do more than just 4201. And that's where the US actually proposed 4207 which is built on existing series of conformity assessment. It's a part of

what's uh the ISO has a conformity assessment uh party. Conformity assessment is how you know aircrafts run today. Various parts of aircrafts go through various tests and

certifications. There is an accredation process. Right? So 420,07 will allow sector specific consortia to build schemes to build let's say for this particular application a consortia

group of people in that vertical uh leading stakeholders and thought leaders creating a scheme here are the things that you need to do additionally in terms of testing so that you can be

assured of a certain level of safety and this is a standard that's being developed 4207 and And I think it has a it has great kind of value to the overall ecosystem.

&gt;&gt; Yeah. Uh thanks. I [clears throat] think uh I can see multiple things but maybe you know to sort of summarize. So one definite concrete or like concrete thing that I see is uh the AI the assessment

of an AI system cannot be static anymore. It's like an AI system has been developed and let's say you know they go through compliance or whatever and then say we are 42,0001

you know compliant but they can't say that you know we have done this and then the next year we will do. So I definitely see a need that we have to look at continuous assessment of AI

systems. So the static to continuous is a is a concrete thing that I think we have to think as a community both the standards community as well as you know from the government side. The second uh

you know critical thing that I uh envision is that there is a need for uh standards. Uh again like the way I would see it is uh uh India cannot be just adopter of standards but we need to

create our own standards because we have multilingual scenarios. We have you know very diversified data sets. We h we have lot more scenarios where this context are is unique. So the the the approach

to we will take 420,0001 or 420,0007 and then you know adapt them to India versus having an approach that starts looking at standards saying that in the Indian context AI is being used by

billions of people right now in that case how do we look at creating standards that consider you know Indian context is a critical thing in my view as well right and to sort of like you

know one more quick uh thing is we also need to look at uh again like you know I mean like you know whether it could be BIS or you know the mighty or the government uh any AI based uh product or

a process that comes out or being used there should be some sort of a hallmark. I know it could be a you know being an academic I can say that no I want to envision a future right but I also see

that there should be a mark that has that should be labeled and said that hey this AI system probably you know the privacy policy is not validated yet so then you know there should be an

explicit mark so I definitely envision that this is a direction that and in fact that's a request or an ask from the mighty where we have to look at these systems and see if we can label AI I

systems across these different levels so that it's visible in terms of whether a particular AI system has gone through the complaints process or is still evolving. Yeah,

&gt;&gt; absolutely. Uh very well said uh Shrar and I think India realized this and we have been proposing standards at JTC 1 SC42 and uh I think uh one on benchmarking of

uh AI system was proposed by India. So initial thought was this only to have some sort of labeling on the products keeping in mind that kind of benchmarking system. Uh but uh later on

after deliberations and other uh like within the SC42 community like uh the the standard is I think has already been uh uh in the stage of publication and uh so we'll see what comes out of that

standard. So very much agree with what you are saying for the interest of all the citizens. So there should be some kind of you know labeling or some kind of how much AI uh is there in one

particular product or how much like we can rely upon that kind of um product through some kind of labeling thing. So that is for us to ponder over in future and uh also think of from the

standardization perspective the guidelines to do so. Uh so over to you Abishek. &gt;&gt; Yeah. So in uh my view the organizations should adopt safety by design approach

across the entire life cycle start uh from the deployment uh in initialization phase, designing phase then the de development phase, deployment phase, post deployment phase, audit in auditing

phase also and we in India AI mission also we build in we emphasize on the trust by design approach And uh for this we are building uh various solutions a tool uh set of toolkits such as ethical

eye frameworks for uh watermarking and labeling defect detection tools um and uh uh machine learning etc. So we have already uh initiated 13 projects or 13 organizations have been interested to

develop this these toolkits. as far as the governance guidelines by sharas are mentioned. So it's not a sing means it's not a document that has been done and it's completed yet it's a living

document and uh BIS is also a part of this committee and uh we in this current version also BIS has given many means they have uh give us various inputs and like the there various standards which

are existing in the AI are also mentioned there and we never said that this is the final document and it's a living document it will be reviewed time to time so that the because as we

believe that AI is evolving very rapidly and our guidelines, our regulations, our approaches needs to be updated time to time so that we can keep uh we can keep pace to that. Otherwise, we are saying

we we should be pro- innovation but we should not mean we should avoid user harm without compromising user harm. If we do not update ourself, we do not update these guiding documents, then it

will be difficult to to balance to uh make this delicate balance between the innovation and the uh innovation and balancing the user harm. So it it will be done it will be keep updated and the

more guidance will be added. As far as prescriptive nature of the guidelines currently it shows a vision it's talk it's talk about the vision and what should be the approach what should be

done it but as far as implementation is concerned it also talk about goals like the short-term goals long-term goals they are also defined here which we which we means which we intend to uh

complete so that uh it's it's not does not become just a guiding document. Further as far as regulation is concerned currently we believe our existing regulations whether it's an IT

act or a BNS or the other acts from the user harm perspective they are already taken care because any wrongdoing to any person or any citizen is already covered in in these acts and uh as per the

provisions of these act the punishable things can be ex exe mean executed and punished under these acts. So creating another law or act for this mean we feel uh right now we can rely on the existing

laws even for the defect defect is a crime when it whether it is done using AI or not using AI it's it whether means it is always a crime and we already have provisions in our acts to prosecute any

anyone who is guilty for that. So but we are also open in future that if required we can come up with that but right now we we do not feel we are at that moment to maintain that balance of innovation

and to prevent the user harm. &gt;&gt; Thank you. I think uh can we take one quick question only one? [laughter] &gt;&gt; Okay. Please, please quickly.

&gt;&gt; Yeah. Uh my question is to Sridar. Uh first of all uh thank you all for it's a great session and uh very informative as well. My name is Ankita. I'm doing my masters in cyber security and as you

said uh having standards uh sector wise like vertical uh approach on building uh these uh standards and you also said another thing that for India it's a diverse

country so we should have standards according to that what do you think would should be the approach of uh the government considering that we are already late and we als also have

quantum coming uh in next few years. Uh what should be the approach right now according to you? &gt;&gt; Yeah. Uh uh a quick uh you know I mean thought that's coming in my mind is I

think we should have uh you know uh a way to configure context specific standards. So like you know the governance guidelines that are generic versus you know the cyber security

related or IT act or other acts. So what I mean like you know it's it's really hard to implement all of that for every product but what I would say is like uh you know we have to create a context and

create a configurable you know uh standards or like you know guidelines that are related or specific to to that. So I I think you know if we can come up with a a framework where we can

configure the existing guidelines or standards that are specific to a particular domain. I think that could be a potential &gt;&gt; our time is already up for the next

session but I would I just &gt;&gt; on that part I can I would like to add one more thing. &gt;&gt; We can discuss offline like we can ask because the next session is there.

&gt;&gt; Yeah. Just want to add one more thing. uh in the the AI governance guidelines they are talking about like the overall approach they do not talk about the sectoral regulations or sectoral

guidelines and guidelines says that they should be taken up by the sectoral regulators and if you see over the period of last year RBI has come up with their own guidelines for the financials

se has also come up with their own guidelines similarly CCI has also come up with the report so the the mighty or One agency in the government cannot define the complete guiding structure

for everything and we are also envision in the governance guidelines about the risk framework about defining the risk of the application so that accordingly guidelines can be defined sector to

sector because all means uh every we cannot compare each and every sector at at a same stage or at the same level. I would like to stop uh like at this point of time and thank all the distinguished

panelists for their valuable insights and also to our audience who is very eager to ask so many questions but I'm very sorry because of the time limit and uh thank you so much for this important

conversation which was really engaging and we'll be happy to answer your questions offline like outside this hall. &gt;&gt; Thank you. I thank all the speakers. To

express our appreciation, we would now like to present momentos from BIS and mighty to our esteemed moderator and panelist as a token of gratitude for their valuable contribution to this

discussion. For that, I would like to invite Mr. Jatendra Kumar, scientist E and head from LIT Bureau of Indian Standards to present the momento to Dr. Shrar Chimalandha.

to Mr. Rohit Isani Miss Gayatri Kamaram Mr. Tim Maggar Mr. Abishek Agraal &gt;&gt; and to our moderator Mrs. Reina G.

&gt;&gt; Now I I would like to request Mrs. Chhattis BLA member security of AI committee for the vote of thanks. &gt;&gt; Thank you Kavita. Uh I would say uh that was a wonderful session with all the

relevant speakers. uh panelist that we have and specifically I would say the session has uh bring out the point of that assessment and conformity assessment should be continuous and the

standard that ma'am was mentioning about is the 42106 standard that is
