# AI-DPI Experimentation and the Role of Sandboxes

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 8 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/0td8ZW9JUog?feature=share) |

## üé§ Speakers

- Adesh Khadka, Ministry of Communication and Information Technology- Government of Nepal
- Adesh Khadka, Ministry of Communication and Information Technology- Government of Nepal
- Alexandru Oprunenco, UNDP Asia-Pacific
- Dr. Nkundwe Moses Mwasaga, Information And Communication
- Dr. Verena Kontschieder, Opendata.ch; Prototype Fund Switzerland
- Kavita Bhatia, Ministry of Electronics & IT, GoI
- Lorrayne Porciuncula, Executive Director
- Morine Amutorine, Datasphere Initiative
- Sushant Kumar, Kalpa Impact

## ü§ù Knowledge Partners

- Datasphere Initiative Foundation

## üìù Summary

This session explores how sandboxes can support safe, accountable, and trustworthy AI adoption in DPI systems. Through presentations and panel discussion, participants will engage with practitioners to examine challenges and complexities introduced by AI-enabled capabilities in DPI. The conversation will focus on how sandboxes provide controlled settings to test new technologies while fostering trust through diverse stakeholder involvement. Participants will leave with practical governance insights and design principles for building inclusive and scalable AI-powered DPI.

## üîë Key Takeaways

1. This session explores how sandboxes can support safe, accountable, and trustworthy AI adoption in DPI systems.
2. Through presentations and panel discussion, participants will engage with practitioners to examine challenges and complexities introduced by AI-enabled capabilities in DPI.
3. The conversation will focus on how sandboxes provide controlled settings to test new technologies while fostering trust through diverse stakeholder involvement.
4. Participants will leave with practical governance insights and design principles for building inclusive and scalable AI-powered DPI.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/0td8ZW9JUog/maxresdefault.jpg)](https://youtube.com/live/0td8ZW9JUog?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Thank you Jodna. Hello everyone. Good morning. Before I begin, just wanted to take a pulse of the room. How many of you have heard about sandboxing? Show of hands.

Excellent. So, we can go into deeper discussions. How many of you have heard about DPI? That's great. Almost everyone. And how many of you have heard about AI?

Okay, everyone. Great. So, looks like we have a room full of not just enthusiasts but people who are really aware and uh are looking to go deeper into the discussions and for that we have a very

esteemed set of panelists who bring in not just different perspectives but also deep experience of implementing digital transformation in their own country and that's a privilege that we have for

today. I am Susant Kumar. I'm the founder and CEO of Kalpa Impact and it is a privilege for me to moderate this session today as part of the India AI

impact summit. As you all know and you've raised your hand as well, digital public infrastructure is the foundational layer for public service delivery and it has

been transformational in reaching citizen services to billions of citizens across the globe uh not just in India. And now with the AI capabilities which are getting integrated or the

governments are looking to integrate AI capabilities into the foundational layers. We are navigating complex questions around governance, institutional readiness, trust and

accountability. And you may have heard this digital transformation progresses at the speed of trust. If citizens,

governments, civil society do not coordinate and there's no trust uh digital transformation could stall or even be a failure. And therefore in this session the role of experimentation

including with technology with policy regulatory and technology sandboxes. How do we utilize those to enable safe trusted and responsible AI adoption within the large scale DPI systems which

are operating at population scale. We are building off our discussions we had at the presummit event with sandboxing where we received tremendous outpouring of interest and that has translated into

our uh uh partners and my old friend Lorraine putting together a detailed report which will give you an insight into uh you know how to think about experimentation, how to think about

sandboxing as well and we will come to all of that and we will come to uh you know the report launch and a speech by Lorraine. However, for today what we want to begin

with is something important. We have amongst us uh Shrimati Kavita Bhya G who is scientist G at the Ministry of Electronics and Information Technology. She is also the chief operating officer

of India AI mission. She has been a lynchpin, an anchor of several initiatives across DPI and now with AI that India has witnessed and we have all been privileged to see her

contributions on national initiatives such as mobile SAR enabled services which is the digital ID enabled services single sign on frameworks and standards for digital

governance and payments. So what you will hear about is from Miss Kavita Bhartya her experience of linking sandboxing prototyping experimentation in technology at a scale which serves a

country with 1.4 billion citizens. So without further ado may I invite Miss Kavita Bhya for her keynote speech. [applause] Thank you all.

In fact, uh it's been a very busy morning for all of you and uh I've been seeing lot of people attending lot of sessions. So distinguished colleagues, partners from data spear initiative,

Kalpa impact, UNDP, fellow government representatives and all participants, it's my privilege to address this panel today which is having a high and key prof

which have key speakers which you will be hearing just after a few minutes uh discussing about the uh DP API and the AI integration. So basically when the government goal uh global community is

actively shaping the future of AI and API this is a very important thing. So we need to very look into lot of things uh which are critical for the success. I would just wanted to say that India's

journey with DPI through the platforms like Aadhaar, Unified Payments, Coo and a broader India stack which uh just now has been mentioned has demonstrated that at population scale India can do digital

systems which are inclusive, interoperable and innovation friendly because the proof is being shown that the entire population some way or the other is connected and using like the

payments um in India we have QR code uh code payments we generally try and not to carry cash and it's very easy to have a digital and this is also one of the success story of the DPI the systems

have not only enabled service delivery but also catalyzed priv uh private innovation improved transparency and strengthened the citizen trust and when in our country when we have uh success

of any solution that is only because the citizens have lot of trust. So today we are actually standing at the intersection of DPI and AI. AI all you know is a new layer of a capability

predictive intelligence adaptive system automation at scale. In fact government is also want uh building this layer on top of DPI because then the government will become a proactive government

rather than asking the citizens to seek for the service. it will proactively give the service. But this layer also has a complexity. When AI is embedded into the DPI, the implications are

systematic, bias, opacity, data, governance, risk, accountability, challenges can uh scale as quickly as benefits. In fact, that is the discussion I heard that you will be

having after a few minutes. This is why the theme of this session is basically very important. AIDP experimentation and the role of sandbox is both timely as well as essential for global majority

countries. AI powered DPI offers a transformational possibility which will enable uh smarter welfare targeting which I said that the governments will become uh proactive realtime public

health surveillance. We can in fact identify where a pandemic is coming and we can take a proactive steps. Adaptive learning systems in education, precision agriculture and climate resilience and

efficient governance um uh redressal and public service delivery. However, these opportunities come with structural constraint, uneven data quality, capacity gaps, procurement rigidity,

regulatory uncertaintity and trust deficits. In such context, the experimentation is not a luxury, it's a governance necessity. So for the government of India's perspective,

regulatory and sandboxes serve very critical and have three uh functions which need to be looked into. First the controlled environment because the sandbox will allow innovators and the

others to test their solutions on a real data so that we will know what exactly the results are going to be. Second risk anticipation and mitigation. This will also make sure that whatever the

algorithmic biases uh are there they will be um known before it is actually uh sent on a large implementation. And third iterative governance because this also is a very important that we will be

able to get the feedback which can be incorporated into the solution and final output is what is desirable for all and will make sure that we have inclusion with the solution. So India experiments

um experiment with the fintech solutions digital health pilots and open network experimentation has shown that the structured experimentation reduces uncertaintity and will preserve the

innovation velocity. So as we advance today's agenda which is again built on the three principles humanentric safeguard interoperability and standards open standards because we believe that

the standards should be open and the solutions should be interoperable and third capacity and institutional readiness. So this is also very important that the policy maker the

technologist and the frontline administrators must learn through this experimentation. So with not taking much time I would also mention that today's panel will build on the AIDP sandboxes

presummit dialogue which was held in December. It is encouraged to see that many governments are sharing practical lessons. If we experimentation uh if we experiment rightly we will not merely

deploy AI AI in DPI. We will shape the trustworthy AI ecosystem that strengthens democracy, enhance public value and build citizen confidence. The future of AI power DPI must not be

accidental. It must be deliberate, principled and collaborative. India stands committed to the working with global partners, global de glo governments, development institutions,

innovators, civil society to co-create frameworks that ensure AI remains safe, trusted and inclusive at scale. In fact, we have already launched our AI governance framework. It's a framework

now we have to build on top of it. So we are very um we would be welcoming all the researchers to come forward or the innovators to come forward and tell us how the risk assessment frameworks and

methodologies should be built on that framework. So I look forward to the insights from this distinguished panel and the collective visions in this room. Thank you very much.

Thank you so much ma'am. That was uh really helpful in setting the context extremely clearly and that uh sets the task for us in terms of uh uh the panel discussion as well. With this we'll be

moving now to the launch of a short video from the datasphere initiative from my dear friend Lorraine. This captures the insights from the ongoing work on AI DPI experimentation and use

of sandboxes across different regions. So, please allow us a minute as we set up the video. And here you go. I hope the audio works.

&gt;&gt; Hello everyone in New Delhi. &gt;&gt; I wish I was there with you today. I can only imagine how exciting must be with all the buzz of the AI world converging in India. Uh if it was not for the fact

that I just recently had a baby, I would not miss it for the world. So I hope you waste a video of me instead. Before anything else, I wanted to compliment the panelists and the co-organizers UNDP

and Kalpa Impact for their partnership. Our journey started a while back and in fact our exchanges led up to a presummit dialogue convened in December last year to address the theoretical foundations

of digital trust. That session was a key moment to explore how countries can responsibly design, test and govern AI powered digital public infrastructures. And we had three takeaways. First that

AI and DPI must be understood as an interconnected infrastructure. two that trust building and meaningful inclusion are foundational for this process and for these infrastructures and three that

experimentation and integration must become the norm. It was also clear that countries across the global south are already pioneering innovative governance models and scaling these efforts will

require long-term investment in institutions, skills and civil society engagement. So it's deeply symbolic that we are gathered here in New Delhi within a nation that was largely responsible

for coining and spreading internationally the concept of DPIs and by hosting this summit the first one in the global south India continues to lead the way providing the definitive context

for our discussions today. So why does the nexus between AI and DPI matter? As we witness the rapid integration of AI capabilities into national identity, payment and data exchange layers, we

face not only gains in multilingual interfaces and predictive analytics, just to mention a few, but also increased complexities that can amplify bias, opacity, and exclusion across all

downstream applications if left unchecked. Because API carries higher stakes than sector specific systems, its design choices can affect millions of people.

And to navigate these risks without stiffly innovation, we're calling for the use of DPI sandboxes as controlled and inclusive environments for co-creation. Sandboxes can be what we

call laboratories of trust. When done responsibly, they can serve not only as technical testing grounds, but as levers for trust. by testing solutions and preventing silent failures there where

technically functional systems quietly harm human rights or exclude marginalized groups. Sandboxes cannot resolve all governance challenges. But we have found that experimentation

grounded in iteration, transparency, and collective learning can and should provide a structured way to surface tradeoffs, test safeguards, and generate actionable evidence on areas for

improvement before and after rollout of DPIs. That is why it is my pleasure to launch today our most recent report, Sandboxes for DPI, co-creating the blocks of digital trust. This report

represents the first global effort to investigate, document and systematize this nentude of the intersection between sandboxes and DPIs. And we do so by structuring this reporting to three.

What are sandboxes for DPIs? Why do sandboxes for DPIs? And where can we find them? I should also note that back in 2022, the Datasphere Initiative was the first organization to establish

a taxonomy of sandboxes. And today we have used the occasion of this report to revise our definitions and frameworks and sharpening the distinction between regulatory, operational and hybrid

sandboxes while also proposing the first ever formal definition of DPI sandboxes. Our definition which you'll see in the report focuses on initiatives specifically designed to test

technologies or governance arrangements within the three core layers of DPI identity, payments and data exchange. It is also building on this definition that we move beyond theory and provide the

first global map of DPI sandboxes. This is the where despite this being a nent field, we have identified 16 pioneering initiatives. From the other sandbox in India to the

European digital identity wallet, these cases have mapped that we have mapped reveal some key insights. First is that feedback loops and institutional learning are features of

successful DPIs that DPVI adoption depends on trust and that we are seeing hybrid models of sandboxes emerging in the context of DPI.

We also see that testing is typically done upstream from the foundations up and among the cases analyzed we see more prevalence of DPI sandboxes and ID systems followed by data exchange and

payments. We also conclude that investing in DPI is dependent on the delicate equilibrium of balancing the opportunities and risks of global markets and digital

sovereignty. And that adds to the argument of moving DPI development away from rigid implementation and towards systems that are iterative, inclusive, and responsive

to the people they serve. Our recommendations point to the need of treating sandboxes for DPI not only as oneoff pilots but as institutional capabilities necessary for governments

worldwide. Ultimately the question facing DPI is not whether experimentation is needed but how it's carried out and to what end. I want to finish my intervention by

stating that our commitment extends far beyond today's launch. Throughout 2026, we'll transition these findings into a practical how-to toolkit to DPI sandboxes and launch a dedicated track

at our sandbox summer school in Disbon. I invite you to join us by downloading the full report in our website and exploring our global inventory of case studies. Let's us use these laboratories

to co-create a future where digital infrastructure is built on inclusive and responsible foundations. Thank you so much for your attention. I wish you a great panel today and a

summit throughout the week. Um, in order to facilitate the launch of this report, can we please request all the panelists to come forward for a picture?

Thank you. Can you switch Can you switch to the presentation? This what you see here, this what you see here is the QR code for downloading

the report and I hope it's uh visible to everyone and you are able to scan the code and download it. Yes. And we'll put this up uh at the end as well. Um now without further ado let

me transition to the next segment uh of our session today which is panel discussion and uh the first panelist that we have u may I request Mr. Adesh Kartka to join us here

on stage. Please give him a big round of applause. And as we speak Dr. Nakund Moses has perfectly timed his entry and he's joined us for the panel. I hope it

wasn't too much of a trouble finding this room. &gt;&gt; As long as we have you here spot on time. Thank you so much for joining us. Please join us here. Um there's a chair

for you. And uh next I would like to call upon uh Alexandro Opruneno. He's the team leader of innovation and digital Asia-Pacific regional bureau. uh UNDP

may I now call Moren who's representing the data sphere initiatives. She's the Africa sandboxes forum lead from the data datasphere initiatives. [applause] We have Dr. Vena who is

co-CEO of open data.ch in Switzerland. She's program lead for prototype fund Switzerland. And uh it will be my pleasure to moderate this discussion today. Looking forward to it.

&gt;&gt; Check great. Dr. Nakuni, I have uh the first question set up for you and we were waiting with our uh uh holding our breaths that we

will have you here and we'll begin with the first question. I think the first time we met Dr. Nakunve was uh for the discussion on jummy stack. &gt;&gt; That's very correct.

&gt;&gt; That's very correct. Yes. So I have had the pleasure of discussing Jami stack in Tanzania Jami number the ID payment systems uh that Tanzania is rolling out and therefore uh Dr. Nakunve we would

love to hear from your experience of rolling out some of these foundational elements of DPI but also now that there's discussion around how do we integrate AI capabilities into it. So

talk us through two things. First tell us about the state of play of digital transformation in Tanzania and then uh do inform us about how you're thinking about sandboxing prototyping with AI and

&gt;&gt; Uh thank you very much. It's a it's a very good question. Um like the way I've been introduced I'm the uh ICT commissioner of Tanzania. So I look at the all the things digital

transformation for our country which our journey started in 2003. The way we look at digital transformation we look at at is um it is a third level of how to transform the

economy to be digital. That is you start with digit digit you digitize um the data you create the system and then level two is digitalization and then the last phase

is a digital transformation itself. Now why are we doing that? We're doing that because we want to accelerate uh transformation for our country so that we'll achieve what is in vision of

achieving personal governance and in the personal governance we need to use AI but we do understand that AI needs three things to be available to any economy. One is data

two capability of computation and strong algorithms. This is how we we see it and from the point of view of Tanzania is we see that we need to build those three capabilities as quickly as possible.

That's where the DPI is coming through and our experience of the DPI is of course uh we we do understand that there are levels on how uh we can transform and start to get get benefit of all

these things. When we started this journey, we started with u um policy documents and strategies on how to build digital infrastructure and is the digital infrastructure. We do look at

two things actually hard infrastructure and soft infrastructure. Then uh where we are now we are building the digital economy. But the the goal of where we see is to create digital

society that is a society that is consuming all these technologies in the digital in a seamless way. Now in doing that Tanzania I have created um digital ID number we have dubbed it as Jam

number. Jami means society. society number is a number that is going to convert the population that we have to have digital population. Then um there is a interoperability bus

of the country where at at current moment our government uh is having more than 800 systems that is deploying to all the people. So we want all these systems to be able to talk to each

other. So there is a bus uh for interoperability also we dubbed it as jam jam bus. And then the final thing is uh to having instant payment system

that will enable um our people to be able to perform transactions seamlessly um just like the way ED have been able to achieve that. We look at that things because we know

that it's going to solve one critical problem or I can say challenge that we've been having in our economy informal sector the informal sector which always grows. So we believe that

by providing digital ID number making all the system to be able to talk to each other we are able to convert the informal sector to be formal. Now where the entrepreneurs or the

innovators are going to sit they're going to sit on top of the uh the DPI that we are having and we believe that by achieving um personal governance system that is using AI to be able to

provide personalized uh services to our people. there will be limitless opportunity for um entrepreneurs um and all the other people that they in the entrepreneur ecosystem to be creating

all the system that they want. So this is this is where our our journey is. This is where we are and that's what exactly what we are looking for in our country. Thank you very much.

&gt;&gt; That's so fantastic Dr. Nakun to hear from you and uh just to remind the room that Dr. Nakundi is the director general of ICT commission of Tanzania and he holds a broad scope on delivering

digital uh transformation for all of uh Tanzania and that's it's so useful to hear his perspectives but I have a rapidfire question for you as the director general of ICT commission and

it's a rapid fire question. &gt;&gt; What are the two challenges that you feel like are holding you back? Well, because you know from the way we look at uh digital transformations for

our country, we look at five pillars and five pillars are the one that they provide challenges but it's something that we are working on it. One is to provide digital skills for everyone in

Tanzania. You know our population is 62 million. Uh there are people who are not computer savvy. We just want them to be able to use all this AI system that they are variable. So providing the basic um

digital skills to everyone is one of the challenge but we we are trying to tackle it. Um there's a challenge of digital security and trust. Um digital security is about cyber security. Everyone knows

about it but our people need to understand because they'll be interacting with all these platforms that we have. But in the trust is protecting the personal datas for

everyone. The issue of p privacy and also the issue that has to do with consumer protection. And then there is a telecommunication services so that it can re they can reach everywhere

especially in the level of 4G if possible and and 5G the digital uh economy itself and also the digital security uh innovation and entrepreneurship. So those five pillars

are the one that we are working on. It's a challenge but it's a challenge that we are tackling at the country. &gt;&gt; Fantastic. You did mention trust and that's a thread throughout. Miss Kavita

Bhartya also mentioned that as we scale citizen services at population scale so do the challenges around cyber security, privacy, data protection and therefore the context of this conversation becomes

all the more important. And then I would want to come to uh Mr. Adish. Adesh uh is joint secretary for uh the ministry of technology in Nepal. So we're getting the second government perspective in

here. Uh so Mr. Adesh my question to you is uh uh you know related to your experience in uh Nepal. When you face the pressure to deploy AI solutions because of all this buzz that

we have around you must be feeling the pressure to deploy AI solutions and quickly. But how do you ensure that the institutional safeguards, the regulation, uh all of this is in place

so that you can protect for you know the harms that would scale uh as quickly as the benefits. &gt;&gt; Thank you Susan and uh very rightly pointed out uh and I think it's a crux

of the problem across all the government uh agencies. uh when there is a innovation and especially the innovation of the scale of AI uh we generally see two faces of or two parts of the

government itself uh the one part it's more on the promotion of the uh technology promotion of the innovation how do we uh set up the startups how do we set up the ecosystem for the startup

but at the same time there is another face of the government more traditional more uh into a regulatory framework and who would be like how do we safeguard the the the actual things uh the core

trust of the uh citizens the core trust of the market. So uh this is a very very fine balance that we have to walk at this point and um very beautifully pointed out by the Lauren in in the

video the all the aspect of how where uh how and where we have to be careful on uh doing this in the Nepalese context. Uh there are uh there is the national ID uh as the DPI part and most of the uh

citizens has been enrolled in uh in that uh national ID. We have a very good uh private sector uh working on the digital payments. Uh as of today we lack the very uh elaborate data access platform.

Uh there are few uh um the technological shortcuts for the uh data to be extensed but then we lack uh the data accent platform and uh as a country we are planning uh on this uh the complete DPI

transformation. At the same time uh we have also introduced the AI policy at this point and that policy clearly mentioned that we'll be using the sandboxing. So I see two point at this

uh at this uh time of u you know this um the technological intervention. One is how do we improve the capability and capacity at the regulators the the agency that regulates they are they

aware of the risk and the technology that uh the people are uh the the innovator are trying to experiment and at the same time how do we introduce this acceptance of failure because these

these are the experiment at the end and there could be a failure there could be some kind of a problem that are introduced by the technology and how do we make sure that the traditional

regulator have these vision that this might fail and how do we accept it. So these are the two big question that we are facing at this point. Uh other I think it's very work cut out for me by

the Lauren. &gt;&gt; Thank you. &gt;&gt; Fantastic. So good to hear those perspectives and uh my good friend Alex you have an Asia-Pacific perspective on

innovation digital DPI AI. when you speak to governments such as say in Nepal or in Tanzania, what is the big question uh they ask you or what is the big surprise you face and within that

context tell us about when you think about and bring in sandboxing and experimentation um as a recommendation to these governments.

&gt;&gt; Yeah, thanks so much Sashan. Perhaps uh I will take uh where you finished uh because recently we just had a request uh to support an AI sandbox. Uh and uh my big first question was about what is

actually your use case and that unfortunately drew a blank face uh from my counterpart from the government. Uh I had another meeting around um AI uh application service

delivery. My question was what is your use case? Do you have a problem statement and again a blank face? So and that uh once you uh see the pattern across you understand that there is

something is missing in the conversation about AI and DPI uh in in the government and in the service delivery and I would say there are three big questions where we try to draw a discussion uh with our

counterparts. Uh the first one is why right and uh uh this thing I kind of wonderfully uh picked in Cape Town uh when we were part of the conversation with the Indonesian delegation with

Nandan Nilikani the architect of Aadhaar uh where he started why DPI was introduced in India because uh they wanted to to cut uh leakages in public programs and they wanted to improve

financial inclusion. uh when you start discussion around DPI in many countries they cannot say uh they discussion falls immediately into the three building blocks and whatever

might be required for that uh without uh actually saying to what extent DPI and AI should be speaking to the policy in ter of the government where the government wants to drive digital as an

enhancer of development trajectory so that's the first question the second question which is really important is for whom DPI and AI is for whom? Uh is it for

private sector? Is it so that people in the government feel better about what they do and need to spend time less time on something or is it about the people for whom the services are delivered? Uh

and again I will not name the country. Uh we had a conversation about a super app uh that in a way sits on the top of the emerging digital public infrastructure. My question was what is

the perception? what is the feedback from users on interacting with your super app and the response from the sector was oh our police officers are very happy

which is uh amazing uh right because effectively it shows the perspective often in the government is to solve their own problems &gt;&gt; it's not to solve the problem of other

people uh which is a huge gap especially when we imagine world where as Lorraine saying AI comes at the center becomes a fuel and oil for the DPI. Everyone knows right we don't point

fingers but each roll out of the massive public infrastructure digital public infrastructure has issues around inclusion uh around okay so not exclusion around missing

something around uh driving some gaps and mistakes with the eye this thing becomes like on steroids &gt;&gt; uh not asking the question for whom we are deploying a particular solution is

really important so and the last thing where I would close Sashant is uh how does it change what we do &gt;&gt; when we do that right so Lorraine was saying about talking about learning

institutions what does it mean if you look at the way how most of sandboxes and experiments are designed they're trying to work around those particular variables in terms of technology in

terms of regulations and so forth they're actually not looking at the way what will change in the relationship between different departments &gt;&gt; who work on a particular issue of the

sandbox how the institution will learn and take it to scale. So I think this is uh the third important thing to reflect together when we are starting developing sandbox because sandbox is not just a

test it's a learning experience a lab uh as as luren said so uh this is how we kind of try to drive um uh this work with the government. Lastly, what I would say and I hand over to you Sashant

is that uh what is really important is how we contextualize uh and how things are really possible to be carried forward by the people in the respective context and what I mean is

not just colleagues in the government moset or in on Mafaga right ministry of federalism but also by the users themselves &gt;&gt; will they be able to use it confidently

with trust and fast. Yeah, thanks. &gt;&gt; Fantastic points, Alex. And uh uh really you were uh pointing at some of the uh I guess reflection questions that governments should also have. And uh

I'll come back to you uh Dr. Nakon not right now. Uh first I need to get Moren and Vina have their say as well and u and uh Adesh as well. And the question will be are governments solving their

own problems and not citizens and uh whether experimentation or the learning experience could play a role on that. So we'll come back to that. But uh we've heard from the government stakeholders,

we've heard from UNDP across the Asia-Pacific who are working on live uh sandboxes. We have Moren who's leading Africa sandboxes forum and uh working not just from a civil society researcher

perspective but also what do governments need? So Meen um my question to you is when they are building foundation governments are building foundational DPI adding AI capabilities

what are the strategic choices that helps them prioritize to deliver public benefit especially in capacity constrained contexts where you don't have it all and what's the role of uh

sandboxes in such settings. &gt;&gt; Thank you Susant for that hard question. Um I think I want to first take an opportunity or rather steal an opportunity I hope it it doesn't count

to my minutes to just address something that Alex mentioned and thank you so much for mentioning the part of asking um authorities really when they are

thinking about sandboxes what is the use case I think it's something that we have noticed um also in Africa especially where I've been engaging with uh authorities from different countries

that they recognize the importance and the need of sandboxing but they have not gone to the next step of the particular use cases that they actually want to learn uh from or what we use this time

at the datas initiative is your challenge sandboxable because sometimes even what you're dealing with doesn't need a sandbox sorry about that I hope you can hear me better now so I wanted

to see an opportunity there to say that part of what we are doing in Africa now is handholding really. So if whoever you are talking to, probably it's not an African government, maybe it's someone

else, but if anyone here knows any African government that is actually looking into sandboxing. One of the things we're doing this year is what we're calling one-on-one coaching. But

it's really handholding to look into challenges that you're dealing with and see do they need a sandbox. So it's another tool that you actually need. And if it's a sandbox, how do you go from,

you know, planning the sandbox to actually executing it and evaluating it, going through the sandbox journey? Uh we have uh uh plaque cards that we will hand out for those who are interested in

actually learning about that journey. So now I will start answering your question. So let's start counting the time from now. [laughter] &gt;&gt; So it's really a pleasure to be here and

I wanted to just take a step back and start by defining a sandbox. um the way we are defining it defining it especially in our new report. So think of sandboxes if you're here and

you're wondering what we're talking about as controlled learning environments designed for structured experimentation as Alex said but underdefined governance frameworks uh

built-in safeguards and time frames. So now going to the question that I was asked about strategic choices that help governments to prioritize which AI solutions really would be valuable for

delivering public benefit. The way we have looked at it and I'm happy to note that this is something that is even covered in the report that Loren talked about is some of the strategic choices

that um authorities need to look into is contextual testing of AI together with DPI and what do I mean by contextual text testing testing of of AI and DPI. So we have learned that AI um

experimentation cannot be separated from broader infrastructure um infrastructure setups. Uh it cannot be uh separated from governance considerations but also it includes a

number of things including interoperability system performance and regulatory compliance. And so for us, we see the intersection between AI and DPI as an

opportunity to not just test AI in as in isolation, but to test it in um a context that is already set up for systems that are built to serve greater people. So that's one of the strategic

choices that we think that can be taken by people to test DPI in context rather AI in context with these foundational um systems that Loren talks talked about uh digital identity digital payments and

data exchanges and so we have already learned that this is something happening actually with um India's ad sandbox that in as much as it's set up as a DPI sandbox AI capabilities is part of what

is being tested and it is through that kind of testing that then you're able to identify solutions that are going to be um that are going to be benefiting the public. Now coming to the second part of

your question um which which ideally is asking about how to deal with risks and harms. I want to start by painting a picture of the kind of risks that happen when AI is

integrated [clears throat] with DPI. again just in case someone here is wondering. So when um imagine when AI is embedded into core DPI functions but then these digital identity or payment

systems um have been set up with say some biases. So that means AI is going to be using data that is based on a system that already has biases. So you realize that now the challenge becomes

foundational. So the risks that uh come when AI is um when DPI is powered by AI are actually very costly if I may use that word especially if they are caught after implementation

because that's a whole DPI layer that is powering AI that is now going to cause harms and um and all the risks that you can already think about. So what sandboxes we know

help in addressing this is that they allow governments to invite in stakeholders. One question that we usually get is what makes sandboxes different from say any

other collaborative tool or rather any other experimental tools that can be used for say testing emerging technologies. And what we know for sure is sandboxes are one of the best tools

that create an environment where government is not just experimenting. When I say government, I mean authorities really um and regulators. They're not just experimenting

uh with service providers who will be innovators or entrepreneurs but they the sandboxes create an environment where now you can invite in civil society, community groups, academia and all these

um it it creates a structured way in which to invite in others to be able to experience and interrogate some of these innovations that are coming up. And through that is how we build the trust

that for example our keynote speaker Kavita talked about because once we're able to build the confidence of civil society and community groups into these systems then we are building trust in

the systems that are being put up. I I I know I'm doing bad on time. So I want to conclude by saying that's what happens when you make a lot of notes because I'm I'm I'm wondering what am I missing?

What have I not said? But I want to conclude by by highlighting again going back to our report and highlighting that part of what we have covered in our sandboxes for AI report is how sandboxes

help to bring out some of these issues in rights and inclusion. As Loren said, we're looking at sandboxes as laboratories for building trust. And so we elaborately really mention how

sandboxes can help in dealing with rights and inclusion issues, data and AI, cyber security and resilience, sustainability and environment and finally the crossborder challenges and

data so and digital sovereignity. So all that is what you will find in the report sort of showing you how sandbox is actually best suited. &gt;&gt; Thank you. Thank you. Thank you Marine

for that overview as well as a very exhaustive summary of what it is within the allocated time. So really appreciate that. Um now we'd move to um Dr. Vina and uh with a question that's also very

close to my heart which is how do we design sandboxes that test governance models or infrastructure as a whole? not just technical robustness but also thinking about AI um regulatory

robustness. So um that's my question to you but before you answer that I just want to remind uh my panelists that I'll come back to you with uh a question which is what is the one word that comes

to your mind after this discussion that we have gone through and it's trust me it's only one word that I want to hear &gt;&gt; trust [laughter]

Thank you Dr. Vina. Please &gt;&gt; thank thank you so much Sashant. So uh yeah I think this has also been one of my main preoccupations. How do we not just test models but actually test

models in context and for that um yeah I I do consider that question particularly problematic in the context of DPI. Why? Because DPI is infrastructure and as soon as AI enters into that

infrastructure AI becomes infrastructure. So, as Lorine said in the in the launch of the or in her in a video message, um AI all of a sudden becomes so foundational and so

fundamental to how we work and designs us as a society and us as a network. Um and I think in that in that context the the central question must be how are we not just creating models or the

technology or the business models around those technologies um that like in a possibilistic manner but how are we actually considering societal considerations and that is one of my

biggest worries because sandboxes are sometimes really used to facilitate access to market instead of trying to work out a balance of um healthy societal considerations and healthy

economic considerations and technological considerations. Um and what what do I mean by um trying to to explore in a sandbox the modeling context? I mean um you know all the

governance elements that we have been discussing for now um over a decade actually nearly 15 years in responsible AI like for instance um privacy safety oversight decision rights um

transparency fairness inclusion um to name to to name a few more and um I want to double down on that because um in my previous roles I also worked uh in tech amongst others uh and in one human

centric design approach that we that we uh ran there. Um we really saw and witnessed how organizational um incentives were really set so that models would be produced and new models

would be launched but there was much less incentive to actually investigate the models once they were out on a platform or in the product or in the service. So um speaking of use cases um

speaking of also what I heard from the World Bank the other day um on a on a panel discussion the last line of defense which should be actually human considerations and there I think we can

even learn for and I close here for DPI and AI and DPI from actually small AI considerations. &gt;&gt; So I'll begin with you in terms of our question. What's the one word that comes

uh to your mind after the discussion today? Um, &gt;&gt; okay. Maybe you can take your time. Alex is ready. I have it with his one word.

Okay, &gt;&gt; I'm ready. Um, experiment. &gt;&gt; Alex, how about you people? &gt;&gt; Uh, Adesh, &gt;&gt; should I also answer the previous

question? &gt;&gt; Sure. &gt;&gt; Okay. Uh &gt;&gt; can we just finish this one word round and then you can come back to that

provocative question are governments solving for themselves or for citizens? &gt;&gt; So word would be sustainable. &gt;&gt; Sustainable. Uh Moren &gt;&gt; I have three words.

&gt;&gt; All right. [laughter] You you've got a special pass. &gt;&gt; Okay. Um these are actually not my words. I I picked them from um Kavita. She talked about the need to building

citizen confidence. &gt;&gt; So those are my three words. &gt;&gt; Dr. Nakundi, &gt;&gt; my three words. &gt;&gt; Trust. Trust. Thank you. Um Adesh, maybe

you can uh answer that question very quickly. Um on are governments solving for themselves or for citizens? &gt;&gt; Yes. And uh thank you. uh it's uh it's very humbling question uh in a way and

uh we generally find that this is the case uh for the government also. So uh we accept that uh generally there are these uh parts uh but um again as I've already said there are always two part

of the governments that we say when we introduce the technology the one that generally introduce wants to introduce and for that uh that force the citizen the tech industry the private sector and

the government inside this employees are also the equal stakeholder. So unless you have something for their side generally technologies are not introduced. So maybe it's more on the

power play within the bigger ecosystem that we see uh that's panning out there. &gt;&gt; Thank you Dr. Nakuni. 30 seconds. &gt;&gt; Um there's four questions that I think um every government should you know sit

down and and and try to answer. One is just like what Alex said. What is the problem in which DBI claim to be a solution and whose problem is it? That's question

number two. What new problem can be created because of the solving the problem of uh introducing DPI? And the last one, who will be most harmed by DPI? If you answer those questions, you

have a solution that touchs people. &gt;&gt; Thank you so much. Thank you so much. I'm really grateful to all the panelists here for a really thoughtful very grounded and clearly you've you're

coming from u your contexts your experience and uh providing us with insights that that come from lived experience of either uh you know building for your country or you know

kind of paving the path for building for your country and we have entrepreneurs we have uh you know advisers to government so it's it's been a really really good use of our time and I think

the room will agree and with that I thank thank all of you and we will put up the report that was launched by the datasphere initiative as a QR code and in the final uh few seconds that we have

I would urge the room to download them. Um our apologies we couldn't get to the audience Q&amp;A but I hope uh you'll find the speakers outside the room and uh make sure you get your questions

answered. So with that I thank all of you. Call this panel to a close and we'll put the QR code for the report for download on the screen right away. &gt;&gt; So thank you everyone for joining us and

giving your thoughtful views on AIDP experimentation and the role of sandboxes. On behalf of impacts summit's team, we are going to offer you a souvenir with our sincere thanks.

&gt;&gt; [applause] &gt;&gt; Thank you so much. They are putting the next one. Everyone's absolutely

Can I
