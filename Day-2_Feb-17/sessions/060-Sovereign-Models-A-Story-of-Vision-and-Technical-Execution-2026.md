# Sovereign Models: A Story of Vision and Technical Execution 2026

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/1b-sjb-L-ig?feature=share) |

## üé§ Speakers

- Dr. Abhay Karandikar, Department of Science & Technology
- Dr. Jitendra Singh, Ministry of Science & Technology
- Dr. Kris Gopalakrishnan, NMICPS
- Prof Ganesh Ramakrishnan, IIT Bombay

## ü§ù Knowledge Partners

- BharatGen, TIH for IoT & IoE, IIT Bombay.

## üìù Summary

The flagship Param2 17B-parameter sovereign multilingual foundation model has been built fully in India using a Mixture-of-Experts architecture. It supports 22 Indian languages and is trained on large India-centric datasets developed under Data lakes.
Alongside advanced text models, sovereign AI capabilities are being expanded across speech models in 12 languages as well as document vision models. The event will also showcase deployment-ready platforms designed for governance, healthcare, education, finance, and cultural preservation.

## üîë Key Takeaways

1. The flagship Param2 17B-parameter sovereign multilingual foundation model has been built fully in India using a Mixture-of-Experts architecture.
2. It supports 22 Indian languages and is trained on large India-centric datasets developed under Data lakes.
Alongside advanced text models, sovereign AI capabilities are being expanded across speech models in 12 languages as well as document vision models.
3. The event will also showcase deployment-ready platforms designed for governance, healthcare, education, finance, and cultural preservation.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/1b-sjb-L-ig/maxresdefault.jpg)](https://youtube.com/live/1b-sjb-L-ig?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Europe, Japan, South Korea, Singapore and India. It connects 430 plus experts to drive innovation in AI, 6G, semiconductors and IoT etc. And uh CADC center for development of

advanced computing is the premier R&amp;D organization of the Ministry of Electronics and Information Technology MIT engaged in R&amp;D work in IT, electronics and related areas. With this

background I I invite our speakers. Uh first Vit DL. So Wit is uh director International Neurodeenerative Disorders Research Center NRDC Czech Republic.

My uh second speaker is uh Lalit Patil. He's Clara Ethics and uh Yeah. Uh, Clara, ethics and security specialist, International Development

Research Center, Czech Republic. Uh, our third speaker is uh I I'll call out. So, our third speaker is um Miss Arti Sand, senior partner ACB and partners. So I invite

you on to the DAS. So myself Romesh I moderate the session. Uh but this is not a panel discussion. This is a workshop. We will have a series of talks. At the end we will have a Q&amp;A session uh from

the audience. So myself Romesh I'm scientist F uh look after AI activities in SAK Bangalore. Thank you so much. Now I call upon uh Dr. Lalit to start his session.

Hello, good good morning, good noon, good afternoon all just we are just four and a four four and a half hours prior to India we are based in Czech Republic Prague. Let me introduce myself. I'm

Ledit Pat. Uh I'm specialized in data privacy and AI compliance in European Union and I work with CL and NDRC as ethics and security specialist. It's just a compliance guy there. Uh so I

just got this 15 minutes here. So I'll try to sum up and focus on important points from compliance perspective. Uh as I understand that uh it's it's afternoon and we all I mean uh Indians

uh we all go for lunch and for this time as well. So uh okay. uh and today I'm speaking on safe AI from cross compliance perspective. Uh cross compliance here is India and EU is the

perspective I am uh considering for this session. Uh India with uh 1.4 billion people and European Union with 450 million people. So it's a one country with four 1.4 4 billion people and it's

a union of states countries with uh 450 million people. They have dedicated EU AI act uh prior to innovations and prior to AI uh developments. Uh but we as a 1.4

billion people we don't have dedicated particular AI act. It seems like okay we we we are something okay there is a gap but it's not it's actually uh a blessing we can say it's a because uh we are

focusing more on innovation than regulation presently because if you consider EU AI act it's one of the strictest act in the world and if you consider your AI u developments or your

company to work in EU you have to comply with EU AI act with uh stricter regulations s and uh so much of compliance but uh it's actually necessary from point of view if we

develop something it has to be very safe uh especially with the AI. So considering that uh this uh I mean it depends what's safe AI for you and what's safe AI for European Union. So

there are some criteria from European Union AI act that we might consider that these are the parameters for safe AI. So it depends like it's it's solely based on risk classification. You

are a company working in India. It has implications. Your users are from union European Union. It's still you have to comply with EUI act and which makes a very uh difficult for companies to

companies uh to do crossber compliance. Are you okay? &gt;&gt; Yeah. Yeah, it's okay. So, so it start with classifying risk. If you are a company works to who wants

to work in EU and makes a crossborder compliance it starts with high-risk AI system de correct classification of systems which is high-risk AI systems limited risk

minimum risk AI system. So if you know that your system is very basic or high risk it depends and you are getting categorized to categorize for which compliance and what compliance are you

you might need to consider for your AI uh even if you do this compliance that's okay you're you you categorize under high-risk AI system such as military uh AI or AI system developed for military

or something social uh uh profiling or something. So it still fills under this uh your personal data is being shared with uh this AI system. So you need to consider that high-risk

AI system or lower risk AI system depending on it uh we the AI act is something that commissions considered very uh stricter regulations and considering that the all

of the companies in Europe are demanding uh getting extension for compliance if we consider same with India I mean we are open we don't have regulation you know uh like uh every time you use what

when we consider AI we mostly use uh Gemini chat GPT and the kind of AI models which are available like okay but there are many other things that we need to consider and nobody reads their AI

policies or privacy policy it's just very common it's very obvious that we can't read their privacy policies throughout what word by word so that's why if the regulation makes any system

or any application or any AI safe by its regulation or by compliance it's it's it's that users don't have to bother about whether it's safe or not. It's regulated by some regulation which

is very strict which is very uh reliant. So it's it's better to for rely on such uh applications. So even if it's now we the second parameter could be um risk classification if it's high we go

with the continuous risk management. Now you you have passed the system that okay it's a high risk it's a moderate or a lower risk system you still have to continue with this classification

continued for the till you are using it and till the companies are deploying it now if you're a company you're not just classified as just a company or just a AI user or AI deployer it has

classification like AI deployer AI uh manufacturer AI promoter depending on it you are making some changes into AI systems It another categorizes you into using your trademark or using your uh

system which makes it reliable that who actually is operating this and who actually deploying it. Now as I said that the continuous risk classification gives a track record of

identifying risk mitigating them and not the reduce those risk and for our use so that it get comply now for developing such AI in European

Union or any other it's like we depends on a data because all AI is based on data data which is being shared by us and data data sets that's available on public domain or is a private. So if

their data sets or these data sets are biased somehow the results are going to be biased. Let's consider we have this data that works on u how our platelets are going to increase or decrease and if

the European Union or the different race people or our Indian race people or any other if it's something bias then actually it's going to give something different. So uh the authentication of

this data set continuously uh is one of the parameter that we can consider for safe AI. Another is a technical documentation. What system you are using what detail

design you are going to detail in it. Um and risk management uh steps along with testing methods. If you cannot explain your AI system that means you know that you cannot prove it that it is safe.

Coming further is transparency to users. Uh now we are at the end of AI summit. I guess we will become with some rules in India as well that all of users or something which is created by AI should

be mentioning there like it is been created by AI. So, so this is transparency to sis users that okay what we are looking what we are witnessing what results we are are generated by AI

how they are developed and how they are you know being what purpose it is developed for and um human oversight the another parameter human oversight you develop

something AI for developing a website you develop a any application for this and you have to continuously oversight side every time you edit your prompt in the chat GPT just like putting your edit

option there and you can change that that's a human oversight anytime between the system anytime between the development if there is a human oversight that considers okay it is

safer that it is not generating something different that we want it is not if we if there is something risk we are going to mitigate in between so that's one of the parameter like human

oversight it's not just we are going to get this AI system completely automated every time in between we can interact and change according to us that's the human oversight that's one of the

parameter it is a safe AI it's okay it's okay it's okay yeah that's the last no problem yeah yeah yeah now accuracy of the AI

robustness and cyber security uh you we might have used and most of us heard chat GPT but how many of you have heard lum mobile Proton it's a Swissbased privacy

uh chatbot or or GPAI general purpose AI. So sometimes we give prompt to chat GP or any other AI model it gives some uh accurate or some results but if we give some kind of another like lumo or

any other which are developing themselves for privacy perspective and there is no uh they sometimes give okay we are not working on it like uh we can't give something error comes out

that's accuracy. So why this is important? You you're working your health data. You're using that health data or getting some outputs from these AI deployments or AI agents and you got

okay my blood pressure is just 120 but why it's showing from last day it's 180. It's generated by AI. So accuracy is more than important. You don't want to get wrong medication by when we use AI

in health sector. At INDRC, we use this health data to find uh a probable solution for Alzheimer's and Parkinson disease and simultaneously cyber security. So,

so every time I visit most of these public places, they have something uh passwords like Delhi at 123 or something kind of right everyone. But that's was the cyber security for AI just uh just

in time something uh happens like a data poisoning. uh we have these data sets and if they are poisoned somehow to get something some results which we we are not going to believe that okay these are

the data we just know the output of the data but considering this poisonousness of the data which must have secured cyber security standards which is the one of the parameters that uh we

consider for safe AI and post market monitoring so we you deployed the AI and uh even if the postark post market monitoring is very important

uh considering uh the feedback from the users, monitor real world problems and performance and take correction action where it is required. AI system evolve and monitoring is uh ensures ongoing

safety just like models we are receiving daybyday. This is uh XY Z model with another version. So these are the parameters of safe safe. There could be more parameters from AI perspective from

India perspective because uh Indian laws or Indian legal system is not very strict or lenient considering our political and personal our constitutional value. We might have more

parameters add or subtract from these parameters along with it. Now I come with now this is the first part like okay safe AI now it's a cross compliance. Cross compliance is just

you're uh it's like you're working in another country with another users for their according to their values according to their standards. So for this cross compliance it means okay we

don't have to read GDPR we don't have to read AI act it's nothing like that if it's if your company if your AI is working in any other countries uh for users we have to comply with their

values we have to comply with their acts so how can we do do these things okay is we have developed something for Indian market we have developed something for European market there could be

possibilities that some of the safety standards are different but either we have to include all of these either we have to consider only common points but that's not the situation the

situation is okay you have to comply with the EUI act then you have to comply with the all of their required procedures like oh whether whatever I mentioned for high risk lower risk and

according to we will get classified to it and make a compliant and technology standards like this so so every time I mean you're physically outside of EU or any like even they are sitting the

European in innovators they are sitting in European they have to comply with Indian AI act maybe we we might witness an AI act in upcoming years so so that's a cross compliance and this cross

compliance perspective you have something common uh safety standards that's that's the minimum that we need take and addition and subtraction to that it's a collaboration between multi-

states that we need to consider in conclusion like companies operate across India and EU must comply with relevant regulation in India and each territory and more importantly they must

design AI system that satisfy not just a cross not just their territory but it's a cross compliance so as per our regulatory standard as well uh so if we understand the risk uh use

good quality data keep humans involved protect systems from misuse and keep monitoring performance uh we can create AI uh that people feel confident using and that's the our uh that's our line

for this AI summit as well like welfare all happiness for all yeah I think I okay um I'm I'm done with this uh presentation in presentation is mostly like okay uh it's the same what I

mentioned I forgot to slide slides it's cross compliance technical meaning which which is some of the gray areas some of the considering data law we have different data law now we are getting

compliant with the IT act with just 66D 60D and uh with rules from the AI uh we are just relying all there but it's okay we are we are innovating and for that we have this sandbox that world can

consider okay uh I think I'm some Okay. &gt;&gt; Uh thank you Lalit for discussing about uh the complaints part. Now I invite uh Vid Dol Dr. Vid DL so to discuss on uh

AI safety especially with a perspective on cross compliance uh Indo and Europe. &gt;&gt; Thank you very much. So ladies and gentlemen, good morning.

I'm very happy to be here. I'm happy to be here actually and I'm very thank you Romesh and CDC team for organizing such a important event and I also thank Indian government and

his excellency prime minister Modi for organizing AI summit which is very important and uh we are participating there also in our booth. So if you want to see check boot in expo you are

welcome to come to hall six. My name is Vid Duchal. I'm uh my background is law as well. So I think it's a be session of lawyers. That's great. And let me please uh give you some onsite of our projects

and how we actually are ensuring u uh trustworthiness of AI systems. Let me speak first about Clara. Kalera is a center of excellence funded by uh European Union and Czech state by more

than 43 million euros and we are trying to make a benefit of emerging technologies uh not only a IML but also large models and uh uh HPC and quantum computers as well to understand things

and aspects which actually we couldn't understand before because we didn't have these technologies in our hands obviously. when the chip was released, you know,

2022, I guess. Yeah. And first quantum computer in Europe, I'm not speaking on the IBM's one, but at least the academics ones, they were actually installed last year. So now we have

these technologies in our uh in our hands and we can try to understand very very different aspects very complex aspects multimodal nonlinear aspects in our brain within with within the scope

of these technologies which is great but we should not forget the compliance side because if we are trying to understand the processes to understand why neurons for example are not living for more than

100 years although they are supposed to live for 100 years and why other cells for example which are supposed to die like cancer cells are not dying we need to understand the optimal performance of

the system at the cellular level and understand more the signals signaling uh silver cell signaling pathways therefore we need to use very large amount of data which means privacy which mean

compliance At least from the perspective of lawyers, but actually in Europe and I believe also here in India, not in not in all countries in the world, but we

agreed in Europe and in India, the technology goes hand inhand with trustworthiness of the system. January 22nd in Prague, we organized a official pre-summit event

uh which was actually acknowledged by AI summit AI impact summit India and you might see that also first secretary of the uh Indian embassy in Prague was visiting this event because actually

it's very important to discuss how to ensure the transportiness of the systems even in the development even in the research as you know AI act it's applicable for um technologies which are

entering the market but if you are doing errors within the innovation or bias or something you could never ensure the trustiness and AI act compliance when you are entering the market so we need

to think about that well advance although it's not applicable at that time but it will be applicable so we need Don't think about that right away. So actually there are two main questions

when you are dealing with AI systems in in healthcare at least in Europe. It's not only about AI act, it's also about medical device regulation because AI system is a medical device or could be

understood as medical device. So the first question if you are a developer of such a system serving uh the clients in EU is whether there is the applicability of medical device regulation MDR

because if it is then you need to do more paperwork. Then the question is the second question is if it is applicable MDR then how do you

set your metrics to validate the transport how do you assess the transportance what are your metrics bias detection you know accuracy how do you how do you actually prove the regulator

and notified body that uh it's it's explainable and it could be used so we actually develop and discuss and Actually at that meeting there it was public bodies or public authorities

there uh notified body the check methological institute it's it's a it's a body who's actually putting the the approvals. So we discussed the four layer framework how to define uh this

let's say process even in the research and innovations period. The first is some kind of due diligence you know premarket validation. It's a kind of due diligence to risk risk assessment risk

classification both things what valid actually was explained. The second is that you need to track the process the workflow because you know there is a lot of

aspects in the workflow cross-sight compliance must be assured during the whole process. So you have due diligence, you have the process workflow assessment and then you have to assure

that it's actually valid across the time because some data are longitudinal. So it means that you actually the population changes you know and and and it should be actually validated across

the time as well. And last but not least is the human- centered validation because uh you know who would be liable when errors occur you know so what would would your physician said oh sorry I did

bad medication because the system no it's always about the human and uh you might not know but in some cases we go even beyond the AI act with respect to ethics which is called digital humanism

principle. Because the statement is that that actually we are failing. We are failing because the technologies sometimes you know um are in front of us

sometimes but we cannot fail and the digital humanism principles was signed five years ago in poorf in Austria also by the Czech Republic and and it was acknowledged not only by European

commission as a driving principle but also UN United Nations. So it's not an act, it's not a regulation, it's an ethical princip. Uh

big data needs big processing capacities. So I'm very happy to announce that very soon May 1st we will launch AI factory um AI factory project. It's 40 million uh investment

40 million euros investment for three years to support AI services in Europe. So imagine you have a spin-off company or a startup and you need AI service some maybe

experts from university uh that will help you with maybe validate your language model and you need robust processing uh robust computational power. You just call us you go and you

get it. Of course you there must be it must be a good success story. It doesn't it's not for all but for great ideas but you basically receive this service for free.

INDRC uh is responsible to provide to be the entry point for AI services in healthcare and biotech and Czech technical university which is my second

affiliation is for uh advanced manufacturing industrial AI services. Moreover, uh INDRC with with kind help of lit is actually the entry point for startup

support, business development and legal and ethical uh um services. So one question to you, how you know innovators from India could have access to these services?

You know European Union and India signed the landmark agreement, the trade agreement just three weeks ago and we need to implement it. We need to

accelerate the business and we have tools to support it. And this is my last slide.
