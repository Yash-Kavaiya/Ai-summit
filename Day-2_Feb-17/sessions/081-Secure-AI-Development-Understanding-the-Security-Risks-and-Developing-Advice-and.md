# Secure AI Development: Understanding the Security Risks and Developing Advice and Global Technical Standards

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Sushma Swaraj Bhawan | Nalanda Banquet |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/KLMJmJJpBrg?feature=share) |

## üé§ Speakers

- Mr Oliver Brooks, UK Foreign, Commonwealth & Development Office (FCDO)
- Mr Oliver Jones, UK AI Security Institute (AISI)

## ü§ù Knowledge Partners

- British High Commission

## üìù Summary

Discover how the UK Government is working with global partners to understand the risks and shape the future of secure AI. The UK AI Security Institute (AISI) will introduce the key findings from its Frontier AI Trends Report. The session will showcase the work of the UK government, including the NCSC, to collaborate with global industry, governments and academia to produce security requirements and drive the development of the world's first global AI security standard.

## üîë Key Takeaways

1. Discover how the UK Government is working with global partners to understand the risks and shape the future of secure AI.
2. The UK AI Security Institute (AISI) will introduce the key findings from its Frontier AI Trends Report.
3. The session will showcase the work of the UK government, including the NCSC, to collaborate with global industry, governments and academia to produce security requirements and drive the development of the world's first global AI security standard.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/KLMJmJJpBrg/maxresdefault.jpg)](https://youtube.com/live/KLMJmJJpBrg?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

uh we work with our international counterparts and not just those that are in North America and in Europe. We also work with a whole variety of partners all across the globe including global

south which is one of the main reasons why I'm here. Um uh um we also work with the academic sector as well. So, universities, research centers, think tanks. Um, and we also work with just

the general public as well because actually ultimately the end users of cyber products, digital products are the public and they need to be informed about what we're doing and we need to be

aware about what issues are coming up when they're using technologies. And it should be said this relationship, it's not a linear relationship. It's not just us providing that advice to uh to all

these different stakeholders. These stakeholders are providing advice to us as well. We are getting information from them um so that we can provide the best possible advice so that it's practical

and and realistic. So in terms of actually what we do, we work to understand the evolving cyber threats. We develop cyber security mitigations and publish uh advice and guidance. Um,

and we reduce risk by securing and improving the resilience of both public and private networks. And if all goes wrong, if it all goes pete tong as as you would say you say in the UK, you we

also help to respond to significant cyber security incidents as well. [snorts] [clears throat] So in terms of technical standards because

this is what this kind of presentation is going to be kind of really focusing in on in terms of the work we've been doing to develop a technical standard. For those that don't know technical

standards because not many people do. It's quite a niche area. I will try my best to explain what a technical standard is. Ironically, there is no standard in how a standard should

look. Standards can look in a variety of different ways and they are developed in a variety of different ways. But in a very basic way of explaining it, a standard describes a good practice in

how something you know a technology piece of software um uh some sort of digital technology usually of how they are designed and developed and deployed when uh when when when being used.

So standards are useful for compatibility and not interoperability reasons. It's the reason why we can um we can call uh to different network operators. It's the reason why we can

make phone calls to different countries. It's the reason why our phones work in different countries. Admittedly, usually at higher cost, but the fact is that they actually do work. Um and it's the

same across all digital services, all across the internet. Everything works purely because different companies that have different IP and different technologies all are working together

using standards. So that is the fundamental reason why standards are actually good. They provide the underpinning. They [clears throat] also accelerate

innovation. And then why I particularly care about it from a from a from a kind of a cyber security perspective is that they actually ensure that products and services are performing safely and

securely providing at least the minimum baseline security standards that we would expect to keep users secure. &gt;&gt; [clears throat] &gt;&gt; Um

uh uh so standards are mainly developed through an industry-led multistakeholder process based on consensus, openness and transparency. Um and then they are usually not always

admittedly but they are usually developed in in what is called standards development organizations STOs or you could just call them standards bodies themselves.

And so these are what the these are a small handful of standards bodies or SDOS's that we work in. The ones on that on on this graphic here are the ones that we from UK government typically

tend to engage in. It is a proper alphabet soup. There is lots of acronyms there and it can be quite complex. They all do slightly different things. They all work slightly differently. the the

um the standards bodies highlighted in yellow are the ones that we in the UK government typically work in. So there's ISO. ISO is probably the one that is very well known to most people if you

you know if you're if you have a fairly basic understanding of how standards work. ISO is the one that you might recognize. That's the international standards organization or maybe or

international organization on standards. I think technically how that operates is every country has a national standards body. In the UK it is the British standards institute BSI and

you form a delegation a group from your own country and you uh you you develop standards within your own kind of country and then you take that up to ISO um and then it is agreed on a consensus

base across different nations. &gt;&gt; There is also the ITU, International Telecommunications Union that is a UNbased uh standards body. So it's attached to

the UN. The [snorts] ITU is very different com uh if you compare it to other standards bodies where the the the delegations the work is led by

governments where different standards bodies it is led by industry. industry are the one who are developing the standards where government is supporting in other standards bodies where the ITU

it works the other way around where governments are leading the development of those standards with industry supporting. [clears throat] We also do work in those

other um uh yellow boxes. So Etsy um which specializes in information uh or ICT ICT and telecom standards that is where the their real specialtity is. They're industryled and it's um and they

are based um the standards body itself is based in the south of France but they produce global standards but they specialize on um ICT and telecom standards and we do a lot of work there.

There's also 3GPP which uh is uh which stands for the third generation partnership project. Can't remember what the last P stands for now but uh essentially they

specialize in mobile standards. So 3G, 4G, 5G and then you know 6G or whatever whatever 6G is going to be called whether it's you know uh future telecoms or whatever it's going to be called but

they specialize in that in that particular area. W3C, the worldwide web consortium. They specialize in worldwide worldwide web standards. IETF is the internet engineering task force and they

specialize in internet standards, internet protocols, internet governance, the whole kind of the whole formation of how the internet is run. Those particular organizations, those

standards bodies we do a lot of work in. They all work very differently as I say and they all they all have um their different pros and cons I should say as to how you kind of work in them how you

get the results how you actually develop the standards that are good quality but then also improving whatever it is that you want to improve for us it's cyber security

in terms of the actual different technology areas that we do in these different standards bodies got them on the board there but telecommunication ations

all the kind of telecommunications security you can imagine quantum technologies as well and then that also includes postquantum cryptography we do a lot of work on PQC

and I'm doing a talk tomorrow as well a panel on PQC uh tomorrow as well we also do semiconductors AI obviously and I'll talk about that in a little bit more detail in a minute and then obviously

the internet as well how do we secure the internet and that is itself just very quickly in terms of how you secure the internet that is a very politically difficult subject as well because

everyone wants privacy but then there's also about how do you ensure that you get privacy whilst ensuring that bad people aren't doing bad things on online on the internet and that is a

debate that every single country government has with every other government but also how governments also have difficult conversations with the private sector. You know, there are some

technology companies, usually US-based companies who are who have a different view to put it politely, they have a different view to how maybe some governments have it. Um

and that is a good those forums particularly the IETF on internet it's a good forum to have that debate and actually come to a reasonable compromise on how you um uh on how you handled

standards like that. So [clears throat] so just very quickly should be said I'm not an AI technical specialist. I understand this at a at a good level, but my my

bread and butter, my specialism is on standards, not on AI. So, if you have particular questions at the end, which hopefully there will be time, um uh please don't ask me too harder AI

technical questions. Um so, in terms of just the the cyber threats to AI systems, I'm not going to be able to like list them all. In part because there's quite a few and in part we're

we're actually still learning more and more as the technology is developing. We're learning more and more different cyber threats, but here's like a handful of different threats that are specialist

to AI systems um that I just kind of want to bring out in a little bit more detail. So, it should be said that the kind of the traditional cyber threats to software apply pretty

much applicably to AI systems. It is still a software. So the those different threats and therefore the security measures need to be put in place that those traditional cyber security methods

need to be put in place as well. However, with AI there are some unique things as well. So in terms of um so one particular threat are adversarial inputs and so those are maliciously crafted

data designed to trick AI models into producing incorrect or harmful outputs. There's also data poisoning which is the insertion of corrupted or malicious data into training sets to compromise model

integrity. Um there is uh model inversion and membership inference. So these are attacks that extract sensitive information about training data from

model outputs. Um and then there's indirect prompt injection which is very well known about but that's exploiting input prompts to override system rules or produce unintended outputs. So those

are some of the more very specific uh threats to AI that is not very well um there is there is less information on actually how do you mitigate those particular threats which is where

UK government stepped in to kind of try to solve this to try to give good information on how to mitigate those particular threats um and to give good advice on how you can practically do

So our main goal was to address those those cyber security risks to AI. As I said, we are still learning more different with more threats and risks to AI, but it's it's but it's what we can

focus on now that we're aware of and then any further particular risks or threats that that kind of unfold over the coming years, we will just have to adapt and continue to provide more

updated advice. But the work we wanted to do was to target all AI systems. There are so many out there. But this is about including the different models, the different tools, the different

technologies that AI systems rely on. And we also wanted to target the entire life cycle of AI. There's quite a lot written already about how you protect the kind of the development, the

deployment and the kind of the operation of the AI system, but there is very little if any really or any good advice out there on how you then decommission the AI system. How do you retire it? How

do you kill it? And then we also wanted to focus on the entire AI supply chain with particular focus on the developers and deployers for obvious reasons because they are the

ones who are ultimately responsible on how you kind of build and maintain an AI system. But actually it was going further than that. It was going for the entire supply chain of AI.

Oh, my thing has frozen. My slides have seemingly frozen. Sorry. Technical issue. Yeah. 30 second pause whilst I uh whilst we

just resolve it. &gt;&gt; Yeah. &gt;&gt; Yeah. Yeah. Just as we're waiting. Oh, there we go. It's starting to move. As we're waiting

though, um out of interest, just by show of hands, who is who who is um who understands standards? Are there people out there that work on technical standards here? I'm just trying to

understand the kind of the baseline knowledge of the the audience here. It's okay. No, no one particularly has a full grasp of standards. That's great. That's not that's not an issue at all that I

just understand the kind of the level I need to pitch at here. So, yeah. Yeah. So, I'm skipping ahead here a bit and I will

go back, but I wanted to show this. This is a really important slide. This is ultimately what we landed on in terms of the best advice to um to secure your AI systems

based on those threats and risks that I just outlined on that previous slide. So and so we put across 13 principles across five phases of the AI life cycle setting minimum or baseline security

requirements. Okay. Now this is baseline. You could go further. However, from our perspective is that we want we want as many organizations at whatever level you have

to meet this meet these requirements. We want to be honest we want people to go further but actually sometimes that is just not practically possible. It's too much money. Um it takes up too much

time. You're maybe not a business that that necessarily has those resources to do. But this will at the very least provide you th that kind of those good baseline security requirements. So if I

just kind of quickly kind of just run through those principles. So it should be said there are a number of provisions obviously I'm not going to go through every provision because I'll be here

like the entire day but the there are a number of provisions within these particular principles. Some of these provisions are mandatory and some are voluntary. And what that actually means

when I say mandatory provisions, it's h when you read it on a when you read it on the technical standard, it's you shall do this, you shall do that. That's mandatory. Voluntary is you should do

this, you should do that. So that is very much a this is what is essential and this is what is ideal, preferential. &gt;&gt; So in terms of the actual um uh the principles themselves. So the first life

cycle design first principle within that is raise awareness of AI security threats uh and risks. Principle two design your AI system for secure uh for security as well as functionality and

performance. Principle three evaluate the threats and manage the risks to your AI system. Principle four, enable human responsibility for AI systems. We then go on to phase two, development,

[snorts] which is identify, track and protect your assets. Principle six, secure your infrastructure. Principle seven, secure your supply chain. Principle eight, document your data,

models, and prompts. Principle nine, conduct appropriate testing and evaluation. And then onto the deployment phase. You again there are provisions under the principle conduct appropriate

testing evaluation because there are overlaps there and then also uh principle 10 communication and processes associated with end users and affected entities

and then on the fourth phase maintenance phase. Uh again there are provisions within principle 10 communication and processes associated with end users and affected entities. Principle 11 um

maintain regular security updates, patches and mitigations. Um and principle 12 monitor your systems behavior. And then the final phase end of life there is one principle of ensure

proper data and model disposal. Now as I said there is less uh information out there. There's less research out there on that final phase. That is why there is only one principle out there at the

moment. Obviously a number of provisions within that principle, but there's one principle. We are hoping that over the kind of coming months and years that there's

going to be much more research uh practical and and theoretical to actually inform that even more. And we would look and we are planning on on reviewing this this particular work um

over the kind of coming year or so anyway to update it on you know both the end of life area but then all the other phases to be honest with you but essentially these particular principles

are what we see as the best way to protect your systems that are also practical as well. So in terms of the evolution of the work like there's one thing in me saying this is what we think

but actually what what's the credibility behind that you know in terms of the actual evolution of the work and how why we are confident that this is good. It's not just because it was written by some

clever people within the UK government. It was written by and supported by clever people throughout the world in various different organizations that kind of have different interests in this

area. So in terms of the actual first thing that we did was the UK national cyber security center developed the guidelines for secure AI system development. This was a this was uh I

think about two and a half years ago now that that they were developed um actually um roughly in time for the first AI summit, the one that was in the UK at Bletchie Park. Um so it's quite

it's quite nice actually that I'm now talking about it, you know, the the um at the Delhi AI impact summit. Um but the the this was a first attempt of providing those security guidelines on

how to develop AI systems. Um it was done in collaboration with the cyber security and infra uh cyber security and infrastructure security agency CISA which is a which is a part of the US

government but we also did it in collaboration with um 20 other cyber security agencies across the world North America, Europe, Asia, Africa and South America. So it went across various

different uh uh organizations. It also had some level of industry consultation as well. They didn't necessarily write it but there was a level of consultation. The the our first uh our

our main intention for this was to kind of firstly understand what do governments think of from a cyber security of AI perspective. Then once that was published, my um the

UK Department for Science, Innovation, Technology took the guidelines um along with some other material out there uh and produced a draft code of practice. This draft code of practice

went out for public global consultation. We purposely um advertised and promoted this particular code of practice uh consultation to ensure that we could get

as many voices as possible from throughout governments, industry, the public, big companies, small companies, whatever. Trying to get their feedback. The consultation I think ran

for about four months or so. Um and we received hundreds of um uh uh uh well yeah we received hundreds of feedback um comments. Um yeah hundreds of stakeholders fed into the consultation.

Um the overwhelming majority supported the work or supported the actual advice within the draft code of practice. But there were naturally

things that needed to be amended. And so we uh we went through all those different comments and took them on board and then finally the code of practice was then published as a final

document. [snorts] [clears throat] We then took that code of practice because we knew that a UK code of practice doesn't necessarily mean that

it will get picked up globally. You know, it's had global input. doesn't mean that someone saying like someone looking at a UK code of practice will necessarily think I want you know this

is good you know if you're if you're based in India if you're based in based in Nigeria you're based in France wherever will you necessarily think I want to implement this so we then took

the code of practice to Etsy and I talked about Etsy earlier for those who don't know Etsy stands for the European telecommunications standards institute it's a standards

Don't be put off by the fact that Etsy begins with European. It is a global standards body. It can it develops global standards. It has global membership.

Um I wish that they would actually change [laughter] it from European because I think a lot of people assume that they only produce European standards and only by Europe uh

only by European partners and that is not true at all. There are plenty of standards out there that Etsy have developed that are adopted across the world

but [clears throat] we took it to Etsy um and we first developed it as a technical specification and the f and the one of the main re well actually there are several reasons why we took it

to Etsy in part because from UK government we know Etsy we know that they are really good at both the AI side and the cyber security side they are really good at the stand that they're

really good standards professionals the other reason is we knew that they could through this process develop a standard reasonably quickly. Anyone that works on standards, a standard could

take four or five years to develop and that just simply in some circumstances is just way too long. The market, industry, the market are crying out for a standard of some sort to be produced,

some sort of advice. But waiting four or five years is a too long and b by then there are new kind of cyber risks out there and it's all kind of outdated. We knew that through this particular

process that I'm running through now we could develop a standard reasonably quickly but not at the cost of the quality of the standard because there is a risk if you develop a standard too

quickly it's just poor quality. But we were confident in this particular process to make sure that the quality continued. The other reason why we went with Etsy

is that they produce free standards. All those other standards bodies that I mentioned um do produce free standards as well. 3GPP, W3C, all that produce free

standards apart from ISO. So the one that everyone knows about ISO and they produce really good standards. It should be said anyone that works on ISO, they produce good standards. It's just that

you have to pay for those standards. And our perspective is that standards should be free. that should be available to anyone. Whether you're a big company with billions of dollars or whether

you're a you're you're you're a small company or just a person in their basement, there should be available to everyone. This is good cyber security practices that should be available to

everyone and people should have that that level of support to ensure that their technologies, their IP is being protected. So that's why we went with Etsy rather than kind of ISO.

Um it should be said that we are still supporting work similar work going on in ISO in relation to this work as well. So yeah so we developed that that uh we took it through the the Etsy um

technical committee on securing AI and we worked with those particular individuals there those those uh standards professionals to ensure that the standard was how it should be. it

had all the kind of relevant um security requirements in there. And then we then decided to upgrade the standard to from a technical specification a TS as you can see on there TS 104223

to EN304223. Now I won't get too technical on this. In reality, that doesn't really change anything particularly. The the advice, the actual content within the TS and the

EN is pretty much exactly the same. The only reason why we upgraded to an EN well there are two reasons. Sorry. The first reason is that it provided additional consultation with the

standards body sens which is a European standards body. So it's good to get further views on actually is it you know are we taking on board all the relevant information out there are we referencing

all the other kind of international frameworks that are out there and then the other reason is so that it could meet the requirements within the EUAI act. Now, I'll be honest. I don't know

every single requirement with the EUAI Act. Um, and I probably wouldn't expect you guys either to necessarily know it, but essentially any company wherever in the world that operates in the EU market

is strongly encouraged to adopt EN standards. So that is one of the reasons why we went and upgraded to an EN was to ensure that the standard itself could be

adopted by various different global companies who are operating in the EU and they can say yes we are definitely meeting requirements from the EUAI act. Now companies that operating outside the

EU you can choose to adopt the TS or the EN it doesn't really matter. The actual content is exactly the same. So the the actual um and and how and how you kind of then um uh kind of yeah implement it.

It doesn't actually matter whether it's the TS or the EN. So this process how [snorts] these particular requirements were put together were tested several times across various different

organizations, hundreds of organizations across the globe. We went we managed to get comments from every single continent minus Antarctica obviously. I'm not going we're not going after the penguins

in Antarctica, but every part of the globe was um was was was uh collaborated with was consulted with as part of this and as I say across that

multistakeholder across different governments across uh industry, academia, big companies, small companies, cyber security experts, AI experts, standards professionals and

that is how we then ended up with the the final product and those particular security provisions. [clears throat] So in terms of supporting documentation,

so on the left of that of that slide there, obviously you've got the the EN talked about the EN304223 that provide those security requirements. There is also and you know everyone

everyone loves a good reference number uh TR104128 that's technical report 104128 that is also freely available on the Etsy website again similar route of how we

produced that particular technical report you know lots of consultation um in part it kind of was part of this consultation and then we ended up splitting out some of the work. So

focusing on the security requirements and then bringing an implementation guide um in a separate document just for ease. But essentially we produced an implementation guide. What that

essentially is is a is a practical way of different companies that are running different AI systems on how they can actually implement the different requirements. So whether it's a you know

whether you run like a chatbot AI chatbot AI app or a kind of ML fraud detection system or a kind of you know you're an LLM provider or you're you're an open access LLM.

There are different examples and individual kind of user use use cases on how you implement the different security provisions because obviously different AI systems work differently and

therefore the requirements require a slightly more tailored advice on how you um on how you implement it. How do you secure your systems based on that? And then it's all mapped to existing

international frameworks and other kind of standards that are out there that might have a link to that. And then we are currently working on uh a conformity assessment t it'll be once it's

published it'll be TS 104216. What this essentially means is that once it's published and again that will this will all be free as well. It's a way for different companies to assess on

actually how are they meeting are they meeting and how are they meeting the different security requirements within their own AI system. Um and and because often you need that conformity

assessment either because your company requires it or there are certain regulations in place based on whichever country you're in that require a level of conformance and you need to prove

that assessment there. Um so yeah so uh yeah let me just let me just go back on this here. So all these documents here are there to support the actual work of

this particular um of these particular security provisions. And this is how we ended up um developing a uh a a standard within a couple of years or so using the multistakeholder framework

driven by the UK government but not led by us. We were very conscious of not coming across as we were leading this. This is our advice. It's in part our advice but also it is in part or or more

so other people's advice but just us as UK government providing that kind of that that that drive through the different organizations that we took it through. Um

so yeah that's my presentation. Um I guess are there any particular questions uh or comments that people have? Um I can see one at the back there. &gt;&gt; Yeah, myself I'm Prashant. I'm from

State Bank of India. Um you said that 13 principles are there uh and there are uh certain principles which are should be considered as mandatory. &gt;&gt; Sorry I I didn't get that. I can't hear

very well cuz probably because the microphones are facing that way or the speakers are facing that way. &gt;&gt; Yeah. 13 principles you have explained. &gt;&gt; Yes.

&gt;&gt; Uh in those 13 principles uh what are the principles can be considered mandatory? &gt;&gt; Which ones are mandatory? &gt;&gt; Yeah. Yeah. Which you consider as

mandatory? Yes. What? &gt;&gt; So there are so there are different um so it should be said I didn't say this at the beginning but a standard is a voluntary thing. We in UK governments

uh we strongly encourage companies to um to adopt standards but we think they are better when voluntary. Now doesn't mean that every single standard should be voluntary. some are

uh uh are kind of are form the basis of regulation and different different governments uh do that. So just firstly just that kind of very kind of high level standards are are voluntary in

terms of the actual pro uh principles it depends on which provision yeah provisions within the principles. So different provisions are mandatory within the different

principles and some are more voluntary. So as I said earlier some there might be some kind of you know it shall you shall do x you shall do y &gt;&gt; those are within the different

provisions and then there's and then there's the you should do x you should do y which are voluntary. I'll be honest, I don't I don't know off the top of my head which provisions are

mandatory and which ones are um voluntary, but you can look on you can look on the the the the the standard and I do strongly encourage you to to look at it. But there was a lot of debate

within within the Etsy group as to which ones should be considered mandatory and which ones should be considered kind of voluntary provisions. Um, and it, you know, it led to a couple of days of

pretty heated debate. Uh, and this is standards here we're talking about. You know, we're we're all quite calm people. Um, but there were lots there were lots of conversations about how to what is

what should we be saying to people? This is essential to purchase systems and this is voluntary. Did that did that answer your question? Sorry. &gt;&gt; Okay. It will take time then for

abstract principles it will take time. What for mandatory? Could you say that again? Sorry. &gt;&gt; Uh what you are telling that ex the principles uh what you are telling

uh you you have told that uh they are not abstract in nature right now. &gt;&gt; Okay. They should be formed. &gt;&gt; Okay. Thank you. &gt;&gt; Okay.

&gt;&gt; So my question uh yesterday uh attended a session where uh this session was chaireed by uh ey and uh in that session there was one

participant from Singapore I think probably Singapore government &gt;&gt; where uh I'll just let you know the uh session effective AI assessment verification and assurance establishing

the foundations for responsible confidence in AI. &gt;&gt; In which one of the note I made was that they have published AI verifi verify function by Singapore government a set

of uh hardness where you can run your AI uh developed uh whatever software you call. &gt;&gt; So you can run through those harness and at least get some sort level of

confidence that &gt;&gt; uh they're probably they're covered. I'm not sure there those are in sync with your standards. I'm not sure about that. But my question to be very specific is

when you are having a standard is there a harness where we can run through that harness and say that okay uh it's complying with certain set set of standards rather than just uh going

through the document and then we building our own harness and interpreting the &gt;&gt; since it's a very new field probably there's a lot of interpretation risks

are there standard. &gt;&gt; Yes. Well, thank you for letting me know about that. I'll I'll check it out. Um, and I will admit there's lots of there is lots of information out there

and there are different standards out there that are on cyber security but they're on a different tangent of this. So there's work going on in ISO which is what we see as complimentary to this.

Um, which is why we're supporting some of the work going on in ISO as well. So like I I'm not familiar with the work you just mentioned, but I I'll check it out and see in terms of how you meet it.

The the you know the that hopefully will be easier to kind of explain once the conformance assessment is published. Um the the implementation guide provides

those different examples as I said on how you can meet it under different terms but the conformance assessment itself will be able to kind of tell you whether you you are meeting it and how

you're meeting it. Um that's the only kind of that's the only way you can kind of do it at the moment. Anyway, we are considering different ways of of how that comes across as well, whether

it's kind of self assessment or whether it's uh independent or like third party assessment as well. So that's all kind of think that's all part of our thinking as well as to making sure that

those companies not just have the right advice but are also checking to make sure they are doing the right thing. Um uh and there are pros and cons to to to both of those, but um yeah, that's the

that's probably the best way I think. And we're hoping we're hoping the conformity assessment will be out in a few months or so. Um yeah. &gt;&gt; Hi, my name is Ishita. So I have a bit

of a general question. So uh in the 13 principles that were listed yeah so there there are some points about monitoring the systems behavior and uh assessing the threats. So

uh so AI being such a like emerging field and the models that we have today are themselves showing an emergent behavior. So it's a bit difficult to predict uh what kind of behavior we are

going to see in future. So how do we make sure that the standards are not catching up with AI but rather like uh are they like they're in pace with the development in the AI field in general?

&gt;&gt; Yeah and it's a great question. Um I think as I as I said standards can take a long time to develop. That's that I think that's okay in most cases, most technologies because kind of

with other technologies there are developments but they're all kind of fairly steady for the most part. AI is as you say one of those technologies that just at

least in these last few years I know AI has been going on for decade. You talk to AI experts, people say AI has been going on for decades. But last few years particularly with the amount of

investment and the the amount we are seeing both being used publicly [music] and just within the AI industry itself, new things are cropping up, new ways of actually how you how you use AI. You

know, there's there there's AI, there's um artificial general intelligence, AGI as well. And that those are different elements of AI. So the uh this is a bit of a this is a

so because of that there are new things coming up and you're totally right and there are probably areas where we would want to want to do more work on this and that is exactly why we are looking to

update this standard in a year or two. um uh we're not quite sure when is the best time to do it and we're in part we're thinking that actually it

might sometimes it might be better to actually rather than update the standard in its entirety it might be better to support the work of other standards bodies or kind of other um governments

or uh industryled initiatives to provide kind of advice that kind of is like almost like an annex like an unofficial annex to to this to provide that kind of more updated advice based on you know

changes in the technology or just increased knowledge on the different risks and threats that are out there. So it that's it it's not I know it's not a great answer but it's a

uh we want to do as much as we can but standards inevitably take a long time to develop. Um but the industry and the end users the you know us as consumers expect those particular um systems to

run securely. Uh so that's kind of that's the that's the the balance that we're trying to meet at the moment. Um, so as I say, we want to review this in a year or two once we have a bit when

there's a bit more uh research and information out there. But in the meantime, provide some support and assistance to uh AI companies or other standards bodies or different

governments on making sure that information or the updated kind of security information is is given to the public and given to to the industry. &gt;&gt; Hello. Hello,

&gt;&gt; my name is Bridget. I work with an organization called Paradigm Initiative and I see the uh 13th principle highlights uh proper data and model disposal. But I'm keen to know how all

of the principles um reflect on issues of data minimization especially in an era where data is often extracted without um uh the necessary safeguards or also without

the necessary consultation from specific communities or vulnerable communities. And also one of the other principles also highlights um testing and evaluation and I'm keen to know how um

principles of uh concerning issues around oversight are being taken into account. I know uh testing may involve uh regulatory sandboxes but what oversight mechanisms are are in place

for such a a um an output that you've developed? &gt;&gt; Really good questions. So I'll take the oversight one first. Um the so the standard itself does outline specific

roles and requirements um of the different stakeholders. you know whether you're a kind of data custodian um or or or kind of some sort of AI

developer. So the standard itself provides the um the not just the terminology but the actual um responsibilities of different um stakeholders, different kind of AI

developers and deployers within an organization about what you should be doing as a as a um as a as a developer as a deployer of AI. Um it's never you can't get it perfect because every

company will have a different structure. Um uh you know big companies will have different levels of staff working on uh uh developing and maintaining their AI systems versus like a a small company

for example. But the actual standard itself does provide a sort of um a level of guidance on what different roles and responsibilities and requirements those

different um uh those different roles within a company should have to maintain you know data security or data integrity as well. Um your first question I'm trying to

remember what your first question was again. It was &gt;&gt; minimization &gt;&gt; data minimization. Yeah, that's it. So the standard from memory, the standard

doesn't go into huge amount of detail on that because that often is um that's often more about the kind of the ethics I think of AI in terms of how much information

should an AI model have access to? Um and so uh and and how does that information how is that information acquired? So this standard itself its parameters are purely on the security of

AI systems. So making sure that that data itself has come from secure um uh secure places and it's treated securely. uh but not necessarily about the like

whether the the you know how much data is actually coming in or coming out necessarily as that is I think my understanding is that's more to do with the kind of the ethics of how you use

data which is under which I think there are other standards going on the being developed at the moment on actually how that should be does that does that answer your question I don't

sort somewhat We we can talk about it maybe at the end if that's helpful. &gt;&gt; Hi. Hi. Thanks for your presentation. Um I I wanted to understand the process of developing the standards particularly

from the fact that um you must be working with different jurisdictional bodies and different regulators altogether. uh I think uh the fact which pretty much

boils down to uh regulations and standards when they when they are in the development processes how stringent or how flexible you can make so that uh it is easier to navigate for

multi-jurisdictional organizations or entities. Uh so I wanted to understand what kind of different standard bodies and regulatory bodies did you connect with whilst developing uh the framework

that you did? &gt;&gt; Yeah, really good question. So in terms of um the regulatory part of that question, the

because generally as I said the UK government tends to tends to see standards work as a voluntary thing. So for us we focused our efforts more about just the volunt making sure that this

standard was voluntary. Now if other countries decide that they want to take this standard or any other standard and and turn it into a into regulation then that is that is entirely up to them. The

UK government currently is not looking to do that. Doesn't mean that you know the Indian government won't do that or the French government or or whoever. So in terms of the regulation question the

only thing we touched on really that was kind of linked to it was on the EUAI act. um because the EOI act is a is a is a kind of form of regulation somewhat. Um and so that's why we then upgraded it

from a TS to an EN to just ensure that we were meeting within the EU framework. As far as I'm aware, there isn't the EU AI act is not quite like there there isn't a similar there aren't similar

kind of requirements in other jurisdictions across the world. I know to be fair other countries are thinking about this and trying to work out and and that is probably that will be a an

area we will need to look into a little bit more um if if different jurisdictions end up end up taking a similar route to the EU. Um, in terms of working with just other

other jurisdictions, you know, in in making sure that the standard was applicable, we worked with a whole range of different countries across Europe and outside of Europe. And we have been in

constant um uh contact with Senelch which is the European standards body for the kind of that that that um that takes a primacy on the EUAI act but then also ISO as

well. So ISO obviously you know every country feeds into ISO. Uh India as part of the Indian as part of the Indian national standards body feed into ISO as well. And so we're we've been um uh um

collaborating with them to make sure that the work we are doing does not duplicate or contradict the work that that ISO is also doing but actually if anything complements it. So the the the

the the different um standards experts that are working in ISO are checking to make sure that what we are doing is not not um causing any issues from their work but also is just a good quality

standard and we're doing the same thing making sure that actually the work we're doing is complementing their work as well. So it's we like to think that we have been

trying to talk to every single person and it's a it's a it is a competitive field you know developing standards and AI is a competitive field but we'd like to think that we are kind of making sure

that we are providing complimentary work any more questions I think I'm I think I'm probably at time but I'm happy to speak to people at the end um if there are any kind of further questions

Thank you very much. Thanks very much. Appreciate it.
