# Culture and Code: Creative AI for Equitable Development

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:30 ‚Äì 16:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/1Qaa3HsyQAc?feature=share) |

## üé§ Speakers

- . Ms. Siok Siok Tan, Author, Filmmaker & Entrepreneur
- Mr. Shekhar Kapur, Internationally acclaimed filmmaker
- Ms. Jaya Deshmukh, MICA
- Prof. Olivier Oullier, MBZUAI
- Vilas Dhar, The Patrick J. McGovern Foundation

## ü§ù Knowledge Partners

- MICA, Ahmedabad

## üìù Summary

The session will deliberate on the role of Artificial Intelligence in democratizing creativity and advancing inclusion, while addressing concerns related to authenticity, ethical use, and equity. It will explore how AI can broaden access to creative expression, along with the safeguards needed to ensure its contributions support responsible and inclusive development.

## üîë Key Takeaways

1. The session will deliberate on the role of Artificial Intelligence in democratizing creativity and advancing inclusion, while addressing concerns related to authenticity, ethical use, and equity.
2. It will explore how AI can broaden access to creative expression, along with the safeguards needed to ensure its contributions support responsible and inclusive development.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/1Qaa3HsyQAc/maxresdefault.jpg)](https://youtube.com/live/1Qaa3HsyQAc?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

is really very dear to all of us and uh got a wonderful panel from all over the globe. Uh and I will make introductions very quickly. Um but we are here to talk about creativity. Now it's a real tough

act to follow person Jooshi but we are going to try and because our panel is really great. Um and I think the conversation that was going on before uh was about you know can AI replicate

creativity. uh we we have a slightly different stance. Uh we want to talk about what really happens with creativity. Uh when we were young, all of us were

creative. Um we didn't need to be told uh how to be creative, right? We just were creative. But as we grew older, what we understood was to be creative, we needed to master skills. We needed to

master tools. But AI is going to change that. Because AI will give us the tools to express ourselves and express our creativity. And with this possibility, with this ability, uh comes a few

tensions. Uh the first tension is is it genuinely going to result in us being able to express ourselves in a unique way in with originality or is it really going to take everything down to the

least common denominator? You know what person Jooshi was just saying that it is the least common denominator of the highest act of creativity. So is that what's going to happen? Is there going

to be a flatness or a sameness uh in what we do? Uh so that's like tension number one. And then tension number two is will we all get access to that creative within? So for example when I

was very young I used to write poetry and then I killed the poet in me the moment I came to my 10th standard you know like because I had to study. Uh, but will AI allow me to once more

interact with that creativity within me, give me access, or will it just be another way by which data gets collected about something so close to being human, so close to what it really means to the

way we live, the way we experience, which is to be creative. Will we hand over the creative process to AI? And now to discuss these tensions and hopefully we should have some vivid arguments and

debates. Um &gt;&gt; hoping hoping right uh I'd like you like to introduce you to this panel. Uh very quickly we've got Suktan. She represents um her work is in Singapore and

Southeast Asia, China and she is a documentary filmmaker um and she is an writer. She she's written a book on AI and humanity. On you know it's this like a boxing ring, right? [applause]

And on my right is professor Oliver Olivier. Um, Olivier is very very proficient at human centered AI and his specialtity amongst many others, he's a musician as well, is that he uses brain

waves to make music. He gets people who are seriously limited by their physicality to drive an F1 car actually. and he really believes that

creativity is within. Right? [applause] And then to my left is Dr. Dhar. Uh Villas Dhar is a philanthropist. He is behind one of the biggest foundations that invests into AI. And

what he does is to see that AI gets used really for human dignity. And he brings all of that together. He evangelizes the fact that AI is not a tool for few. It's supposed to be democratized. It's

supposed to be for each one of us. And they invest in initiatives that brings AI to everyone. So what we would hear from him is why it needs all of us to make AI really successful and to unlock

value. [applause] And to finally um I don't think I need an introduction but the filmmaker Oscar nominated director [applause] Shaker Kapoor.

So really happy to be here and to get us started I'm going to start with the first tension right [clears throat] and um the first tension is really is AI about democratizing access to creativity

or if everyone can become creative will it result in something like cultural flatness. So what does this cultural flatness means? It means that all of us will give the same kind of prompts the

same kind of prom. It'll be the same kind of art with the same kind of prompt and therefore all content will look the same. So debating between this I'm going to first go to

villas right that if you believe that this is what's likely to happen sameness or access what do you feel is the responsibility of funders and governance frameworks how should they reward

cultural diversity rather than just efficiency how do they intervene to protect &gt;&gt; Thank you Z and thank you for that introduction and thank you for the work

that you do at MIA Uh it's an institution I really admire. Um it's nice to be with you all. Um I think the question needs a little bit of inspection. Will AI create cultural

sameness? I think cultural sameness unfortunately lives in our world for reasons that have nothing to do with AI. They're the product of centuries of colonial oppression of globalization of

the expression of power. You know what's funny is I can go anywhere in the world. I'm a man who travels on my stomach. I can get a pizza or a hamburger but I can't get a kulcha kulcha chole.

Cultural sameness has happened because we have expressed the ways of thinking, the ways of imagination, the ways of education that come from a very small part of the world and pushed them

through the rest. Why do I share this with you? Because in many ways, I think AI reflects the same phenomenon. What we embed into the tools we create, the cultural values that go into these

systems could potentially create a frame in which our voices, the voices of the global majority, the voices of people who think a little bit different get pushed out. But that's not inevitable.

In fact, when you think about it and you think about designing AI systems that are not grounded in western thought or on the online kind of expressions of people on the internet, but are grounded

in community data and information, community wisdom, you think about how a poet who's working in South America who speaks Ketwa can create something that's not just translated by an AI based model

that's trained in English, but it's something that could never exist in the English lexicon. We see these capacities when we flip it. When AI becomes a tool of enablement for people not just to

produce more but to actually reinvent and re-engage with their cultural heritage. To actually think of AI as a way that we bring back the cultural diversity of our world because every

individual has the power, has the capacity, has the tools that let themselves express themselves in meaningful ways. The other thing I'll say and I'll be very brief is this.

Algorithms they dominate for the things that they think work for the most people. You might look on something like one of the online streaming platforms and what's presented to you is often the

thing that most people have liked. But I like things that are a little bit weird, a little bit odd, that represent me and you and don't necessarily have to represent a billion other people. I want

to see the kinds of algorithms that lift up eccentricity, that create cultural value, that make us connect to each other in small and meaningful ways. I think these are both possibilities, but

as we've said, they are not inevitable. So Vas, I think you're squarely on the side of the fact that it's going to democratize and it's actually going to give c greater cultural diversity than

sameness. &gt;&gt; Well, you know, my argument is always it could, but whether it will is in our hands. &gt;&gt; I take that. So if I were to go over to

Shaker, right? So Shaker, my question for you is what do you believe? Like do you really believe that uh AI will give everyone tools to be creative to be storytellers

filmmakers or will it turn storytelling into a formula? &gt;&gt; I have a question for you. &gt;&gt; I got it. But that that was not anticipated.

&gt;&gt; When did you grow up? Because everybody's saying that you're creative when you were a kid. Why does anybody grow up? Why? I don't I mean I just I spend all my days trying to be a child.

I get admonished for that. But I'm Are you grown up? Is who's grown up here? Who Who says that I've lost my childhood? Come on. Oh no. Then don't do that. Yeah. You'll be very creative.

Forget about AI. Let's talk about childhood and play. I mean children play. That's why. So play. Play is the operative word. Will AI make us stop playing? Okay. What is play? play is

where the outcome is unpredictable. AI cannot deal with unpredictability. And the reason AI will win if we become predictable. Like when you go out and see uh Game of Thrones, everybody's seen

it, right? If you go in the morning, in 6:00 in the evening, if it comes at at 2:00 in the morning, you won't see it. 6:00 in the evening, you want to sit in the chair, watch Game of Thrones. You

like the antagonist, you like the protagonist, you like the conflict, you like the world, you like everything. You know what you're doing? You're becoming predictable. That's what you're

doing. Suddenly, Game of Thrones changes. The protagonist is different. Antagonist different. Game of Thrones unpredictable. Suddenly, as long as we

are unpredictable, it is human inertia that makes us makes us predictable. Humans have an an inherent inertia. As long as we don't lose that inertia, I mean as long as we have inertia, we'll

become predictable. AI will take over. But then what does intelligence mean? What is being human being? You know when I was a kid, I used to go up to the mountains here from Delhi. I used to

live here and I used to run down a river. I went from boulder to boulder to boulder to boulder. First few boulders that you run down, they're fine. You can see the next one. After a while, you

can't see. You can't just plan ar your momentum is too high. When your momentum is too high, you get into something I call the zone. Then you're active intuitively

and then you're hoping that you're not going to fall. You're hoping you won't injure yourself. You're hoping you're not going to die. And when you go when you get down there, you you say, "Wow,

that was so exciting." Because your hope came true. Now you'll say Ion Musk will give you a little thing put in your brain and AI will predict go from here to there and go from here to there

nothing will happen. Question is why would I do it then right and why we live is because we hope AI cannot hope and hope is unpredictable. I hope I'll survive. I hope you love my lecture. I

don't know you know I hope I'll be given a job. I hope I'll survive tomorrow. I'll hope I I won't get into an accident. Being human is about being unpredictable. Living. Loving is about

being unpredictable. Remember when we were kids or when we still kids, we go, "She loves me. She loves me not. She loves me." How many you remember that? Yeah. She loves me. She loves me not.

She loves me. She loves me not. AI will do this. She loves me. She loves me. She loves me. She loves me. She loves me. Right? What's happening? What's happening is love is becoming predict

but it's not love. Love exists because it's a mystery. AI cannot exist and it'll copy the mysterious novels. We are alive because we hope. We are alive because we fear. Hope leads to fear.

Fear leads to fate. All of that. And that's not AI. So creativity comes from everything that I've mentioned. Creativity comes from hope. It's not just in my brain that there's a

creativity. I put on a switch and I get creative. I hope. I pray. I fear constantly. Constantly fear. I wake up in the morning. Is this right? Is it wrong? Is it right? Oh, let me ask Chad

GPT. If Chad GPT gives me my answers, then I am giving into inertia. It's human inertia will drive us. If we are, if we maintain it, but if we don't, if we keep running down and keep

challenging life, challenging love, challenging everything, we're alive, then AI can't do us, then it becomes our slave. &gt;&gt; So, should I take this to mean Shaker,

that um it's not about flatness of culture. Uh, as long as we stay fearful, &gt;&gt; hopeful. &gt;&gt; Hopeful. &gt;&gt; Everybody say hopeful.

&gt;&gt; Correct. &gt;&gt; I I want to take this conversation slightly ahead. You what you said is very interesting that we always remain children and creativity is not in the

brain. Um, but uh probably Olivier will have something to say about it given that you are a brain scientist. Please don't &gt;&gt; there are

&gt;&gt; amazing pieces of art that have been created because adults went through hardship. So it's not just about being kids our entire lives. It's about our

experiences. It's about what makes us unique. And the one thing that we don't like about ourselves, meaning that we're somewhat denied our uniqueness when some people come with

blanket statements about this kind of population, this generation, we shouldn't do the same make the same mistake with AI systems. We speak generally, we hear about AI as a

monolith, but there are so many different AI systems. So so so many. It's not AI, it's different AI systems. However, we can expect some things. First,

just like human beings, the more diverse the experience, the more likely for the AI systems output to be something that would be meaningful. That's the first thing. The second thing

is for a lot of people since the end of November 2022, AI equals text. large language models. Look at me. I'm a dude from the south of France with Latin origins. I speak with my hands. My

facial expressions have a life on their own. This enhances I like to think magnifies what I say. But we need to train AI systems with

things that are beyond words. Words are just one part of what makes us humans. Think about facial expressions, movement, our individual, our collective history, what makes us who we are. This

is why we're moving beyond large language models. And we are moving into the era of world models. The big difference between me and a system today is my ability as a human being to

leverage my brain to have an image of a world, to map the world, to anticipate things, to have trauma, a brain. I'm a neuroscientist. A brain on its own, it's totally useless. If you

put the brain on the table, nothing is going to happen. What is going to make my brain useful is the exchanges of information within the brain, between the brain and the

body, the body and the environments, physical, digital, my personal, my collective history, what I imagine, the fact that memory is not a system to remember the past, but the

best system to build the future. If we start thinking this way, then we will train our models not just with what we consider to be perfect information, useful information, but in order for an

AI system to be able to have outcomes that are relevant to us, it might need to go through what all of us go through, love, depression, envy, jealousy, creativity.

Now we can think about outcomes that matter because today we are so focused on the tool itself on the systems that we forget what matters most. If it's ethical, if it's legal, if it's moral,

if it doesn't hurt, then only the outcomes should matter and we should focus more on the outcomes than the system itself. That the technology itself which evolves on a daily basis.

on a daily basis. My job is to create AI systems that assist people, assist everybody because true inclusion when it comes to AI or otherwise it's creating solutions that benefit everybody

regardless of their physicality, their abilities, their needs, however special those might be. We need machines to adapt to who we are. And in order to achieve that, we need to train those

machines with brain waves, with facial expressions, with movements, with physiology, with text of course, but also the intonation of a voice, everything that we can find. And maybe

we're going to reach a level where technology serves us the way we expect it to serve. And I will end with this kind reminder. So far, AI systems or made by us, trained on data that comes

from us, turn into products that are sold and used by us. Those systems that are out there as products, they learn from interactions with us. Us us as human beings. Look at our history. We've

been able to create the most magnificent things and the most horrible things. What do you think those systems are going to do if we don't keep them on check?

It's us who are using them. It's us so far who are creating them. So expect the best, except the worst. And yes, as human beings, we've always always hoped that machines will be allowing us to

achieve things that we cannot achieve ourselves. This is why I hear people looking for objectivity, neutrality, absence of bias. Those don't exist in real life. Why

should we expect them from machines? Well, maybe because as human beings, we don't fly and machines have empowered us to fly. So, expect the impossible and keep the humanity in it by training the

systems with what makes us who we are, not just a few words here and there that are anchored in the statistics of the people who produce the biggest amount of language so far that is available

online. &gt;&gt; So, that's like super interesting. Super interesting that the brain scientist, I know I'm reducing it so much to the work he does, but the brain

scientist um thinks that being human is way beyond the brain. Uh &gt;&gt; so &gt;&gt; hopefully &gt;&gt; yes

&gt;&gt; I wish for you. I hope for me of course it's all about what feeds our brains, &gt;&gt; right? and and that that is the the gamut of experiences, the different ways in which we engage, our interaction with

culture and community. And so, Suku, since that's your forte where you create storytelling with communities, um what's your take on this? &gt;&gt; My take on this, um I think when we talk

about AI, you think about generational content being frictionless, becoming easier. But the point is not generating content, it's actually making meaning. So when Shaker talk about being hopeful

or being fearful, we're making meaning. We can only experience hope or fear if we make sense of what it means for us. So I think that we have um we are overindexing on the frictionless

generation of content. We are underestimating our human agency to actually make meaning which I think is very important is also part of understanding suffering uh feeling pain

uh feeling uncertain experiencing defeat so I think that's very important I think the making of meaning will be the ultimate human act in terms of creativity the other thing I want to

resonate with villas is really the idea that we talk about more diverse voices but algorithms are design choices. Our algorithms are designed for us to amplify what has already worked and that

if we go along the path of least resistance means that the unheard voices will remain buried even though you have more of them because they are being generated. So I think we need to step in

and shape and co-create algorithms that will amplify unheard voices. So we cannot take that for granted and also we cannot blame AI. It's us. We have to step up and co-create. And the third

thing about culture texture is I feel that friction is actually valuable. uh we have to be able to resist automation, optimization and present something that is idiosyncratic, cultural, maybe niche,

but that resonate with our community. Maybe 10 people like it, maybe a 100 people like it. So I think that we need to be courageous and to create friction when it can generate a sense of life, a

sense of community, a sense of shared purpose. Thank you. So if I were to try and synthesize this um what I understood was that if we want

to really democratize AI and creativity and get the maximum value make this an enabler then we need to embrace each one of us being fearful &gt;&gt; walk in

&gt;&gt; not of AI but just being brave and going into fear. Be human. Be fearful. What does it mean? Be um embrace unpredictability. Um myriad experiences. Um far more than

just a cognitive process. Uh lean in lean in to the biases. Lean into the imperfections and then do that with a structure with philanthropy with governance that allows us to be who we

are. So could that be a proper conclusion of this tension? &gt;&gt; A proper beginning for the next part of a conversation rather than a conclusion. Right.

&gt;&gt; So the the good. So this leads us to the next one. So when Olivia was speaking, I was getting scared. Um the reason I was getting scared is because when you describe the fact that you know how does

an algorithm work? It works through data and the kind of data it needs is the kind of experiences we have, the kind of facial expressions, the way we use our hands, our emotions, whether we react

positively, negatively, the entire gamut of human experience. And probably creativity is a materialization of being human, of being a child. If this gets fed into a AI tool, then are we inviting

in surveillance? are we inviting in a new form of surveillance? So, um Olivia when we were discussing this already told me that he's he's he's going to come out of the gates talking about why

this isn't the right way to think about it. But, uh I'm afraid that if he were to hand over all the data and the nuances of being creative to a tool, will we then be handing hand over the

secret sauce, the myth around creativity? So um maybe I will start with you Olivia because this is in your part of expertise. Access is important when it comes to

technology. Think about technology has been affording us human beings to create things. There wouldn't be cinema without the invention of a camera. There wouldn't be some symphonies without the

invention of violin. If you see artificial intelligence as a new form of technology, it allows for new forms of art, new forms of creativity and that is the history of mankind. New

technology leads to new inventions, new forms of art etc. Now when it comes to collecting the information about people, my very biased view is

ethics and access means providing solutions that are powered by the most advanced science at the moment they are being used. A lot of us have been judged, have been

discriminated for jobs for instance by technology that is unscientific surveys, questionnaires, cognitive tests, psychology test, IQ test, all these things that have more than 50

years of scientific literature showing that they are not accurate, that their predictable power is low, yet they have been used as weapons of mass discrimination.

Do I want to be discriminated? Absolutely not. But I'd rather being understood by a system that really understands how I am and who I am than a system that extrapolates my personality

from a bunch of questions that are ridiculous. That summarizes me as a human through 10 questions asking me how I feel or how I solve a puzzle.

Call me pretentious, but I'm a lot more than these kind of things. I cannot be summarized this way. Now, can an AI system today understand me entirely?

No, it can't. Um, I have to respectfully disagree with you when it comes to say that we humans are unpredictable. As individuals on a daily basis, we can be unpredictable, but sadly we're so

predictable as societies, as group of people. We're seeing patterns in history repeating and not the most beautiful ones. And I think this is one thing that leveraging technology in order to better

understands us. If we use it, if we leverage this knowledge in order to allow to assist us to avoid repeating mistakes that cost lives, then this is what I call progress, a positive

outcome. Of course, the history of technology and inventions and science is also a history of hijacking those inventions and those things that have been developed with the best intentions

and turning them into negative things. So, we need to be very careful about that. But so far, as long as we human beings have a say on what AI systems are doing, we're accountable. We're

responsible. There might be a time where we no longer are in control or even have this illusion of control, but to date, we still have a role to play and we are accountable when it comes to what

outcomes we're offering the world with this wonderful technology and science because yeah, we talk a lot about technology, but it is above all science. It is our

responsibility today. So would it be right to say that we should not look at it as a surveillance tool uh so long as we put the right guard rails around it?

&gt;&gt; Do you consider a paper and a pen as a surveillance tool? Because it's been used for so many years by secret service before cameras in order to track people's behavior. But

the same pen and the same paper or at least the same technology was used to draft some of the most wonderful novels in humanity. &gt;&gt; I think that's a good question to ask

Vas. What what do you think? &gt;&gt; Let me let me come to the question from a different angle and every time I sit with Shaker and we become friends, he encourages me I think implicitly to

think about playfulness. So let me give you a playful answer. I want to tell you all I have a very good friend who's an artist and her work just popped into my mind as I was hearing you speak years

ago. She did an installation. It was called The Secret. It was a quiet room, entirely dark, walled off from the world and soundproofed. You would walk in and in the middle of the room was one

pedestal. And on the pedestal, nothing more than a keyboard and one of those old CRT screens with the green text. And here's how it worked. You would walk up to the screen and you could type one

secret. One secret that nobody in the world knows. A secret you would never tell another person. You could type it into this machine with no record that it was you. Nobody would ever know. And in

return on a small dot matrix printer, you would print a secret that somebody had al somebody else had told the machine and you would walk out with a slip of paper. I want you to sit with

that for a second. A promise of privacy of no surveillance. What would you tell the world if you could tell it with no consequence? Think for a second. What secret would you have typed in?

And then you get somebody else's secret. Something that is their deepest, darkest wish, maybe their greatest fear, maybe something they've done that they're so proud of that they can't tell their own

family, or something they're so ashamed of. And how would you react? That's how I respond to your question. Is it the paper, the pen? Is it the video system? Is it surveillance? At the end of the

day, I don't think it's the right question. And the right question is what are you willing to share of yourself with each other and with a machine? I'll give you one other quick story. On my

way into this room, and this person's in the room, and I don't want you to feel bad about it, but somebody I've never met came up and I think probably like Shaker, we're used to people coming up

and asking for a selfie. I'm always happy to do it. But this person asked something else. He said, "Can I have your email address?" I didn't know his name. I didn't know who he was, but he

wanted my email address. There are things that if he had asked me even intensely private questions, how are you feeling? What are you joyful about now? Even if he had said to me, what are you

scared of in this moment? I would have given him an honest answer. But he asked for my email address and I had to say, I'm sorry, I can't give you that. And yet, I'm happy to go on a website and

give it my email address, my credit card. I'm happy to give it all kinds of quantitative information about me, but I can't imagine talking to a machine and telling it what I'm scared of or what I

care about or who I love. That's something I hold for people. So when we talk about surveillance versus privacy, let's acknowledge that the intimacy that we share with each other, an intimacy of

meaning, is something very different from the data that I'm willing for a machine to have. And you might say that you want the AI to know you well, and I appreciate that, but I would rather my

wife, my nieces and nephews, my friends know me well, and my AI, I know how to use it well. To me, it's a very different frame. May I just remind you that the latest data showing the use of

LLM is the number one use is not for coding, is not for writing, it's for companionship, is for the role that a lot of isolated people um or using it as a friend. I'm not saying it's good. I'm

saying that this is the reality of the use of LLM today. I'm like you. Um I'd rather interact with people. However, first it's not mutually exclusive and some people do not have a luxury to

interact with other people. &gt;&gt; Yeah, I'm sorry, but I wonder if we take the wrong lesson from this. You wanted a debate, so let's have a debate. I wonder if that's the right lesson. Like is the

lesson that because people need it, we should normalize it. Or maybe we should ask the question, what kind of society have we built that people feel so alone that the only place they can go is to

talk to a keyboard or talk to their phone about those things that are so uniquely human? I think we divert our focus from what matters. When we talk about ethical AI or responsible AI, what

we should talk about is what's the society we want to build and how does AI enable it, not what should the AI tool look like to replace that that we've lost.

&gt;&gt; So if I think I think Shaker wanted to come in, &gt;&gt; right? &gt;&gt; Uh just a few things that have been talked about here. Um Olivia I did not

say that humans are unpred humanity is unpredictable. I said being human is unpredictable. Humanity is not because we are tribal. We fall into tribal behavior and fear and other things drive

us to tribes. So then that becomes predictable not human beings. Uh I find a lot of the questions that are being asked on AI and answered a western perspective.

What we forget and we keep saying that to us. Oh, it's the most democratic technology ever. Democracy for whom? Privacy is a western concept. Come on. We live in joint families. We are

community people. There's nothing about me that my my you know people around me as a community joint families everybody. There was no privacy, right? Actually, if you try and have privacy, it breaks

up. So, privacy has a different concept for us as a community of people. We are community people. We have a problems, political problems, everything. But we are the other thing that I'd like to say

is it is the most democratic technology because not because they are LLMs and not because Sam Alton is here. We are constantly looking at that. I tell you a little story very quickly about this

chair, this guy that went to raise $10 billion CEO. He goes to his office when nobody's there but the cleaning lady. The cleaning lady is there. Okay. Sir, I saw these papers. They look

important. Can I throw them away? He looks at them. It's his presentation. And as he looks at his presentation, where did you get it? He looks at her, but she can't read. She's uneducated. He

goes back in his office. And as he's going, she says, "Sir, I read it and there are problems with it." And off. Right. And he goes and he reads it and there are problems with it. And

there's a knock on his door and suddenly she says from outside, "Sir, I've also written a presentation and she pushes some papers underneath." He reads them and they are correct. They're right. So

here's the question. How did she know? He'd gone to Harvard. He'd gone to MIT. His whole education was in the West and everything. And he hired Mckenzie's. Mckenzie's charged him $3 million. It's

a $10 billion presentation. He went to Harvard. He went to Mckenzie's. There's a whole thing that he lived on the top of the pyramid. She lives in the bottom of the pyramid. My whole contention is

when you come here to India, everybody that I walk talk to right now, I need AI. Why? Because I want to better my life. I need AI chat GBT because I want to better my life. So when we go to the

bottom of the pyramid, what was working for her that did not work for him? What was working for him was that he was not aware of the rest of the people he lived there. She needs to feed her

children. She needs to make money. She needs to survive. And somebody said, "Hey, there's a new language out there called prompting. Why don't you learn that?" She learned prompting to feed her

kids, not to raise $10 billion. And when she learned prompting, now they're equal. The pyramid has collapsed. Why is she winning? Because she's has what he's lost, intuition. Because intuition comes

when I'm filming and I have 600 people. I don't know what to do. intuition kicks in. If there's a t I can go on talking about oh my god if there's a tiger and coming in when the tiger actually is

pouncing at me intuition fits in ces in so intuition at the bottom of the pyramid is what's going to drive the use of AI because they need it it's need-based that's what we keep

forgetting we keep talking about the top &gt;&gt; so if if we talk about intuition if we talk about um you know the nec it being a necessity and if we talk about what you were saying that you know what's the

you know what's the culture that you want to create you know let's divert it towards that uh rather than talk about you know yes surveillance is an issue but talk about what we could do with the

tool rather than the tool dictate to us but in this backdrop Suk how does it feel when you look at you know when you look at cases where uh an author has been um you know

someone else has taken over the tone of the author or someone else has taken over the the voice of an actor. Uh so how do you how do you deal with that? &gt;&gt; I I think that uh all really

um exciting dynamic um arguments. However, I do think it's important to acknowledge power dynamics. Uh when we talk about surveillance, we're talking about asymmetry of power. If you look at

state power, there are only a small number of countries that have really advanced AI capability. uh within a society also certain people who hold power have uh command or own

the the platforms or structures for AI. The power of AI is in the hands of maybe six 10 companies around the world. So I think we need to acknowledge that there's an asymmetry in terms of power

dynamics and that uh we should not be dismissive of the concern about surveillance. However, I do think that we should reclaim agency in terms of intentionality.

I think it's what Vas was talking about like when you walk in just imagine every session that you have with an AI, you're walking into a room. What are you what secrets are you giving to the AI and

what are you taking away? And I think it's the intentionality that is a form of AI literacy that we do not talk about enough. Um however I think the the optimistic news is that when we talk

about the democratization actually we all have some ability to design system shape data sets. I mean I'm not a technical person but I have like vibe coded things by now that they are not

very good but you know at least I could do it. So I I do want to invite everyone first of all to understand the power dynamics, be more intentional in every encounter in terms of how you're using

AI and what you're trading off for output, but also to become co-architects to not just kind of be passive victims of what AI is doing to us. I think there's too much of that language of AI

is doing this to me. Uh AI is surveillance. But I think we need to think about we are building and creating the tools and models is up to us to step in and co-create it to resist if we have

to. Yeah, I really like that. And if we as we come to the close of this panel discussion, I want to uh do something slightly provocative. Right. So this is the rapid fire one question, right?

Rapid fire one question. Uh &gt;&gt; I would like each of the panelists and we'll start first. What is the one thing that you would gladly give over to AI and you can't say you can't say you know

chores like uh washing clothes and things like that, right? So what's the one thing that you would gladly give up to AI? So uh let's put uh Shaker on the spot.

&gt;&gt; Um I cannot speak for the whole society from the top to the bottom. I'm I'm a privileged person, right? There are millions of people here also who will gladly give up, you know, and I give up.

Look, there are I would give up education to AI, right? I mean, listen, the whole education system, the informal education system is worth $30 billion. you know

all the coaching classes and everything that you see chat GBD could take it over today middle-ass families are foregoing a meal a day to send their kids there the day chat GPD says we'll give you a

certificate it'll take it over so I would give over education to AI in India now education Oxford or Cambridge no maybe not but I'm talking about here I live here here's where I see it all for

me I'm very happy that AI will will is will is bringing the bar The film that used to cost me $300 million in Hollywood will cost me $3,000. Why would I not embrace AI? As long as I can tell

an unpredictable story, storytelling doesn't change. As long as I can be unpredictable in the way I show it, I love AI because it brings down the cost. I can go and compete with Spielberg. He

gets more money than I do, but I can now make a film cheaper and compete with him. &gt;&gt; Okay. So uh it's a bit uh disconcerting that I'm the head of an educational

institute that we will but but but I understand no I understand and appreciate appreciate the honesty. So I will go to suk like what's the one thing you're willing to give up to AI? We we

we've got to wrap up I think in this. So I'm going to I'm going to take these answers. So one thing you will give up to AI but not chores. &gt;&gt; Not chores fighting with people over

money. Yeah. Fighting with people. &gt;&gt; So, so you'll you'll get AI to fight with other people for your money. &gt;&gt; Yes. Yes. I think fighting with people

in general, but especially over money. &gt;&gt; Okay. &gt;&gt; Yeah. If it's possible, if I can sign AI agent to negotiate for peace and more money,

&gt;&gt; Olivia, &gt;&gt; I would have gone with education, but it was already covered. Sorry. &gt;&gt; No, but I think uh we converge on that. It's a lot of people Yeah. back to what

information you share. Honestly, if a kid has to share information about themselves interacting with a model that makes them better at literature, better at languages, better at maths, etc.,

I'll happily let my kids share that information if in return they have education they wouldn't have otherwise. So, education being covered. The other one is you we need to stay alive,

health, health and healthcare. And the fact that there are so many things that can be enhanced with systems and the fact that today in the region of a world where I come from because of AI

regulations, there are solutions that could save people's lives that are stuck on shelves just because some people are regulating AI based on processes and not on outcomes. If a solution is legal,

ethical, and it saves people's lives, it should be out there now. And to round it up, Villas, &gt;&gt; these are great answers, but I have to tell you, I'm very jealous of my

humanity. Like, I own it tightly. I don't want to give up very much at all to AI. I don't I like the things that I can do in this world. I like the things that make me grumpy. I like the things

that I argue about with my friends. I like the things that don't work because they tell me what's valuable. They tell me what does work. They help me be the person I want to be. So, I don't want to

give anything to AI. Now, if AI will help me do those things in easier and faster ways, great. If they will help me be the person who can express myself in better ways, great. But I don't want to

give up education because I want to spend time with children. I want teachers to be there. I want to build them not just as people who know facts, but as people who understand their

emotions and maturity. I don't want it to be health because I don't want a computer to make health decisions for me. But if it will help a doctor support me when I have to get bad news, I'll

take it. I want AI to be something that makes us more human, not something that makes us less. And that means we have to build the systems that we want. [applause]

&gt;&gt; And if I were to round up having sat here and listened, I would say taking what Shaker said and all of you did. I would give up to AI my adulthood. I would go back to being a child. I

would go back to being brave and I would say, "Hey, help me retain the humanness in me and let me not get cynical. Let me not get defeated by the things that come my way, but give me the eyesight to see

future, see hope, see the goodness that we do to each other." And so, yeah, let's go back to being playful and children and being creative in everything that we do. So, thank you so

much for joining this panel. Thank you for being such a wonderful audience. &gt;&gt; It's time to be unpredictable. You all want a selfie with uh my neighbor here. You all go down. We're

going to make one big selfie, the biggest selfie of this uh event. So, everyone goes down here and let's go here. So, that's we're going to save you some time.

&gt;&gt; All right.
