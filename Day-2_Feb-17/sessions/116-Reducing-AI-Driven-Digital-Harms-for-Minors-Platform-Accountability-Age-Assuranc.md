# Reducing AI-Driven Digital Harms for Minors: Platform Accountability, Age Assurance, and Safety-by-Design

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 14:30 ‚Äì 15:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 10 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/ABbFuQLv0fY?feature=share) |

## üé§ Speakers

- Abhineet Kaul, Access Partnership
- Aleksandra Chmielewska, UNICEF
- Kelly Forbes, AI Asia Pacific Institute
- Libby Giles, New Zealand Centre for Global Studies
- Niki Natrajan, Department at Rutgers, State University of New Jersey

## ü§ù Knowledge Partners

- AI Asia Pacific Institute (AIAPI)

## üìù Summary

Over the past decade, digital platforms and AI have transformed how children learn, socialise, and access information, including within schools. While offering benefits, these technologies also heighten risks such as harmful content exposure, harassment, privacy loss, addictive design, and mental health impacts, with generative AI amplifying scale. This panel explores global policy approaches‚Äîduty-of-care, age-appropriate design, age assurance, recommender governance, and education safeguards‚Äîto balance innovation with stronger online safety for children.

## üîë Key Takeaways

1. Over the past decade, digital platforms and AI have transformed how children learn, socialise, and access information, including within schools.
2. While offering benefits, these technologies also heighten risks such as harmful content exposure, harassment, privacy loss, addictive design, and mental health impacts, with generative AI amplifying scale.
3. This panel explores global policy approaches‚Äîduty-of-care, age-appropriate design, age assurance, recommender governance, and education safeguards‚Äîto balance innovation with stronger online safety for children.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/ABbFuQLv0fY/maxresdefault.jpg)](https://youtube.com/live/ABbFuQLv0fY?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

AI across various sectors but especially more recently education. So many governments have announced to be integrating AI into school curriculum and um with that there are also

new issues around online safety that we are seeing an increase of. Um for I guess background we have the AI Asia Pacific Institute that is hosting this conversation has done in the past uh

great work with nets safe covering um issues on the rise of the intersection of AI and online safety. Those issues that were introduced to us with the rise of the internet such as misinformation

which are now being aggravated with the rise of AI. We are also about to embark on the journey collaborating with access partnership that join us here today uh covering particularly what we are seeing

globally on the landscape of governments issuing regulations to protect children particularly uh but also how does that influence how education and the future takes place

across those issues. So uh we will walk through um each panelist one by one here but let's just start with thinking about can you give us some introduction to the work that you do starting with you Libby

and uh what are you seeing globally when it comes to safety the rise of particular issues and also regulations from New Zealand it's really lovely Now that's better. Thank you. Um so

thank you very much for having me and and as Kelly said this is rapidly developing issues here. So net safe started 20 years ago when um when internet was being increasingly used in

schools and kept safe. We started with a product called Hector's World with this little dolphin appeared on your computer screen to give you a little bit of a warning when you might what to do if you

maybe stumbled across something that you shouldn't. Of course, things have grown really rapidly since then and now exacerbated it such as with AI misinformation and so on. And so our um

our approach really is about practical ways to keep people safe, to keep children, their families safe, and stakeholders there's no simple fix here of course uh rapidly developing

conversations about increased regulation from some regulation to outright banks so I think we'll pick up those discussions a bit as we go &gt;&gt; hi everyone uh good afternoon my name is

Ainid I'm a vice president with access partnership I lead a lot of our work globally on AI and as the generation which is obviously responsible for developing AI and deploying AI Okay, we

obviously have to look at both the sides the opportunity and how do we harness that uh looking at the scaling aspect the adoption aspect but also mitigating the harms right u and the the question

about AI is not that how AI is in children's time it's how it's structuring their childhood that's a big change uh we all had we didn't have digital technology when we were kids uh

but now you are not only talking about where is the content store it's also about what what content are they seeing, what content are they sharing, what content are they creating with with AI

and so on. Right? So what we are seeing globally in terms of regulation, we're seeing a clear shift uh from voluntary child safety commitments. There were countries which said have some

commitments. UN has had some commitment. Everybody talked about like we need to have some child safety commitments to something which is more binding obligation uh and posible duties of care

for everybody from from platforms all the way from a shared responsibility perspective. We are seeing a lot of convergence on the same pillars right based foundations safety by design for

example and as Libby said we are seeing those two extremes you have on one hand more age based restrictions u you have heard a lot about some of these things obviously there are challenges pros and

cons of all those approaches but on the other side we're also seeing a lot of uh systemwide controls uh which is minor modes content classification we'll we'll go through the session as we go through

so there's there's obviously a wide variety of how and countries are trying to agree with this solution. &gt;&gt; This works. Yeah. Thank you.

Good afternoon everybody. I'm Nikila Natraan. I go by Nikki among my friends and colleagues. Um I'm a youth and media researcher. That's a fancy way of saying I hang out with kids and teens and I ask

them these questions that we're bringing to this conversation and I tell those stories through their voices. That's the work that I do. And my entry point into this conversation today with all of you

would be from the vantage point of the pillars of this conference itself. People, planet, progress. Out of that I'll choose two people. Who are we talking about? We're talking about

people we love. sisters, brothers, daughters, sons, grandchildren. These are very special people, right? And when we think about progress, we

think about progress in those in the context of these children and teens. We're thinking basically about how do we create the conditions within our homes, within our families, within the larger

technological environment to keep them happy for their well-being so that they thrive, they have the best shot at a future that is bright and and good for them.

And um with that, I will start with some provocations for this room. First and the most important, youth voices and youth perspectives and their

experiences must be centered in any conversation about technology policy. They have to be at the table. Second and connected to that is that if we take a developmental lens to this

problem, not come to it from the point of view of the technology, take a developmental lens. How do they grow? How do they develop? What are the characteristics of teens that we must

pay special attention to? What is it that makes media use and technology use really challenging for them? Where is the opportunity? then we can reorient this conversation in a powerful way

because institutions are usually slow to respond and it's like a bicycle chasing a race car. So that's the second thing and the final thing I think is India in the last few weeks alone has given us a

powerful and timely example of what common sense regulation could look like. You'll all remember January 3rd that week u the gro issue with the obscinity with the women's pictures and how India

responded especially matey and that response is essentially rooted in our culture we can do this it can be that simple it can work and there is broad public

agreement here in India for that move so I think Um, just one last thing because before I hand it over to you, Alexandra, while I was on this flight, long flight from New York to here, right? 8 hours

plus 8 hours. So, there's a bunch of youngsters next to me in the in the middle aisle with the four seats. So, we were passing notes to each other and I was asking them, you know, India has

done this. What do you think? You know what they told me? They said, you know, this should be an international standard. And they were from everywhere. They were from France, actually. They

were going to Singapore and on the way they were going to Rajasthan and these guys they told me all three boys they said this should be an international standard. It's a great idea.

&gt;&gt; Um thank you so much. Um so I'm Alexandraka and I work for Giga which is the joint initiative between International Telecommunications Union and UNICEF. Um

and our goal is to connect school every school in the world to the internet. So you know before we even start discussions about AI we always try to make also try to make sure that we

bridge the digital divide at the very you know the the very basics right so we still have more than um 30% of population that doesn't have access to to the internet. So we have to also

consider this when we are discussing about AI and equal access to AI. Um but my perspective to this panel will be u you know twofold. First um sharing what UNICEF and other um European countries

most have been doing to make sure that young bosses are included and I'm glad that you mentioned that and there have been a lot of developments on that matter since December last year. Uh but

also you know I'm here I guess the youngest panelist so we haven't really discussed the age though but it seems to me so um I'm also wearing a hat of a person that's you know I can call myself

a generation social media Facebook generation um I grew up basically when those platforms were created and developed um and so I witnessed firsthand how it

really impacted the relations you know our brains our selfdevelopment without those platforms being regulated, right? Um so um you know we we had evidence a lot of evidence about harm

that those platforms are are posing and there has been researched and leaked by turn by by Mera that was saying that one out of three girls um that is interacting with with Instagram uh is

thinking badly about their own uh bodies. Um, so now we have AI that is being embedded in those platforms and I'm just glad to see that we finally start to discuss how to regulate this

but I believe the majority of us unfortunately have already suffered some consequences. Um, so that will be the perspective that I will &gt;&gt; Great. So we have a lot a lot of great

things to start with not enough time unfortunately like to stay with you Alexandra because um I think a lot of great things were mentioned including Dr.

talking about the approach of India. Um we're also going to talk about stride as well but I know you're based in Spain and Spain has also introduced some new ways of thinking about this. I think

research now tells us and we have had many incidents particularly in the last year or so of teenagers and children and the real harm that some of these tools can take um can take a toll on people

and Also we are faced with this question where does accountability lies right does it lie with the organization the social media companies uh what exactly

does the government need to do and is that approach working right is that is regulation the way forward so what is your perspective on that and particularly from what you're seeing on

the ground &gt;&gt; um yeah of course thank you for this question among the European and young countries has been really at the forefront of uh

you know proposing progressive laws to protect children from the harm that is being created by the platforms. Um we follow the example of Australia all right that is really a front runner when

it comes to banning access to social media and setting the threshold at the age of 16. Spain is currently proposing the same thing and is leading a coalition of six other European

countries that are not only suggesting a threshold but also proposing to uh ban um you know such harmful uh social media features as infinite scrolling that I think we've all been suffering victims

to to that. Um I do believe regulations uh is important and unfortunately we can see for the moment that the system It puts the burden on parents to police uh the access on kids to self-regulate on

educators to manage access to the platforms and of course you know it takes a village to raise a kid but the village also needs to have resources right so um so we really really need to

make sure that we have laws in place and not only in place but that there are enforced um so EU a transferability um I don't want to steal more of the time but The AI act is really a groundbreaking um

proposal that was enforced in February last year. But we still have to see what what will be the results of the um of uh of those regulations. So it's very early uh but as a society overall we need to

just argue towards the governments to make sure that platforms are accountable and that we shift the burden from the village to um to uh to the companies. &gt;&gt; Right? So let's now Think about building

on that context we know that safe is based in New Zealand and it's also which is a country also observing the steps of other countries right including the very close neighbor Australia. Can you speak

to that and what you think that approach means? &gt;&gt; Certainly I can. Thank you very much. And I'd really like to just tap into what everybody has talked about here is

that we're really talking about humans here. We're talking about the effects on people and understanding who we are in this place. So in terms of the New Zealand is watching very closely the

Australian um developments and what's and the trend in Europe as well. There is a bill before the New Zealand parliament to ban social media for under 16safe

actually is opposed to that idea. Um we actually think that it's it's a lot more complex than that. It's accountability is a shared thing and that it doesn't actually it's not likely to improve

safety. more likely to make things go to ground you know so we'll hide it um it would be we should be cautious perhaps and see what happens in Australia um well actually we already know quite a

bit of what is in fact a lot of kids are still on their social media they're not being thrown off by the platforms so it's very much as we see a shared accountability and um and this has

really got to be about building trust and relationships across across the sectors but We just we actually think that for a lot of reasons we should be really cautious

regulation may help some regulation to some level but when AI is shaping what children are seeing in learning some very quickly uh

something that we need to think about is when we talking about AI and regulation I think wholesale we need a new vocabulary to talk about AI because if you open up your phones or your a young

person's phone AI is present there in many forms so there's an inventory of media that they use which has AI embedded in it and that's the engine that is behind their

feeds which I've called an ambient AI media environment. So when we're talking about AI we are essentially saying what that it's predicting based on your past patterns of behavior and it's predicting

something that is incentivized to make you stay or if it's not social media it's incentivized to give you instant rewards. Now, the reason I'm bringing

this up to this room and asking us all to think about it is that young people, children and teenagers, they are they're in a place where they're exceptionally fast at learning

things, but the way they're developing, they're like a race car where the brakes are still being built. So, the onus of decision making is put on the kid, and that's not okay.

So the reason I'm saying this is if we start thinking about this stuff like this then no matter what technology comes next we have a better toolkit to deal with it. Just some thoughts. Yeah.

&gt;&gt; I I just to add I love what you say that because we are all currently struggling seeing deep fakes online and having to decide is this is real. This is not real. And

our grandmas get extremely upset when you tell them this is not real. Right? So you can imagine the pressure that children currently face and how do we expect them to be able to process that

information in the same way when their brains are still being formed to make those decisions right much about I think learning about AI is building the capacity to know when it's lying to you

when it's hallucinating. Right? and children are still not properly equipped to deal with that. &gt;&gt; Yeah, could I add? I mean, um, great points made by by the panel. I might

disagree with Alex a bit because I think it's it's not just the provider's fault or it's not just fully responsibility of the provider. It's a shared responsibility. It's but it's not shared

equally. providers obviously have to do a brunt or they will get a big chunk because they are deciding what type of recommendation what type of content is going to the kids and what type of

content they are generating and how is distributed but it's obviously responsibility of the parents and educators and to your point I think I'm very thankful that at least for kids we

have parents and educators who can build resiliency and literacy for seniors we don't have any of that that's a totally entire panel topic but we'll come to that separately but it's also the fact

that it's not longer a conversation about content takedown or content related issue. It has to be by design which is where the role of regulatory is also important. You can't just have kids

locked down and their entire childhood becoming a biometric lockdown where they have to keep proving their age every time they log in. Right? I I came from a my childhood was in an area which is a

very militarized zone. I know the PTSD of like seeing you being checked every time. Imagine these guys are online on any platform and they are asking them for in an ideal world age verification

but in the real world they're asking them for digital ID verification which is a lot more data which is not really required but that's where because there's no design there's no systems to

comply to just look at how do you just check the age so to me it has it's it's a governance issue it's obviously an issue which the platforms have to take the brunt of it but it's also an whole

of society issue as So now I want us to I guess take all these concepts and ideas and think about that in a context of education right because we know where where I'm based

the UAE has been I believe the second country to announce that they introducing AI into school curriculum right after the US I believe um and you have seen a drive from other governments

following that approach as well of course we don't want to leave children behind So they need to learn about AI very quickly. On the other hand, one growing issue that I'm seeing and

watching very closely is that you have all major technology companies forming uh large partnerships with local schools and governments to not only provide the whole technology there but also shape

how education will happen in many ways. Right? And we know well this is now happening not just inside social media this will happen inside schools as well. So how do we go about shaping that in a

way where we also see how there's almost a point where they been taking advantage of the fact that governments are almost often slower to introduce safeguards and they know less

about the technology. So technologies so technology companies can come in a lot faster and say here's all we can provide and let's design the way that this is going to what way this is going to go

right so shall we start with you Dr. what your thoughts on that? &gt;&gt; So, uh, Kelly, you're basically asking about AI in education. Basically, AI inside schools, right? Ask the kids.

They have amazing stuff to say. Um, they'll say it's cringe. They'll say it's creepy. They'll say it's disgusting. And they're very nuanced when they respond. And since I've been

chatting with them and doing surveys, they are really happy to talk about this stuff. and they know where the red lines are. We just have to listen to them. We just have to ask them. Every student

that I've spoken to in middle school and um high school and I've spoken to hundreds of them and done a survey statewide in New Jersey, the general red line that the children draw is look, we

don't like this imagebased AI stuff where it kind of gets into our creative stuff. just stay away you guys. They they don't like it. But um Frank, a 16 year old boy, he's using it for square

roots because he he's an athlete. He doesn't have much time. He's using it to learn stuff. So I think uh children are unique and their uses of AI are unique. Um and they absolutely have the right to

know how um the incentive structure works and how these companies make money when they're learning so many other things right on these media platforms. Certainly this can be taught because

once they understand how their attention or data is bundled and sold, let me tell you, they'll have surprising insights to offer us on how to regulate it. Um I can just add to that. Um it's it's

amazing that we've been involved in consultations with with children and as I said at the beginning there has been an increasing effort by international organizations also to include uh

children in the discussions about the use of AI in in education. I attended an amazing panel yesterday organized by by UNICEF and there was a young UNICEF ambassador that was pres presenting um

UNICEF uh children and youth statement with eight very clear asks one of them is to be you know part of the of the conversations and the consultations the statement was produced based on

consultations with more than 50,000 children from more than 180 countries. So it is happening right the involvement of children the it is happening. What is important in my mind is to keep you know

to make sure that children are being consulted but they're not being held accountable. Accountability should still lie within the regulators um you know and platforms.

I think that's an important point right it is distributed yes but at the end of the day um yes governments are still task with the role of um managing policies and regulations even though it

does impose a higher challenge now because often times you're regulating something that is you know fairly new and introduces to us a lot a lot more new challenges that we've experienced in

history of times Well, yeah, I think great points again on uh in school. I think kids know that if they don't have access to AI, they lose out in the market because we keep

saying people with AI won't take your job. People with AI skills will take your job. So, kids obviously are mindful of that. Uh they want to learn more AI. However, obviously, as Alex talked

about, there is that whole concern when does it change from from just learning to continuous monitoring. How do and even at a school level how does it become something which sort of profiles

them which sort of tracks them which sort of follows them throughout the years right from all the way from grade one all the way to till graduate school then college how does it become

something which is which is profiling them even in their like this particular kid is a problem child for example right so all of that stuff obviously should not happen right so that's how do you

have a guard rails around that uh and there are four things which obviously we talked about in some of the work that we have done we talked about how there should be strict boundaries on data.

What is that data used for? How do you sort of look at that data? Impact assessments before deployment. That's where the school's responsibility is. They need to look at before and platform

as well. How do you deploy some solution so that it doesn't obviously impact the procurement aspect, the governance aspect? How does how do you keep keep track of that and surveillance should be

avoided at all cost? default should be there should not be the AI system should not be used for surveillance in a school environment in an education environment because that's something which is very

easy to go down the slippery slope it's very obvious for schools and education institutions why we need to do that how should we profile but that's something which obviously has to be avoided by

default &gt;&gt; oh yes thank you there are so many so many pieces to pick up here it's hard to know where to start but for me in the education space we need to be bridging

uh the gaps between polic and practice we having impunities and uh sometimes um new policies are reactive not proactive it can be really hard to keep up so in this

hyperconnected world full of challenge and change I think it's really important that and has also picked up on the lifelong learning piece right so this isn't just children people of all age

need to have some understanding here and in terms of shared responsibility we need to we need to be teaching people uh some basics and working on is the concept of digital global citizenship

and who is that person? Who am I? Am I a school kid? Am I a grandma? Am I um a parent and how how do I identify that digital global citizen? How am I connected to everybody here and what is

my responsibility so that I can ask big questions like how do I know what's real? And when I do figure out what's real, what do I do with that information? So that actually everybody

responsibility as a person. So this is this is &gt;&gt; great and I think just building on that and something that Alex like Sandrea also mentioned is one of the largest

issues that we have with AI is of course the digital divide and how it's leaving a lot of people behind as well and that is almost more serious than oftentimes right because when we think about um

even more serious than exposing children too much to the risk of of AI it will be the separation from the children that will never have access to that because they don't even have access to the

internet right now in a lot of countries or remote parts of the world, right? Um but I want to ask I guess thinking about um action and concrete ways that we can shape this conversation. Um, one of the

things that came out of out of the study we did in collaboration with netsafe was that we thought about what would be the recommended approach going forward and we came up with three steps right is the

preparation for as we know this is an ongoing process in terms of how technology is changing um is the code process when we need to think about what are the changes that must happen and

then finally how do we intervene when things go wrong. So that means in practice agencies or you know now you have cyber agencies Singapore has also introduced as one of the first countries

to do that right that you can report real harms and that that is how so how net safe works right um so where people can go to when you have issues as bullying um cyber bullying harmful

content um subject you know, deep fakes being made out of you that are not real, right? So, influence and this is these are things that are very very real happening in a lot of households right

now. So, can we go back to each one of you and think about what would you propose that would be tangible steps? What do we need to see? Um I think Levy for example when we talk about

regulation perhaps we're saying perhaps that is not really the right way. What how should we be thinking about this? &gt;&gt; I think the first thing to do with the regulation is to have a conversation

with the public. I think this has become a binary argument. Are you for it or against it? And actually it's much more nuanced than that. And most people really not sure of the ins and outs.

They're not sure of why um why banning or might not. So I think it's really important and we don't just rely on digital tools to find these things out but actually that we get into

communities and have these conversations so that we can we can actually see what will be effective for our young people because the whole point is we want to prevent harm and we want to promote

positive engagement in the digital world. U uh for some reason I'm the only one with a unique mic. Uh but anyway u on the

points you highlighted. Yeah, &gt;&gt; you can talk longer. &gt;&gt; I hope so. Uh so I think that there are obviously a few things. One to me is I I look at it from two perspective

in the internet age and this is I'm talking about preocial media. I think we were we had some tools we had mechanisms to deal with these problems. We have failed this in the age of social media

web 2.0 And we are obviously failing this in the age of AI. And in my head, the biggest factor is the fact that internet age was a lot more modular where content takedown was possible

because it was a single web a single website. Today in social media, you have to block a content. It has you have to work with the company. You cannot do it you know in a modular fashion. And AI is

the same issue. Unless and until we talk about we solve the business model problem, I think this is going to be a challenge. we have failed our kids in the age of social media. We will we'll

have the same challenges. I think that's one. Number two, I think on the on the point from the platform perspective, I think there has to be some sort of a risking. Uh not everything needs to have

the highest category of risk. There are for example public interactions, there are direct messagings, there are live streamings which are a higher risk. Maybe do you need a lot more preventions

there as compared to maybe some normal interactions like kids talking to each other on social media. What's the harm in that? Let the people have you have there are studies which say people also

kids also enjoy they find that as a way to explore the world and the kids today are a global audience how many of you here have kids who don't eat food without watching TV or without checking

out a game right I mean unfortunately only one I thought it's a very common thing I see it in any in I'm based in Singapore so anywhere I go every kid has a device in front of them because that's

the only way and you can't expect kids 10 years down the line not play games, not play, not watch YouTube because that's the experience they're growing up with. So, it's our responsibility to

make that something safer for them. Let me just stop there. &gt;&gt; I feel guilty now because I did get my child an Atari for Christmas. Does anyone know what an Atari is?

&gt;&gt; No. No. No more books, right? &gt;&gt; That is his first introduction to game. Yeah. So, &gt;&gt; so Abin, thank you for bringing that up. &gt;&gt; So, you heard what he had to say.

Now very interesting lens you can take to during this period between you know 11 and 25 it's a long period but it's a that's adolescence now so

people in that age group are much more tuned to their peers than to their than to adults in their house. It's not like they're not listening to you. It's just their peer orientation is heightened

during that time. And we can think about this differently rather than think about why are they on that app or why are they doing that during having dinner. Think about what does it mean? What are the

kind of environments we can create which has their peers around them or has those things that they are oriented to at the time when they want it and we could have a very different scenario.

The I the big idea here that I want to leave with all of you in this room is let's not foreground the technology or the technological harms. Instead, let's think how can we build a better

conversation with these young people so they sit across the table with us and talk because you want them to come back to you when there's a problem. &gt;&gt; Um yeah, so many points to um to to

discuss. Um I agree that there should be conversations with the society about regulations and um in fact I was just checking uh you know the stats about uh the public service about the threshold

16 um age thresh threshold adopted by Australia governments and um apparently there are 70% of citizens that support this but only 25% believe that it will actually work. So so we really have you

know a problem here right um basically people just no longer believe that regulations can work and can enforce uh things. You can um there is an example from the European Commission that has

been imposing serious uh fines on on meta for breaking GDPR uh rules and most of them I think it was 2.7 billion euros that Meta has to pay for breaking GDPR um regulations and half of this is

related to child protection policy but in the end the companies are doing costbenefit analysis and it's still profitable right so we are not talking about AI for humanity we're talking

about AI for profits. So I think my point here is we definitely need to make sure that there are more teeth in the in the regulations that we um and that we impose and yes I

I do agree with you the last points. I think the technology also reveals several gaps in the other systems that we are having and a lot of kids are consulting uh you know chbetd

uh to to discuss questions about mental health right so so the problem is not on the side of technology the problem is um on the yeah on the society how social services

&gt;&gt; yes so we still have about five or 10 minutes left I want to give some time for questions do we have Um any of the facilitators do we have a microphone?

&gt;&gt; No, I'll just swap to you. &gt;&gt; Thank you. Uh great session. Very good points that you guys uh discussed. My question is that uh do you think uh good solution would be uh appointing a

local leian for every district especially for a country like India where uh internet is free but education is expensive. So not every child has access to education or not every child

has a parent who is educated. So uh appointing a local leian for every district who educates and goes to every house and makes sure that uh especially the uh kids who don't have access to

such things but are using internet are using AI uh are educated in this way or are made aware of the consequences this way. &gt;&gt; Thank you for the question. Your name

Ankita. Thank you Ankita. Um what I do know and what is being discussed in some other rooms here so I'll bring it to you. I believe that last 500 million in India who still are like you know off

the off the grid in a sense that's really the focus of the India AI mission now and they're hoping to bring voice enabled um facilities to that to that population so that they can access these

services on voice without even having to you know type it out. So I think absolutely yes. Yeah. Is that okay? Yeah. Cool. Um, I'm actually from Australia, so I love that

everyone was talking about what we're doing in Australia. Um, but what I was actually going to like maybe a comment, maybe a question is, you know, when you were talking about the desire for like

high support but probably not effective or you know that you were saying before that maybe there's not as much impact being had on the platform. Um, what I would probably say is from a comment

point of view is that we have to remember that big tech has massive resources to muddy the water in terms of the conversation. So when this was happening inside Australia, you would

find a lot of people were in in ardent support of the programs but it became a very convoluted situation because the means of getting knowledge and understanding were were actually

impacted on. So the knowledge for people to fight back was actually problematic. Um but yeah, like I think that that was a thing in terms of what I see for you guys going through in New Zealand, in

Spain. Um there there is just a lot of complexity there with how that happens with big tech owning the means of distribution of knowledge. &gt;&gt; Yeah, thanks. And really interesting to

get your your comments there, too. I mean, obviously there's a couple of things here. We've got a lot to learn. see what happens, right? And also we know from the in terms of the

interaction with other people, you've got you've got kids in Australia who are 200 kilometers from anybody. So the the the need for that sort of social connection is really really important. I

think just something too I'm thinking in this kind of um education space is that and I know this is a pattern around in in many countries of of like getting back to the basics in education of you

know reading and writing and and having you know STEM and becoming more and more modular. We're not in the industrialized world anymore. We're in the globalized network

chaotic world. So, we need to get better at the complex and this is what we need to do. &gt;&gt; Okay, we have time for one last question short.

&gt;&gt; Hello panel. I am really loving this session and Alexandra you mentioned that many students these days they use CH GPD for their academic work. I myself am in high school and I look at my Ph and

publicity Gemini JPD it's like there are academic integrity rules because in the international bachelorette there there is a whole section on academic integrity but you can still not limit people using

AI you can make them use that as a guiding hand but awareness like aside from awareness how do you exactly think that can be like how will we be made to know what

are the consequences unless we actually uh like have that conversation. I think Nikki mom also mentioned that. So that's my question. &gt;&gt; Yeah. Um well I'm also using tragic for

the record. [laughter] [gasps] Raise your hand. Who doesn't? Uh I'm very curious. uh I was actually not arguing against the the the use of of you know AI and those platforms in G

education that would be unrealistic right so the question is not whether we use them whether we embrace them but the question is how and I do agree with you that's um you know we have to just put

an effort into educating children and also teachers um on you know biases hallucinations that those platforms can have and also learn a bit more critical thinking and and answers they're they're

giving us and I think you know some companies are already creating versions for young students like education platforms where where the chat doesn't necessarily give you directly the

answers but tries to enter with you into discussion and actually push you into you know like critical thinking so this is a positive step but it is here to stay um and uh you know even

organizations like UNICEF UNESCO are investing a lot in making sure the children and um educators are well trained and know how to use them effectively. We all use them.

&gt;&gt; I'll just add to what Alexandra said, tiny little story of Kelly will allow me. So back in 1950, Alan Turing um he came up with a question, can computers think, right? Which is that famous paper

which launched the AI uh field? But within within a short while he changed that question to can a computer um effectively deceive a person into thinking that it's this is a human.

Right? The the short point here is let us never forget that this began as a game of subtle deception. It was never meant to be overt. Right? And if we can call out subtle forms of deception as

deception, then we have a better starting point. &gt;&gt; Excellent. So we have about four minutes to go. I can see people coming into the room. Um less than one minute. What are

the closing remarks? What are we taking away with us here? So from my perspective is the most important thing is for us to educate ourselves. And I precisely think it's conversations like

this that really help us to do that. So I'm very grateful to this incredible panel here today. Thank you all for joining us. And let me pass to Lee. Thank you Kelly and thank you everybody.

And I couldn't agree more. It's about educating ourselves and each other. It's about stepping up to the world with confidence, courage, and a sense of shared responsibility.

&gt;&gt; I have a mic. Uh and I must compliment the fact that in the world of or everything fake we have real flowers in front of us. But the to answer to to that point I would say u uh in in a

world where you know we are sort of living the fact that there have been a lot of effort by parents and a lot of responsibility on parents and educators fighting upstream against all the harms

like 72% I just read a study I don't know how true it is but 72% of teenagers in in the US have intimate conversations with chatbots massive issues right and we are just focusing on parents and

educators fighting against this thing rather rather than looking at can we look at the business model. Can we look at this thing from a design perspective which is where some of the countries are

taking steps. It's not a yes to technology versus no to technology. It's about how do we get a safe environment to everybody. So that's that's what I'll maybe end up with.

&gt;&gt; Thank you. Youth agency comes from a very difficult juncture in development. Recognizing it is central to us having better conversations. &gt;&gt; Uh thank you. Yeah, I think we're at the

inception point. We're really seeing uh lots of you know laws, regulations and activities by the countries international organizations happening. So that's definitely uh very positive um

only 22 years after Facebook was created but still you know that's there is a progress uh but I wanted to to end on a on a positive note so just plugging all those positive things that are happening

you know we really need to look at Australia as a as a test bed if it if it works and ultimately just make sure that technology does not extract the value from children but empowers them and I

think this is something that We were just starting to observe. And on that note, thank you so much and thank you everyone for joining.
