# Open-source Tooling for Safe, Secure and Trustworthy AI

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 16 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/qstAnmC_GaE?feature=share) |

## üé§ Speakers

- Amanda Brock, OpenUK
- Audrey Herblin-Stoop, Mistral AI
- Mark Surman, Mozilla 
- Balaraman Ravindran, CeRAI & IIT-M
- Oliver Jones, UK AI Security Institute
- Karine Perset, OECD

## ü§ù Knowledge Partners

- OECD

## üìù Summary

This session will explore how open-source tools support safe, secure, and trustworthy AI. Panellists will discuss the open source ecosystem, identify gaps, examine capacity building in underrepresented regions, and present a call for submission to the OECD.AI Catalogue of Tools.

## üîë Key Takeaways

1. This session will explore how open-source tools support safe, secure, and trustworthy AI.
2. Panellists will discuss the open source ecosystem, identify gaps, examine capacity building in underrepresented regions, and present a call for submission to the OECD.AI Catalogue of Tools.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/qstAnmC_GaE/maxresdefault.jpg)](https://youtube.com/live/qstAnmC_GaE?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

I think I think we're short. want to move down because remember we had yesterday at the Oh,

&gt;&gt; there you are. &gt;&gt; Welcome everybody. Good afternoon. Uh welcome everyone um to uh the uh today's panel on democratizing trust open-source uh to

enabling uh tooling and to enable safe secure and trustworthy AI. We're going to start with a group picture. Sorry about that. Um it'll be quick. Stand up.

&gt;&gt; No. Okay. So, with that, I I think we can get our panel started. Um, I'll make a few introductory remarks before we dive into

the the meat of uh and the really exciting part of our of our session today. Uh, we're currently living through an extraordinary moment in AI development. Um we over the past couple

of years we've uh seen rapid advances in AI cap capabilities but also growing questions about trust, safety and who gets to participate in um shaping AI's future. Uh at the OECD uh and the global

partnership on AI, we've long believed that AI systems should be both innovative and trustworthy while respecting human rights and democratic values. And that's why the OECDI

principles adopted back in the Middle Ages 2019 emphasized that the development, deployment, and use of AI systems should be guided by factors such as transparency, accountability,

robustness, and inclusive governance. Um, and in line with these principles, today's discussion uh is going to center on two critical question. First, how can open-source tools help democratize trust

uh in AI systems? And second, how can these tools support safe, secure, and trustworthy AI development? Um, so through throughout the the conversation, our panelists will explore one, what the

open-source AI tooling landscape looks like today, uh, and where the gaps are. Um, two, how can open-source tools build capacity or help build capacity in under reppresented C regions? and three um how

how and which of these tools can help both the technical and the non-technical communities monitor and assess AI safety, security and trustworthiness. Um so before diving in I just give a

short recap on what lots of tools and metrics out there to help actors AI actors build and deploy trustworthy AI systems. But these tools are are often hard to find and at times

they're um absent from ongoing AI policy discussions among governments. And that's why we created a catalog of tools and metrics for trustworthy AI. We started that about six years ago. What's

hard is not building the catalog. It's keeping it up to date. Um, and that's really the the the grunt of the work. Um, so this is a available online at ocd.ai/catalog I/catalog and it's really

a one-stop shop to make it easier to identify type you helpful approaches, mechanisms, and practices. Um, and today the catalog features over 900 tools um designed to help AI actors identify

resources to develop, deploy, and use AI systems in a manner that's fair, uh, transparent, explainable, robust, secure, and safe while respecting human rights. And that's I'm not saying all

the tools do all that, but um looking through the tools, we have tools that uh that are specialized in uh at least some of these um uh values. And in line with today's panel and the work of the

summit's working group on safe and trusted AI, we just launched a targeted call for submissions focusing specifically on open source tools. uh and these submissions will be featured

on the catalog and also directly inform the trusted AI comments uh which is a key deliverable of the working group the Indian working group on uh safe and trusted AI of the India AI India impact

summit. So um now to explore these questions I'm really delighted to introduce our uh distinguished panelists. So with us today we have uh Amanda Brookke who's B Brook Brooke

sorry I'm if I butchered that rock who is uh CEO of open uh UK Mark Surman uh president of the Mozilla Foundation who also represents well get into he he he wears several very important hats. We

have Odre Erblan Stoop who's senior uh vice president for global public affairs and communications at Mistral AI a French AI uh developer. We have Oliv Ali Jones, Oliver Jones, deputy director at

the UK Department for Science, Innovation and Technology, who's responsible for international AI policy and Bala Raman Ravindran who's professor and head of the department of data

science and AI at the A India Institute of Technology, Madras. So, thank you very much for being here today. Uh, and let's dive in. Um, so to get us all started, I'd like to ask the same

question to all our panelists, I guess maybe from the the the audience is left to right. So starting with you Ollie, um, which is why are open- source tools relevant for trustworthy AI and where do

you see the biggest gaps in the opensource uh, tooling ecosystem and what would it take to close it? just then &gt;&gt; is this a bit better? Okay, fantastic.

Um, there's a lot in that question. I will try doing it justice. Um so uh for those of you who don't know the UK has an AI security institute which is the first um kind of statebacked research

institute um trying to advance some of the techniques and science on uh AI safety uh and evaluations. Um, we have an open-source tool. Um, I hope uh it's uh a recognizable name to lots of people

in the audience called uh Inspect um which tries to do exactly this um try and try tries to open source a tool for the benefit of a wider community which has um developed uh around it to try

solving some of these trustworthiness uh and safety kinds of questions. um uh how big is the gap I will I will leave to others. Um but that's our small contribution so far.

&gt;&gt; Thank you very much Oliver. Actually I'm going to I'm going to swap over um sorry for the change. I'm going to I'm going to move uh over to um uh to Amanda um because for Open UK's given open UK's

work and deliverables uh for the summit which I understand are pretty sizable um and uh and bring your perspective from open UK. &gt;&gt; Uh thank you very much for having me

along today. How many of you in the audience are part of the open source community made a contribution? That's really great to see and I'm going to start by saying thank you so much. We

had even more people in this room this morning. It was slightly chaotic but it's really exciting that India has such an engaged and large open source community. Um to answer the question I

think I'm going to talk about two things. So for those of you who know me and one or two of you know me very well, I'm an ex lawyer if there is such a thing. I was a lawyer for 25 years and I

started my open source career in 2008 in Canonicle and the engineers and I used to talk about issues and then I would go and talk to risk professionals in other organizations and what I quickly learned

that when you have a risk or a legal challenge around technology the answer isn't regulation and it isn't law it's usually a software or a technical solution and it it works best that way

because that's what the engineers the people who build the technologies understand and can work with simply. So if I said to you, here's a 2-in printer out of the EU AI act, go build some AI,

you're not going to do it. But if I say to you, here's the the UK's Inspect platform that will let allow you to self-certify the safety of your outputs, your LLM, you might well do it. And you

you can self-certify as well as do that through the AISI. So that utility of that tool to enable the process is critical and I think it was uh inspect was probably the first

big tool that we saw open source and it's critical that it's open sourced because then it's freely available to anyone to use for any purpose and that gets back to the you know what made open

source great what got us adoption was that free flow and that trust that you can put in open source that when you take it you use it you can pass it on to others so I think there's sort of

double-edged answer there. There's from a legal perspective, the best way to make this happen is actually by giving the engineers the tools that create your output. So, your outcomes that you're

hoping to achieve. And then I would say the second thing is that if you try to control engineers, tell me if I'm wrong, you fail. Right? You're all nodding. I knew you would nod. So, what you have to

do is engage them and take them with you. And by helping them and doing stuff that they want to engage with, you're going to get your best outcomes. Thank you very much Amanda and uh fully

subscribe to your um to your to your uh assessment that giving a a large document to engineers might not lead the the the results you are looking for. Um so Mark uh so I'm I

know I'm changing everything. Sorry about that. I'm spicing it up a little bit. Um Mark, I'd love to hear sitting in the wrong order. You're doing fine. Yeah. [laughter]

&gt;&gt; I'd love to hear your thoughts particularly from &gt;&gt; Okay, that was not me &gt;&gt; from [laughter] from Modzillaas and Roosts. It was maybe

the rooster um experience championing openness. &gt;&gt; Great. Yeah, as as thanks Karina and thank you everybody for having me here. As you just suggested, I'm here

representing Misilla, but also an organization that launched at the last AI summit in Paris called Roost, which makes open-source online safety tooling. And I would say kind of two things and

picking up a little bit on Amanda's uh one is really a critical thing is the tooling that allows us to look focused on open source AI tooling for developers. We're not building models.

We're really trying to make it easier to adopt open source AI. And in the early set of libraries we've released is something called any guardrail. It does exactly what you can imagine is there's

a whole proliferation of open source tooling around guardrails around evaluations making it easier to pull them in as a developer switch them out compare them the ability to consume

things which is what you know you think back to something like iuntu or or early Linux distributions what they did wasn't create the Linux kernel or the whole ecosystem they made it easier to pull

from the ecosystem so I think as we see more and more trust and safety tooling making it easier as a developer just to not have it be a hassle to deploy but easy to deploy is a really key piece.

And Roost is doing something in a very um specific area in that same way is that big companies Meta uh you know the formerly Twitter those types of folks have invested a ton in trust and safety

for things like um social media but most small companies don't have that kind of trust and safety tooling. What Roost is doing is making trust and safety tooling so you can do content moderation, CSAM

detection, all of those things free and open source so that if I'm a small startup, I've actually got an ability. Somebody like Blue Sky uses Roose's Osprey libraries to do 45 mill look at

45 million events a day. They do I think a 100,000 content takedowns and enforcing rules a day all through open source software that basically does what you know what Facebook does. um but

without having to have this huge set of resources behind it. So one thing is tooling. The other thing I would say and maybe we can pick it up later especially because we have a model builder beside

us is really looking at not just open weight models. I mean open safety is not just about the models but it does matter that the open source quality of being able to inspect and study what is inside

is really important and is much more difficult with you know models that have gone through this expensive pre-training and we don't know what went into them and so I think moving more and more to

where we can see the provenence of the pre-training what data went into it inspecting in a way that we can rely on so it's not just openweight models but something closer to open source. That is

a big gap that needs to be filled. &gt;&gt; Thank Thank you uh very much Mark. Um so now I'm going to turn to you uh and uh ask for your perspectives on uh MA your perspective and Mistar's perspective on

this uh especially given Mistra's leadership in this ecosystem. &gt;&gt; Yes, thank you. And I do not want to repeat everything that has been said. Um so maybe gives a perspective of the

model builder and why we believe that it's important that we have more openweight or open source model in this world especially where we see the trends going more in the direction of more

closed source model than than open ones. Um what we when we started all of this two years and a half ago, it was a strong belief within the founders that all of this should be open. Um, and why

they believe that is that because they were really convinced at the time and we are still even more convinced now that for such a transformative technology, a technology that has such a big impact on

our society, our government, our infrastructure, our defense, our power, soft power, outpour in the world that if it is just in the ends of a few largely American and companies. Um, it

ultimately can be a problem. A problem for each government uh to reclaim its autonomy, a problem for each citizen to know what is done with their data, a problem for company and enterprise to

know how to use it and to not provide all of their trade secrets uh to those model providers. Um and that's why at the very very beginning it was really strong for this company to to create

models that are open weight and indeed uh not fully open sourced yet. Um but we really believe that we need to put something in the end of everybody because then you give the control to the

people and you do not retain the control in the end of a few and for such an important technology it is so important. Um and on the the the tooling indeed having some tools like

Is this one working better? Yeah. Um, it's really key for small companies and and Mistral is just a two and a half years old company. So having the ability to build uh on top of open source

solution and open source tools is really so important for developers and engineer inside those small structure to actually move faster. Um and indeed we are facing the tension between trying to be as open

and transparent as we can and at the same time protecting our trade secret in a race that is going so fast and is so competitive and that's where we need to find the articulation and the balance.

&gt;&gt; Thank thanks excellent. Um so now I'll turn to Bala Raman. Uh and as chair of the working group on safe and trusted AI uh and given your academic background um what's your take on this?

&gt;&gt; Yeah. So so obviously we do support having more and more of these tools in the open source and uh not necessarily the model. I mean I I don't know if we have a say in whether the model should

be open source or not if people are going to listen to us but certainly the benchmarking the evaluation that are there right they should be in the open and at least as an academic I can tell

you that we are putting our efforts where our mouth is so all the all the work that we do at the center for responsible AI that I had are being put out in the open right so all the

benchmarks that we have built for India specific uh deployments and things like that are in the open but now stepping back and talking about the trusted AI comments a bit. So you had asked

initially what is missing in the whole ecosystem and I do believe a focus on the global south is missing right. So we don't have enough benchmarks. We don't have enough data sets to test our models

on and we already know that you know uh these know models fail when you're stress testing them on Indian languages and sometimes it's easy to jailbreak multilingual models when you're looking

at low resource you're interacting with them in low resource languages and so there a lot of these already well established things so in fact recently I was looking at the statistic so the

Delhi police have stopped using facial recognition technology because they feel that the the recognition rate is low for Indian phases and they don't want to rely on that uh too much as a

investigative tool anymore. So that's that's one of the things that is coming up. So a lot of these things are not even tested properly for the Indian context right. So as an example I was

usually quote this right. So a lot of work in India on building AI bots to help farmers help and so in the agriculture is a sector of focus here and somebody says that they have a bot

that can work in the agree sector. I mean there are you know people are testing it people are creating tools to test it when they are trying to deploy it in the market but these are not open

these have not these test benches have not really been evaluated they have not been stress tested by the community before we so that we we can't really you know rely on these as a benchmark right

even if there's this one company which is doing rigorous testing if the And this is a certainly something that's true across the global south and I mean some of the bigger organizations like uh

you know like working with ML comments people are trying to do uh kind of uh improve the representation of know resource constraint resource power languages in these tests but not enough.

I mean we are talking about a,200 just have to invest a lot of resource and this can't be done by one organization by you know one one country trying to invest in this it has to be a

global effort and that's what we are trying to hope with to achieve with the trusted AI commons work with uh you know organizations like OECD which have been doing this for a while but also try to

you know take the same protocols that to use but then give it a know more of a global south focus so that we we can make sure that uh AI models that are being deployed in applications

where most pe more people need it right are also trusted so I think that's we have to go that way &gt;&gt; thank you Balaran and those are those are really really critical gaps and

they're also yeah identified by the the an initiative that the we support at the OECD we uh where the secretary for which is the global partnership on AI and and of course that's that's a critical um

topic uh in that fora um so so now um I wanted to um ask you each uh sort of a question the same question um which is um um

which is really um kind of to to take to to look forward and um and um you know building on what you've all shared with us today uh and in light

of this year's summit focus on democratizing AI resources uh looking ahead in five years uh what would be for you a sign or a clear sign that an open-source trustworthiness iness

ecosystem has failed or has not or has uh succeeded especially for underrepresented regions and communities. So uh switching the order well this going to be complicated. Okay,

I'll switch the order for fun. Okay, Mark, &gt;&gt; let's start with you and then Amanda. Uh I mean I I I think where we want to be in five years flows from some of what

you've heard here and I think certainly generally the the shift whether it is you know safety or trustworthiness or just generally human progress looking at a much more distributed AI

ecosystem in terms of who builds things who gets to shape where they go who benefits from them. So I I think the global south is piece is is a absolutely central piece or one example of where we

don't want the core of what technology we all use in our uh lives. Like how many people here have a an iPhone or an Android phone, right? So they all come from about five

miles from each other in terms of where the software is designed. And so I I think where I would like to be in five years is somewhere very very different than that. We have an opportunity.

This is much more diversity in the production and the economics and the power structure uh of of how AI works. &gt;&gt; Okay, great. Amanda, so five years is a very long time. I

don't know where I'm going to be in five minutes, five days, five weeks, five months right now. Um, &gt;&gt; do you think so? &gt;&gt; I don't know where Karen is, but he'll

tell me where I'm going. Um, I think the the what matters, but the how is almost more important to me. And I think in the world that we are living in of this geopolitical shift of all the friction

uh Mark Carney's comments about middle nations if we want to have a collective collaborative AI future we have to be brave and we have to cross borders and continue to collaborate globally. If we

don't do that, none of this is going to work. Um, secondly, I think that if we recognize that we can't do this without open source, we have to pay it respect and open up the things that we use open

source to create. So what we give back, we have to, you know, give back properly and open it up and we have to see that shift coming from companies across the planet. And then I think the third thing

is about access and engagement with the open source community. So, it's very easy to say what we're going to achieve and to put a website together and fill it with tools that you're going to want

to use, but you then need to find a way to get that to the right people. And I talk about the submarine under the digital economy a lot. We are as an open source community not recognized in our

home geographies normally. That's why we're in small rooms. We are an internationally collaborative community. And to be recognized for what we do and what we build, we need to have

governments engage properly with your communities and talk to all of you. And it means they need to shift the communication channels and the engagement process from what they're

used to doing to what suits you. &gt;&gt; Thank thanks. That's that's great. Um I do feel a little you know targeted with a catalog of tools, but okay. [laughter] &gt;&gt; Sorry. No, it's not. It's just generally

how you can take that catalog and get it engagement with this this group of people. &gt;&gt; No, no, no, no. It's it's it's an excellent point. It's absolutely

accurate. Um, Balor Raman. &gt;&gt; H so in five years from now, I'm not even sure what the landscape of AI is going to look like, but [clears throat] as we all agree, uh, open source

should be a strong component of it. I mean, if you look at how computer systems development has happened, open source drove it in ways that we never thought wouldn't

have imagined if that had been just an IBM or a Microsoft driving the whole thing, right? Just two companies driving it. So, we don't know what would be the shape of things and and opening it up,

right? Uh uh will certainly get a lot more participation going in. So, having said that though, uh what is different with AI? I mean if there had been open source when there had been only

mainframes I'm not sure how much of an impact there would have been because there was so much investment that was needed in getting the hardware done before we

could you know think about open source software open source software had this impact because we had cheap PCs right right now if you think about the investment hardware investment needed in

building frontier models right it's it's exorbitant right so it's not that you know even if you open source things it's going to completely democratize it. People are just still going to be

fine-tuning these models. they probably know what is happening under the maybe they can be a little bit more focused in their finetuning of these models but truly to contribute in pushing that

frontier model capacity right we need to figure out how we are going to get this running on cheaper hardware I mean the entire stack should be more democratized and more widely usable before we can see

the true true impact of open source that's what I feel &gt;&gt; okay thank thank you uh Ali Oliver I don't I know what to call you. [laughter]

&gt;&gt; Thanks. Um so just picking up on on what we've heard, I think there's a big gap on um state capacity. uh basically um uh we are proud of uh of a quite a modest initiative uh a network of international

safety institutes and the point of that is to try getting uh inspect um and like tools into the hands of as many people as possible and I think this week uh if we're preempting by a few days um we're

going to welcome the uh inauguration of a network for the global south and I think that's a great initiative which is about building state capacity as broadly as possible so that we can avoid some of

the kind of uh pitfalls that we've heard um uh about a kind of um sense of disempowerment but also reduce the frictions of putting these tools in the hands of as many people as possible.

&gt;&gt; Okay, thank you. &gt;&gt; It's difficult to be the last one every time. &gt;&gt; I'm I I I won't do that again. I'm I'm winging it.

Um no on top of all of this um I think indeed if we want to make that work and and make sure that the biggest majority of people will access the technology um indeed that is was mentioned it it's we

need to make sure that it is culturally tailored for everybody and to do that at is what mentioned we we need to be able to have greater data sets uh more open data sets and and we need a strong

action from governments and and states and and universities to to make sure that we can leave in this world of nuance and knowledge with mainstream culture. uh and that's

but uh German, Italian and Spanish for the first model in 2023. Um and since then we we train multiple model in multiple languages but we will not succeed to

build trust if the models are not good enough in language. And when I say language, I mean cultural diversity and everything that goes behind it. And and we can do everything we can to to work

harder, have more infrastructure to train. If there's not a global movement to to share those data openly, uh we will not succeed. &gt;&gt; Okay. Thank you so much um to to all of

you for these uh these are really compelling visions. Um and um what what would um uh what what would so what would success look like? Anybody?

Uh so I'll give you three guesses at the word I'm going to use. Success would look like openness. It would look like openness that was trustable because it was transparent. It would look like

openness that created access for all and allowed more innovation and allowed all of you to access the tools that you need to build better AI. And I I'm going to just make a quick shout out for Ollie

and the work they've done at AIS. Um before when I was saying that we need to see our governance governments engage more with the open source communities, the people who are building the tools

and the cataloges engage with you all. AISI actually worked with us to do case studies when they first launched inspect and they came along to our last two conferences and they conducted

uh surveys amongst the open source community about how they should be doing this. Was this working the way we wanted it to be? And I think we need to see a lot more of that kind of engagement. And

we need to see open source and openness recognized as a digital public good where we've got funding globally from the public sector and our governments as well as from enterprises. And I think

enterprise and the public sector each keep each other honest by having them together and I think that's going to be really important to a successful and open future.

&gt;&gt; Thank you Amanda. Um Balor Raman from your point of view what what would success look like? &gt;&gt; Well given in the short term I hope we get the trusted AI comments up and

running have it. [laughter] &gt;&gt; Okay &gt;&gt; in in in the long run. So all right. So I would love for the entire community to evolve to start thinking about trust

primary objective not as a post hawk uh you know evaluation based verif verification that we do right now. So trust should come it should be the source of the design first before we get

into know let's do whatever works and then we'll try to figure out if it's trusted or not. I think that mindset really has to change in the AI community. Part of it comes from, you

know, the researchers never having to worry about real world deployment until about five years ago, right? So, I mean, we all working in the laboratories and back but then we really really have to

get this uh the the safety and trust as the central design tenant and once we have that and once we have our whole design ch AI design chain flowing from the trust, I think that would be the

ideal situation to be in. I don't I don't know if you'll need five years, but that's certainly what success would look like. &gt;&gt; Okay. Th Thank you. And uh this is a

really valuable perspective. Um Ali Oliver, what about from the safety and security standpoint? What is what does success look like? &gt;&gt; Yeah. So, um I think uh we could be um

over optimistic that the diversity of our open-source ecosystem is the total panacea to all of the risks that we um know now um and risks we don't even know about. Um I think you know even if we do

have um you know much better developed um uh ecosystem and state capacity I think success involves a recognition that there will be remaining gaps and I think there is room for

um a discussion at national and international levels about kind of resilience members and what the measures and what the policy response um could look like which I think is a is a key

component of a kind of wider um trusted ecosystem. At the risk of sounding a slightly uh down note, &gt;&gt; it's important to consider both the the upbeat and the the risks. Um we can't we

can't pick one over the other. Um okay. Uh now I I would like to I mean I I think I think uh as we move towards our final question uh we have uh 14 minutes left. I realize that it's it

would be pretty impossible to distill everything we've discussed. Uh but um if the audience remembers you know just one thing about open source tools from the session what should it be? uh and what

what's one concrete way they can help the the the public at large and and the audience in this room can help move this global effort uh forward. Uh so let's keep the responses to about a minute

each so we still have time for uh questions from the floor. Um and uh I'm starting with you. Um I think um the main thing I I I would like people to remember when we think

about how um how we should promote open source and continue to build on that. Um I think the the first thing is how do we foster an ecosystem? How do we make sure it's a

vibrant ecosystem? And that's the only response to actually closed approach is to have a very active open-source ecosystem. So my take would be to encourage everybody to build opensource

uh to build on top of open source models to build open source tools to use them to benchmark it to publish about it. Um, and the more we'll have a strong activity and a strong ecosystem, the

more we can build a very powerful ecosystem and and open source for the long term. &gt;&gt; Okay. Thank you. Um, Amanda and then uh Mark uh Oliver and Balor Raman, please.

So, it's Chinese New Year today and the Chinese ecosystem have built the leading position today in AI and open-source and that hasn't happened overnight. That's taken them eight years to do it. They

first announced in 2017 that they were doing this. They had a 5-year plan in 2020 and a new one at the end of October last year. And it's very clear, it's very straightforward, it's very

concerted. What we'll see from them in the next months and years is that they're going to reduce the number of competing Chinese open source products and they're going to tie it more to

monetization. That's the the next step of their strategy. If we want to build open-source, if we want to build a future that is open and transparent and trustable for everybody and creates this

innovation collaboratively, creates access for all, a policy or a law even is not going to do that. It just doesn't work. And we've seen that demonstrabably over the last 10-15 years. And what we

have to do is invest. And we have to invest in the landscape, the ecosystem that sits underneath open source that enables open source communities to work together, to collaborate. You know, you

guys need to have conference funding. You need to be able to get together. You need to work with your colleagues around the world. You need the infrastructure to do that. You need representative

organizations. And that's the kind of stuff that government and the private sector collaboratively are going to have to fund if we are going to have this thriving global community. And I think

my takeaway would be anything that you can do to help to explain that that it's not the what, it's not that we want it to be open, it's how do we get there and what do we need to get there that we

have to think about. That would really help. &gt;&gt; Thanks Amanda. That's very uh inspiring. Um Oliver uh and Balarama, please.

&gt;&gt; Sorry. &gt;&gt; Oh. Oh, sorry. Sorry. Sorry. I I'm sorry. I'm sorry. &gt;&gt; I'll I'll go quickly. Um so yes to all of that and certainly one of the things

that I'm trying to do with Mozilla is provide more of that infrastructure and more of that support. So I I think that's 100% to what Amanda said and I think to to link it back to your

definition of success. I think it's yes, you know, we all either need to build or build on open source. I think that's a thing that's going to accelerate us and make it uh you know create the

alternative in the future that we want. I think we also need to build that idea of trust into the open source we're building and how we deploy it. And so that is a thing if there's one thing to

take away is it in the same way that security that the broader landscape of cyber security is something that belongs to all of us that actually open source has really been proven as a powerful way

for us to stay as secure as we can in a rapidly changing threat environment. But we know how to do bug bounties. We know how to file bugs, security bugs. We know what it looks like to have a zero day.

like we are going to need to do that in a much broader scope of trust as we move into a world of agents and relying on systems that are automated. And so I I think that's a thing to get our head

around is we are not just the builders and users of open source but we need to be the stewards of an environment of trust in order for this to you know create the kind of benefits we want for

each other. And we kind of know how to do it. We just need to do it bigger and together building on what we know from the last 20 years. &gt;&gt; Okay, great. Ali and Balor Raman.

&gt;&gt; Thank you. Um so in my previous job I was um private secretary to Rishi Sunnak when he um inaugurated this this uh series and um the discussion we're having now is unthinkable

from a few years ago. I mean it f felt a bit like a kind of closed shop for closed models at least if you looked at the kind of cast lists and participation.

Um and I think the theme that we've just heard is um the vibrancy of the open source community has not happened by accident. Um Amanda thank you for mentioning the initiative that the AI

security institute did with the open source community. I think the message is that you know we should have the confidence to to do that and the confidence backed with um you know quite

a lot of energy a bit of a political commitment um uh and and funding as you suggest. &gt;&gt; Okay. So so one of the things is that the Indian open source community has

been vibrant. I mean so we've even had uh many of the open source for false conferences happen in India as well and so it's a huge uh uh uh uh energy in that community. So one of the thing

that's you know could potentially be a deterrent for people to think about open source in the modern AI era is perhaps you know the investment that's required for you to actually build models from

scratch. But what we are talking about today is not open-source models alone, right? We're talking about open source tools for trustworthiness, benchmarking, testing, safety and so on so forth. And

in fact, a lot of the application oriented testing that we have to do has to come from the community. There is no way developers sitting you know in a lab who are working on you know optimizing

engineering the last bit of uh you know efficiency into these models are not going to really worry about you know what what what really are the you know ground truth benchmarks. In fact, we

have been doing a lot of work on audio defects now and we we find that the benchmarks that people have been evaluating these on are not at all good indicators on how you would deploy these

uh audio defect tools in in the field. They don't work well. I mean they they score very well on benchmarks, but when you're actually trying to use them for filtering fake calls, they don't work

that well. Namaste. Good afternoon to respected Sars and madams in the panel members and respected Sars and madams in the audience. My question is compare and

contrast relating to artificial intelligence open-source tools for building for building implementing and making consistent sustainable safety security healthy ecosystem

relating to open-source tools to solve real world problems in the nature or society or in the business environment in A2. 2J domains. I will give two cases case studies also relating to healthcare

and algorithmic trading and uh relating to artificial intelligence and integrating with human intelligence. What will be the safety, security, healthy and trustworthiness

ecosystem building? Compare and contrast between those two things relating to these A to Z domains. One is algorithmic varies in that scenario. How to build a safety and security for the investment

made by the investors and traders and to make trustworthiness for their investment to get a result in that 1x 10 to the^ of 9th part of second they can gain the money or they can lose the

money. That is one use case or case study. Second one is relating to medical domain relating to robotic surgery and within that fraction of seconds the patient's stage may changes in this

scenario compare and contrast relating integrating with human intelligence and artificial intelligence. &gt;&gt; If you want us to answer it you're going to have to give us some time because

you're you're you're finishing our time. &gt;&gt; Yeah. &gt;&gt; Yeah. We we need very short 30 seconds 20 seconds questions. I'm sorry. Are we doing two or three questions and then

answering? Yeah. &gt;&gt; Yeah, that makes sense. &gt;&gt; So, my first question would be for &gt;&gt; Yeah, I'll keep it short. Uh my first question is for Oliver. Um I'm glad you

mentioned UKAC because I'm interested in that. Um so my first question is what are your thoughts on AI 2027 model and what personal personally what AI safety um methodology that you follow? Is it AI

control, steering vectors, etc. So yeah, that's my question for you. &gt;&gt; I take interest of time. &gt;&gt; Uh yeah, a a a quick version is um uh a

plurality of methodologies um quite a lot of which is published on our website. um the I mean in the spirit of the discussion we've just had the UK AC makes a virtue of publishing uh its

research agenda um and um uh kind of blogging and uploading periodically about its results. Um and then we we've also published the Frontier AI trends report um in December which is a kind of

synthesis of all we've observed um kind of open source uh in the world. So, um, yeah, a variety of methodologies. &gt;&gt; Thank Thank you so much. I'm afraid we ran out of time. I'm being told we're

out of time for additional questions, but uh, I wanted to thank our panelists for such a rich and thought-provoking uh, discussion. We can other additional questions. You can grab the panelists if

you can before they run away um, um, and ask them. Um but uh I think just what as we've heard today, open source uh tools aren't a technical matter. They're fundamental to democratizing trust in AI

and ensuring that communities everywhere can participate in building safer and more trustworthy AI systems. Uh what emerged from our conversation that I heard is the real the the real gaps

existing in uh open source tooling ecosystem particularly in the global south enormous uh potential of open source approaches. the concrete actions we can all take together a lot of them

and uh and um you know to open source contributing to open source projects sharing knowledge among communities uh are advocated for more advocating for more inclusive uh governance so thank

you again to uh Audrey Amanda uh uh Balarama man Mark and Ali for sharing your expertise and insights and uh thank you for being part of this important

conversation to everyone everyone in the room. Uh we have uh small tokens of appreciation uh for all of you [applause] &gt;&gt; in the in the form of bags.

Thank you friends.
