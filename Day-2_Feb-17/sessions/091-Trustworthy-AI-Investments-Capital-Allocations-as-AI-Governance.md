# Trustworthy AI Investments : Capital Allocations as AI Governance

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/GYRAUl82Pjs?feature=share) |

## üé§ Speakers

- Amir Banifatemi, Cognizant
- Balamaran Ravindran, CeRAI - IIT Madras
- Joanna Shields, UK Government
- Karine Perset, OECD
- Mohamed Nanabhay, Mozilla Ventures
- Sophie Fallaha, CEIMIA
- Wan Sie Lee, Info-Communications Media Development Authority (IMDA)

## ü§ù Knowledge Partners

- AI Commons

## üìù Summary

This panel examines how venture capital, sovereign funds, and philanthropy are shaping AI governance, exploring trustworthy AI investment frameworks, transparency in capital flows, and aligning AI innovation with long-term public interest.

## üîë Key Takeaways

1. This panel examines how venture capital, sovereign funds, and philanthropy are shaping AI governance, exploring trustworthy AI investment frameworks, transparency in capital flows, and aligning AI innovation with long-term public interest.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/GYRAUl82Pjs/maxresdefault.jpg)](https://youtube.com/live/GYRAUl82Pjs?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Fahala uh CEO of SIMA will be with me and then we're going to jointly moderate the session because we have a lot of brain power here and I cannot handle it alone.

Uh so Sophie uh maybe you can start but before you do that um the reason of this conversation comes from the fact that everybody talks about governance and everybody talk about investment and

somehow these two conversation have not match each other and uh a lot of people think that governance is a boring topic which it should not be and a lot of people think that investing is very cool

which is not always cool. So we're trying to make a sense of that today and look from the lens of really a balancing act of how we can actually make a difference with uh with this

conversation. Without further ado uh Sophie uh let's get started. &gt;&gt; Thanks very much uh Amir. Hello everyone. Thanks very much for attending the the session. So what we want to

explore today with our fellow uh panelists is to explore how capital allocation is really a tool and is really this is a force and lever in AI governance. So we want to go beyond the

classical understanding of uh of AI governance and the different tools that we have in our AI governance toolbox. So very classically in the AI governance toolbox you will have some soft

governance tools. So here you can think about framework guidelines around the ethical trustworthy AI and on the other end of the spectrum you will have the more the more hard uh governance tools

such as uh laws regulations etc etc. So we want to go beyond that uh that understanding for the for the simple reason that the flow of capital at the end of the day will determine will

decide which AI system is built will decide who will benefit from the uh AI systems. It will define how safety will be developed, how inclusion will be developed, how resilience is also

prioritized. uh so we will draw on uh new investment data from a project that uh is going on and uh on which we have the latest news on the side of the global partnership on

AI. We'll also hear from uh Madilla ventures and our different uh partners. And so the session will highlight the critical gaps in funding for safety infrastructure, foundational research

and the global majority innovation. And so I'm very happy to introduce our uh panelist for today. Um and so starting on my left, so to your left uh as well, we have Muhammad Na Nab, managing

managing partners uh partners, sorry, at Modilla Ventures. So VC fund that invests in responsible technology and responsible AI. We also have Juan Sili de d d d d d d d d d d d d d d d d d d d

d d d d d d d d d d d d d d d d d d d d di and d d d d d d d d d d d d d d d d d d d da in anomfo communications media development authority IMDA Singapore afterwards we

have Alpesha head of e standards followed by Julian Bio CEO of SCAI and Gabriela Ramos co-chair of the task force on inequalities and social financial disclosure and former ADG

UNESCO so this is it to kind of kick off the the the panel am so I'll perhaps very quickly pass you back the ball to then dive into

the the discussion thank you very much Sophie so you've seen the staggering numbers of investment the past uh at least two three years but it started probably in about six years before where

AI investment has gone dramatically high and today we'll see all uh all the investments going uh from uh six digit to seven digit to sometime eight digit investments. So how much of that

investment really is done into trust EI and what investments are done for and right now we're trying to dive into the questions about if we invest into models and data and safety and security what

are the trends of investment and uh who's investing in that because really today we have very little data about the the the size of investment that is going toward what we call trust for the AI uh

and there was some some interesting data to to to dig in uh so I'm going to ask First Muhammad about u what we think about investments what goes into models how much money you put in models how

much money put in data science and so forth and what the trends that you see in the market today &gt;&gt; thank you air and Stephanie no I think it's it's quite clear to everybody

sitting here um understanding sort of the the billions of dollars going into AI infrastructure whether it's frontier model building um the data that powers it the data centers that power it. And

you know, there's just such a scale of funding that's going into this. And you know, when we sit back and look at it, it's really this sort of planetary scale both of capital, but also of change

that's going on. Um, and if you believe some of our billionaires, it's not even just planetary, it's going into outer space. And you know, sort of looking at all this change, it's clear that

governance lags behind. We're investing in the frontier, but we're not thinking about the governance. um and we're not thinking about what the systemic risks might be uh to the technologies that

we're building. And it almost feels like you know in a way we've seen the story before because we've seen the way the internet developed and you know we can't imagine a life before our mobile phones

and before the modern internet that we have it even though it's you know uh a 30-year phenomena but when we think about AI and this rate of change I don't think we've experienced this space

before and you know it's clear when you hear the conversations that we're all having regulations behind and uh what we're trying to do um thinking about governance is behind and it's really

capital that's deciding what's trustworthy and what's investable and what's at the frontier and examining those capital flows lets us understand where this is and with the competitive

pressure we're seeing in the market amongst these frontier labs it's clear that money is not going into trust. So this is why this is a really exciting conversation and as somebody who's been

investing in the sort of trustworthy ecosystem for a few years, you know, it's something that we think is important and you know excited to dig in with the panelists here and how we go

and unlock the different areas in the capital stack. &gt;&gt; So as you pointed out the majority of the investment, I'm not talking about the budget, the investment goes into a

handful of model uh development and and very little safety tools today. So um how can we understand that? How do you explain right this difference? For instance, why do we not put more money

into open source tools and why the money is going only within handful of of models? Because in fact when we talk about governance and regulation really the the budgets and the investment talks

for themselves. This is the real governance, right? You put the money into building certain and that money drives the innovation pretty much. So how do you uh understand that? and then

I'm going to ask the question to other panelists as well, but maybe you first. &gt;&gt; Yeah. Uh, you know, it's it's clear that we we're sort of in this moment where there's a handful of companies, four,

five, six of them that are building these frontier models and there's a feeling that there'll be a shape shift in the economy that happens because of them. And that's why capital's flowing

in the manner it's flowing and we seeing these funds being unlocked and unlocked in ways, you know, we we often haven't seen before. It's not from the public markets. For example, historically, a

company the size of OpenAI or Anthropic would have been in the public market already. You know, if you go back to the earlier generations of internet companies, whether it was Google or

Amazon, they went public at a much earlier stage in their sort of lifetime in scale. Um, so I think there's this competitive pressure that's happening on the commercial side. Um, and people are

rushing towards it and they're not thinking about what the governance and risks might be. um because everybody's releasing a new model in sort of months right and that's you know there's always

a new model being released and in the other hand I think there's certainly a national security issue driving this as well where we seeing countries uh trying to control this AI destiny and you see

this playing out between the US and China um and other regions as well and we've heard the discussions here about sovereign AI so between these two competitive pressures we're not seeing

the money flow into either thinking about risks and thinking about trust into these systems or thinking about what the open source tooling might be so we can ensure that

everybody benefits from these technologies. &gt;&gt; Thank you very much. Thanks uh thanks very much and I'll actually just bounce back on um what

what you mentioned and also like all the challenges it would represent to uh national security and I kind of uh like try segue to the notion of of standards and I'm turning to uh to Alpes and could

you please expand expand a little bit and share a bit like your perspectives on what does it mean in terms of uh how should the the the the the capital be also uh uh sorry focused on the

development of uh standards. &gt;&gt; Uh sure. No, I'm I'm happy to uh answer that question. I I think you know when we're talking about capital allocation, it's it's as much a an issue of

liquidity as it is around um the race for fixed assets. &gt;&gt; Mh. And at the same time, [clears throat] we're seeing the race for human capital as well, right? It's

the combination of these elements along with the points raised earlier of the sovereignty pushes and uh also the fear of will I have a job which has folks sort of jumping for that unicorn ticket

as quickly as they can for the resources that they can secure uh to to make an attempt. Um but as it was shared earlier not everyone can get enough resources to even have a chance to do this. I think

this is where when we talk about this from a allocation perspective and I'll you I'll use standardization from the sense of the tool of standardization uh it's incredibly useful on a few

fronts. The first is that as you're considering uh really many of these tools, many of these issues we're talking about, there's a level of public utility that that also has to come into

play. Again, not everyone can afford these tools, right? Uh at the same time on a panel yesterday, uh you know, we touched on the need for incentives as well. And what you can imagine is that

not only sort of national uh interest to see greater development of specific tools to enable greater scale, but I think you start to see greater number of alliances starting to come together that

may be beyond just the geographical borders to allow for it. And in some of those cases, it may be for the reason of capital primarily to drive it. What we may see result along with this

is uh the the development of ecosystems where certain groups still take on more ownership of certain elements here uh whether it's the data element whether it's uh developing the frameworks and so

on I can share very pragmatically uh we have a um an approach for AI ethics governance uh our certified program use it as an example here because uh this tool is being utilized by uh several

governments and companies as a mechanism to drive corporate value. Uh at the same time uh utilized as a capacity building tool to help push greater um capacity development initiatives to see then more

innovation occur. Uh I I'll leave it there. Thanks very much uh Alpes and I like what you uh mentioned on the importance of also supporting developing the tools for capacity building and also

making sure that the different regions are empowered in that uh in that in that uh exercise and what I find what I found really interesting in different interventions here is that to uh support

all of these exercise it's not really the regulations that are needed to make that uh to make that true and perhaps I would want to do another step on that notion of of the different uh uh capital

allocation between regions and what we could call a discrepancy or an asymmetry perhaps it's a it's a best uh choice of a word between the global north but also the global majority so

low middle and emerging economies and so on given uh the position in the uh like regionally I would love to hear your thoughts on what uh what you saw and how you saw that Singapore in the past years

and decades kind of uh tackled the strong positioning in terms of uh of consolidating the strong position for Singapore in the uh in the region and kind of tackling the

the challenge of that symmetry. &gt;&gt; Thanks Sophie. Um interesting question. Um thanks for the question. &gt;&gt; Um maybe I'll talk a little bit about um two things I think. The first is how

are we investing in in um supporting more use of AI? Because at the end of the day when you talk about capital allocation as AI governance, one aspect of it is how you creating opportunities

for people to be able to benefit from AI, right? And so there's a lot of um a lot of what the government is doing today is putting government um funding um public policy money right into

supporting innovation. &gt;&gt; Um we're not talking about funding the the big um the big labs. um it's really about funding um startups who could actually build upon models or actually

deliver um value right to the users in terms of use cases in our context in um in the sectors whether it's in education in financial services in healthcare and so on. Um so we're doing quite a lot a

lot of that um funding both in terms of um investing in the startups or providing some kind of grants or providing some kind of tax exemptions and so on as well as creating the

opportunities um for them to come together to uh to learn and to work together uh physical spaces. So we have this space called Laurong AI. Uh we started with uh with Laurang is it's a

Singaporean term for road, right? So an AI road, right? So it's a it's a it's it's a space where we want the startup community to come together and and learn from one another and interact and be

able to build new products easily, right? And it's it's grown quite a bit and we're going to actually create uh a larger space for um um for this community um very soon. Um so that's one

way we we can direct government funding to support startups and and this is the logical flow, right? Money goes to support startups. startups innovate, create opportunities and jobs in the

local economy, create good um outcomes from their products and services to consumers. And that's where I think then you get this um um positive externality from startup investment. But maybe I'll

just also bring uh bring the conversation to capital allocation specifically in AI governance. So my work is in um AI governance and safety. So I I do

policy in this space. Um so if you think about regulations um that will be something that I'll be working on. Uh if you think about other types of levers besides regulations and to drive a

trustworthy or safe and reliable AI implementation within our within Singapore ecosystem that's also the work um that I'm doing. So we were thinking a little bit about how do we work with

venture capitalists? How do we work with um um funders um so that they can drive their funding towards reliable and robust um AI implementation. Right? So you can do this in two ways. First

supporting the creation of strong third party verification or um testing companies, evaluation companies. I think that's a that's one way we can start to create companies that can tool and

implement and enable trustworthy AI implementation, right? Um so one of these such companies in Singapore is Rosaro. It's actually funded by a sovereign fund Tamasic. It's a

subsidiary or startup that's funded through Tamasic. Um and Rosaro actually is a third party um assurance provider testing company. So that's one way you can you can help right by creating these

companies actually enables AI governance and trustworthy AI. Then two, once you have these capabilities, then you can start providing that assurance, hopefully eventually some form of

certification that actually demonstrates that a startup that's providing a product, a big tech um AI model developer is delivering AI in a very in a way that's reliable and safe. Um and

through that assurance, then that are signals that can be given to hopefully venture capitalists and investors then to say yes, this is a signal that I want before I put in more money. It still

depends on the motivations of the investors but ultimately at least we're giving them data and decide how they want to direct the investment. &gt;&gt; Thanks very much.

&gt;&gt; Thank you for that comment. Um we are we are focusing on um the funding asymmetries the lack of funding. Let me ask you a question uh here in the room. How many of you uh took a plane to be

here in Delhi? was a large majority of people uh when you took the plane did somebody tell you that the plane is not 100% uh safe there is a chance that 5% chance that it falls

and if you had that's that basically uh not in your ticket would you have taken the plane so we think about uh simple issues like this but we don't think of AI as being

safe we use AI right now we we get excited about it and definitely there's many potential but we don't think about the consequences the safety of that that's why we talk about safety and the

safety is part of the trustworthiness of AI the reliability and then unfortunately or fortunately there is a growing trend on AI safety investment and support and standards but uh not

enough so there is asymmetry so we try to see this from different lenses one is regional lens but also as a global south global no but also institutional differences so I like to ask a questions

to both uh Julia and Gabriella Julia on the uh differences in terms of investment and then to Gabula and then the global stage the difference between north and south and this investment or

this this focus on on safety and trustworthiness. So give us a perspective about why there is this asymmetry why we don't have enough investment in safety today Boeing or

Airbus put as much equal weight on on safety that on the rest of the engineering &gt;&gt; well you know that's a tough question and I think it's really linked to the

capital allocation markets markets are more rewarding today growth than safety but I think that can really change you know um in fact scali I'm not the scalier in the US we're scali we're

nonprofit organization based in Canada and our mission from the government of Canada is really to help companies adopt AI and create an AI industry in Canada and I mean creating trust is at the core

of what we do because if there's no trust there's no AI adoption by people and even not AI adoption by companies meaning if you are a board member if you don't trust the AI solution your own

company is building then obviously that's not going to happen so building trust is absolutely critical in every investment decision even at board level or any AI investment decision. So um we

really see that today you know it's a bit like raising money on financial markets. When you raise money on financial markets you need accountants giving a certification. You need to have

certified accounting to raise money. We really think in AI you will have the same issue at one point meaning people will have to certify what your AI is doing is good because if you don't have

that certification people will not invest in your company. We are not there yet but a lot of stakeholders are raising questions about okay my company is going to invest in AI is it really

safe what kind of risk should I take as a stakeholder to accept this AI investment so there's a raising pressure I would say a really bottomup raising pressure coming from stakeholders about

AI investment in the corporate world around boards around directors around all these people who want to be sure that the in AI investment they allowing are really safe are trustworthy because

if they are not there's a huge reputation risk for the company and that ultimately can be a great protection for uh trust and safety in AI. &gt;&gt; Maybe let me just get into the not the

AI but the financial sector because it's not only that the financial sector is not financing safety at the scale it should. I I think they will because this is a high priority for G7 countries and

when G7 countries are interested on safety they get the funds. Uh what I'm thinking more is how do we get the the flow of resources not only to safety but to fill the gaps in the global south to

take advantage of the these technologies. How do we fill the gap for the 30% of people that don't have access to internet that is stable? How do we fill the gap of skills? You see among

the big tech how much they fight for skills. And then let's just think about what happened with the climate financing. It's not that the financial market

market without any incentive and without any rule and without any instruction from the government started flowing funds to finance climate mitigation and adaptation. It was the rules of the

financial sector. It was the incentives. It was the government saying you invest in fossil fuels stranded assets. They introduced the regulations to red diminish the investment in those areas.

They put grants and subsidies to channel more funds to finance climate related actions. And this is what we need. We need the incentives in the financial sector for the for the market actors to

do it by themselves. and then they created all these 100 billion to finance adaptation in developing countries. So I feel this is the way to do it through investments, through regulations,

through the rules of the financial sector. And that's why I'm glad to be as co-chair of the task force for inequalities and social related financial disclosure because if we don't

put these rules for companies to have a better allocation of sources of resources to different parts of the of the AI flow that it would not work and it's not working because the rules

are not there. &gt;&gt; Thank you very much. That's a good uh good comment. We need to dive also into the causes of why we're we're not doing that because the mechanisms exist,

right? We know incentives exist in the general economy and market. We know tax incentives and procurement. We're going to talk about that. But can we dive a little bit with the everyone in the

panel? What are the um the the real causes that we are not able right to create those incentives and to basically strategically be aware of that there's a global north and global south issue.

there's different sizes of investment but um do we have any idea any any notion about why we have this lagging for now because the the the knowledge of safety exists we know what the issue is

but why we're not able to invest more &gt;&gt; so I mean I'd start by saying the you know there is some investment right like it's it's not that there's no investment we're seeing sort of a bjgering

ecosystem of entrepreneurs and founders and researchers is working on these questions. Um, and I think it's how do we get them to the next level, right? And what's that next level of capital uh

that has to be there to unlock them? And there's a there's a question in the back which is, you know, there's regulation and we all expected the EUAI act to sort of put a wind behind all of these

companies. It's not. So maybe regulation takes time because capital's flowing much faster than regulation right now. Um, maybe it's a catastrophic risk. you know, go to go to your airplane example.

You know, when we see something on fire, you know, it it causes us to act. Um, but we don't want to leave it to that, right? Like we want to do this before so we don't end up in the point where we

have some catastrophe that we're responding to. We want to try to address it earlier on. Um, so there's a there's a part that's education in the market and education to investors and you know,

as we think about the financial stack of people investing, we're investing at the early stage. We've invested in maybe you know 10 companies working on AI governance a trustworthy AI at their

core many of them you know running sessions here um who are the limited partners who are funding the venture capitalists you know higher up the stack who are the sovereigns funding those

limited partners and as we go up the the stack of capital flows who are the people who need to be asking this question of how are we thinking about governance how are we thinking about

safety are we doing the risk assessments are we thinking about the downstream effects and I don't think those questions are being asked unfortunately um I think everybody's rushing to a

future and you know it's great we as a venture capitalist we rush to the future we don't know the answers but we funding entrepreneurs who are trying to explore that future but I think you know further

up the stack people need to be asking this and pushing downstream &gt;&gt; can I just add a comment as well I think also further down the stack the people need to be asking that the these

questions you just take a aviation example So, how many of you will fly in a uh an airline that has a poor safety record? You you will. Oh, because it's cheaper. That's a poor safety record.

Yeah. I mean, so consumers actually have have a potentially have a say in this to ask for certification, to ask for asurances and then then in turn then that may then drive certain behavior

upstream. um then investors may then expect the same kind of um asurances from the companies that they are investing in because at the end of the day if you say

let the market decide then the market will move away from um organizations hopefully with poor safety record. So that's one way to think about it Julia first.

&gt;&gt; Yeah. No, I really want to emphasize the role of this AI by design when you build the safety by design when you build AI solutions because you have two approaches on this safety and trust. You

have the top down approach regulation exactly what happened on financial market or aviation but you also the bottom up approach. We've seen in some companies when you lose the culture of

safety bottom up then you have issue despite regulation. So you need to build the top down approach and the bottom up approach meaning in the financial markets uh what happened to investors

when Enron crashed then everybody saw the importance of more financial regulation and more culture of regulation into companies AI will be the same at one point we'll have an issue

and then people will understand stakeholders will understand they need to build and be more cautious about when they build the AI solution from a very bottomup approach just and not just

relying on regulation so I think it's a combination of culture at the corporate level culture on stakeholders to really be sure that AI is trustworthy when they build the solution and of course

regulation and governmental approach uh to control that. So &gt;&gt; thank you. If uh if I may just add I I think you know some of the the elements we talk about end up becoming conflated

quite quickly and but if you look at some of what's adding to the fear of capital allocation uh liquidity into certain markets is the lack of clarity whether the additional

expenditure is worth the EPS right the earning per share And when that isn't so obvious and you're working on a quarterly basis, your expectation is to meet your numbers. Your expectation is

not to say, can I add on another expenditure? Right? I mean, that's what the market is expecting you to do. Except if you are in a market where you can differentiate yourself by focusing

on these elements. This is the the element of capital allocation that we should really be thinking about if we want to push towards a more responsible future and a stronger future where a lot

of what we talk about in terms of economic power and progress really results in better well-being. I can't tell you the number uh of people that approached me just yesterday uh

working at at uh great companies that said um I'm afraid I'm going to lose my job. Now, I don't know about you, but from management 101, if your employees are

afraid and the exact thing that you got them working on is going to take away their job, I don't think you're going to realize

those returns. Thanks very much. Gabriella, you wanted to add? &gt;&gt; Yes. Just just to say that uh I I think that we don't need economist everywhere

but in this discussion we need economists because at the end it's a matter of incentives and and we forget that the governments have very powerful tools to change the incentives of the

markets. The incentives now are just for profit making among the big tech and that's it. get to the market, scale it. Racising to the question of um

general AI, no super intelligent AI and then the geopolitical context that is not helping. But governments have some tools for example just the public procurement

15% of the budget of each country in the OECD 12% in developing countries. If you go to the market to buy some of these programs to whatever reason to support businesses, small businesses or health

or whatever and you put some conditions, you are a company that invests certain percentage on safety, I grant you the the the program or the project tax breaks, deductibility

of investments on safety or development or infrastructure. I go for deducting from your tax receipts and you invest that money on safety. These things change the

confirmation. So I really think we need to change the incentives for the market players. &gt;&gt; Thanks. &gt;&gt; Sophie, can I add a question to that

question? Yeah, I was &gt;&gt; for all of us here uh what's the incentive at our individual level either in training or upskilling or as an entrepreneur

&gt;&gt; because we talk about the incentive at the government level at a large corporation level but for all of us is there an individual incentive on mentioned that we have a opportunity to

voice right our concerns and ask for proof and conditions that's one uh but as we learn as we use AI daily do have another responsibility to push towards more of this capital allocation towards

this discourse. &gt;&gt; Sure. No, I I mean I think the consumer uh and the public at the end are the key stakeholders here who we can't forget, you know, and often we talk about them

in the abstract, but they're real and they're here and you know at Mozilla we're a consumer internet company. We built the browser that was in the public interest that balanced privacy and

profit. Um, so we've been doing this for 25 years and we showed that you can build technology that puts people first, right? And that's not exploitive of people, that's not selling their data

and so on. And you can build a good business and one that has a brand that's trusted. And I think that's key in this discussion as well that the consumers need to demand it. We need to, you know,

be educated and it's something that we need to push for. can't accept a world where our memory and context and all these things that go along with AI are locked up in some proprietary company's

algorithm because these are things that fundamentally make us human and who we are and you know for me it's really interesting to go back to sort of the conceit of what you asked in the start

you know is capital what leads to AI governance you know can we invest in this and I think the question really is can we afford not to invest in it because right now you know the there's

potential systemic risks downstream as we deploy this technology in every part of our lives. Um, and as consumers, we need to sort of be aware that right now it's kind of cheap to invest in AI

governance because we're at the start of this journey in AI. Um, it feels like we're a long way into this technology, but you know, it's still early. It's going to cost us much more if we try to

address it later on. And if we wait for things to develop and evolve and be deployed and touch our critical systems, the cost of going in and building governance and building trust is going

to be much more. So right now is the right time. Uh it was better yesterday uh better tomorrow than the week after. &gt;&gt; Yeah. Also I would like to emphasize also the role of board members and

managers in that because at the end of the day I was in the world government summit in uh in Dubai two weeks ago and the prime minister of Spain, Prime Minister Sanchez said that now Spain

will will take uh will take legal responsibility for all owners of social networks that uh infringe the law. they will be personally and legally responsible, criminally responsible. And

I'm not saying that's nice or bad. I'm just saying that if you do that, you give a much more pressure on managers, board members in all companies to really be accountable of what they do. And so I

mean my point there is you need to work at different level and management and board stakeholders are also an important role. If you have them legally responsible of the consequence of what

they accept, what they fund, that's also we raise more pressure and have much more control about trust and AI safety. &gt;&gt; Maybe just a very quick uh plus one to that. Um so we have a program in

Singapore that actually educates board members about AI governance just so that it you know you you do need people to be aware of what it is so that they can ask for that um in the board um um um from

of their companies. Yeah. Al Pesh, you wanted to add on this? &gt;&gt; Just just building off of uh what's been shared. Um so I I I think there are uh certainly a few things at at several

different levels. Yeah. Uh and we've discussed trust in many different ways. So I'll I'll say you know at the the highest levels uh when we're talking about both from allocation as well as a

governance side and incentives uh what we have found at least uh through our our 7,000 series work and um our ethically aligned as work and the the certification programs is that uh part

of it just begins begins simply by what what you were just saying which is the awareness of right um I mean in in some ways governance ends up taking on a feeling of something you

have to do right if we look at the ESG's conversation right it's a I have to do this right um and but there are some that say no we should do this this conversation though is much is sort of

taking on a much different light right because there it's it's sort of an understood uh here it's we don't have to accept it yet in in some cases and the value of the awareness what we

are seeing uh firsthand is that it's then leading to now more intelligent questions of how do we address this is there a way to address these when um not just at the design stage but if they're

already out of the gate how do we start thinking about it that way so we have work going on right now around multi-agentic systems working on problems with unknown bounds

uh and at the same time you So the the work reflected a little bit earlier around the the certified program is looking around issues of transparency, accountability, etc. But

the main point is realizing that you need an inclusive governing body. It needs to be iterative. It needs to be integrated into your so your statement of uh processes and procedures. And then

the incentives have to support that. And uh if you take it even further and and this is to the point raised uh around the consumer groups and and getting involved, what has to change from a

governance model and and I agree on the the board makeup is the the boards also do uh get a g great deal of advantage in having diverse actors from civil society sitting at those board tables now and at

the same time creating independent assessors and auditors While it's an additional cost, it is also something that provides tremendous value and allows for some earlier

releases than than not. &gt;&gt; Thanks very much. And I'd actually would like to go back to something that Gabriella mentioned, which is the different tools that the government has

to kind of uh um focus the different capital investments and Gabriella mentioned procurement as an example. So I I would like to for us to kind of take a step back and think a bit about like

what are the different buckets of investment that can accelerate the development of trustworthy AI and the priorities. So we mentioned the procurement uh there are also impact VC

model sovereign catalytic capital. So I would like to pick on the brain to uh of all of you uh on the panel to explore a bit these different types of fund alloc allocation and on the question of uh

government procurement uh perhaps more specifically when I know that uh in Singapore you have a very interesting approach in terms of procurement um so perhaps a few words on this. Well, first

of all, we haven't had any requirements from a government procurement with regards to air governance. So maybe uh maybe that's a little bit later. I think the reason for that is because I think

we do need to define what the standards are quite clearly um and it's a little bit uneven at this station. Maybe something that we could work with E on. Okay. But coming back um to the

procurement question, maybe I use an analogy of a program that we have and and perhaps then for AI AI governance to to to um to move into that space as well. So

we have an a program called the accredititation program where we accredit startups for their products right um so my colleagues in in this program what they do is they they look

at the the the the product make sure that it's secure it is does what it's meant to do um and I'm trying to get them to also look at AI um trustworthy AI governance or at least AI safety as

one element of that um they look at the company to make sure that the staff still going to be around in in a year's time that it's made up properly uh of people who can actually execute and so

on. Um and a few other things, right? Then they accredit and this is what we do as a government agency. We put our brand and our name to a startup to say this is a good startup. It is it product

is it's what it says it does and it's going to be around and that accreditation buys the startup what one it gets into government procurement very quickly. Why do the government my my

fellow government colleagues buy from the startup? uh because number one they don't have to do a long procurement process which for a government for civil servants is a real pain but um uh but it

allows us green lane this um this process into into uh green lane the procurement process so it's much faster to buy and two it derisk it so in the past they might think well I'm worried

about this data I rather buy from a reputable agency or organization but at least now um with IMDA sort of accredited stem of approval they can say actually uh I trust it, I can buy from

it. Now, if you can then take this process and translate it into um AI products and we can then also put the same kind of accreditation on AI products and how would that make it much

easier for government agencies to procure. It's nothing to do with I mean one is yes make sure that it's safe and reliable um but it's also about making it just easier and reducing the friction

so that it's it's uh it's much faster. So that's one way if you can think of government procurement as a mechanism to drive certain behavior. &gt;&gt; Excellent. Thanks very much. Any other

interventions? &gt;&gt; Uh sure. I mean I'm happy to talk about venture capital and specifically how we think about what we call impact venture capital. So you know we have a what we a

double bottom line. So when we're making these investments into these companies, we're asking ourselves both is this going to be a great business, but also what principle is it advancing in the

world and is it advancing something that's net benefits for society? Um and we're looking at, you know, things around trustworthiness in AI. Um how does it improve the lives of people? You

know, what specific problems uh is it going to solve? And you know often we'll see great businesses and we don't feel they're aligned with our principles and values and we won't make an investment.

Um but you know so I think by balancing these two things you know we're ensuring that we're finding those startups who have good governance and trustworthiness at the core of what they want to do. And

I think this type of capital is really important because it makes sure especially as we're thinking about a new field that's emerging that we're finding people who want to build this field. Um

they could easily go out and build different types of companies. um but they see a problem that's in the public interest and they want to attack it and solve it.

&gt;&gt; I I really think that you touched the nail in the head because when when uh investors uh venture capital or any other kind of investors, the big funds uh send market

signals that they will appreciate or that they will invest more in companies that do X Y or Zed, you really move the markets. And I just wanted to say the a very short comment because when when

Black Rockck came out uh five years ago and they say I'm not investing in companies that don't have 30% women in at in their boards. It was amazing the rate of change of something that has

been so slow for for decades. So I feel that this is core to the to the whole transition to a more uh funding for these kind of issues. Well, it seems that we are uh advancing

the case that capital allocation could be a tool for governance and probably a very powerful one. uh as the saying says money talks uh so if we can uh if we're able to align our principles and provide

guidelines and resources to do more of that I think we can probably accelerate notwithstanding the tools and safety and protocols and standards and I think has to be around

it where nothing otherwise but I think as a disposition we we think that governance is slow and we talk about uh closed doors about all those principles etc but it seems that in addition to

that which we need to continue doing and alignment and anything else. Probably uh we need to put more uh investment in general from private funds, public funds, sovereign funds and ourselves

into our own companies into probably promoting more trustworthiness in in a domain or in a technology that is really changing everything. As you all know, this is not the typical

technology that is around us. It's going to probably u shift us in ways that we don't understand yet in terms of high takes decision out of our hands. And uh this is something more critical than

just safety. I think it's a safety of uh of how we behave in society and how we evolve and how we learn. And uh this is amazing opportunity. I think capital investment should be also be thinking

about that is that protecting all of us uh in a in a wake of a change that could be extremely exceptionally good and important but probably not completely understood

because right now we're focusing on as Gabrielle said AGI and super intelligence and we put all our eggs in one basket but we don't put enough eggs in the basket of agency and people uh

ownership of these capabilities uh in a way that is protecting them and The example of the airline was one but you wouldn't buy a medication if the medication is that you have a 5% chance

of dying. So there is an FDA there is but even pharmaceuticals right now putting so much effort into for instance when you talk about and those who know this topic

uh in pharma in pharmarmacology research there's a step which is toxicity right elimination and that's basically kills probably 80% of the drug candidates through just that that phase. So a lot

of investment goes into research but then are are eliminated because of the safety issues. So without thinking too much of that uh summary I think uh what we learned today I would like to ask the

panel probably uh one last question is that if you had today a billion dollar or $5 billion what would you invest that billion dollar first? &gt;&gt; Each one of you

&gt;&gt; who wants to start with the $1 billion question &gt;&gt; can make it five billion start again. [laughter] Um so you know one of the things uh one

of one of the companies we invested in the founder Krishna Gad is really uh somebody I admire who's been working on this problem for a long time. Um and during a discussion he said something

really interesting to me. He said you know trust can't be in uh can't be left in a PDF which means it's it's not a tickbox exercise. it needs to be embedded in the runtime you know and I

thought when he said this it was really wise because it sort of captured the idea that every part of our system needs to have trust built into it every element and as our systems are becoming

multi- aent and becoming uh on prem on device everywhere we look um you know I think if we had a billion dollars we really can't allocate it to one thing it needs to be up and down the stack um

touching the edge touching the cloud touching wherever we're building the systems and a billion dollars is not enough for So trustworthy by design.

&gt;&gt; I think I guess we're going down this lane. Oh, go ahead, please. Yes. Um I will yesterday on this stage I talked about the individual and the humans. Um so actually I'll say I'll invest in the

individual and the humans. um because I think that's where all the ideas are and it's not just about investing in people to have the skills to be effective and to to relevant in the AI economy but

also in investing in them to understand what is trustworthy AI what is AI governance because then they are the ones who will then build this into systems and the products they are the

ones who will demand for this uh as consumers so that's where I will put my billion dollars thanks &gt;&gt; so human capital &gt;&gt; human capital

&gt;&gt; yeah well you know I've been president of a public listed company so Something I would have loved to have at one point would be a certification mechanism. You know, as as a board member, as an audit

committee member, I want to be sure that the company I'm in is doing the right thing, and I need somebody to tell me my company is doing the right thing. So, I don't know if $1 billion is enough to

create a certification mechanism for AI. We know it's very complex, but at the end of the day, I'm sure the successful companies will be able to put a label close to their name saying, "I'm AI

ready or I'm AI certified." And we need to build that um whether with the private sector, the public sector, I don't know. But we need to build that kind of certification to to give

stakeholders comfort about what they are doing in AI. &gt;&gt; So certification working closely with standards then &gt;&gt; maybe I would I will just uh copy my

dear 1C. It seems that we always agree. Uh but but the fact is that uh if capital is a scarce for the kind of things that we want in terms of the AI ecosystem, I feel that skills are also

scarce. Not only in terms of what we see the the big companies snatching their talents. Uh but in terms of our people investing in our people's skills, the skills of governments, the skills of

workers that will need to transform their own capacities to take advantage of AI. the skills of of of school children that will need to understand better the world and more than anything

the skills of women uh because women are also not very well represented in this world and I think that the whole outcomes are going to be as skewed as they are nowadays if we don't bring more

women to the table &gt;&gt; and alish &gt;&gt; so the the three areas uh it was five billion you said or one billion up to 10 billion okay Um, the sky's is the limit.

I love it. Uh so I I think the the first area is and I'm going to build uh a little bit more off of what Muhammad and uh Gab Gabriella were saying uh you know investing in the reframing of what

success looks like uh at a uh at a market level and uh in that accord uh people planet profit sort of in that order become a very critical aspect uh in terms of how how we might want to

think ahead. Uh the second uh I would say is that uh a great deal of what's required um to do many of the things we're talking about is based on the idea of fixed resources. there's not enough

to go around which means that uh we should be investing more in both the idea of public utilities and commons as well as uh looking at what others have done and reusing as opposed to trying to

recreate. So partnerships is where I would also invest. And then uh finally um I would say from a a third point and uh Julian we can talk about that certification program uh and

&gt;&gt; I've got a procurement program for you too. Um, and I got something for you Muhammad and Gabrielle as well uh afterwards. But, uh, very specifically, I think the third thing really is we

need to invest in a campaign to very much raise up people's spirits because today, you know, we're here at the AI impact summit, right? And the impact people should not walk away from out of

this conversation that we're having is fear. What we should be walking away with is hope, opportunity, and with all the youth in the room and

intelligence, we have a much better chance of succeeding. &gt;&gt; Thank you very much. it kind of closes uh perfectly. I think that uh we will

look at optimism and look for the opportunities and I think that we have the perfect task force on the stage to work on the different key topics that that were discussed. Thank you very much

to all. Uh I know that we need to wrap up. Thanks Amir for the co-odderation and uh have a lovely afternoon everyone. Thank you very much.
