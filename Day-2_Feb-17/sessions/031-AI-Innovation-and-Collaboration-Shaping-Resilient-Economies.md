# AI, Innovation and Collaboration: Shaping Resilient Economies

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 10:30 ‚Äì 11:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 6 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/575SB74YIXo?feature=share) |

## üé§ Speakers

- Mr. Abhishek Ranjan, BSES Rajdhani Power Limited (BRPL)
- Mr. Deepesh Kiran Nanda, Tata Consultancy Services
- Mr.¬†Jal Desai, U.S. DOE National Laboratory of the Rockies
- Ms. Jaquelin Cochran, U.S. DOE National Laboratory of the Rockies

## ü§ù Knowledge Partners

- U.S. Department of Energy (DOE) National Renewable Energy Laboratory (NREL)

## üìù Summary

This panel examines how innovation and collaboration can transform AI data centers into strategic assets for secure, reliable, and affordable power systems. Bringing together hyperscalers, utilities, and public sector leaders from the United States and India, it will explore advances in compute efficiency, cooling, grid integration, and demand flexibility, alongside enabling policy frameworks that strengthen power systems and position AI infrastructure as a catalyst for long-term resilience and economic growth.

## üîë Key Takeaways

1. This panel examines how innovation and collaboration can transform AI data centers into strategic assets for secure, reliable, and affordable power systems.
2. Bringing together hyperscalers, utilities, and public sector leaders from the United States and India, it will explore advances in compute efficiency, cooling, grid integration, and demand flexibility, alongside enabling policy frameworks that strengthen power systems and position AI infrastructure as a catalyst for long-term resilience and economic growth.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/575SB74YIXo/maxresdefault.jpg)](https://youtube.com/live/575SB74YIXo?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

of this session is to move from insights to action. Focuses on solutions to address the energy challenges created by AIdriven data growth. We all know electricity demand is

rising, grid complexity is increasing and infrastructure timelines are tightening. The question is not whether AI will scale. It already is. The question is how we deploy data centers

that are that enhances resiliency, flexibility, reliability and performance. So let's dive into solution. So first I have Jacqueline Cochran uh from the National Lab of the

Rockies uh to give the opening remarks and set the context. Jacqueline. &gt;&gt; Great. Thank you everyone. So my name is Jacqueline Cochran. I'm an associate laboratory director at the National Lab

of the Rockies. You may remember us as National Renewable Energy Lab. And our name changed in December. We are still the same people, same buildings, amazing research. We're located in the in

Colorado, which is that green dot. So uh all the rest of that is other department of energy laboratories and as a whole we work on the lab on the research that's long-term has like grand challenges

ahead and there is nothing that speaks to a grand challenge more than AI and data centers. We work with over 80 countries around the world on advanced energy systems

including uh in with India for over 20 years at the National Lab of the Rockies. Our science drives innovation. We work on energy systems integration. So for

example, grid modernization. We work on transportation and fuels such as hydrogen fuel cells, bio bofuels. We work on buildings and industry. So advanced um uh building properties, uh

advanced materials and manufacturing and then also different generation sources like geothermal, hydro, solar. A great example of energy systems integration is our work on data centers.

Data centers are complex interconnected systems and this chart shows that range of issues that we're all talking about when we're looking at how do you expand data centers. So on the left we have the

chips and some of the research we're doing there is on how can we uh create newer chip cooling solutions and then on the rack side how can we improve the power density to improve the

power electronics to manage everinccreasing power density sizes at the facility level we're trying to understand how can we better manage the load both electrical and thermal and on

the campus you know, for campuses that have backup storage or behind the meter generation, you know, what is the optimal sizing for that? And then, of course, as it's

connected to the grid, the distribution grid, data centers now are even developing their own substations and distribution systems, the transmission and and bulk generation to to meet all

this demand growth. This map shows is data center infrastructure in the United States. And what it shows is locations where it would be easier to build data centers

based on existing infrastructure such as the location of fiber optic cables and transmission lines and generation sources which are illustrated in the map. The challenge here, as it is

everywhere in the world, is that we need to get things built and we need to get them built fast. But the people who are responsible for building things quickly are trying to manage many competing

goals. They're not necessarily competing, but there many goals, but they do compete with each other. For example, we need to make sure we have the fuels and

materials and infrastructure available. Our energy needs to be affordable. Utilities need to be profitable. The grid needs to be reliable. And people need to make decisions based on

incomplete information and to be able to do so quickly. So, one of the challenges that we have at our laboratory is how can we use our models and data to be able to help address all of those goals

together and optimize across many different stakeholders and many interests in the development. This is an example of some of our modeling where we just peel apart data

center like just citing a data center is very you know many different complex factors that go into it in terms of you know what especially what we were hearing this morning too on the pricing

the affordability aspects the water availability the proximity to uh related infrastructure and so at at our national laboratory we use our GS spatial capabilities to really dip into each

layer and be able to look across different, you know, even local ordinances of, you know, how close can you be to a school and things like that that will help us look across. All

right, how do we build out the natural gas pipeline to optimize around data centers or optimize around data centers plus new manufacturing? And then at our laboratory, the the

National Lab of the Rockies, we couple that modeling and data analysis with hardware experimentation, testing, validation, so that as data centers and as people are bringing on new

technologies. They want to be able to know that it works as expected. And so that's what we do at our laboratories. We do different um and my colleague Marley Bugu will be

uh going into this in more detail but looking at different controls, different load management, power electronics and thermal management. And then finally,

we're not just looking at data centers at our laboratory, but we're looking at AI across the whole research portfolio. So looking at the for example at the top left core AI methods how can we use AI

to better operate the grid and on the right how can we have more trustworthy scalable infrastructure so for example can we use AI to do more red teaming adversarial testing for grid security in

the bottom left energy applications how can we use AI for example to do more autonomous uh energy management or critical materials processing. And then the finally on the mission impact on the

bottom right, what can we use to make our research go faster and more efficient? We are a taxpayer public institution in the United States and we want to use AI to

to accelerate our research findings and to do so at less cost. And so with that, I'm going to turn it to I Merly, I think you're next, right? To my colleague Merly Bugu. He's a lab

program manager of grid integration at the National Lab of the Rockies. &gt;&gt; Thank you, Jacqueline. Thank you for setting the stage. Thanks everyone for taking time to attend this particular

session. I'll just dive a little bit deep into the capabilities at National Lab of the Rockies. My name is Merl Bagu. I'm a collaborative program manager for grid integration works very

closely with department of energy's office of electricity and other grid offices to execute on this particular mission. I'll actually dive directly into

research capabilities because I know Jacine did a great job of introducing different issues that we see with data centers. So just to begin uh the thought process here as you can see right I mean

there is lot of complex uh systems involved in data centers all the way from chips softwares racks facilities you know all the way up to the grid side which is distribution transmission and

generation I think we do work uh in all these gamuts we call this the chipto- grid approach uh for what we're doing and actually do a co-op optimization of the integrated energy system all across

the gamut I'll probably touch up more on the grid side given the interest of the panel here uh but uh you know as I said we do have a holistic approach across all the different areas that we're

talking let me talk about our data center that we have at the national lab of the rock uh which we call high performance computing or data center which is a

living laboratory as you can see you know we have our own uh uh cooling uh and you know data center in the in the middle of the picture right there and and other things but the main aspect is

you know this particular data center really spans uh uh uh to like a 10,000 square ft¬≤ facility with up to 10 megawatt of computing power. So pretty big to learn what really happens inside

the data center. Uh we also do large scale modeling, simulation and AIdriven research in this one. So we can actually put in diverse loads on the data centers to understand uh what it's going to do.

We have a very good what I call innovative cooling method uh for this particular data center. we we use component level liquid cloning uh with water and then we actually use that

water once it gets heated uh to heat the building and other things. So we squeeze heat out of the water that is coming out of this particular data data center and circulate it inside uh the building to

really do uh heating the building and other things. uh this particular data center really enables us to collaborate with our partners uh evaluate advanced

technologies and also optimize operations for data centers and validate new cooling and power methods that are used across real world solutions out there. So in a way we are the guinea pig

to look at what this looks like uh when it when it scales up in all other data centers out there uh in the world. I'll get into a different facility which uh which uh uh I mean which the data

center is part of which we call the energy system integration facility. This actually have the other side of the equation. The grid side of the equation is what we have here. Uh I mean we can

really create our own grid to connect to this particular data center or to any grid integrated uh holistic uh research that we are looking at. uh we can actually create virtual utility

operation rooms in there any smart grid interoperability and cyber security level testing in there and uh we have assets all the way up to megawatt level to do hardware in the loop experiments

to really test uh how different data centers work and uh when interacting with the real grid. We also have what we call the distribution management uh side of things to look at how uh the

management of these things really happens on real time when when it comes to load management and other things. uh the pictures there actually shows a setup of uh both simulation and hardware

on one of the data center projects I'll which I'll talk in one one of my examples I'll actually get to a different facility which is also at national laboratory of the rockies which

we call the advanced research and integrated systems uh flat irons campus uh here we actually have uh all the way up to 10 megawatt levels again the size really matters when it comes to data

centers we need to make sure uh we have big size to test different applications different different control methods uh three examples that I'm showcasing here is one we call the powerronic grid

interface uh which is a birectional power device that can be connected to different UPS and other different applications of data centers to test how they really work on realtime basis. The

other one uh which I want to mention is advanced powerronic test bed or apt to be precise uh which actually look at looks at MBDC or medium voltage architectures for data centers and even

going all the way up to HBDC depending upon the size of the data center we're looking at. Not listed here is actually what I call the storage pads. I know there was actually discussion on storage

in our earlier session where we look at uh different storage applications to see how they help mitigate uh issues that might arise on the data centers. uh just to talk through the whole

picture here. These are some of the tools that we use to support data center deployment all the way from planning to operations. Uh Jacqueline mentioned some of the graphics there which probably use

some of these tools like reads, sienna, uh rev and reopt and others which we use to both optimize as well as plan for data center applications. Let me jump into some of the example

projects uh real quick in the interest of time. The first one is uh you know data center as a flexible load. I know this was talked in the earlier panel where we where we looked at can we make

it flexible enough so that grid and data centers can work uh in harmony is what the idea here is this is a work we are doing with the virus a data center manufacturer or I would say aggregator

then manufacturer or integrator uh where we're looking at uh data center can supporting the active uh grid stability aspects of it. Can we really manage the load in such a way that where we can

support the actual grid stability? We are modeling a 70 megawatt data center uh in AIS platform that I mentioned uh really completely doing the power flow solution and combining with the battery

system so that we can show the flexibility of the system uh in the in this particular in this particular case. The second one is on energy. This is actually looking at different component

of the data center. In this case we are looking at how UPSS that connect to data centers. If you really look at data centers right uh we can't afford losing power even for seconds on data centers.

So each of them have UPSs which which take care of issues from seconds to minutes and then we have backup generation which take it from minutes to uh day hours to days. That's what in

most cases so the UPS is a very critical component of the data center. So in this case we are looking at testing UPS for rapid loan changes to see how grid disturbances so if there are low voltage

issues or harmonic issues on the grid how that impacts data centers and we're actually seeing UPS actually plays a very big role in doing those kind of things.

The next one is uh with electric power engineers I think one uh beautiful thing of having an HPC in house is to really we can monitor that HPC in all all ways possible. So in this part this

particular project is actually capturing uh how can we come up with different load types uh uh you know for utilities we are working with electric power engineers on this particular one where

we are modeling uh uh different utility and interconnection processes and also coming up with different load shapes uh uh for data centers on this particular one. Last one uh that I will showcase is

the hybrid generation for uh pulsating loads. This one I think we used all the assets in our areas uh to really recreate what a data center load looks like. The data center loads really

pulses a lot depending upon uh the batch processing that it does. So we're trying to see if we can use our regular base load resources along with energy storage and other uh dynamic polronic resources

to really segregate the load in two parts where some of it can be taken by base load and some of it can be taken by variable uh energy storage is what we are trying to demonstrate in this. I

have a nice video for this. I'll probably get into the video and then uh I'll conclude my talk here. Let's see. &gt;&gt; In less than a second, a data center's power can drop or growfi

switch up and down on 10,000 homes. How can the electric grid or a company that owns a data center power such a large, rapidly changing load? Answering that question requires a real power system

that can simulate these exact scenarios at high fidelity. And to do it, the US Department of Energy has the Aries platform. In a project sponsored by the Office of Electricity,

power system experts showed that using a mix of energy resources can tackle the challenge of powering data centers. See how they did it. First, they modeled a power grid. They built a scaledown data

center and its power sources identical to what exists in cities across the country. Next, they used a generator that can replicate gas, nuclear, or geothermal power along with real

batteries and fuel cells for fast responses to large load swings and if needed, backup power. Then to simulate dynamic power demand, they leveraged energy data from a

leading AI data services company. Finally, they initialized the grid scenarios and pressed go. The first thing they noticed was wear on the generator. The data center's cyclic

demand put torsional strain on the shaft, which is not built for rapid start and stop power. If this were to continue unassisted, the generator would soon wear down. But when it is combined

with other technologies like batteries and fuel cells, these more responsive resources supplied the pulsating loads so the generator could spin smoothly, providing steady base load power. The

researchers then went a step further and simulated a generator failure. When this happened, the battery and fuel cell temporarily provided reserve power to keep the system running. The combination

of base load generation integrated with other technologies could be the key to lowcost high reliability power for data centers AI and more. And that's just one of the many experiments made possible

with Aries. This is your platform. Find out how your company can advance power solutions with Aries. in less than a second. That thank you. I would like to

introduce my next speaker here, Aijit Abankar, who is the chair professor of electrical engineering at IIT Delhi to talk about research and innovation to tackle energy challenges for data

centers. Thank you. Good morning and thank you Enil uh rather NLR for having me. Sorry about that. Uh and what a lovely presentation we had from uh Dr. Bugu taking a deep

dive into the technological aspects of data center. So let me bring some uh academic perspective uh into this uh whole discussion. What I'm going to discuss very briefly is the nexus

between the energy and AI and what are the research and collaboration opportunities uh for researchers, research institutes, general researchers, academia, lab uh

people and industry. Now all of you have been hearing about this the data centers the importance of the same it's basically you know uh forms the core of any digital

infrastructure for cloud AI fintech IoT ego governance kind of activities and you know that generally speaking there are two types of uh data centers hyperscalers and colloccated

and they are supposed to operate 24 by7 with high redundancy and reliability requirements. Why energy matters when we talk about data centers?

This is because simply speaking the data centers especially the AI data centers they are power guzzlers and this accounts for major share in opex. So if you compare this with any

manufacturing unit or a factory, the input to data center is nothing but only and only energy, right? And the output can be some meaningful information uh which is based on certain level of

computation. So there's great deal of energy involved. There's a significant carbon footprint involved globally. There's a lot of talk happening these days about

the kind of decarbonization or the hurdles in decarbonization that uh the AI data centers would put in. And of course there is some some some element of truth in that. Let's say if you talk

about the requirements of any data center one of the requirements apart from the power uh and energy is the water requirement fresh requirement because the modern data centers they are

going to be liquid cooled. So just to give you an example let's say if you give 50 prompts for to get some uh response from your chat GPT or something it results in consumption of about half

a liter of water fresh water. So a typical 100 megawatt data center consumes about 20 lakh liters of fresh water per day. Apart from that the equipment that is used in data centers,

the IT infrastructure, it involves gold, silver and many rare earths and the mining of the same also has got carbon footprint involved. So these are certain concerns that people are talking about.

There's energy security and grid impact concerns. That means the data centers, AI data centers, they are going to be huge power demanding clusters. perhaps embedded within the distribution

systems or if the data center is a real hypers scale data center then there is a chance that it may get connected to the transmission systems as well. So how do you plan for the same so long as

delivery of energy electrical energy is concerned. So that is something which is very uh important from the point of view of planning per se. Then there are uh environmental, social, governance and

sustainability compliance pressures which add uh burden energy burden to the Okay. So AI's impact on energy demand as I said the AI requires high density GPUs. Now gone of the days the AI data

centers they don't work on CPUs. No chance you need GPUs. But then the GPUs also if you talk in terms of the racks rack requirement the power requirement for the rack it is minimum 100 plus

kilowatt per rack. Okay. Add to that you have AI accelerators like neural processing units tensor processing units which again are they demand lot of power. The LLMs they also significantly

increase the compute demand. There is huge deal of uh training required uh thousands of hundreds of billions of parameters which train the large language models and that is also

significant there's a significant demand of energy higher cooling and power infrastructure requirements. So just to give you some number about 40% of the total typically 40% of the total

requirement of energy for data centers is consumed in cooling right so you can imagine the kind of requirement and highest reliability requirements the data center should have 99.99999

you know percent reliability what it means is that data center should be 24 by7 so if you want to achieve that kind of reliability then you need backup backup to backup

backup to backup right for example now in India we are talking about edge computing data centers right so this will result in having tier 2 and tier three cities having you know small data

centers located around them and then uh if you want them to be reli have a reliable you know power supply then you have to add dig uh DGS Apart from the battery stoages now the

BDGs with them you have to make you know provision for large storage of fuel that is diesel. So you know they talk about decarbonization energy requirement and all this you know it goes in circle and

circle we have to have solutions to this. Globally data centers they consume as of today about 1 to 1.5 of total uh electricity uh requirement that and hypers scale facilities they are

increasing day by day and it is projected of course there are a lot of numbers floating around. So one estimation is that electricity demand will be doubled by 2030.

If you look at now let's come to some research discussion what are the opportunities. So let us start or let us have this figure in front of you and uh this is a typical energy flow for any

data center. When I say typical, it's it's just the representative picture. You can see that the power electronic uh side it consumes about the losses they are about 7 to 10% uh in data center. uh

the IT load it consumes about 20% of the total requirement of data center and the major focus is on cooling about 40% as I said it goes and sits or as a requirement of uh cooling load and then

other other you have about 10% or so if you focus on this slide you can easily understand where to focus what are low hanging fruit so long as to solve energy and AI nexus or to

[clears throat] make AI more energy efficient. So this slide shows four quadrants. Okay. Uh which talk about what could be the research trends pertaining to energy in AI. Now I'm not

discussing here the chip related uh uh research and power electronic related research. they are they are walking their own path right and very neatly nicely in a committed fashion so I'm not

going to talk about that but if you focus on the 20% of the IT requirement of energy and 40% for the cooling requirement you can see that if you focus on this these are the four

quadrants which uh come uh in front of you the quadrant number 1 2 3 they talk about improving the energy efficiency of data center so if you talk about uh energy efficiency uh nowadays there is a

research that is going on on thermal aware server placement. So how do you optimize the workload so that you optimize on the overall thermal loading of the data center. Similarly energy is

another attribute. So along with energy how do you optimize your workload and allocate the work to different servers so that you optimize on energy. That's that's one way of you know carrying out

research quality research. Second is server uh consolidation. So as of today the uh idle energy consumption of a data center typically can be of the order of 30 somewhere between 30 to 50%. So that

means the data center is comes doing nothing slipping but still it continues to consume 30 to 50% of the energy. So that's a challenge. So how do you how do you overcome this problem right uh or

how do you improve the situation? So you can do optimal server uh consolidation. So there are algorithms people are working on on dispatching appropriate set of commands or the workload to

optimal set of uh servers at the operational stage as well as planning stage. So how do you do that? That's another uh level of uh research. Cooling there is great deal of work that is

currently going on. So you have two-phase and singlephase immersion cooling systems. Singlephase is where you have you know data centers. The IT infrastructure is embedded into a

dialectric liquid material and in two-phase system you have evaporation and condensation of some liquid that is happening. You have direct to chip cooling where the uh racks are connected

with the cold plates and the liquid fuel is sorry liquid coolant is is made to for flow through these cold plates. So people are working on this and the fourth quadrant if you see this is very

important. So the first three quadrants that I spoke about they talk about uh uh energy for AI. Okay. The fourth quadrant research uh group is AI for energy. How can you use AI to improve your overall

energy perspective, overall energy situation? Now this list in itself is 1 hour lecture in IIT Delhi but I have you know condensed it to just three points which I feel are very important for

discussion over here. How do you use AI for energy? Basically the in my personal opinion the the the great deal of advantage if you of AI is in distribution systems. If you make use of

the same for example forecastinguling in the wake of large scale renewable integration uncertain variable the forecasting plays a big role and now the EPO change has come where you are using

you have to use AI for forecasting extracting maximum juice out of DRS. So how do you how do you make DRS available for system operation? How do you extract juice uh and create various commodities

out of the same DER for overall system efficiency? That's another line of uh research. Load modeling and DR potential. So how do you do the NILM non-intrusive load modeling so that the

distribution system gets to know what kind of load it has right and then take decisions like it can come out with what is the DR potential in certain clusters and come out with certain regulations

and policy. Well this list can be very big u before I move on to the next slide let me just tell you that there are two hidden messages in this particular slide. Number [snorts] one, you can see

that the research areas, they are zoned out in various they they they they occupy the entire spectrum of knowledge. So you when you want to carry out research, you can't work in silos

henceforth. If you want to work in in AI and energy nexus that is you want you want people working on energy, you want people working on power, you want people working on material science, you want

people working on thermal uh energy and uh you know policy regulation. So uh there's a great deal of opportunity where entities, institutes, people working in these areas they come

together and work towards the common goal. Uh [snorts] that's number one. Number two message over here is that there is certain kind of circularity involved in this that is AI for energy

and energy for AI. So what it means is that if you take good care of the uh AI so long as energy requirements are concerned AI is likely take likely to take good care of the energy part as

well. Right? So before I stop this is my last slide. Let me just quickly give you the projection so long as Indian condition is concerned. So on the left hand side you have a map uh which shows

uh the data centers. So the black dots are existing is the existing concentration of the data centers uh as of today Delhi, Mumbai, Hyderabad, Bangalore, Chennai. Uh the blue ones are

emerging hubs right so you can see in Ahmedabad, Pune, Visak, Kolkata these are emerging hubs and uh there are age data centers. So you can see a few tire two and three cities as yellow dots

where there is a chance of you know data centers emerging. Uh [snorts] the projected data center load by 2030 is 5 to 8 megawatt in India. This is India specific. Of course there are multiple

numbers but 5 to8 is the common range that is the common projection and by that time we expect that uh projected generator installed capacity would be 750 plus gaw out of which around 500

will be non-fossil. So the decarbonization angle we really have to see how much uh importance should we give it to to that particular aspect. uh H computing I have talked about data

localization is government of India policy and India AI mission is supporting the PG students in a great way. So this uh India AI mission is supporting about I guess 500 PhD

students 8 5,000 uh M techch master students 8,000 UG students in next 5 years and uh one important thing that uh usually gets uh unnoticed is that the uh national education policy which was

floated in 2020 has got mention of AI and it states that the students of grade 9 and onwards they should be given flavor of AI henceforth and Baj Bharaj Jen is the new LLM initiative that

consortium of IIT has taken up and ANRF has DST has funded it [snorts] and I think I should uh stop at that thank you so much &gt;&gt; thank you Dr. Abanker so now let's go to

the next presentation by Dr. Go. &gt;&gt; Good morning. Um, first of all, let me thank the national laboratory for of the Rockies. Enreel has become ENAR. Uh, but uh friends are friends by any other

name. uh thanks for organizing this uh very important session and uh it was really illuminating to uh hear about what you're doing um in Colorado and uh

professor Winker uh a lot of the issues you've highlighted are extremely pertinent especially for uh India where our energy and our water demands are growing not just because of AI but AI is

the is the latest sector that's adding to that to that demand. So what I'm going to do today in my presentation is uh present um uh of uh about this report that we just brought out. There's a CW

and systemic report uh on scaling India's data center ecosystem um drawing very much on the broad themes that you've heard about already to understand to what extent are we ready

and what more do we need to do. I represent the Council on Energy, Environment and Water. We're one of the world's leading climate think tanks. As you can see from the map, we worked with

20 state governments in India. Uh several ministries of the central government. This year, I'm also chairing the AI and climate global expert group for this AI impact summit. So,

particularly privileged to have drawn on the wisdom of many experts from across the world. Um so uh as we've already heard AI runs on water, energy and planning. It doesn't

run just on code. Uh the adoption of AI is of course accelerating at unprecedented scale. Globally it seems one in six people are using generative AI for some kind of activity. um more

than 90% of organizations globally and in India have adopted AI in at least one business function. Contrast this with the speed at which the internet uh was used. The the the pace at of diffusion

of the technology is much much faster when we come down to institutional organizational levels. uh AI workloads of course could then represent about 50% of all data center capacity by 2030 and

India's AI market of course is growing this uh means that there is a surge in the data center capacity u the global number could reach 200 gawatt uh professor Abanker gave the range of 5 to

8 we have a slightly more conservative range but broadly in that same area of 4 and a half to 6 and a half gawatt by 2030 30 uh that would mean it will intensify the water and energy demand in

India. Data centers account for about half a percent of India's current electricity consumption and about 150 billion lers of water. Uh this demand is expected to grow twice by 2030. Globally

about 1 and a half% of global electricity uh is being used. Um this is equivalent to say the entire electricity consumption of Japan. A global data center industry cons consumes about 560

billion liters enough to give water to 8 million residents. So the question here therefore is how do we ensure that the AI uh growth u runs in parallel and intentionally in sync with optimized use

of resources. So there are a number of factors therefore that we'll have to keep in mind when we think about where to site the data centers. Um firstly do we have

uninterrupted power with reliable backup especially if we use cleaner power sources. Secondly do we have adequate water for cooling and operations and efficient draining for the water

management. Thirdly, do we have the right connectivity? The proximity to fiber networks and subca landing stations for high-speed connectivity. Utilities,

do we have access transport to supportive public uh and policy regulatory uh frameworks, clear sites um from uh interference with other kind of signals. Are those locations resilient

against climate shocks and extreme climate events? whether it's a flooding event or a storm surge etc. And then are we making it future ready not just leveraging the present is there space

for growth in a modular way as we look towards the growth of data centers and as professor Abanker already mentioned and our report also identifies you already have Delhi, Mumbai, Chennai,

Bangalore, Kolkata as already the emerging hubs. Notice that many of these are along the coasts. So that might be a a strength but we also have to leverage or or protect against potential

weaknesses. So optimizing for these additional resources means that there is going to be tradeoffs. If you want to have say air cooled systems, you'll reduce water

consumption but you'll increase energy consumption. If you have an energy um restriction but you have water availability, you can switch to water cool systems with high water consumption

but lesser carbon footprint. So ultimately the choice of the cooling technology will depend on location will depend on on choke points will depend on operational efficiency. We also see and

and some of this was also identified in Mr. Bagu's presentation uh there are advanced cooling technologies directed chip cooling dialectric plate cooling etc. But like with any advanced

technology we've faced challenges of high upfront costs supply chain issues limited vendors etc. That doesn't mean these are insurmountable. We've done this with clean energy we've done this

with batteries etc. How do we design public policy that enables for the adoption of the most efficient technologies, incentivizes them through the lifetime of the

operation rather than put the burden of the upfront costs right up front. Um now one of the things we notice therefore is that like with any many things there is competitive federalism even in India

when it comes to data centers. We don't have a national policy framework that is binding for data center development. But as we heard from the recent budget, there is uh the data center development

is has been granted infrastructure status and there's a long-term tax holiday over the next few decades. But in the absence of a central framework, several states have taken the lead. From

that map you see about 15 states in India already have notified dedicated data center policies as part of their industrial policies uh to attract investment. However, we find that only

five of those 15 states um in their policies have sustainability related provisions. So we think we need to inject this with a degree of intentionality to fill three systemic

gaps. Understand the water governance deficit. look at the performance standards whether it's power use effectiveness or water use effectiveness or even the

carbon effectiveness that was mentioned earlier and then is there sufficient resilience against climate risks if we can inject these frameworks then I we we estimate that the the the investment

attractiveness will actually increase because there'll be more confidence in the kind of infrastructure that is being built out so as I close how could Can India position itself as a sustainable

hub for AI and data center development? First, and here's the formula. First, measure what you manage. There should be mandatory disclosure uh of environmental footprints for all large data centers.

We should perhaps aim for a national AI energy star rating, maybe even an AI water star rating and provide the regulatory clarity early on. so that industry is ready and knows what it's

heading into. Second, site with foresight. Evaluate the water, land, and energy requirements in advance. do your resource adequacy mapping so that your datadriven decision for sighting can be

made into a tool that helps industry and then accordingly prioritize data center parks and colllocate with uh renewable energy sources or where water is more plentiful. Third, innovation and

optimization. Let's adopt a right-sized approach rather than just compute just compete for compute power. So, how do we encourage public private collaboration to accelerate more R&amp;D in advanced

cooling systems in battery energy storage deployment to have better uh demand response participation in in managing the grid more dynamically? I'm sure Reggie will

have things to say about that. And finally, keep humans in the loop. We need to leverage AI to support humanbased decision- making, not replace it. We have to prohibit automated

enforcement actions without human review. Ensure that there is due process and accountability embedded in our institutional architecture as much as it

is in our data architecture. If we get this formula right, we can be ready for the future and make sure that the AI revolution serves the public purpose for which we've all convened today. Thank

you very much. Look forward to the discussions. Yep. I would like to call Reggie to give the closing remarks. Thank you NLR for inviting India smart

grid forum for this very important uh topic. Uh 3 minutes given three topics. Number one about the grid challenge. uh we heard in the presentation professor Aayenar said 8 gawatt of uh data center

load which Arunava has brought it down to five but last week I heard one very senior official from the ministry of power said that they have visibility to demand for 16 gawatt

yeah by by 2030. So now as most of you know an AI data center load can go up and down up to 80% in few seconds. So even if we take 10 gawatt load by 2030 that 80% up and down

that is coming down to 200 megawatt and thousand megawatt in few seconds depending on the computational load in any continent or on the orbit is something which are we the grid

operators are here Samir Sar and Sims are here [laughter] how are we treating this and all this over a century we planned grid with n minus plus one reliability standard for

data center they talking about N plus1 and N plus2 it's a entirely different paradigm shift coming to the second point a very recent report I seen that lot of protest massive protest in US

particularly in the east coast where PJM has 30 gawatt of connection request for data centers by 2028 and if all that connections are given average household electricity bill can go up by $70 per

month and in Texas there are 240 gawatt of connection request spending till 2030. So where is it going to take how regulators and policy makers are going to uh address this issue? Third point

like to highlight is last two years our favorite topic in every such forum was talking about AI for energy and energy for AI and we debated that in our one event in

Bombay in November also for two hours or or distribution utility meet and a week later star one cloud has taken an H100 GPU to the orbit and I'm told that it is working perfectly. and doing high

performance computing load in last two months and that has maybe that has uh encouraged alone to announce a million satellites where data centers will be hosted on the orbit in the coming years.

So if trillions of dollars investment on the grid which we are going to make on ground what will happen to that if all the data centers are going to be on [laughter]

on on the orbit these are points to ponder I stop here it was a great presentation great many points where uh there are no solution this and and this 10,000 ft¬≤ 30,000 ft¬≤ data center to

square mill data center is something which happened in 3 years it it didn't happen over a decade or a century. So this is something new uh unknown unknowns are dealing with we and

everybody has to work together and our NEP national electricity policy 2026 is little oblivious of this data center challenge. We have given some comments. I I think maybe

grid controller and other people will give more comments on that. Thank you. Thank you all the speakers and thank you
