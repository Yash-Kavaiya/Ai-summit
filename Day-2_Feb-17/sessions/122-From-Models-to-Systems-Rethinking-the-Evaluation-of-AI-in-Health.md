# From Models to Systems: Rethinking the Evaluation of AI in Health

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:30 ‚Äì 16:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room No. 6 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/vvjRbQV6k9E?feature=share) |

## üé§ Speakers

- Arjun Venkatraman, Gates Foundation
- Dr. Mona Duggal, ICMR
- Dr. Smisha Agarwal, John Hopkins University
- Dr. Suruchi Gupta, Center for Global Digital Health Innovation (CGDHI), John Hopkins University
- Mala Kumar, Humane Intelligence
- Sameer Pujari, WHO
- Sarang Deo, Indian School of Business

## ü§ù Knowledge Partners

- Center for Global Digital Health Innovation

## üìù Summary

AI is increasingly being adopted across health systems, but evidence on safe and equitable use remains fragmented and not consistently aligned with decision-making needs. Existing frameworks often prioritise model performance over real-world interactions with digital infrastructure and contextual factors. This panel will examine methodological gaps in digital health research and discuss a more holistic agenda for AI integration, governance, effectiveness, and equity, concluding with a set of recommendations.

## üîë Key Takeaways

1. AI is increasingly being adopted across health systems, but evidence on safe and equitable use remains fragmented and not consistently aligned with decision-making needs.
2. Existing frameworks often prioritise model performance over real-world interactions with digital infrastructure and contextual factors.
3. This panel will examine methodological gaps in digital health research and discuss a more holistic agenda for AI integration, governance, effectiveness, and equity, concluding with a set of recommendations.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/vvjRbQV6k9E/maxresdefault.jpg)](https://youtube.com/live/vvjRbQV6k9E?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

Um we have chat bots advising mothers on um neonatal care, infant nutrition. We have chat bots simplifying management for paliative care. We have algorithms predicting disease outbreaks and even

ambient scribes that can document and populate a proper electronic health record for clinical encounters. The scope and promise are enormous. But here's something that you know intrigues

me a lot. Our evidence base is probably not keeping up with the pace of innovation and we have a pattern emerging that's eerily familiar to most of us who've

been in the digital health space for a while now. So two decades of digital health research have showed us persistent methodological gaps and limited attention to the context of

implementation which is something that we found ourselves talking about a lot in the last one and a half days. Um our work at the John's Hopkins Center for Global Digital Health Innovation has

documented this systematically and now with AI we risk repeating the same mistakes but at scale at speed and with potentially greater consequences. Um coming to AI evaluations. So most AI

valuations today focus on model level of performance which is very very important such as accuracy metrics, benchmark scores, but they almost tell us nothing or very limited about whether frontline

health workers will actually use these tools, whether they'll work in facilities with unreliable electricity, whether they'll reduce health inequities or worse amplify them. And lastly and

most importantly whether they will actually drive health impact while being worth the opportunity cost in resource constraint settings. So today we're bringing together leaders who represent

the full ecosystem. We have academics, global funders, normative agencies, responsible AI advocates, and together we're going to examine what a more intentional evaluation approach to AI

might look like. Um so let me introduce our exceptional panel and yeah we have with us Dr. Sisha Agarwal director at the Johns Hopkins Center for Global Digital Health

Innovation as well as associate professor at the school. Dr. Agarwal has over two decades of experience leading evaluations for digital health and AI tools as well as ecosystem readiness

assessments. She brings critical insights on what makes evidence actually useful and applicable for decision makers. We also have with us Dr. Mona Dougl who is the director of a national

institute of research and digital health and data science at ICMR and opthalmologist by training. Dr. Dougl and ICMR are at the forefront of establishing AI evaluation frameworks

for India with a focus on data sovereignity and safety. Um we have with us um Samir Pajari who leads AI for health at the World Health

Organization. We all know WHO has led standardization for digital health evaluations globally and Samir with us today will share insights on what's needed to do you know what's needed to

replicate this for AI based health interventions. We have also with us um professor Sarin Dio who is uh the professor for operations management at Indian school of business. Dr. Dio

brings the operational and economic lens and hopefully we'll listen from him today all of his expertise about metrics that matter for adoption and evidence that justifies scale up.

Um we also have with us Arjun Wenatraan, senior program officer at Gates Foundation. um Arjun brings a founder's perspective on how to evaluate AI investments that span multiple sectors

and depend on several dependencies. So uh let's get us started and I will pose my first question to Dr. Smisha. Um Dr. CJDHI's analysis of digital health evidence over the past 15 years

has revealed significant gaps that I was just talking about especially with limited attention to implementation context. As AI tools rapidly enter health

systems, we face a similar inflection point. So, drawing on those foundings, what would a new more intentional approach and agenda for AI and health look like and how do we move beyond and

not repeat the same pattern that we have often found ourselves doing? Thank you Suji and um thank you everyone for being here. Um, of course, this is an area that, uh, we have worked in for a while

and so I have some slides in case we can pull those up. Um, and I knew this question before, which is why I have for it if it is feasible to pull it up. Can we go back to the slides instead of

a &gt;&gt; Thank you. Perfect. Um, so I think uh, what we've seen over the last two decades of doing evaluations is that most evaluate most innovations fail due

to lack of intervention context fit. So you see the simple graph here. It's a messaging service which could be uh which actually the next steps are to integrate AI into this messaging

service. And when messages are sent to a cervical cancer screening population we see a 4x impact. In the same population when messages are sent to a hypertension diabetes care population we see barely

any impact. And what this shows us is that the high level of impact for cervical cancer is actually driven by the age of the population. Uh it's a younger population in the 30s versus a

older hypertension population in the 50s. And um a younger population is more likely to have smartphones and responsiveness to the intervention. So intervention is the same, population is

the same, but the actual match between the intervention and population is what's driving impact. uh what's happening with current AI evaluations is they are largely focused on models uh a

lot of emphasis uh is on supercaling superersizing uh repeating models uh but they fail to actually answer questions about the context within which the model is faced because what we see repeatedly

with any level of digitization in community in primary healthcare secondary tertiary care settings is when you put models even a excellent model into a context, it might fail because

healthare professionals don't use it. It might add to their workload. Um the devices that it runs on are suboptimal. I think that's a popular the uh issue that's often underrecognized or people

may not trust the output. These are just some reasons but the list of reasons are endless. And what that results in is low fidelity is people don't land up using the tool. So I think um in a previous

panel that I was on, we talked about chat bots and community health workers. But the question is how often do they use it? Do they depend on it for their information is a key question. And so

even when models work well without interventions, risk predictions have no health impact. So we can have a ton of massive data that are high quality that have low missingness uh that are very

well representative of the target population and we have high 99% accuracy right but in an implementation context you put it in the wrong context with poorly trained doctors with facilities

that are illequipped you can't take action on the results and that's the summary of it. So a perfect model but we can't actually act on the results and ultimately we see no health impact from

the best working models and so we really um in this space need to think beyond model accuracy. We need to think about the right solution and maybe this is speeching to a public health choir right

but the right solution for a it starts with the problem. Um often in innovation space we have a solution and we are trying to find a problem. Um and we need to understand the context. We need to

recognize that a useful tool is really a tool that is that is used you know it'll be used if it's useful essentially and that when um AI models are highly complex as they often are are a black

box they tend to have low fidelity because of low trust. Um I this is actually a summary of who guidelines for digital health that were were released in 2019. And what you see

here is that the evidence is actually quite poor. There wasn't a lot of evidence on how digitization improves uh healthcare. And part of it is because we just prioritizing and measuring the

wrong outcomes. we tend to overindex on impact on downstream outcomes. Um and measuring outcomes that are too further downstream results in us not being able to show anything at all. So let's say AI

powered clinical decision support tool for diabetes will improve diabetes control. Um this is a wrong definition in some ways because what goes in between is AI powered CDSS will improve

quality of care which will result in better adherence which will improve diabetes control but better adherence is dependent on availability of drugs habits at home affordability many other

factors the supply side factors which are interventions not addressing and so the right when the right outcome has to be closer to where the intervention is and we have to stop overindexing on the

outcome that is further downstream. Um I think also the right right counterfactual the evaluation we often see the challenge of this. I think a lot of AI tools are being embedded into

digital tools and we want to we have to have a clear definition of what the comparator is. Is it paperbased support? Is it digital decision support without AI? But but acknowledging that AI can

add cost and complexity and we want to account for that as we think about evaluating these tools and um I think apart from how to do and I can go on about this at length but how to do it um

how to evaluate these tools um there are some critical approaches I I think we've heard across that RCTs are not the way pace is critical so is rigor so is neutrality you can't judge your own baby

there is no way that you know you can evaluate your own child uh rationally. Um you build for the problem. Um there is really a role for research teams to be embedded within programs for rapid AB

testing and quality improvement. Um we need interdisciplinary impact teams. And then we need a pragmatic approach that considers proximal outcomes, counterfactuals and contextual

variations. And I'll just start there rapid fire and over to you. Thank you. Um that was terrific and I have great followup but I'm going to come to that later. Um we spoke about

problems and starting from problems you know and instead of um not not looking at the solution first but looking at the problem and then designing it even within our work at the center I think

what we've um learned is or what I have learned is that for every digital health tool you need to there are different outcomes that are affected and you probably need a different evaluation

approach for the same. So here I have a question for you Samir um which is that who's work at um designing the digital health taxonomy has supported standardization of

evaluations for digital health for all of these years. So what do you think is needed to bring about a similar standardization for eval for AI based interventions?

&gt;&gt; Thank you Suri. Thank you very much and thanks uh for setting up that structure and the tape. I love this image by the way pick it up for everything. I mean it's so so nicely explained

&gt;&gt; indeed so nicely explained and I think uh it's very important u I was in the morning session this morning and I think we all here to see AI grow and scale I mean that's why I think what in either

way of it we see the potential but we want to be careful about it right and and the core that comes behind was governance of course which is required but then trust and I think one of our

colleagues actually mentioned that we do not need to worry about scale the users the patients will scale to themselves right but the trust has to be there Now how do you build that trust and this

brings to the question this is a foundational questions that you're looking at at who to understand that first the trust factor we need to understand what AI is doing and where

the different structures or different tools are this is what happened in digital uh health I mean everyone started talking about digital health we have M health we have e- health we have

SMS programs but there was no structured taxom no understanding of what's happening so you could not evaluate you could not understand what this specific solution is doing and how do you do it

and I think that's the core it's like learning your grammar in the school the language in if you can't speak properly you will have chaos it's like putting people from 10 different languages in

the same room and not having a coherent language and that's I think where the core of the taxonomy comes into play for evaluation for anything if we can all speed the language and it's different

schools we're coming from the developers I was talking in the morning session again ethics is just a buzz word for them regulations is a dangerous word for them but to understand that the

taxonomic together I mean we've seen we have heard about diabetic retropathy we heard about radiologies pathologies CDSS we've launched this case book on health cases for this purpose itself in the

morning is how do you categorize and just for the lack of of tax in the beginning we said let's put them to six buckets we have computer vision as one of the first ones right where we have an

understanding of all the technology around vision because AI uses a different language and health is very different so we then started to look at all the vision protocols where we can

use and how we can see and that's where AI has actually moved a lot the CDSS or the language models as we're fitting into that world is new it's quite he it's very happening in the space but do

we do need the science behind it right so that's still evolving in that we have ambient AI with sensors coming in as a big area of work just by categorizing these big areas and then we have digital

twins which is an upcoming space Mona spoke about in the morning where we have the potential to upgrade science differently AI fits differently into these different boxes that we're looking

at and I think that's Why it's so important to have this taxonomy to even start the foundation of evaluation and evaluation has to be practical, real and implementable.

That's what the key part is to facilitate that again to build that trust we need to have the taxonomy build up and I think that's what we're doing from who's digital taxonomy is try to

replicate that and create that through the evaluation group working with different partners so that that language becomes universal and so anyone who wants to regulate that product or scale

it up is able to then replicate the same taxonomy understanding I think that's why the foundational issue of of taxonomy is critical and again it has to be delivered through global

acceptability So I'm again as a call for this group is let's work together and do this as something that we can then scale appropriately. I'll stop at that. Thank you.

&gt;&gt; Thank you. And a quick follow up on that. I heard you talking about safety and regulation and you know just lightly alluding to these um big terms problematic terms and uh I want to ask

you that several AI vals today they emphasize on accuracy on tech performance right so what from the WHO's perspective are additional domains of evidence that should be considered

essential before AI tools are recommended or scaled &gt;&gt; how much time do we have uh in the two minutes. &gt;&gt; No, I think that's a very difficult

question to answer, right? I mean, you and and the answer it is difficult because you don't have to have one formula fit all, right? There are we have to look at the value chain of each

of these products. There's some which are very helpful healthcare providers assistance which can be deployed rapidly. They don't have access to health resources. These can be

facilitated through chat GPS and I think they're low hanging fruits or the the chats um in in a sense these can be put out very quickly. If you're talking of robotic surgery as as robotic uh

arguments that's a different ballgame. So you need to have much more regulated components of it. So the regulation we are working with uh who is working with about 50 regulators globally. We've been

working for the last two years drafting temporary laws for them as well. The the point is that you cannot regulate single product for single place. It's different in different countries but it needs it

has to meet the problem statements in the areas and don't generalize is what we're saying formulas. It has to be localized at the end but we have to keep it at a way where every product is

different. Two years ago we did not know that the CDSS can be influenced with the large language models and the generative AI models right and the regulations work started before that. Sorry. So it was

very difficult to address from that perspect. I think we should be agile as a as a regulator we are putting out checklist and we're being doing that for ethics for equity. We are putting out

checklists already. We have training modules where people are being trained um working with as we'll be putting out some training modules for integrating education in the health medical systems

as well. So that we have to continue doing from our side we have looking at the current problems but where the technology exists and the opportunity exists I think what we want to do is try

to simplify the process of scaling it up. We don't want to have a hindrance where during COVID where we had technology to contact trace it but because there was no regulation in

several countries we could not deploy it for several months and that gave us a massive problem. So I think that's what we are trying to target is without answering directly your question and

being very bureaucrative on it. The point is um I think we want to facilitate AI as much as possible. Um and there should not be any once formal fit all answer to it. Thanks.

&gt;&gt; Great. Thank you. Um but since you were quite bureaucratic about it, I have to move to Dr. Ma and let let me reframe it. So you know we know India is thinking very seriously

about data sovereignity. Um how can we drive the assessment of all of these safety guardrails that need to be kept in check and how do they pertain to data security and safety and what steps has

the country taken for it? Um thanks. Yeah. Um so I think uh India is actually like uh we are almost at that point where we have to think and coming from the ICMR perspective I think if we

have all who have gone through the HMSSE uh people who understand HMC that is uh the security c like it's a screening committee but if uh people don't understand it is like all the ministries

do sit there uh and we do screen a lot whenever there are foreign funding anything that is involved we have a screening mechanism where uh anybody who's applying we have to check how the

data is going to be shared. Um people are aware the biological specimens a lot of those guardrails have already been implemented. So you have to be very careful how you actually word it and how

much data it's only now for the quality check but in research pretty much the biological specimens are if the India itself has the capacity it will do it within the country and if we do not have

the capacity any foreign funding and any partner we request that the uh the capacity is built within the country has a part of the ground. So this is something that we are doing in the

biological specimens for the AI part as we are talking uh the data we already have now the data repositories all the big three I think DBT DST and ICMR we have our own data repositories that are

there uh earlier I remember that uh public funded we did not have to deposit any of the data but now with new uh guidelines if you are looking at anything that is publicly funded for

research will come into the data repository of the research organizations. Those are the steps that are being taken now. So this is something like we are already doing for

any of the research also even if it is foreign funded. It has to be within the like the cloud has to be within the Indian data Indian uh boundaries. You cannot allow the data to sit anywhere

else and all the compute and everything has to be done here. Whether it is implemented well we are we still have to figure that out. But yes those are some of the things that we are already

looking into. [sighs] Second comes the state and the ABDM. I think the states already have their own data exchanges that we are working in. Telangana has it. Orisa already has built there.

National level thinking has already started. How do we actually talk to people uh talk across uh the research organizations in a federated system and where the data can sit and it is there.

ABDM has a consent manager. we uh are looking at the state level where the states are taking the implementation challenges at their level to ensure those things are done at this level. Um

I think we all miss that health when we are talking I think because this is a room that is full of people who are very enlightened but we we actually talk to the health sector I think there's a lot

of capacity building that needs to be done so because um coming from that background I think Samisha also knows it for us data is uh something that we really do not think that rationally what

is data privacy how do you share it those things have to be built ground up so those things have to be the guardrails like I think uh we have this now the chart GPT and all where we have

the medical records how to upload the simple thing how are you uploading do we really realize that we are not supposed to share how much and where but in the finance I saw that the moment you have

these things there's a lot of IEC that starts happening but in the health we are still that much backward so I think the implementation part the IEC part has to come out so that has to be in

otherwise it is going to be a long road now how do to train. I think uh the training has to be start. There has to be some courses like we have statistics now as a part of it. How do we train?

How do you share data? What is the data privacy laws? What is the DPDP act and how do you actually implement it well? So those things have to be starting right there at ICMR level at the our

level. We are the going to be the enablers of it. So we have already started talking to the state at the state level. So like if they can build the like something like called like

computational health units it's not it is you can name it anything but the basic idea is like we are the many mini replicas. So at least you have people within the state who are trained in both

the languages. It is like you understand compute, you understand medicine, you understand technology and you understand the law and those are the people who can guide the state level things so that

anybody and everybody who goes to the state they're able to help them decide whatever this anybody is coming with a solution is it applicable in the state is it something that can be integrated

in the health systems unless until you have those kind of guardrails at the state level because health is a state subject it is going to be very difficult for us to implement. The good thing

about ICMR is we uh are kind of pan India. We are we do not it's a research organization but when it is implementation level it becomes a state subject it many of the things uh lie in

the they are going to be at the state level. Yeah. Perfect. Thank you. Um I think what I was hearing a lot was um data compute where do you store it as well as ABDM

which brings me you know segways very nicely into our next section where we want to talk a little bit about digital public infrastructure. So Arjun um you know you place a bunch of investments in

several AI domains you know across health across finance, education, social protection and the value here actually the primary value here lies in shared digital public

infrastructure and Dr. Mona also just alluded to finance and how we so much clearer when it comes to finance but within health we out here uploading our you know personal health records on

chant GPT and asking if he should get a gallbladder stone surgery. Um so what lessons from AI investments in sectors like finance, education or agriculture have most strongly shaped how you now

think about AI and health system? &gt;&gt; Yeah, it's a good question. Thank you. Um, so I'll try and respond to some of the stuff that other folks on the panel have said and then I'll try and tie it

back to what you're asking. See, I think some started us off with a nice term taxonomies. It's essential what we what we've realized and we've been working with AI in India for at least 5 years.

Um I remember when I joined the foundation in 2020, COVID was raging and we were doing data modeling um on disease spreads and figuring out how many beds you need in what hospitals and

so there was technology developed for that and u and the same considerations used to show up who will share data with whom is it is it okay to share data at an institutional level what protocols

should be there and DPDP was not out by that point in time so lots of things were very ambiguous there were draft rules tools that had come back and forth. There was lots of debate about it

and then we had a crisis going on. So within those constraints I think a lot of stuff got understood and developed. Um the government did a phenomenal job a fair number of digital interventions

that I mean at least a few of the folks here would have used to get their vaccinations done and and then track some of that stuff and then use it to travel. Obviously there were challenges

but uh but for the most part it it allowed the the majority of people who wanted to do what they needed to do during that time to get it done and I think those are the lessons that have

really shaped a lot of the thinking about DPI is sort of a substrate for AI in that regard. So so so how does that scale up? It's shaped a lot of that. So

we tend to think of our investments as well either use cases being use cases or being enablers. And within the enabler segment we think about three broad kinds of enablers data infrastructure and then

what we call the ecosystem which is sort of a broad term but it it covers all of what uh Dr. Doug said about capacity building evaluation training building the context um capturing mechanisms for

different use cases. It it takes it really takes an ecosystem. It's it requires different actors to come together with different skill sets, different expertise and

different authority to to engage and then align on the right way to go forward on some of these things. And this is what then allows for the infrastructure to get deployed. India

has done a phenomenal job of demonstrating how a country can rapidly build up its core infrastructure requirements um simply by having public finance targeted at the right sort of uh

in the right sort of way. So having a subsidy announced and then that stimulates private sector investment and then eventually you get to a point where it's no longer a challenge and you have

H100s available for less than a dollar an hour. So so we we've already reached that space and we started only in 2024. So it's been demonstrated that if you get the right ecosystem together and you

have the right incentives in it, you'll get there right. So so so there are problems that are solvable even at scale and India has demonstrated this in the past with population scale stuff like ID

payments. Um I mean for all the complaints we all make about things not working and you know this environment here that we are in in the summit a lot of folks have expressed some discomfort

with the crowds and so forth. But this is what AI and technology is going to look like in the global south. It's going to have to deal with crowds. is going to have to deal with noise. It's

going to have to deal with heat. Um, and it's going to have to work under all those circumstances and get us into this room having this conversation. It's managed to do that. So, I think we're on

the right track. um from data piece, I think data has been a contentious conversation for the longest time because what we've inherited from the big

technical profit generation systems of the world is that data is your oil. It's your moat. It's what allows you to retain your edge in the field and therefore there's absolutely no reason

to share it. Uh this this works very well when you're thinking about pure commercial outcomes. Uh but when you're thinking of developmental outcomes or population scale outcomes or or outcomes

for vulnerable populations, that math may not always necessarily hold because those people aren't going to be paying you. It's probably going to be a government paying you on behalf of those

people and that requires solid procurement structures, good thinking, transparent standards that can be questioned, audited, improved upon as we go along. This taxonomy that I'm talking

about is the taxonomy we have as of today. this taxonomy has was very different one year ago, it will look very different a year from now. In that sense, it's less a taxonomy and more an

ontology. It's a it's a bit of an evolving space. Um but but [clears throat] we are confident that if we are constantly sharing what we are doing and and what is what the outcomes

are. I heard something really interesting in a panel this morning which said we shouldn't be thinking we shouldn't be evaluating say health AI on whether doctors think it's doing a good

job. It should be about did the patient have the right outcome and that's the ground truthing to device loop where you want to actually eliminate potential for error. Um and that's a hard job to do

because at some point you are going to have to have a human take accountability for a decision and and then how do you play off the incentives there right? So this is this is the enabling the

enabling part and here the ROI is really how much does your enabler how much how many use cases does your enabler support and so things like language technology uh very clearly

support multiple use cases and uh some of the foundation model builders from India have been demonstrating some very good uh tool sets around very relatable sounding AI very different from what

we've heard from the west so far very relatable very non It it doesn't sound like a very enthusiastic thing trying to sell you something. It actually sounds like somebody who's who's giving you a

service and you don't want to engage just for the sake of listening to the voice, right? This is the kind of design thinking that needs to be there. So these sort of tools will really enable a

lot of uh different kinds of use cases and so we think those are sort of things that are really good to invest in irrespective of um the use case because it's it's kind of agnostic in that

sense. from a domain specific point of view here we rely more on our program teams they are the experts in in the kind of things that they want to get done in their particular areas. So so we

do cross learn. So what we're realizing is that for direct to consumer use cases um engaging finding the user and getting them on your channel is really the highest cost in in the commercial world.

This is called a customer acquisition cost. I tend to find the term acquisition a little problematic in in the context of developmental use cases. onboarding maybe a better term but those

costs are are generally pretty high in in most countries where you don't have a strong um BPI identifier and what we feel is that in India this will be radically cheaper because you already

have certain structures built up you have a farmer registry you can reach farmers it's all in one place what you do need to do is convince the government and the ministry of a that this is

actually a good idea uh and that's the hard part because now you have to show benchmarks that are transparent can be compared to other folks and and this is where I tend to become very unpopular

with innovators because I insist on dealing with solutions as classes and not as individual products. This is essential for procurement and this is something I tell people who are

innovating in our partner ecosystem as well. While you might think of your product as unique, it is if you're ever going to have it deployed in a public context, you have to think of it as a

member of a class and it has to be able to compare itself to other members of the class transparently. So I think these are some of the basic core principles that we are we are um looking

at when we go into evaluation of AI as well. Uh what's going to be [clears throat] interesting is to figure out how to keep evaluating while the technology is changing rapidly and uh

and there I feel we need a lot of innovation in the science of evaluation itself. I mean what methodology will we use? Is RCT going to make it on uh you know it's going to be the only way we

evaluate AI or is it going to need something which is more dynamic where you can look at a control and a test arm simultaneously cross share learnings. This has been anthemma for the longest

time. You don't want to mess your control with your test and all of that. But I feel like um these are the things that we'll have to start questioning. We have to start questioning some very

basic ground rules. &gt;&gt; I'm going to have to stop you. &gt;&gt; I'm sorry about that. Uh we still have Dr. Saram for his remarks. Um so I'll keep it very brief and quick. Dr. Sarang

um you work at operations management and essentially scale. So what according to you are the operational metrics that we should be paying attention to and that are often absent in many of the digital

health and AI valuations in healthcare. And second, I'm sorry, I'll just say it. um in your experience what matters more for successful AI adoption is it model

sophistication or is it alignment with existing organizational processes and I'd also like to give you back what Arjun was just talking about you know this entire debate with do you use RCTs

do you not and how do you balance this with the time that RCTs take and map it with the you know that speed with those speed of uh which AI evaluations are booming.

&gt;&gt; Okay, that's a lot, Surji. I'll try my best. Um, let me just say this, right? If the theme of the panel is evaluation and evidence, um, you know, we all start with sensitivity, specificity, area

under the curve, those sorts of metrics. And I was reflecting on what the panel was was talking about. Uh, I use drugs as let's say a parallel, right? As an analogy. Uh, we talk about safety and

efficacy when we approve a drug. Correct? So think about sensitivity, specificity as those types of metrics. They're relevant to a regulator and and we talked about that, right? But I think

regulator is not the only entity that's evaluating a tool, AI tool, digital tool. So the question we have to ask is who is evaluating and for what purpose? Correct? So it could be um MDNHM

evaluating a tool, it could be a hospital administrator evaluating a tool and they would look at different evidence. Therefore they would look at different uh metrics outcomes. Uh what

is very clear and and this is people know this is technology people systems is the troa that we typically talk about right. So this technology this AI tool is going to get embedded in a health

system that is people by patients right. So if you want to have again if you think about clinical AI and if you want to have an impact on patients as an operations person I would say it's

important to understand the baseline which is how are patients accessing care today what is their pathway and where in this pathway do you want to embed this particular AI tool and what do you think

will change as a result right a quick example is suppose you know you want to do something with non-alcoholic fatty liver disease right we've been hearing about this right and we say I have an AI

tool and and the AI tool is so sophisticated and so accurate that I want a doctor in a tertiary care facility to use it. Now, if the problem is late presentation of patients in

advanced stages of the disease, having a tool that can only be used in a tertiary care facility is not going to cut it in terms of health outcomes, right? So, immediately right off the bat,

understanding this pathway is important to say which tool would be appropriate for me to have an impact. Right? um just and I want to switch gears a little bit here because we implicitly

talk a lot about clinical AI but there could also be nonclinical AI also in a non-public health setting so let me say private health because I'm guessing 90% of the people here or 80 70% of people

in India seek care in a private hospital right what are they doing to evaluate AI tools and a lot of those use cases could be nonclinical so we hear about discharge summaries all the time. Right?

So there's an AI tool that reduces discharge summary creation by 50%. What was taking half an hour takes 15 minutes. What was taking half an hour now takes 10 minutes. Right? How should

a hospital evaluate this tool? The first question is I mean this is coming to the metrics question, right? Reducing the time it takes for discharge summary. Does it actually reduce the discharge

time of the patient? What do you think? We don't know because there are many things that go on in parallel before a patient can be discharged. So the impact on just the discharge time may be

actually zero because creating of a summary is not a bottleneck. Right? Furthermore, it could be that reducing the discharge time by 15 minutes has no impact whatsoever on the bottom line or

top line of the hospital. So then the willingness of the hospital management to invest in this tool is going to be very minimal. And I think this is the kind of message that needs to go back to

the innovator to say you know what is the ultimate impact but also what is the proximal impact that you're trying to have right and if I now talk about those environments uh coming back to the

methodology Suruchi a lot of businesses in India across the world run successfully make money without RCDs of course we have AB testing now right but that's online businesses and they

can do AB testing so I'm pretty sure that there have other ways to evaluate tools. It could be experience. It could be mixed methodologies. Um I think the bigger question for us is you know the

wedge that always exists between private uh incentives and public health goals. So the question is how can we make sure that the private entities adopt AI tools that are good for their business but at

the same time lead to better public health outcomes at the national subnational level. Right. And the last thing I will say, I've talked about the hospital administrator, but also think

about an MDNHM or a health secretary, right? I think the discussion that needs to be had is you know what is my strategy for my state? What are the health outcomes that I want to push? Is

it IMR? Is it MMR? Is it you know number of you know diabetes control days of my population? Whatever it is and therefore which AI tool should I procure and how should I procure them? I see so much

enthusiasm to develop AI tools. [laughter] It's exciting. No, it's very exciting. But as you know, Arjun was pointing out that the class of these solutions, how

can I buy? And I have to say this, right? If states are going to buy AI tools, they have to enter into some budget line item somewhere. So, we will have to at some point talk about NHM

budgets, PIPs. without that there's no going to be no public health impact of AI tools. I'll stop there. Thank you. &gt;&gt; Oh, that's terrific and um very impactful. Thank you for your comments.

Um we have under five minutes. So I was thinking if we can do one short quick rapid fire round with just under a minute each speaker I'll start with you. I know you've been thinking about sorry

this is this was not in the notes. Uh I know you've been thinking about AI and DPI and Arjun hair provided a lot of insights on that. So what do you think and where are you coming from about

this? I &gt;&gt; mean I think uh DPI is of course the necessary foundational uh infrastructure for AI to thrive at scale. uh of course there is a lot of AI that can happen

that has happened without cross- sectoral DPI but if we really want uh if we want the benefits of it to exist across populations like I I think in India we've already taken the steps with

ABDM to create the health data exchange uh there is already the financial sector and their digitization of that data which uh which is I think the critical sort of under underpinning for then

start to start to do um start to think about how can we actually operationalize this for for use in AI. I'll just keep it brief. &gt;&gt; Yeah. Oh, we have 10 more minutes. You

can take more time. Sorry, our panelists need to leave. I think yes. I don't know. So, do you have a question? Sorry.

Um I think what I wanted to ask you was that you know you're coordinating research at ICMR at state level and national level and across in you've been in digital health and now moving to AI.

So what do you think is the biggest mismatch here with what we have and where should we get at and what do you see as the pathway to get there? &gt;&gt; Uh so I think I alluded to the fact that

really you need like a midway population that understands both the languages. I think uh somewhere uh at least people need to get together or more courses need to be developed where all three can

get together. Uh even like when I'm now sitting at ICMR uh I'm looking at the kind like you having lot of proposals that are coming in uh but we do not have enough people to review them. So the

training even to review the like what kind of proposals are coming in uh because even the innovation every everybody puts in the proposal this is an innovation but you cannot have up to

6,000 proposals that are coming in 3,000 have AI as an innovation so so how do you screen them out and how do you understand which is actually really people understand what they are doing

and there are people who do not understand simple budgeting they do not even understand what kind of budgets to put in. So just simple training capacity building both at the level that is the

youngsters that are coming up to that understand the language and people who are reviewing it if they can be done because that is what is required at least at the research level at the state

level identifying people at least the good thing is like many of the what in our experience I think we have worked and sisha I think you have done a very good job you're getting lot of

bureaucrats under your in at the center of global health so uh seeing where we can get that synergy because if you have people who are at the policy level who are now trained and they have that kind

of a background it is easier to kind of tie up see where those synergies are because many of the global universities where they are being sent to be trained by the government of India so that

network can be utilized to to kind of put it in the states so I think that is where probably those synergies and collaborations can be built like &gt;&gt; yes and we have a panel on workforce

tomorrow um so we'll dive into that uh tomorrow again. Um, quick question for you, Sam. Do you want to add to that? &gt;&gt; No. Okay. &gt;&gt; All right. Okay. We'll see you around.

Um, we were just talking about with you taxonomy and Dr. Mona was also talking about language. I think for myself as a healthare professional who's now working in digital and AI, one of my biggest

concerns has been how do you translate all of this tech language into healthcare people language? There is a lot that I still don't really understand. done you know and it's also

not standardized across AI or tech people they have their own terminology depending on where they work or what school of thought they have so what are your thoughts about a way of making sure

these two schools talk to each other &gt;&gt; it's easy just feed them into chat GP about that no I I think it's again the foundational pieces right I mean uh where we doing it uh how are you doing

your operation and that's why evaluation going back a step behind we're talking of evaluations right the whole discussion on clinical evaluation is one part of it but we stop there often and I

think that's where the challenge of whether it's actually scalable and practically uh implementable doesn't get unanswered so I think we as who and as a group of experts what we're doing is

trying to look at evaluations three pockets one is of course clinical which is the core part of it which has to be rigorous it has to be scientific it has to be done very well but then you also

have to look at the operational evaluation of these programs right I mean a lot of people have been saying there are programs Can you solve things but are there really a problem or just

creating a solution for the sake of creating it fantastic evaluation wise does great job but there is no problem to place it operationally do you need that can you scale it up and I'll give

the example of cervical cancer screening we've seen this problem in in rural Africa global south it costs several hundred to screen female in settings with AI you can take the device to the

person the healthcare worker is now enabled reducing the cost to few dollars I mean that was the operational evaluation that caught out of it and that's scalable. I think that's what we

want to see also impact so we don't all wasting time and and just doing something that's in there. And the third one which which Sud is goes back to the money I mean no matter what it's all

about how much money we have how much can be done. So the economic valuation of those or evaluations of those are very critical as well. So I think the taxonomy or the discussions around that

language has to speak to these three evaluations. Can we have a same language? I don't know if we need it also or I mean yes it has to be understood but um again let's

try to I mean my point would be to see if we can pick up those three areas of evaluations agree on those work together and I think at the core of it is again not just the health and doctor sitting

together or the developer sitting separately in a different room I think it's this kind of group that you've brought together is to come together and talk about it and and try to solve it

and I think I think as as was mentioned it's important that bringing them people here discussing and then taking action into the next stage is critical So I think that's where I'll stop it. Thank

&gt;&gt; Perfect. Thank you. and um pivoting the conversation to money and um so how do you think AI evaluations and this is also a personal problem that I have faced in um evaluations for digital

or AI it's very hard to do costing for them right and now we going into a completely different era and now we're also talking more and more about DPIs which are also so intersectoral and you

know some DPI has been created for something already so how do you envision evaluations um that can capture indirect or longerterm returns from DPI investments.

&gt;&gt; Yeah. No, so so ROI calculation is hard when it comes to development sector investments. In any case, impact evaluations have been not the easiest to do in in this sector

and and we have a lot of history on on how RCTs have been used in the social sector and all of those as well. I think when it comes to evaluating digital and AI technologies like I said was was

finishing towards the end of what I was saying earlier was that you need new methodologies and you need new definitions of how do you do this rapidly. So process evaluations, AB

testing, what we're realizing is that you you cannot do what what was that baseline, midline, endline kind of stuff for a lot of digital stuff. You have to do active evaluations and there are ways

and means of doing that. So when we've gone and done I mean to Son's point as companies have been doing this. We've now realized that we now need to bring some of that commercial rapid testing

approach into um thinking about ROI in in these use cases as well. and that's going to be the the sort of thrust of the next couple of years for us as well. So, so

it's a work in progress. &gt;&gt; Thank you, Dr. Sarang. I feel like you might have something to add. &gt;&gt; I mean, first of all, let me say I'm not against RCT. Okay, I'm running a couple

of RC cities myself, so don't mean to create any enemies. Uh, I think one thing that we've not talked about enough is for clinical AI, the role of the clinician,

right? And we often don't understand this puzzle enough. uh we ran a study where we looked at these X-ray reading AI solutions at first point of contact informal providers right so so one of

the stories we tell ourselves is because the skill set of informal providers is very low AI can help uh to improve those you know outcomes what we found in our study was those who are already good at

diagnosis where the providers who are more more willing to adopt AI and those who were poor at diagnosis were less willing to adopt AI. So again this human uh you know kind of psyche is another

missing piece. So I would say operational that Samir talked about you can split it into two parts system part of operations but also the human part of operations because that can again bring

down the impact of AI from what we imagine it will be. So the adoption that we think about is an endogenous adoption that works for some human agents and doesn't work for others.

Yes, certainly. I think we are at time. I was trying to avoid that. Um, great. Please join me in a huge round of applause for our incredible speakers. Um,

it was um, yeah, exceptional listening from some of the best in the industry today. And I want to quickly summarize, sorry, trip uh, give you like five take home for everyone right here. And um

first evaluations must consider the whole ecosystem, the model, the user as well as the context. Model accuracy is very critical especially for contexts where these models are usually not

developed. And we need contextual studies and evaluations to understand these and to drive outcomes. Um as far as RCTs or rigorous methodology is concerned, we need to find newer ways so

that this methodology can keep up with the pace. We also need to focus on IEC for AI. And lastly change our outlook from did the doctor do any good while he used the tool or she to did the patient

have a good experience. So that's it from us. Thanks so much for attending our session and um look forward to connecting afterwards.
