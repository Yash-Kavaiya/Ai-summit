# Building Trust in the Age of Synthetic Media

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 14 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/IB4kqutX_4Y?feature=share) |

## üé§ Speakers

- Andrew Jenks, Microsoft
- Andy Parsons, Adobe
- Deepak Goel, Ministry of Electronics & IT, GoI
- Gail Kent, Google
- John Miller, Information Technology Industry Council
- Sameer Boray, Information Technology Industry Council

## ü§ù Knowledge Partners

- Coalition for Content Provenance and Authenticity (C2PA)

## üìù Summary

This session will convene a policy dialogue at the India AI Impact Summit 2026 on the role of content provenance in enabling safe and trusted AI. As synthetic media scales, provenance mechanisms can support transparency, accountability, and trust. The discussion will situate provenance within AI governance and digital public infrastructure frameworks, explore standards-based approaches to address mis- and disinformation while protecting privacy and free expression, and examine practical implementation pathways and public‚Äìprivate collaboration.

## üîë Key Takeaways

1. This session will convene a policy dialogue at the India AI Impact Summit 2026 on the role of content provenance in enabling safe and trusted AI.
2. As synthetic media scales, provenance mechanisms can support transparency, accountability, and trust.
3. The discussion will situate provenance within AI governance and digital public infrastructure frameworks, explore standards-based approaches to address mis- and disinformation while protecting privacy and free expression, and examine practical implementation pathways and public‚Äìprivate collaboration.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/IB4kqutX_4Y/maxresdefault.jpg)](https://youtube.com/live/IB4kqutX_4Y?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

I should start at the Hello. and welcome to building trust in the age of synthetic media at the India AI

impact summit 2026. This panel is convened by the coalition for content providence and authenticity or C2PA and the information technology industry council or ITI. We'll hear a

lot about C2PA during the panel discussion, but uh I should introduce myself. I'm John Miller, ITI's general counsel and senior vice president of policy. I thought I would take just a

moment to introduce you to ITI. ITI is a global technology trade association representing companies across the full tech and AI stack all doing business globally including in India with offices

and ITI has offices in Delhi, Washington DC, Brussels, Singapore and we conduct policy and advocacy work around the globe on technology policy issues. I lead ITI's trust data and technology

policy team including our work on AI, privacy, data, cyber security, standards, platforms, quantum telecommunications and related digital policy issues.

Trust is one of the unifying principles informing my team's work and central really to all of these digital policy issues. Trust is of course also central to our conversation today, which is

appropriately part of the summit's safe and trusted AI theme. Trust is arguably more important than ever in the present context. A shared reality marked by both the rapid scaling

of synthetic media and the growing importance of trust in India's digital ecosystem. Many of India's recent policy and regulatory proposals, I would argue, are

really about trust in areas ranging from AI governance to digital public infrastructure to the new privacy law and IT rules. We see legislators and regulators around the world also

considering new laws in these areas. This panel will explore various attributes of trust in the context of synthetic media and importantly the role of content provenence standards such as

C2PA in providing transparency that is essential to trust. Open interoperable technical standardsbased approaches are critical not only to good governance and to aid in meaningful compliance but to

help companies scale solutions to better drive ecosystem alignment and to spur crossplatform adoption. Particularly as regulatory frameworks increasingly reference traceability and metadata,

transparency and accountability are core attributes of trust as well. And in the age of rapidly scaling synthetic media, content providence can itself be characterized as foundational

infrastructure for transparency, attribution, and accountability, not as moderation or censorship, but as verifiable context. We know privacy is essential to

establishing and maintaining trust and providence mechanisms can not only support innovation while addressing miss and disinformation risks but can help safeguard privacy and uphold freedom of

expression. Perhaps the biggest key to trust though is figuring out how to actually operationalize it or implement it. And this panel will explore practical

implementation pathways including the role of public private collaboration. and the panelists will highlight the real world deployment of Providence and what it looks like across platforms,

media and public systems. I'm sure India is proud that this is the first global AI summit hosted in the global south and there may be unique challenges related to AI content

transparency that content providence standards can help solve in India and in the region. But ultimately, as the global companies ITI represents know well, we need to pursue global solutions

to these issues because a fragmented patchwork of regulations across India, the global south, the EU, the US, and across the globe doesn't solve these issues in a scalable and meaningful way.

India has an opportunity to shape global approaches to trustworthy digital content not just for India and in the glo and in the digital south but globally. I'm hopeful that by the end of

this panel we'll all walk away with a greater understanding of how content provenence standards such as C2PA can serve as a foundational building block for such leadership. Thank you very

much. And now I will turn it over to our moderator, Andy Parsons from C2PA. &gt;&gt; Thank you, John, and thank you everybody for being here. Apparently, it's quite a privilege to be in this room with us,

and I thank you all for being at the front of the line. Um I think it's it's no coincidence that uh there's so much interest in this topic not only because of CGPA which I'll I'll talk a bit about

today with my panelists but also because of the moment in time uh that we find ourselves sitting here uh in Delhi at this particular moment. Um I think there's a lot of regulatory um spotlight

on India right now for good reasons and also a lot of tools that are ready to deploy now which we'll talk about. One of those things is the CGPA. Uh my name is Andy Parsons. I am the global uh head

of content authenticity at Adobe. Um we started uh with some industry partners like Microsoft and Google and many others uh a coalition called the C2PA, the Coalition for Content Provenence and

Authenticity nearly five years ago now. Time flies. Um since that time, we've developed a global standard that's ready to adopt. Throughout this panel, we'll talk about um whether it's a silver

bullet for these kinds of challenges. Uh Spoiler alert, it's not a silver bullet, but it is, as John said aptly, a very foundational technology upon which we can build transparency. And I hope this

topic of transparency and cryptographic proof of where something came from uh and what it is and perhaps a nutrition label um is non-controversial because ultimately that is about putting

decisions about what to trust in the hands of all of our consumers, whether you're a platform or Adobe or or a government. So um I have an esteemed panel today. I'm delighted to have Gail

Kent from Google um Samir from ITI policy director and of course uh Mr. Goyle um who is present on the panel from MIT where he oversees cyber security efforts and has been

instrumental I would say in some of the new uh legislative proposals. So I'm gonna ask each panelist to just introduce themselves and if you all could uh please sort of situate the work

that you do every day in this particular moment uh in India, the global south and worldwide. And Gail, let's start with you. &gt;&gt; Thanks Andy. Um as Andy said, I'm Gail

Kent. I'm the global public policy director at Google. I look after search and also Gemini. Um this is my first panel of many um at the AI summit and I'm hoping there's as much enthusiasm

for the for the other for the other panels. Um it really is you know a huge honor to be back in India and to be at a summer where we are talking um not just about the bold innovations of AI but

also about how how AI can be useful for for everyone around the world. And I think this is going to be a critical part of the conversation today because we're talking about how does everyone

understand um information and the images that they see um in this sort of new digital world and it's certainly an issue um that I'm super passionate about and I think you'll hear that um that

Google is very passionate about it as well. The other sort of thing I'd note at the start is it's great to be on a panel with ITI, one of the the groups that we are a member of and also with CT

C2PA, another group that we are passionate members of because we believe that this is one of those issues where cross industry working is really important and then working together with

governments um is key as well. So as we continue and do you want me to talk a little bit about CTPa now or shall I hand over to other people before we &gt;&gt; Yeah.

&gt;&gt; Yeah. So I think that um you know we are concentrating on building AI that helps like productivity and creativity um for everyone but we also know that for people to be truly um successful they

have to understand the source and the history of digital information. And this isn't something that is new for Google. Um hopefully you're familiar with many of our products. And um the ability to

do an image search started 25 years ago. So this is really something we've been thinking about for a long time. For 15 years we've had um about this um sorry for 15 years we've um had the ability to

do reverse image search. We've then had about this image for three years. And then that two years ago we launched circle to search um on pixels. So again the sort of like idea of like how we

understand and how we help every user understand images is like central to what to what we do. And then if you look look to AI and um and the creativity the AI built brings but also the ability to

manipulate and change images and create new images. We know that we need to create um an additional suite of tools and ways for people to understand those tools and key to that are um are like

embedding information into the images that are created and there are two ways that we're thinking about this. One is synth ID which enables you to just identify that something is AI created

and the second one is those content credentials that we'll talk a lot more about in C2PA. to enable to enable people to understand how how an image was created, where it was created, um,

and when it was created because we think this is all a really important part of digital literacy. &gt;&gt; Thank you, Gail. So, Bouet from ITI, why don't you go next?

&gt;&gt; Hear me? Yes, they can hear me. Thank you. Um, yeah, my name is Sam Bor and thanks Andy for the promotion in front of my boss. I'm a senior policy manager at uh the information technology uh

industry council. It's great to be back in India. Uh my background is I'm I'm actually a lawyer from uh India but now working in Washington DC with John um look at a whole host of issues ranging

from AI governance privacy cyber security uh getting into quantum as well of course you know synthetic media and building trust in uh the age of synthetic media is an important issue

for us and our uh members uh with respect to uh how at ITI we think about creating in trust uh with respect to uh you know synthetic uh media. A couple of years ago we came out with a policy

guide where we uh try to provide an initial discussion on you know what exactly do we mean by content especially you know as AI was proliferating at that point of time as content was being

generated uh by AI. uh we want to situate the debate in one existing policy and laws and also to consider what are the new regulatory tools that may be required for uh regulators. Um so

in that paper we spoke about various uh techniques uh the C cPA is is is I would say one content provenence tracking uh technique out out of a host of products. There's of course uh and services.

There's of course watermarking. there is a good old human in the loop you know just having a person uh you know verify content now of course this is probably not scalable al although I'm sure folks

in India would would argue against that seeing you know uh in India we can probably do things at a much larger scale uh compared to you know uh folks in uh the US or the EU and u the

conclusions we finally reached in this was and and I think Andy alluded alluded to this point earlier you the solutions provided by C2PA it's not a silver bullet it is not a perfect

uh solution but it is a solution and I think it is a good start I mean I hats off to our members who decided to you know get together in 2021 because they did see that you know this is uh the

issues around synthetic content and media will become an issue and the industry needs to be some needs to do something needs to be uh responsible stewards. So I think you know the

standards that you know C2PA is creating is a step in the right direction but I do want to stress and underline the fact that it is not uh it is not the only solution probably not the perfect

solution but it is better than uh the status quo. &gt;&gt; Thanks Samir. I'm going to say things that are a little bit more encouraging around CTBA and my favorite panels are

the ones where we may not quite agree but I would be the first of course to agree that it's not perfect. Um and I want to uh turn the conversation over to Mr. Goyle from MIT. Um as I said all

eyes are on India perhaps in this moment. Um and I think in the regulatory landscape uh there's a real opportunity for India worldwide to set a standard for um good legislation that approach

this in the right way. Maybe you can talk about your work. &gt;&gt; Thank you Andy. Where do I start? It was looking like what Andy and and and Samir and Miller

said. It's like four is to one. Uh but uh nevertheless means many congratulations for all of you have who have fight it out and fought it out and came inside this room. So and feel very

sorry for the people who are outside but you may all get cross what was discussed inside. Nevertheless uh I am Deep from Ministry of Electronics and Information Technology working on the cyber laws

part. So when I say cyber law I will enumerate we are working on the four different domains. One is the information technology act another is the digital personal data protection

act. Third is the aadhar one and then the fourth is the online gaming regulation or the act that we brought in. So these are the four core things that we are working upon

and all these four our center is the citizen citizen empowerment citizen en enablement how do we strengthen his hands how do we

educate him how do we facilitate him uh the goal of the ministry is enhance the ease of living of the individuals and while enhancing the e of living of an individual. If we can enhance the

ease of doing the business for the industry also that would be always and very much welcome and added step but nevertheless mean these two are the core goals for us ease of living for the

street CPS and ease of doing the business. So keeping these two things in mind, we do lisate and normally we do consult and consult

on a very high scale with the public, with the industry and within the government also and we hope to we hope that we anticipate we hope that we continue

doing that and that's it. That's more than enough. &gt;&gt; We're not off the quite yet. The first question is going to be for you, Mr. Go. Um, as as we said uh in our intro and

John's opening comments, um there are uh there is a regulatory focus on this week based on the information that came out last week from the government here. Um the CGPA for those who don't know just

to uh for a basic 101 in CTBA this is basically providing cryptographic evidence that is permanently attached to images, video uh documents, audio files uh that will tell you basically its um

its provenence. Uh so hence the name provenence in the title of the C2PA and just like in the art world understanding where something has been, how it was made, even what ingredients comprise it

is the the stated goal of the CTPa. Um I will concede it's not perfect right it doesn't solve all the problems and one of the problems um is how do you define trust these are very loaded terms truth

trust even provenence itself but if we can get to a point of uh objective fact about media and how it was made whether it uses AI or not certainly not to cast AI as bad and non AI as good but to

understand what is a photograph what is a video what is manipulated what is art what is satire those kinds of things can be bolstered with a foundation of content problems Um and this leads me my

first question for you Mr. Goyle. Um obviously the CTA can be a part a component of uh meeting the the regulatory moment. Um but how do you square the regulatory ambitions uh in a

country the size and diversity of India with the tools that you have to apply right now? &gt;&gt; Uh very very pertinent question Andy. Actually uh

for the last so many years that we have been trying to in our context. Uh we tried ourselves to be technology agnostic. Uh and if possible purpose agnostic also

but sometimes purpose we are we cannot do away with. So but technology agnostic we have tried to do means we tried and till now we have been a bit successful and of course the industry was the

basically who initiated all those tech solutions means we simply the from the government side we simply asked for a difficult thing to get resolved and then the industry came forward and gave us

some beautiful solutions which were technology agnostic and then everybody appreciated and I think uh As Miller was asking about the UP means DPI that we are able to offer about the Aadhaar and

the UPI transactions then those two things can scale to any means that has a scaled to mean imaginations we have been talking to so many people around the globe and then everybody just come and

say gosh this is the scale that you are operating mean 1 billion transaction a day. So that is the scale and that has happened only due to the adoption of a technology

agnostic technology technical solutions if we are bound up or we are stuck up with a tech solution I think there could be some friction when we scale up but

nevertheless mean I don't need to say anything about C2P C2P can become technology agnostic if everybody adopts it could so How do we create this trust? I will just narrate a

bit. Uh I have I have written something taking help of so many EI based tools means almost four or five which are prominent. So I have create curated something.

So it's not about content moderation. Uh government is normally known that take down some contents or we want to take everything down which is not in our sense. No, it is not about content

moderation. It is the verifiability, accountability and keeping the citizen at the center of trust model. Can we create an ecosystem around that? And then who bears the risk?

Is it the content itself? Is it the citizen? Is it the platform? Who is bearing the risk? I think normally content is in our words uh sorry uh doesn't matter please uh if

we are able to not means if there is some emergency then please open the door otherwise please don't thank you so uh then platform is platform bearing the risk or is it the citizen as

citizen means we are saying as an individual In our very strong opinion is individual who is bearing the risk. My likeliness is getting cloned. I am

getting cloned. My voice is getting sympathized. My credibility is getting undermined. It is not the platform. My decisions are getting manipulated.

So how do how do we empower our means as an individual that my which belongs to me doesn't get undermined in any case. So these are the few things that I don't have an answer

as of now means but tech solutions as I was we we were just discussing behind the mean just prior to the when the session started that the technical solutions are the thing that we are

going to see many to come in this this future may in say another 10 20 years or down the line we have already started and the company from Google and all those big tech they are some of come up

with some very beautiful good solutions And we pretty hope that they would be coming keep on coming with those solutions and uh they would be getting adopted at mass scales.

So where do we take our citizens once he empowered? He has a right to know. He has a right to protection against the impersonation. And then even if something bad happens,

so he has the right to remedy. Whatever C2PA does or whatever any sort of an standard to this typical thing happens mean it would be like embedding some metadata or some identifiers in

developer in the tools which could embed basically those content generation mean uh the recently as Andy was just enumerating about the rules that we brought in

actually uh I would like to clarify that that particular rule doesn't encompass everything which is AI generated didn't know it is only related to audio visual component

like this document which I had created using EI it doesn't need to be come into the definition of that particular so any AV component audio video or AV component

that gets so whatever we embed it should be transparent understandable interoperable and immutable means

and would and many other panelists they would say that C2PA does that fine I have not tested myself I would love to create I would love to test C2PA and create any documents using C2P standards

if I'm given a tool sort of so this whole system of creation a creation of those AV documents or AV what do we say videos or audios who creates that

basically as an citizen I am giving some prompts to create it's only the platform which is created so we have created another set of obligations and we have given definition to the creators we have

set up some obligations onto those AI creators what could be the ultimate things that we can Can we embed something which

can go up to a level of provenence? Can we create some safeguards which basically reduces the risk to an individual? And then the dissemination part means

say you I created something and it doesn't get disseminated between you and me. I can create anything and it's done means nobody would object between two of us. The issue is the virality of the

content and if I'm surpassing time please just point it out to me please. &gt;&gt; Okay. So uh but the issue is the virality. So can we create some sort of an

mechanism that if there is an amplification so can we restrict that? So let me stop over here and let other panelists speak and then I will come back. Thank you.

&gt;&gt; Uh thank you. So I'm I'm watching the clock. We have about 20 minutes left. I think if you would indulge us, we could probably talk for several hours about this topic, but we won't subject you to

that. Um however, do think about questions that some of these conversations may be raising. We'll have about five minutes at the end for a quick Q&amp;A. Um uh Mr. Go, you mentioned

that uh if you could have CTBA, you would use it. You'd love to try it. you said uh which brings me to a question I think I'll address this to you Samir um India is a a country with I think well

over a billion internet users um across many cultures uh incredible linguistic diversity um the act uh as I understand it we're counting down 10 days until implementation

um there are obviously gaps between what technology can provide today adoption of things like CGPA although imperfect I'm going to keep bothering you about that um uh is certainly not ready to go in

messaging apps. Um unlike the wonderful example that Google is setting with the Pixel phone and Google Photos and YouTube um yay Google uh there are platforms like Instagram which are very

much in use WhatsApp meta platforms that don't yet implement C2PA to that degree. So I'm wondering how do you how do you think about the likelihood of successful implementation within this very tight

time frame given the incredible diversity of the population here? &gt;&gt; Yeah. Um I think uh 10 I I I understand the intent of you know why uh uh regulation needs to be implementedly. I

mean yes when it comes to issues around synthetic media it is creating quite a few issues and I I definitely do understand and empathize you know where regulators and the government is uh

coming from but look I think we also need to be realistic and serious about this. I think it took more than 10 days to you know set up this panel to be uh frank and we

I I think my suggestion would be let's have a phased approach let's get all the stakeholders into probably not just not one room multiple rooms we need to have these discussions we need to you know

have folks like C2PA C2PA you know people who are providing other you know provenance uh solutions watermarking uh solutions and to sit down have a serious conversation about okay what is

realistic what is possible because I think I I want to dispel the notion that companies are trying to run away from the responsibility no that's not the case if that was if that was the case

then C2PA probably wouldn't even existed right I mean I think clearly you know there is an incentive for the platforms for the companies to ensure you know the

content that is out there that is on their platforms can be verified to to the greatest extent to the best uh extent uh possible. I also do appreciate empathize and understand you know where

not not only uh government over here but you know all across the world where they come from uh when when they want you know implement these rules but yes the question about 10 days might be a bit uh

ambitious. I I hope it uh works out but uh I think what would be more practical and feasible and also to Andy's point about you know India being you know one population being over one billion you

know so many internet users and the added complexity of it being such a diverse uh environment multiple uh languages different cultures multiple uh devices as well you know unlike in the

west India is mobile first uh market but that doesn't mean that people don't use you know laptops and computers as well and uh again I'm I'm not an engineer by training but I'm sure you know the

technical requirements for different devices is going to be different and then you know if we add IoT devices uh into the mix that's just going to create a whole uh set of uh issues and yes I

think you know it is good that we're having organizations uh like this. It means uh stakeholders across sector starting from uh the government to the industry uh users as well you know

realize that hey this is an important issue we need to work uh together and um I I think we are making uh progress again uh I'm going to hop on this point of CTP not being the perfect solution

but I think it is one of the the best solutions that are out there now please don't quote me on that but I think uh we are making progress in this space. &gt;&gt; Yeah, thank you Samir. And and in

seriousness like we'll joke about this and it won't come to blows today on the panel but um you know what TTPA provides is one of perhaps its biggest strength is that it is standard. I think we've

all talked about the importance of standards which means it's interoperable by default. There's no intellectual property involved in the standard or the open- source implementations that

support it. Um and this enables companies to adopt it uh across the spectrum from startups to civil society to big companies like Google uh tool companies like Adobe. Um but in some

ways the technical problems are among the easier to solve although we've already established that even the technical solutions have their challenges. Um I'm not a a regulator or

a policy person although I get to play one on a live stream now and then. Um the uh I want to turn um Gail your attention to a particular interesting aspect perhaps of this particular um

Indian approach. Uh and you know feel free to talk about the technology and cPA uh users as I understand it are asked to self-disclose but also bolster that disclosure with some proof. Could

be cryptographic proof via CTAPA. It could be the presence of a SID. It could be any number of things. Um but to me this is this is novel and distinct from the EU AI act and some of the

legislation that has been enacted in California and the United States for example. Um is this interesting to Google? How do you think about these multiple or multi

multi-layered approaches? &gt;&gt; Yes, it's it's very interesting um to Google and I think the sort of like the discussion about the best approach for this is actually pretty consistent

universally. Um so there is very much the same conversation going on in Europe, going on in California, going on in Brazil as is going on in um in India and and how do you approach this issue

of like trustworthiness um in the age of AI and AI generated media. Um I'd like to go back to one of the points that Mr. Gold made which is about how do we create this ecosystem of trust. We need

to be able to trust the products that we are using. We need to be able to trust um uh the information that we're seeing and if we cannot do that then you know none of our companies are are going to

succeed and we believe that that ecosystem of trust comes from three different people working together and the e they each have a role in this that definitely is the companies themselves

is also governments and it's also users um so before I come into like what we think some of the solutions are including CP C2PA which we very much like Um there's just two things that I'd

like to call out. Um just because something is created by AI doesn't mean it's not trustworthy. And I think we have to be like really careful particularly as we see AI increasing

productivity and creativity to get away from from that from that sort of like belief. Um and then secondly and I think we're all agreeing this there is no one s um silver bullet. So what do we think

that the um the group of things that we need to collectively be doing to enable um this trust of of um of what we're seeing um in the age of AI and we think there are there are really like three

things that come together. So firstly, we absolutely do need um tools like C2PA that enable us to um to understand that something is created um by AI. Um how it was created, when it was created, um

what tools created it, and thank you for calling out that the Pixel 10 is the first phone to automatically embed C2P credentials um into into an image. So we need those tools. We also need things

like synth ID which are which work not just on images but works across sort of all multimodality including text and I'm sure there are other other tools that will that we will um collectively

develop. But it's no good just having the tools that indicate um whether something is created by AI and how it was created. You also need the tools that help people understand and those

tools need to be really simple um and they need to work across the multimodality um of the way that people are accessing information nowadays. Um so without the sort of like those tools

which say yes this was created by AI this was created on this date this was created like using this technology um we're not really going to do very well. We need people to be able to understand

that context. That's the second thing. We need tools to be able to read this. And then thirdly, we need to collectively be um uh investing in media literacy. And that's media literacy for

people at all levels of literacy. So whether they are looking um at um just like assume consuming their information through video, consuming it through audio, whether it's on messaging apps,

we need to like have people be aware of how they think about um h about the that information that they are seeing because just to give my own like personal example, my father WhatsAppapping me to

ask if something isn't true is not the way that um h the best sort of like scalable solution we need people to be thinking about what works. But and to sort circle back to to C2PA for us that

it absolutely is a key piece of it because of the the things that you've called out because of the interoperability. It means that anyone can use it. Um it also means that it is

able to be read. So that part sort of like understanding who created it. It can be read by Adobe tools. It can be read by Gemini. It can be read by other Google tools. So we understand like what

is um what's created it. And then the other part that really matters to Google um is the cyber security elements. So the fact that it is cryptographically protected and it can't be tampered with

um is something that makes us particularly excited about it and we're we love the fact that it's one of those digital tools that we can put together with others that then helps people

understand uh the provenence of the material. &gt;&gt; Very good. Thanks Gale. Uh Samir, please take a note. And John, I'd like to add WhatsAppapping Gail to one of the layers

of potential protections for consumers. Um and we'll share her WhatsApp number. No, just kidding. Um I think uh so one of the areas that we've touched on already is that you know this is a

particularly um focused interesting legislative critical and important legislative time throughout the world, not just here in India. Um there is a question that I think about quite a bit

with my temporary policy hat on which is can we have compatible laws across jurisdictions across countries across cultures that don't end us up in a situation where we have a fragmented

ecosystem of incompatible laws and I'll use GDPR as an example particularly in the United States uh of course where I'm from I live in New York City um there is uh the California Privacy Act by the way

called CCPA if you ever wonder why we didn't name our coalition the CCPA. It's because there's a privacy law in California that took that moniker. So, we're the C2PA. Um, but uh we could end

up in a like we have in the United States quite a fragmented ecosystem of privacy laws across states and you know leaving aside various jurisdictions um and how government laws are created. But

I want to ask all the panelists if you think um you know optimistically or pessimistically whether we can end up in a regulatory ecosystem where there might be one or a series of provenence or

other measures that can actually protect us in a universal way uh that legislators perhaps can agree on across the EU, the US, India, Korea and and other places in the world.

&gt;&gt; Mr. B. &gt;&gt; Yeah. uh uh Andy it's like uh okay uh where is the convergence and when there is a no convergence it's a bit of a question that we need to answer

basically so if we are being too prescriptive in any sort of a legislation or any sort of an so it if it's a very prescriptive then I think uh it would be really tough to

have a sort of a convergence but if we are creating some laws laws which are basically principle based. We are simply obligating them on a principal basis and leaving the industry to implement on

their own. Then I think it would be a convergence sort of and a good convergence say uh like uh in the privacy act for which means uh the countries world over have been

working for last 20 30 years and the principles have been almost same. So actual implementations could be a bit different but when we are setting up the principles so there is a convergence of

the laws. So I think the same rule would apply to the synthetic media content also. If we are means like in India we are of a very strong opinion that we would be creating all those laws not to

be very prescriptive keeping the cyian at the center of all these things the laws would be principle based so I think that if the technical implementation teams they work on those

principles the solutions would be acceptable everywhere and I think that should be the way go ahead but let's see how it evolves. Yeah, I couldn't agree more and I'd love to hear Gail your

perspective and Samir as well on this. &gt;&gt; I think I'm going to agree with with Mr. Go. I think it's about um being clear on what what your goal is. So in this case like making sure that people have the

information to make decisions. Um then it's about not being prescriptive and it's also about being um principled. So principles like security um and being privacy preserving are really important

to us and being able to take that whole that goal not being prescriptive and the principles across jurisdictions will definitely mean that we're not ending up with with laws that are conflicting with

each other because I think as as you know um laws that conflict um between jurisdictions make it difficult for for global com for global companies to succeed and provide the best product to

citizens everywhere. &gt;&gt; I agree with uh both Mr. Goyel and Gale and and the one thing that I will add is when it comes to issues around building trust with respect to synthetic media.

It's it is helpful and and and this is especially for you know the uh the policy professionals who are out there you know the regulators who are uh out there to think about these things

holistically rather than just looking it at as a content moderation issue which has to be dealt with only under the IT rules. Uh there are issues of privacy. So of course you know the new privacy

law might be uh implicated. Uh there are cyber security issues. So whatever cyber security rules that the home ministry might uh be working on that'll have to be taken into consideration. And finally

of course you know uh India recently issued uh RAM issued the AI governance uh guidelines. So you know that will also uh cover parts uh of this. So I guess my uh you know uh uh

recommendation would be you know to think about these issues for both you know policy makers those who are in the field of public policy thinking about these issues is to think of it from a

holistic lens because that that itself will hopefully help in the issue of fragmentation uh where I am right now in not right now where I'm based in the United States uh 50 states which each

state is trying to regulate a small aspect of essentially the same thing. And not only are we dealing with uh states competing with each other with respect to their rules and regulations

and potentially with the federal government within the state, we are seeing bills that are in conflict uh with each other just because you know there is this framing uh that okay this

is a privacy issue so we only need to work like this or this is a content moderation issue but you know more often than not a lot of these issues tend to blend together. So I think that's what I

would uh recommend. &gt;&gt; Very good. I was hoping for at least one question where all the panelists would disagree, &gt;&gt; but

&gt;&gt; Okay. Well, there you have it. Uh I was hoping to have the panelists give a one minute summation, but uh thank you. That's okay. Thank you very much everyone for being here. Um and

hopefully tell everyone who is outside the room how great this was. But moreover, uh talk to your your friends, your business associates and families about perhaps an optimistic viewpoint

that you leave the room with, which is we can solve these problems uh that face us. It's not going to be easy, but perhaps content provenence can be one of the factors that we consider. Thank you

so much. &gt;&gt; Thank you.
