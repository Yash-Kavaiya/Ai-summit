# AI in Governance: Revolutionising Government Efficiency

**India AI Impact Summit 2026 ‚Äî Day 2 (2026-02-17)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:40 ‚Äì 12:40 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 2 |
| üìÖ **Date** | 2026-02-17 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/vzjlxsTYteY?feature=share) |

## üé§ Speakers

- Dean Karlan, Northwestern University & former Chief Economist of USAID
- Kapil Viswanathan, IFMR
- Mohammed Y. Safirulla, IndiaAI Mission, MeitY
- Utkarsh Saxena, Adalat AI

## ü§ù Knowledge Partners

- J-PAL

## üìù Summary

As governments increasingly apply AI tools, how can evidence guide their use towards effective and equitable public service delivery of targeted schemes? This session, featuring a researcher presentation followed by a panel discussion with experts, highlights findings from a randomised study that tested whether machine learning can improve the targeting of social services. Building on these results, the participants will learn how rigorous evidence can help adopt AI to strengthen state capacity and broaden political participation.

## üîë Key Takeaways

1. As governments increasingly apply AI tools, how can evidence guide their use towards effective and equitable public service delivery of targeted schemes? This session, featuring a researcher presentation followed by a panel discussion with experts, highlights findings from a randomised study that tested whether machine learning can improve the targeting of social services.
2. Building on these results, the participants will learn how rigorous evidence can help adopt AI to strengthen state capacity and broaden political participation.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/vzjlxsTYteY/maxresdefault.jpg)](https://youtube.com/live/vzjlxsTYteY?feature=share)

---

_[‚Üê Back to Day 2 Sessions](../README.md)_


## üìù Transcript

um first by sharing with you some research that we did in Togo with the government of Togo and then I'm going to talk a little bit more broadly about some of the issues of integrating AI and

the challenges but also the promises of integrating AI and AI research and evidence into into government policies. So here's a very very high level summary

with those two words yes and no. So what I'm going to share with you is results from a effort in Togo to use AI and specifically cell phone data fed into an AI um um process to target who should

receive cash transfers in the time of COVID to help with food security to help encourage people not have to go out into the markets and um and and work. And then we're also going to use the same

process to understand what was the impact of the cash transfer program. And the very short of it is we find that the AI worked great for targeting but not for measuring impact.

So how to identify the poorest is something that is of incredible importance to governments around the world whether wealthy or poor or middle income.

The wealthier countries though have an advantage. There's a lot of data that makes it easier to do. So in the United States for instance, you have a lot of administrative data that come right

through the tax system from anybody who has a job and that allows a lot of targeting to happen automatically almost through that through that process. And so various programs like some of it was

COVID related with stimulus checks and and SNAP benefits is a a food program for low-income households. These are all can happen with a fair amount of ease. But in low and middle inome countries

it's not as not as easy and you you don't have as much administrative data that sits within the government. Part of that is for a very obvious reason. A lot of people are employed in the informal

sector where there's nothing administrative where the information is collected. It's there's no tax records. And also census data um is can often be quite out ofd. So, you know, here's a

here's a table showing you the most recent census from a few different countries. 1986, 1984, 1979, 1943. Obviously, not very useful if you want to target uh in in today and it's

certainly not useful if you want to target in terms of vulnerability issues where where even what what's happening like right now might be important for somebody, not just where they were a

year or two or three ago. So the first part of this project and this is um worked on with a a collection of authors during during it was took place right right during COVID and the

there was a program called Novesi and it started off it was actually I think one of the first it might have literally been the first cash transfer program to be done right at the time of COVID

specifically to help with the co with the issues of COVID to give people who normally would need to go into work and in order to earn money and provided cash that they could have some some food

security. And they started it in the urban area and they did use a data that had been recently available because of a voter registration where they were able through that process to identify people

who were informal workers and they used that as a proxy. There's no AI about that. It was just one variable in their data and um and so that that was great. But then they needed to also do this in

rural areas and they're like well we don't have that same data that would work in the rural areas. So what what can we do? Um and so mobile phone data has been used in

different contexts to predict poverty to um and in a lot of different features within the phone data can do this. everything from where you travel to to the frequency of your calls to whether

you call or get called to your text messages etc. So obviously as everybody knows there's a lot of rich data that is effectively being stored by the cell phone companies that's there and so

we're able to use that data from six months prior to the Novici program with 5.83 83 million subscribers, 1.3 billion calls to use all of that to aggregate up into a um basically a machine learning

pipeline that allowed us to train a model using some survey data that had been collected previously. So we could identify from the survey data what we would think of as the we called that the

truth data. Not to say that survey datas are always perfectly accurate. That's obviously not not true. But we used that where we had a record of their consumption. um and how much food they

ate and their food security in order to and assets was a key one in order to be able to establish who's poor and who's not from the truth and then map that using the machine learning and AI

algorithms to predict who's who's poor and who's not and use that to then target where the cash transfers would go um during the COVID crisis. And so um the you know we're able to also compare

this to other methods of targeting more traditional methods um but some of these methods were not possible given the context of COVID and that real time. So, but it was still an important exercise

just from an analytical process to understand how does it compare to to other methods and um so then proxy means test is one of the one of the key key methods that we're able to compare it to

and it's a very common method. Uh a proxy means test is um you know basically is a form of machine learning where you're trying to identify a few key variables that are easily observed

but you still need some source for those 10 variables that you might use in order to compute a proxy means test. Um so the wait sorry

there we go. this this method was was quite effective and then was used to then deploy the the cash transfers in in rural areas of Togo and there was as you as you all know

from the AI process you don't get out of that a very specific like these are the four variables and this is the formula for for doing it but what we were able to see was that it mapped very well to

the consumption data that we had and that there it also was was clearly picking up the areas within Togo where there was more poverty and less poverty. And it was it was successfully

identifying those areas and and and and was able to be used as integral to this government program to really incredibly quickly get cash out into into well mobile money out into the areas within

Togo uh and the people that needed it and that were suffering. So now the next question though is when we did this cash transfer program there was only so much cash to to give out. It

was not something that could go to everybody who needed cash in the country. And so that was a perfect opportunity to say well you know as much as we'd love all there to be enough

money to give to everybody there is not. So let's find out whether this cash transfer program is actually working. One of the key challenges during co &gt;&gt; is that cash transfers usually Yeah.

&gt;&gt; Are in low-income households are are are transferred both to try to deal with shortrun challenges, food security that a household might be facing, but also to give them money to be able to earn money

and start an enterprise, invest in farms. But there's always a fear among some that if you transfer cash, it's like transferring income and then they might work less. Right? Now the evidence

from lots of parts of the world that are low income does not find that finds the opposite. Finds that when you've transferred money to low-income households that triggers more work not

less. But the irony is during COVID the goal was to help people work less. Right? So it was a little bit on little bit backwards from the way we normally think about a cash transfer and what we

want to see happen from a policy perspective. So it was really important to test and find out in this context given what's happening with the COVID shutdowns

what's going to happen with the cash transfer. So we set this up as a randomized control trial to find out the impact of the cash transfer program. And here's the basic results that show

you the results using both the survey as well as the machine learning and the AI algorithms that use the cell phone data to then redo the estimates of poverty using their cell phone data. And so the

the bar on the left is the survey results um the the kind of the gray bar of each of these outcomes. So food security was was was demonstrabably improved and okay this is probably the

most important outcome to focus on given what was happening in the world and in Togo. Um other things did not move up as much financial health financial inclusion but

mental health did which makes sense if you're not as stressed about where you're going to get your next meal from then your mental health goes up. Um your perceived status also was up. And when

we just look at the aggregate of these measures and we just say well just overall what are we seeing and that's the on the right the aggregate index improved. But now when we use the phone

data notice that all of the phone data results every one of them is including zero as a result and a lot of them are right on zero. So the phone data when we used the same

exact algorithm and we had two different ways of trying to train the the phone data did not work did not pick up the treatment effect. Now you might say to yourself, okay, I have two sources of

information. One says it worked, one says it didn't. Which one should I believe? Right? It's reasonable. We tend in this particular situation because we're measuring exactly what we are

caring about. We put a lot of weight on the survey data thinking of that as more approximate to the truth and then try to understand well okay what's going on with the with the algorithm that it's

not picking this up. So, we have a few stories that I think um are, you know, combining perhaps to to feed into this. Um first is they're measuring different things. The the short-term vulnerability

outcomes are harder to predict than wealth in the cell phone data, right? And that's what that's what the survey is picking up is the short-term vulnerability and the whereas the phone

data might be might be capturing better assets and and just longer term status and socioeconomic well-being. um the the cell phone data um did also predict um it did predict big

differences, right? So it was able to capture big differences across the spectrum of socioeconomic status. Um but the the survey data, you know, was more accurate kind of irrespective of the the

of the size of the of the um the difference between the the people who were well off and the people who were not, right? And so the the survey data was basically more able to pick up that

kind of subtle difference even though the the cell phone data was able to pick up the big differences across a larger spectrum. It's also possible that there was model drift that we were only able

to train off of data from a couple years prior and there's just fundamental changes that took place during COVID that changed the way people engaged with their cell phones and that change made

it so that the algorithms we were not able to pick up the changes that we were observing during COVID, right? And we didn't have new consumption data during COVID to train it on. We had to use the

data we had from before. So those things kind of combine. Um we can't pick a pin to exactly one but it does suggest that like look you know AI is has incredible promise as we all know this is why this

room is full but it doesn't mean it's magic and it doesn't mean it's going to solve all things and we do need to continuously push and challenge ourselves to ask is it is it working

here is it working there when does it work best how do we make it work better etc. Um so the you know the overall takeaway from

it was it was very exciting and it was solving an incredible problem that is helps make government more efficient in the speed with which it can do things because if there's administrative data

and you can use sources like this to figure out how to deliver a program particularly in a crisis moment that is a huge huge impact. If you think about government's role, yes, there's they

should be doing things that try to address our long run development and and prosperity, but it the government role for dealing with immediate crisis is so critical, right? And that's and that was

that's where we found the strongest results that the AI was was successful in doing that. So of course AI can be oversold. Um and you know they and but it also can be undersold and um you know

fanatics may trust it when they ought not to in the same way that skeptics may not trust it when they should right just like this just like the story we heard earlier from um from Cape Town. Um, and

so the challenge that I think we face then is that's a very mix that's a tough message to to say, okay, what do I what do I do with that? What do I what do it mean sometimes it works and sometimes it

doesn't? Like I got to make a decision. I'm a I'm a I work in the government. I have to do I have to take action. I have to do something. How am I going to what do I do with the fact that like

sometimes it works and sometimes it doesn't? And so that's the that's the heart of the second part of the talk. Um, I'm going to talk about three different issues that I think that are a

bit broader. These are not going to be about specific research projects that we're facing when we think about AI from a policy perspective, particularly when it comes to development.

One of them is about some of the challenges that I that I hear a lot from people about how AI is different and because of some of the differences, oh, we can't do evaluations as well or or at

all. And so, you know, that's a when I get under the hood and I ask and I've been in some conversations on that of that nature. Well, tell me more. What are the

what are the challenges you think? Well, it's just that we move so fast. The speed AI moves fast. Evaluation is so slow. So, we said earlier one thing is true. If you want to know the three-year

impact of something that is do that is happening today, unless someone has developed an AI tool for time travel, is that a thing yet? If so, great. If not, you got to wait three years, right? But

the fact is the AI process is, you know, scaling up things very quickly, getting people to adopt um apps and things of this nature and use services very quickly. [snorts] And so, yes, things

change a lot. Um but this is where you know a lot of the the questions that come at that is to say well so are there really fast results that we can use like shortrun outcomes that we can use and

even though it's not getting that long run thing that we really care about is there a shortrun outcome that we can just rely on. That's not a new question. This is one theme that you're going to

hear here. A lot of the questions we're hearing about challenged AI they're not new. These are old questions, slightly different context and some different ways of thinking about it. But these

are, you know, old issues, some of which we have good answers to and some of which are just the nature of what it means to be doing a good evaluation versus not is paying attention to these

issues. So if we can find a shortrun outcome that is a good proxy for the long run outcome where we know if we make that shortrun thing change and go up, then we can rely on the fact that

the long run change will happen. Nothing's ever guaranteed, right? That's the that's the search for those kinds of surrogates has been prevalent in lots of other areas. I did a lot of work 20

years ago in micro credit where people would often talk about repaying a loan is that a good shortrun measure because I don't want to wait five years to find out the impact of the micro credit loan.

So AI has the similar feature finishing a training program uh adopting the service is that sufficient the answer is no this is why we want to do evaluations and see the see the longer run but once

we can establish those links then you can make a lot of progress by identifying through the research process through the evidence process what are those shortrun outcomes and then that

are predictive of the long run. Second is oh but we iterate too quickly. We ch if you roll this out now tomorrow it's a different thing. So how can you evaluate that right that does pose a challenge

but again it's not a new challenge. There's a lot of things that are iterative by their very nature. A class a course a training program is effectively iterative. You ask

questions. The teacher teaches differently because of those questions and they iterate. When you evaluate that, you're evaluating the entire course in its full sets of iterations

and all the things that are encap encapsulated in that iteration. Community-driven development is another program that takes place um in lots of parts of the world that is by its very

nature deliberately deliberately um iterative in in its ability to adapt to the needs of a community and and listen and then adapt. And what does that mean happens when you think about evidence

and impact? It means you're evaluating that full iterative process, right? And that's that's one of the ways of tackling that is embracing that that change and that iteration and saying

it's okay, let the change happen and we will evaluate the full package of that process and what it produces in terms of the impact on people's lives. And if you think by the end of the year the product

is so fundamentally different than the beginning, well then that's can be tested and keep going and then test the test the final product in that phase. Um and the the third is kind of this hyper

reliance that we often see on intuitive outcomes where we think where we where we forget about understanding what's the counterfactual what would have happened had we not done this program. I see this

in big picture questions as well as small. So going back to the back back to foreign aid, one thing that I've heard from in many many contexts uh when people want to be critical of foreign

aid is to say, "Oh, we gave a billion dollars to this country and they're still poor." Well, that doesn't mean the billion dollars didn't work. They could have

been they could have been the problems could have been more stark and worse without that aid. That doesn't tell you just because there's the country still has a poverty issue that the aid did not

work. It also doesn't mean it did work, right? Obviously, but it doesn't mean it didn't. So, that feels like an intuitive thing to say and it's actually depressingly successful in a rhetorical

way in in political circles, but it is strikingly vacuous from any sort of analytical u stance and and rigor because it doesn't answer the question what would have happened had we not done

that. Same thing with a a training program. they finished the training program or you got a job. It's a job training program. You get a job. That feels like that should be the answer.

That's the success. But that's not actually the answer because you don't know what would have happened had they not done that job training program, right? And there could be a job training

program that just took time away from that provided no value and they ended up not not not getting a um being less likely to get a job. Maybe most of them still get a job, but they were still

less likely than they would have been because they spent all their time in this training program, not getting not really getting anything out of it, but passed through the time and survived the

program in a sense and then got a job, right? But it doesn't tell you what would have happened had they not gotten a job. So that that is very applicable to a lot of things I see on chat bots

and AI tools of various forms where there's this um there the sense of like oh they they kind of got to the end and the thing that I wanted to see happen happened for 80% or 60% of the people

and when that happens you should need you need to take a step back and say okay but what was going to happen otherwise what's the counterfactual and that's that's where evidence comes comes

in play and that's the heart of what uh JPAL is all about is is really taking rigor to that to that moment and saying well no but let's find out actually how did the world change because of this um

app or AI tool or whatever it is okay so that's the that's the first issue the second issue how are we to choose amongst all these potential solutions right so there's so much promise um it's

new to all of us new to certainly to me And when you hear about all of these various ideas at the very high level, you know, the the kind of the short 3se secondond story or five minute story

sounds very similar. Lots of nice websites and nice tools and and you know well-designed apps. What's actually working? Now put yourself in the hands of the government having to make choices

and think about what what's their expertise in making that choice. I put myself in those shoes. If I had to make the choice, I would be in a bad spot. I I you know, it would be difficult to

know just by the the mere description and the brochures and the and and a demo whether it was actually um working or not. And so one answer to this is that we need to build better systems and

better support for governments and any large procure so to speak of of AI systems in order to help them integrate more evidence into that decision-making

process so that decisions about what to fund are not based on what's what's splashiest and what looked best and who made the best p sales pitch but actually the evidence on what worked and taking

that to the procurement process to fund and then scale the things that are most successful. And so having that kind of partnership between evidence um evidence gurus so to speak and government can be

absolutely critical for helping to then build the capacity of government to make those decisions to hire the right people to procure the right apps and etc. And in that process you help them identify

what is actually well suited for AI and what is not. Not everything is appropriate for it, right? How do you make that decision on what what is the right like when do I turn to that and

when do I not? How do I choose the right firm or the right pro program and then how do I set up the right evidence generation to be able to track the impact um and the performance within

within my programs. So this is an area that I think is an incredibly important growing area of the intersection between foreign aid and philan philanthropic work and and and government and a lot of

um a lot of times we've seen foreign aid give like direct support to a program but this kind of approach has tremendous more a lot more leverage because you're not taking the foreign aid and providing

a program or a service but you're helping a local government which has a much bigger budget and a much bigger scale. have a bigger impact themselves. Um, and

this is an important area of growth for for um the the overall process of of foreign aid and and development whether it's coming to nonprofits, for-profits or or government.

Third is this recognition of, you know, wow, in a sense we can do a lot more than we used to be able to do. There's a lot of problems that we can solve that previously just had some really big

constraints and I'm gonna just mention one briefly. So I do a lot of work on a program that does uh it's referred to as the graduation program but it's not an education program. It's a program that

helps usually in rural areas to provide support to households in a few different ways including a lumpsum amount of cash and some training um usually access to savings. One of the pioneering programs

was done in West Bengal uh with a with a group called Bondon and we've tested this around the world and it's been shown to be incredibly successful in both shortrun and generating longrun

sustainable impacts in conversations I've had with ministries. For instance, I'm thinking of one conversation I had in Peru with a Ministry of Social Protection.

[clears throat] They were really enthused by the results. But then they said, "But this has you you have to have a field agent for every 80 people in this program. I would

need thousands and thousands of employees in my ministry who are who have not just the hiring process and management of that many people is outside the bounds of my the size of my

ministry. But they also have to they have to be trained and know how to provide life skill coaching. That's not a trivial thing, right? And they have to know about how to raise guinea pigs.

That's also not something that everybody knows how to do. So how do you solve that? And this is where you know budget might you might think is the first issue but it's actually not. The first issue

is just labor force and how you're going to do that. And so the program doesn't get scaled um in that case. It did not it did not go to the country as a whole. But with an AI tool to do that frontline

work and this is one of the things that was discussed in the last panel you can you can crack that right and so now but obviously you can imagine that tool doing well or doing not going back

to the prior points I made. So we need to see good evaluations of tools for frontline workers to provide that kind of support so that programs like this can actually get scaled to to the um the

country. And so for this, this is where I'm most enthralled by the promise of AI is to be able to tackle the problems not just by making something better and faster, but by actually breaking through

to doing things that we simply were not able to do in without it. And that's that's really exciting. And so with that, I will close um and looking forward to the to the discussion and the

remaining events of today. Thank you very much everybody. Thank you so much Dean that was super insightful. Request you to remain on stage for a group photo photograph while

I call upon the panelists for the discussion. Uh thank you. It's okay. Uh now my pleasure to invite the panelists for the AI in governance revolutionizing

government efficiency session to join Dean on stage. To moderate this session I invite Kapal Vishwanatan to the stage. Kapil is the president of IFMR and vice chairman at Kria University.

Through IFMR and Kria, couple leads a unique ecosystem that is advancing India's AI mission, bringing together centers like JPAL South Asia, inclusion economics and well labs and using data

and AI to generate evidence and inform policy. A fun fact, before dedicating himself to the education space, couple has built and scaled a large global content services company employing over

2,000 people across India, Europe, and the US. Why can you stay couple? You can come. Okay. Next up, we have Mr. Muhammad

Safirah. Mr. Safera is an Indian administrative services officer and currently services as the director of the India AI mission at the ministry of electronics information and technology

at the government of India. [music] As the director of India AI, Mr. Safarola heads some of the in some of India's leading advancements on AI. A fun fact, Mr. Sepharila has a distinguished

academic background with five academic degrees across electrical engineering, finance, public policy and administration and machine learning from Carnegie Melon, Harvard and Stanford.

Welcome to the stage sir. Utkash is the co-founder and CEO of Adalat AI where he is leading the effort to transform the justice system through AIdriven solutions from transcription to case

life cycle management. Adalat AI is at the forefront of courtroom innovation. Fun fact, Otar also advocates for queer rights and in his personal and professional capacity, petitioning the

Indian Supreme Court to legalize marriage equality and appearing in oral arguments in this case. Welcome, Utkash. And our final panelist is Robin Scott, co-founder and CEO of a political, the

world's largest online community for government. Its mission is to make government smarter. Her work involves helping public servants learn from the real real life situations across

sectors. A fun fact, interestingly, she's the author of a widely acclaimed and interesting memoir called 20 chickens for a saddle which is about her unconventional childhood growing up in

rural Botswana against AIDS epidemic in the country. Welcome to the stage Robin. Um I now invite the panelists are already seated. So the audience can send questions using the menty Q QR code and

code that is displayed on this screen. Couple you've been handed a tablet. So closer to the end of the discussion, you can refresh the document that's open so you can see the audience questions

that's been posed on there. You also have the timer up front. With that, I'll hand it over to you couple to take this discussion forward. Thank you. &gt;&gt; Thank you. Thank you so much. uh welfare

for all, happiness of all. If uh AI for all is what we really want, then AI and government is something we really should pay attention to because government touches every citizen of the country. Uh

healthcare and education may not, but government certainly does touch every citizen of a country. So, uh this is a very important topic and we have a little more than 25 minutes. So, maybe

we should use some AI to make ourselves more efficient here. Um before we get into uh government effectiveness and state capacity uh I want to put forward a bigger picture question to this very

interesting panel here which is uh are governments across the world prepared for the impact that AI is going to have on their countries in multifaceted ways and I'd like to begin with Robin who's

been working with who can give us the big picture and the global view working with governments across the world countries across the world so um are we ready for the storm that's

Thank you. No, I I mean governments are excited about AI. More than 90% of public servants are optimistic about it. There's a $ 1.75 trillion dollar product opportunity in

governments, but in terms of the impact on their countries, absolutely not. And it starts close to home. So interestingly in our data on government only 30% of government leaders have

looked at the impact of automation on their own jobs in government. Now that's a 200 to 600 million person global workforce depending on where you draw the lines around government and public

sector organizations. So I think that shows the challenge. I'll just give one other data point. When we think about the ethics of AI, which is obviously incredibly important to figuring out the

societal implications, again, there's a worrying stat close to home. So, from our data, only 26% of those individuals in government who identify self-identify as AI implementers. So, it's literally

their job to roll out AI, only 26% understand their government's ethical frameworks. &gt;&gt; thanks Robin. Um looking at more of an Indian view Safi if I can bring you in

before Utkash. Uh what how do how prepared do you feel the union government as well as some of the state governments are for the wave of uh AI that is about to hit or is already

hitting. &gt;&gt; Uh thank you. Uh I think in my view uh there's a very good optimistic outlook. uh uh the positives include u that uh the team, the government employees, the

system uh knows that this is the way to go and they are equipping themselves. Uh so the central government and also the state governments are uh putting lot of thrust on skilling upskilling

particularly and making sure people are aware the employees are aware of what to do. uh and other positives include building the compute capacity, making data open, breaking the silos. But I

feel we still have a long way to go and uh there are challenges because in terms of uh scalability if you look at uh it has to uh it depends on a lot of parameters like uh the data uh the

understanding of guards and other things. So I would say there's lot of positive uh outlook but we have a a long way to go to make sure that the benefits of EA actually uh are filled by the

masses. &gt;&gt; Great to hear that Safi um moving on to the view from the trenches utering the government so far the level of preparedness for what's to come.

&gt;&gt; Yeah I think we look at um two kinds of AI applications and different levels of preparedness for the two. I mean if you look at the conventional AI tools of like you know everyone's used GPT and uh

claude the idea of using uh LLMs that will automate decision-m etc. I think there's a lot of work to be done. There's a lot of regulatory gaps that need to be filled and as Dean was just

talking about this AI moves much faster than everything else and so the regulatory catchup is much slower. But the area that I am still very optimistic about is the automation of processes and

manual and clerical pain points which actually don't come in with the same kind of risks of hallucinations and bias but can still infuse a lot of productivity. So for example, Adalat AI,

which is a legal tech nonprofit that works with courts, doesn't automate decision-making. A lot of people think we're making AI judges. What we're automating is things like AI based

transcription, which is speechtoext transcription of courtroom processes to create the court records, imageto text transcription to digitize the paper flows of courts, case flow management

tools to automate workflow tools. So I think for those the government preparedness seems to be fairly high because it's just a layer of digitization with some AI added on top.

It's the former that makes me a little bit more nervous because there's a lot of decision-m implications for people's rights. Uh where both regulations wise and government capacity wise uh I think

things need to be done for us in particular. One area that's always uh where I think more can be done is compute and infrastructure. We're a sovereign AI player. we're automating an

actual sovereign function for the courts u and so we can't use third party APIs we actually have to run these inside code premises and so the more infrastructure we already have a lot of

support from me on GPUs and compute on infrastructure but I think a lot more there can be done to automate other parts of government processes like the police the judiciary the tax authorities

where risks of API based processes are much higher and therefore less easily available interesting and as we Now as we shift gears into uh government effectiveness

and uh state capacity, I was speaking with uh Karthik Muridan yesterday and uh he's written a lot. He thinks a lot about this topic and he's also a JPAL affiliate. Uh he was saying that his

model of datadriven governance that he writes about is something that can really be taken to the next level with the use of uh AI. But he also cautioned uh that uh uh there is a need to design

uh suitable systems and you don't want to automate inefficiency so to speak. So you have to fix basic systems first uh before we can bring in AI and also control for reinforcement of biases

which is also something we saw earlier today in some of the talks. So it was a fairly um on the one hand on the other hand kind of an economist statement that I that I got from him. Uh but again if

we want to start with a global view on u what is the status quo robin on like um how are governments using AI where is it working where is it not working but also what is the starey dream of what is the

potential what can what can happen how can they put it to use and what is uh a maximum uh use case uh it'd be lovely to hear from you sort of the global view and then the Indian view from Safi and

then the trenches view again from utkash It's first of all I I just want to acknowledge the the difficulty of summarizing a global view because there are um infinite ways of tackling this. I

think on the on the promise just to echo what's been said AI loves bureaucracy right so a lot of the promise is around deploying AI in the right way across the

obvious lowhanging bureaucratic uh fruit as it were and there've been some headways made into that but but characterizing overall the most important thing to say

is there's a lot of talk and there's much less action There is a lot of pilotitis. Everyone's got pilots. More than 70% of leaders talked they've got pilots, but around half of those

have plans to scale the pilots and only about a third have any plans in place to make their data ready for AI. So there's a lot of asymmetry between uh what's being done and what's being promised.

However, when we do look at the the sunny um uplands, there are obviously beyond the bureaucratic automation, there are huge opportunities for improving policy, making it more making

it more adaptive, more responsive, more agile. I do also want to touch on this the second half of the equation though which is almost always forgotten. We talk a lot about now agentic AI and

government. We don't talk about the consequences for people and I am really worried that unless we talk about agentic humans and don't make it a zero sum dynamic where the AI gets more and

more agency and the humans get less and less you get real problems and coupled with that in general in the rhetoric around AI and government there is much more emphasis on automation and

comparatively much less on augmentation and Actually some of the biggest benefits in terms of what we saying seeing are coming from augmentation. I think we need a lot more conversation

and action there. &gt;&gt; Safi there there are uh certain areas where uh in my view the adoption of AI is at an advanced level. uh particularly I would like to say in the uh banking or

financial areas where there is very rich and high quality of data for example in uh goods and service tax or state finance department uh in terms of expenditure analysis to see how schemes

are reaching out which is not doing good. So uh the reason for it in my view is that there is a very high quality of data on execution and it is very precise. uh some areas where uh the

customer centric services are given G2C services uh we have started using it in specific silos uh for example in health in terms of detection of u eye uh specific uh infections or in identifying

crop patterns or in uh helping farmer services. So again this uh benefits because of the rich quality of content uh from historical data which is distised and available for training. Uh

some areas where I feel there is lot of concern is where we talk about the gray areas where there are lot of decision making uh which is involved and uh there is enormous heterogenity in the sample

set. uh for example we are talking about uh if it is finance there is data hetroenity is very less but if it is about uh educational outcomes of students then we are talking about the

background of the student uh the native language the region in which the kid comes from uh the what sort of soio economic profile and all these things. So therefore it is very important and uh

uh very uh uh uh specific uh carefully designed experiments should be designed to ensure we don't uh uh do the mistakes which are already there in the system. So there I feel the system is learning

slowly and uh gradually uh improving and uh which I also support because it's very important not to do something wrong and we create more damage and also the third aspect is in terms of uh

bureaucracy since uh ma'am was just referring to it in a country like India where we have the G2C services at a large volume which needs to be done there is lot of potential particularly

in terms of health education agriculture and therefore the uh it becomes easier for the government's the state center to reach the uh last citizen uh for example in health services in climate services

in terms of disaster management there are lot of specific customized uh uh solutions which are available so I feel that again there is heterogenity in terms of deployment which is there and

we have to be careful and uh link it to the quality of data which is available for training system. I feel again that we have a long way to go specifically in terms of uh uh gray areas where a lot of

human contents are there easier to do in financial aspects and in planning uh planning there are a lot of projects which are there. I just conclude with one example like uh during covid we did

unsupervised learning uh you know where we try to uh do clustering on to see what is the uh uh what is a combination of co-orbidity where uh the possibility or probability of death increases. We

found that uh it's a combination of diabetes and hypertension. So we able to take uh preemptive action the day one itself irrespective of the condition of the patient. So combination of uh uh uh

you know co-orbidity of hypertension and diabetes progressing with age uh and specific gender. So that actually helped us in uh solving uh the you know making a specific intervention in policy uh

because the quality of data was very high. &gt;&gt; Interesting. And is there a view from the states as well because mo since you were posted recently in Kerala the state

governments at a similar level or like is there a different view from the state governments? &gt;&gt; Yeah uh states including Kerala and other states are extremely uh active in

this particular front to see specific deployments. There are a lot of projects which are coming up and uh uh I would agree that uh many of them are uh not scaling up uh they are in pockets uh

because the pilot environment where it has been done uh doesn't give uh scope for scaling it up. Even health solutions we find lot of health solutions in various parts but if it comes to a state

list then state tries to uh take the data validation protocols are still not in place. uh if you are talking about education then again the validation protocols has to be taken in uh taken

care to see what was the design how it was designed what was the sample set uh so in many cases where I see the uh scaling up suffers from this problem where they are not able to convincingly

prove uh the quality of data what was how was a problem designed uh how it has been implemented is there a third party who has audited this not talking about accuracy going into

granular details like sensitivity, specificity, false uh negatives, false positives. So I think it becomes very important to train uh while a pilot is deployed to actually design a very

scientific experiment to see how it can be scaled up and that I find is a serious bottleneck uh which is affecting the scalability of a applications. &gt;&gt; Right. Great to hear that and of course

we'll have to do an impact evaluation before we scale up. So that point is well noted in this group. uh Utkash uh uh as an entrepreneur I'm sure your business plan started with a market size

and potential so the top down view so why don't you talk about uh what the as as an entrepreneur what you see as the great potential for AI and government and uh how much of it we've tapped today

and also uh tell us some of tell us about some of the bullets that you've had to take and some of the pain that you've had to face in actually um taking this forward and making it a reality

&gt;&gt; yeah sure so I I think one um tying this to the earlier conversation on what scales especially from pilots or not and what the challenges are we our experience is that painkillers do better

than multivitamins just to kind of frame this I've seen a lot of solutions that look like multivitamins which are oh this would be good to have in the system uh this is the vegetables or the

broccoli that you should get and there's no there's no real demand and it's not actually a painoint that's solving it. uh whereas painkillers where it's an actual pain point. It's solving a fever.

Uh the scaling is actually not as much as push from your side as much as you being pulled in by the system because you've identified a painkiller. So when we started our work, people were very

perplexed by the idea that the first intervention we identified was stenography. Um and the reason for that and because I'm from the trenches, let me paint kind of an image of what the

trenches look like in courts in India. There aren't enough stenographers. So if there's a cross- examination um and I ask a question and couple you answer it and judge Robin because there's no

stenographer will write the question and answer by hand. Every question and answer is handwritten. Um and so obviously it takes ages to get a single cross examination done. They're done

over many days. Then if judge Robin gets transferred and Sephir comes in, he can't read Robin's handwriting. So they have WhatsApp groups where they're sending each other images of each

other's depositions saying, "Hey, what have you written?" Um and Robin will say it's been two years I can't read my own handwriting and then state departments this is how governance efficiency works

will create special departments called fair copy departments and the entire job of this department is to take the depositions that Robin has written and rewrite them in a beautiful legible

handwriting so that it's actually readable as a court record when we asked them saying why don't you type this out they said we don't have keyboards in Tamil or Hindi right and so when that's

the reality in the trenches. Our point was this is a painoint. Judge Robin complains every day that she's developed spondilitis, that she has backachches, that she's sitting and writing

cross-examinations day and night, she will say that she's not a judge on the system, she's a scribe in the system. And so when you go in with a solution that specifically targets almost a

literal physical pain point here, the demand is generated from within the system and helps you scale it much faster. Um, and it also becomes your foot in the door in the wedge to then

have conversations about the multivitamins. Now that we've established ourselves and gained their trust by reducing their fever in one part of their pain points, the systems

coming back to us and saying, "Hey, can we build case flow management systems and can we build paperless filing systems and I think that strategically was the right call because if we'd gone

with that first, the court would have been suspicious didn't wouldn't have had the trust and credibility. So I think painkillers first before you kind of have conversations on multivitamins uh

develop that trust and credibility become a partner in crime of the state and then kind of build on other aspects of the system. &gt;&gt; Can I [clears throat] just come in on

that because I think uh your your example of where you started the wedge points to a problem we see everywhere which is that AI interventions tend to be very top down and don't look at

actual tasks and workflows. what are people doing 15 minutes to 15 minutes and that is the level at which AI affects work. It doesn't care about role descriptions. It cares about tasks done.

And we've actually in response to that built a tool to help governments just find their footing. And we think a lot of the failure in the pilotitis that one sees is because AI is deployed where it

shouldn't be deployed, where it isn't high leverage and where you say where it isn't a painkiller. This is interesting. I want to first uh respond to what Utkash said and I want

to ask a follow-up question which is uh from an entrepreneur standpoint uh which is the bigger market is it the pain is it the painkiller or is it the multivitamins and yeah there are two

different races one is a a sprint and one is a marathon right to solve the problems that are more systemic which will build involving like you know in courts like case flow management systems

uh it's it's going to take more time and but will also have higher impact I think it's a sequencing ing game. I think the other challenge that I want to highlight especially because this is a kind of a

JPAL crowd is there are lots of nonprofits that work in the education space and health space right there's Nura Health, Rocket Learning, Darcel, they're all here uh where the system is

already familiar with working with nonprofits in the judicial space. There is no precedent for this. So we were also trying to gain the systems trust by saying you should trust civil society by

allowing them to come into exactly these workflow tasks automations and allow us to play a part. And so strategically an entry point a foot in the door is maybe the painkiller but the high impact longr

run solution comes from the multivitamins but you can't do well with there's no like one size fits the all that. It has to be like a heterogeneous strategy and for us we're trying to kind

of leverage both uh to create impact in the system. &gt;&gt; Can I push you to put a market size number there X billion? &gt;&gt; Honestly in our and I think we were Ivan

and I were just talking about this for us the market size is actually not just India and I feel very awkward saying this but thanks to colonization many countries in the global south

inherited the same broken justice systems. So there are 50 million cases in India that impact uh over uh you know millions of life. But if you look at beyond that countries in in Africa that

all inherited the same colonial systems have the same problems. &gt;&gt; I think the UK courts could also use your services. &gt;&gt; We have actually received interest from

the courts in the UK saying actually we have the same problem here. So maybe it's not just a global south problem but because of that you know because there was standardized ostracization uh if our

problems can be the same our solutions can be the same as well and it's surreal for me to go to courts in Laka and Nairobi and feel like I'm back in courts in Bombay we have the same legal

provisions penal provisions language and processes where that's why I I don't want to give a number I I'm very familiar with the India number we can kind of expedite almost 50 million cases

trapped in the system we can encourage people to approach the courts with more cases. It's not just the cases in the system, it's the for every case filed, five cases are not filed because who

wants to waste time fighting a case for 15 years. Uh but beyond India, we're hoping this is a global south conversation because many countries inherited the same broken systems and

can have the same solutions. And notice how he's given a great answer without giving me a number. Um Robin, I think what you said was also very interesting. uh and Karthik was

speaking to me yesterday about the need to measure the right things. So if you're uh if you're in a system that values compliance over outcomes, which is what he's written about in his book,

then you're measuring compliance and you really don't want to be doing that. You don't want systems that so what what you talked about in your AI platform. Um how how do we think about evaluating um uh

AI solutions that are offered and uh how do we set up the pilots? uh how do we monitor what do we monitor for and when do we sign off something as ready for scale and again we'll start with you and

go go to the others &gt;&gt; just firstly very quickly on the last point I think you can put a market size on the painkiller I wouldn't venture what that is in in

the legal domain I don't think you can put a market size on the vitamin because that is bounded only by the imagination in the vitamin category are all these things that could be possible with

government but we don't even think about them because we so focused on getting rid of all these excruciating pain points so I really think it's an unbounded opportunity which is super

exciting in terms of measurement as I said you know there are not uh plans in place can't remember if I gave this exact figure but um it's 45% of leaders have plans to evaluate their AI pilots

which is kind of crazy but if we reverse First at the upstream end, [clears throat] one of the big problems is a they're not designed in the context of where work is actually happening and

with skilled people. Only 20% of public servants are comfortable with understanding the skills they need in AI world. Um but B

things like telemetry are not thought of. So, it doesn't make sense to implement AI unless you know that you've got the data that will tell you how AI is doing in the wild. That's telemetry,

right? So, you've got lots of pilots where after the horse has bolted, you realize you haven't got the right data. So, doing much more design thinking up front and saying, can I actually monitor

this, respond to issues, uh, etc., etc., is very critical. Safi you want to come in? &gt;&gt; I would uh say designing the experiment is very important. trying it out in

multiple uh places to give the diversity um and u uh third party audit also in terms of evaluation of results uh increases the trust in that application because uh uh I strongly feel it is a

trust in that uh system which is equally uh important than actually the statistical results which come out of it and uh once that comes out it becomes easier to scale up. Do you find yourself

being bombarded by variety of AI uh suggestions, options, uh solutions, vendors? And &gt;&gt; in a sense, yes. People want to do something in AI. Uh rather than starting

from the problem and then trying to see what exactly is a solution, so many people come and say, let us do something in AI. Then you said hold on come to step back and see what is a problem that

you want to solve. Maybe it doesn't require any distisation also, you know, maybe it's a problem of what the system creates. So I think we need to go back uh before looking at do we actually need

AI actually do you need a IT intervention at all and come step back and see what can be eliminated from the current process. &gt;&gt; You have 8 seconds with Kash but go for

it. I actually thought there was a lot of wisdom in Dean's slide where he talks about the challenges of u AI evaluations uh considering the speed and the iteration challenges for us one big

learning has been you know an average property case in India takes 20 years now if you cut that down by even 50% it's going to take 10 years to finish how do you quantify that uh and so

intermediate outputs like number of uh judgments you bail orders you pass in a day number of witnesses you examine in a day number of output like amount of output you get in a week is a good proxy

to kind estimate and simulate what the larger timelines are like and with the pace of iteration. I think that's where a lot of evaluations for AI interventions are going to be a lot of

like intermediate outputs and how they simulate maybe the actual outputs that you're trying to measure. &gt;&gt; Great. Well, that ladies and gentlemen is uh AI and government in 25 minutes.

Thank you very much to this amazing panel. A huge round of applause for our speakers as they exit the stage. Thank you so much for the insightful

We now break for lunch. You can proceed to the nearest food court. We will reconvene here in the room at 1:40 p.m. So, please be here. During this time, I invite you to please scan the QR code

displayed on the podium to know more about JAL and our work. Thank you.
