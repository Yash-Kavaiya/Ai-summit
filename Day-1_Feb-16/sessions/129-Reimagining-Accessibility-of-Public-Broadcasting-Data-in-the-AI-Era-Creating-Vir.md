# Reimagining Accessibility of Public Broadcasting Data in the AI Era: Creating Virtuous Production of Data for Local Language LLMs

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 17:30 ‚Äì 18:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/1e31HV9t4Qo?feature=share) |

## üé§ Speakers

- Alison Gillwald, Research ICT Africa
- Diana Mosquera, Diversa Studio
- Gaurav Godhiwani, CivicDataLab
- Geetha Raju, CeRAI - IIT Madras
- Manu Chopra, Karya
- Medhi Snene, UN Office for Digital and Emerging Technologies
- Mukelani Dimba, Information Regulator of South Africa
- Pria Chetty, Research ICT Africa
- Siphokazi Novukuza, South African Department of Communications and Digital Technologies
- Souhila Amazouz, African Union Commission
- Tajuddeen Gwadabe, Masakhane African Languages Hub

## ü§ù Knowledge Partners

- Research ICT Africa

## üìù Summary

This session will gather policymakers and AI practitioners from India and Africa to discuss accessibility of public data, local language LLM training and development requirements, and sustainable financing. The goal is to recommend a governance framework for making public broadcasting data available for public AI research securely. The discussion will focus on regulatory frameworks, practical data use for local language AI, and sustainable funding.

## üîë Key Takeaways

1. This session will gather policymakers and AI practitioners from India and Africa to discuss accessibility of public data, local language LLM training and development requirements, and sustainable financing.
2. The goal is to recommend a governance framework for making public broadcasting data available for public AI research securely.
3. The discussion will focus on regulatory frameworks, practical data use for local language AI, and sustainable funding.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/1e31HV9t4Qo/maxresdefault.jpg)](https://youtube.com/live/1e31HV9t4Qo?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

process of being um uh made operational and formalized. It works very closely with a number of critical institutions besides the public broadcaster who does the production. We're going to be

working very closely with the information regulator. The information regulator we believe is critical to making this um work. We have a very strong information regulator in South

Africa which has not only data protection requirements in the law but also access to information which is obviously a very critical um counterpoint to that as well and is

being looked at and I think Malani let me not trade on your turf there but we are very much hoping that with a very minor adjustments to the law and I know um Priya has also been working on this

it could also be an access to data um law but the actual sharing of the data the sort of technical aspect aspects of what is required there obviously a very um you there's a lot of very specific

technical things that have to happen um you we've got you know people from the universities University of Ptoria working specifically on this but there'll be a wider spread of people and

working together with other groups that are working on this across across the continent but then we'd also have the innovation fund in the science and technology um department that you know

could support it's not going to pay for the public broadcaster but it could be a nice revenue stream for this incredibly, you know, this say this virtuous production of data. Um, and so all these

different elements would be absolutely critical to a governance framework that was recognized through the public through public value through the public purse and ultimately allow for local

public interest um, you know, AI AI um, LLM modeling um, and AI systems um, supporting these AI systems. So that's what the discussion is. Obviously there are a number of legal components to this

but we also wanted to share it because I think for maybe you know certainly politicians it's been a it's quite a hard cell um everybody's in kind of austerity and these kinds of things but

to just you know this is really such a gift and um if we can get it to work um but with you know it'll create so much more greater public value and really address this critical problem which if I

was here would say you know the the biggest problem There's a lot of talk about computational power and of course that's true. But for local language modeling there are three big problems

you know data data data as people say. So um this is really what we are are are hoping that will come to fruition um in in South Africa in the very near term and then could also I know um other

people are going to speak about other public broadcasters often commercial public uh not public broadcasters commercial broadcasters on the continent who are also being resistant and might

we might find ways of them being more receptive to some of these uh some of these issues. So on that note um I think we I'm going to move to Mukalani Dima from the um information regulator who's

going to speak a little bit about that and if Dr. Medi from the um tech invoice office from Adet office for digital enhanced technologies um arrives then he'll speak after you.

&gt;&gt; Thank you so much &gt;&gt; wherever you'd like. &gt;&gt; That's fine. [laughter] &gt;&gt; Uh good afternoon everybody. Can you hear me

&gt;&gt; properly? Thank you. Uh thank you so much Allison for for that introduction. Actually you've covered some of what I wanted to uh cover today. I am with the information regulator of South Africa.

Uh we are established in terms of our data protection legislation. Um but we also have a mandate on access to information. So we also regulate access to information um issues in the

country. So we are a data protection authority as well as an information commission for for South Africa. Now we are not an AI oversight authority not by any chance but simply because um issues

around AI uh really revolve around accessing data. Now data is the currency of the new digital economy. We then become involved in all the discourse and the discussion dialogues around uh AI AI

governance from our perspective AI governance requires that there is protection of personal information but there's also accessing of critical databases that are needed to to develop

AI. So this is our angle as as the information regulator. Um what we want to be able to do as the information regulator to support the work that has been initiated by the

various partners is to um see to it that the legislation that we have is fit for purpose. Unfortunately like all freedom of information laws or access to information laws the South African uh

promotion of access to information act is no longer fit for purpose in in the in an era of AI. A lot of our laws were designed for paperbased information. Um, so one of the moves that we're going to

be initiating with our parliament is to uh move for an amendment of the legislation so that we reimagine what we mean about accessing information. A lot of our laws talk about the state being

proactive in making information available. uh and and we have a a specific idea of what we mean by automatic making information automatically available. We

talk about things such as budgets uh things such as the services being provided by those uh public institutions but but that's a a very dated idea of what we mean about about uh making

information proactively available. Um we need to start looking at things such as algorith algorithmic transparency. Is this something that we should be saying to the partners? They need to be

proactive about um we need to be able to come to a point where we are quite clear around the rules of the game for the development and deployment of AI systems. Um this space is largely

unregulated. I mean I think it's been discussed here uh quite often this point that AI uh development and deployment is unregulated. So there is a tendency by a number of uh uh governments to then look

at the existing mechanisms to see whether those can be used as a form of uh of of regulation. So in our case there's been a tendency throughout the world actually to look at data

protection authorities as possible mechanisms for regulation of AI but that is limited because by its nature the work that we do only focuses on personal information uh processing. So once an AI

system is uh is does not involve the processing of personal information it means therefore the mechanism that you have such as the data protection authority is quite limited in in what we

can do. I think uh ours uh in relation to the project that Dr. Gilworld mentioned earlier, we are quite keen to ensure that uh the data protection legislation is not used to frustrate

innovation uh through arguments around privacy and secrecy but we want to support the partners in carrying out this balancing act between protecting personal information but also enabling

the free flow of data that is so critical for AI innovation. So that is our take Dr. kilowatt. I'll leave it there for now. Thank you. &gt;&gt; Thank you so much. I think there's so

many things people want to unpack about the mechanics of the regulations and the um licenses in order for this data to flow. So hopefully we can come back come back to some of that and we don't have

Dr. Sn. So I'm actually going to go across to Priya. Pria, while we still on Africa, um I'm wondering if you could just tell us some of the um really exciting African context and frameworks

we've got um that uh you know include principles of access to data. &gt;&gt; Yeah. All right. I hope everyone can hear me. Um and thank you so much, Elsen, and thank you for that

introductory context. I suppose it's the dilemma in the South African case, but it's a it's a wicked problem and a and and a good dilemma to have and I'm encouraged by how many people are

thinking about it and I think the level of attention that it received even in a platform like the G20 as Allison mentioned um I wanted to um to turn the discussion if we are thinking about

national readiness um within the South Africa case it could be that other African countries are facing Exactly the same issue where they are sitting on this gold mine of uh broadcasting data

and they have the dilemma of the innovator who is looking to do some incredible training and sees this opportunity. And so the question is if we had to look at the um at the

continental frameworks, what is it that we have that would give us a baseline of where we're at and what we could leverage? The first one is the African Union continental strategy. And I think

the the the kind of opening statement in the continental strategy is understanding the constraints uh for AI. The the very large ambitions we have for AI but some of the constraints. So even

while the benefits of AI would remain high for the continent, we still remain with this divide with AI divide and it persists and it points to three issues. The first

being the lack of highquality and large data sets. The second being the compute and the third being the talent capabilities that are critical for AI development and use. And I want to

provoke here that perhaps we do have the data sets but we don't have the access that we need. And I also want to provoke that perhaps um the the capabilities and the skills that we need will also be

improved once we do have access to the data and our innovation could run more smoothly. So the strategy itself is looking to strengthen a number of things including cooperation. It calls out that

there should be cooperation between research institutes and private and public sector and it encourages the development of capacities in various areas including in this area around um a

large language model training. So one of its topmost priorities is ensuring the availability of highquality and diverse data sets to underpin AI development and ensure the availability

of the infrastructure to be able to process such data. So I want to quickly look at what it says in the detail because it's it says you this is the large ambition but it

also recognizes that there's a need for ethical standards to respect human rights in the way that we uh engage with the data and to recognize people's dignity respect diversity inclusivity

and African culture and values. It speaks about safety and security by design and it speaks about the risks as the information regulator mentioned in relation to privacy and personal data,

intellectual property risks is also raised in the in the uh continental strategy and then the risk of subversion of indigenous knowledge and African cultural heritage. Now that's not to say

that what we're proposing here immediately um is part of this risk framework. But what the continental strategy is advising is that one has to um accomplish this by taking into

account the ethics, the safety by design and the privacy and data. So the governance framework um that Dr. Gilwald mentioned is essential to drive us forward. Two other things that are

encouraging is that we do have since 2014 a convention on cyber security and personal data protection. So if there was another country that faced a similar dilemma and their information regulation

was perhaps not as mature, they would also be able to to rely on the principles of data protection there. That is about accountability for how we use the data, the minimality of

processing. So we only take what it is that we need the security safeguards the responsibilities for data controllers and for any data intermediary that engages with the data. So we do have

those frameworks. There is the AU data policy framework which is a blueprint to establish data governance systems that harness data for innovation, private sector competitiveness, social and

economic development but but is doing it through a national integrated data management system that is looking to unleash the value of data for all. So it's looking to address inequities in

the way that data is accessed and this would fall squarely into one of the ambitions for that. More recently we have the uh initiative driven by the African Commission and human um African

Commission for Human and People's Rights um that passed a resolution 620 on access to data and again it's a regional framework that looks takes a human rights lens to access to data seeing it

as an instrument for human rights for the realization of human rights access to data as a means of realizing human rights so I think all of these regional frameworks albeit a snapshot they they

create this regional facility that we can leverage in a way it's an endorsement that in this point at this point in time where we're at that access to data is part of continental

priorities that you know in the way that we access data of course we must observe our human rights standards but that we can reimagine the public a broadcaster in an AI for development context we we

can be guided by these frameworks and those that are developed elsewhere to imagine the partnerships, coordination, ethical and safety issues and to make sure that our legal and regulatory

measures as was mentioned by the information regulator are also up to standard. Thank you Priya. Thank you so much for that and um my apologies and I hope you'll stay with us because it

sounds like something far more exciting is happening a drinks party or something next door to us. Please bear with us. We're not going to be long. Um because we were meant to have our slides up with

our little small speaker descriptions and bios I haven't done justice to to people. So it will be on our page that we are going to put this up on. But that was Priya Chetti. She's the executive

director of research ICT Africa. Um and I'm now going to keep us in Africa and I'm going to ask um Taj Tajin um Guadab from Masakani hub um to talk to us a little bit about

&gt;&gt; Sure. Thank you. &gt;&gt; Um so Masakani is a is a community of um researchers that are interested in building NLP for um African languages and our work span over a lot of African

countries. We have done um data set collection model building for over 40 African languages on different aspects. Um I want to share some um insights from what we have done in terms of working

with uh broadcasters. So we know that most um big tech use data from the web to script and build models. Now when it comes to Africa and for a community um organization that is interested in

ensuring that we do our work ethically when you look at the websites of a lot of African media organizations you don't have any information on the license that is attached to the data. So you're not

sure whether it's okay to use the data or not okay to use the data. The best way to do then is to actually contact them and ask for permission to use the data. Now when you ask for permission

you might not get a reply but when you do get a reply it becomes a question of so it means the data is valuable. So now we want compensation for that. before you ask they might not really

know the value but when you do ask then it means that there is value to that. So in in 2021, we had a um a project where we're looking at um developing name entity recognition models for African

languages. And we wanted to ensure that the data sets we're using are actually not translations from English but actually data sets from like the the the starting data is actually from um uh

languages and then we thought of broadcasters. So now we look at um Kenya for example, not to mention the name of the organization. We found this uh broadcaster. They had um good data in

law which is one of the languages spoken in Kenya. We checked the website. There is no information on the type of license. We're not sure whether to use or not. We contacted them and they

wanted us to pay for the data. that took us over a year to resolve and also agree on what to pay for that research to go forward. That's the case in Kenya. On the flip side, when you um at the same

project, we contacted um media organizations in Nigeria and the ones we contacted were okay, as long as this is for research, we're willing to give you we are willing for you to use the data.

So, we got to the agreement and then we were able to use the data. But then those were mostly text data sets meaning that there is less issue of bias like because it there is no identifier

whether it's male or female then you can actually use that to develop model. Now the question becomes more interesting when you want to use voice data from broadcasting organizations. Then you

have to think about how do you ensure balance between um speakers? How do you ensure balance between ages? And that becomes a a more complex question that you have to think about the technical

part of how you collect the data. balancing between the process of actually taking the raw data into something useful because the way the data is being um produced there are

issues of personal identifiers there are adverts and other things that you need to remove in the process. So what I think would be beneficial in this [clears throat] process of developing a

a governance framework includes also looking at those um technical aspect of the data especially from a voice perspective what should be there and what should not be there. another way of

interacting with media houses. Um [snorts] earlier today I was speaking to Michael from um Robert Mali and he mentioned that their approach was to uh be a mutual collaboration between um

their organization and the media house. So what they did is get the data to train the model but in return they now train the media house on how to use AI. Now that is um kind of another

relationship that can happen. Now um I'm just going to go back to Nigeria because I'm from [snorts] Nigeria. We do have this uh government broadcasting organizations and they do have lots of

data and from what I have understood you each whether public private community there is a regulation that says that all their data all their programs must be recorded and stored for a period of um

certain number of months. for if there is anything that they need to go back reference back to or in um court cases meaning that the data is there sitting a lot of it and it's not being used and

apart from not being used when they because they don't have the storage so after the expiration of the mandatory period for government storage they delete the data.

Yes. Because they don't have the storage and they need to continue storing the data. So it it it's really important to also look at these different avenues how best to get the data because they exist

and as usually mentioned data is one of the key missing parts in developing AI for most African languages and we cannot continue to rely on um funders and donors to provide

support for creating these data sets. we have to look inward and I believe this is one important step that we can take. Thank you. &gt;&gt; Thank you so much. [applause] It's

really um critical technical um insights there for us. Um and I think Gita Raju is also going to give us GA [laughter] is also going to give us um some some more sort of technical insights to that

particularly in the um Indian context. Um G is from the center for responsible AI and in your response ga please do talk a little bit about your organization and you know the work you

do. Thank you. &gt;&gt; U so briefly I will uh talk about the center that we are working on. It's the center for responsible AI at IIT Madras. Uh so we work on tech and policy

research on responsible AI aspects uh of AI adoption in global south generally and uh I would like to highlight few initiatives that are relevant to data sets multilingual uh grounded data sets

that cater to the diverse languages around India. So there is an initiative called AI for Barat uh which uh hosts uh different models, data sets and other frameworks that will help people to

adopt AI systems that are uh that can cater to all 22 official Indian languages in India. And those things are like publicly available data sets and platforms. So for example uh we spoke a

lot about how do we crowdsource data, what how do we annotate data, right? So there is a platform called Shuna which will help them help the developers and uh the communities to annotate the

crowdsource data and that that is a platform that could act as an enabler for the developer community be it startups and other uh things from a different perspective from the central

government perspective in India right so we have a platform called AI kosh as part of the India AI mission so they host a lot of publicly available data sets that are AI ready. So how do we

come up with a standard of say the standards of data sets which we can declare as AI ready right so for the traditional uh AI models right so you you know how a statistical data should

look like how a machine learning data say a linear data set should look like so how what is it for the large language models how are the anonymization made when when it's publicly available right

so those type of standards the strategies for anonymizing the data that are publicly available uh those things are taken care by the AI course platform before getting the data

uploaded into the platform for public view. So these type of initiatives are happening in India to enable the researchers and the organizations who want to adopt AI for public good and

apart from this I would like to highlight a couple of issues or it could be a kind of sensitive uh aspects which all the developer community should focus on. Right? So when we say AI ready data

for the public good, right? So we can't always rely on the open data sets that are available in social media or whatever that's there in the digitized documents. So we have to go look for uh

department specific data that is owned by governments. So how what is the data sharing policies that is existing in India which will enable people to utilize leverage all the data that is

relevant for adopting AI solutions that will make an impact in people's life. Right? So all these data sharing policies will have to go through certain process and some approvals from

different departments which will take time. That is one of the most challenging thing in India and uh people are trying to overcome all these challenges through um opensourcing all

these datas through the AI course platforms where they anonymize certain things protect certain things and they get something based on some request. So they they publish certain things saying

that okay these are the available data and then you can go request and then access it based on the approvals that you get. Apart from this the concept of anonymization and um the way in which

you crowdsource data right those things are the most important things which the developer should be aware of and crowdsourcing data actually happens only when you build trust between users. So

when you want to build trust there is there is a main concept of uh engaging the user community to all through the AI life cycle where you start engaging with the community end user community right

from the design development and deployment phase and ensure that the user needs are met and also uh you align with the ethical values and policies of the organization and that that those

things are the most important things from the Indian perspective. Yeah. Thank you so much, G. There's so much we've tried to condense into this. I feel like we immediately need to follow up, but um

I'm going to just let us finish this round and we'll try and get back to some of these things. So many questions in in your answers. So I'm going to go to Manu and Manu I know you've got a lot to say

from um from um Ker on and I think it's very well known to a lot of people in the audience but I think what we haven't covered and that I would like you to at least touch on is the question I mean we

talk about public value and public interest and you know building this so people can benefit from it but we seldom speak about the you know it's still extractive from communities and that and

you know the revenue sharing kind of things that you've managed to like actually you know we talk about in theory but you've actually getting working so please do share that with us.

&gt;&gt; Absolutely. Uh one so happy to follow Gita because I think she set up the stage so beautifully uh with some of the things that we've been trying to do in India. Uh I'm so happy to be here. I'm

actually representing my colleague Ashwin who leads so much of her work uh who leads all of our work not so much all of our work outside India. Uh my name is Manu. uh karia is the Sanskrit

word for work that gives you dignity and we think deeply about how can AI be a force of good for all our communities right how do we bring accelerated earning and learning opportunities to

low-income communities across the global south and how do we center our communities I think spoke so beautifully about the AI value chain right so from data collection to model building to

fine-tuning to evaluations how do we make sure across every single one of these uh parts of the AI value chain we're not being extractive And wherever possible, we are giving our

communities the highest wages possible, the highest ownership possible, having agency over their lives and over them over how technology enters them. Feel talks about this beautifully, right? She

says that our relationship with technology is fundamentally broken because all of us for all of us in the global south, it is always a foreign object, right? Technology always happens

to us instead of happening from us. And the question for this AI moment specifically is how do we think of our communities not just as passive beneficiaries of AI models we built but

as active builders, active evaluators. That's what we've been able to do in India. We've done over half a million evaluations, human evaluations in the last year. The last panel actually was

talking about some of the work that our communities have been have been able to do um in in doing really complex evaluations, right? who gets to decide if an AI model is working for a domain

for a people but the people who actually you know ask the same questions in that domain right and I think that what we started doing evaluations there's always this patronizing belief in the tech

sector that oh this is too complicated no no this work cannot be done by the communities on the ground right like that's like but it's not right like of course like it's it cannot be surprising

to us that we can meaningfully engage our communities to build complex data sets across all you know modalities whenever possible. So if we don't open source our data sets or if they're not

owned by our clients, we try really hard to give our workers in principle ownership of their data set so we can do royalties. We've been able to do not a very meaningful amount of that so far,

but we're making a big bet on that this year, which I'm really really excited about. uh and thinking deeply about how do we make sure our communities don't just get you know decent wages don't

just get a say in the revolution they're centered in it in the most meaningful way possible and we've been doing this work in India and last year uh we expanded to well in 2024 we expanded to

Kenya and Ethiopia with the help of incredible partners like Leu Bethlehem desi who's going to be here I think tomorrow uh from Leu um and digital green of course uh from from uh which is

based in India and Kenya and now thanks to Ashwin we expand to South Africa so very excited about that uh with the help of Lapa that is just such an incredible organization we're so lucky to be able

to do that we're thinking deeply about expanding into Indonesia into the US and in every single one of these expansions I want KA to be the most silent partner in that the engagement should not be

called Kar that's very important to us and number two the communities in these countries should own their data sets should get to benefit from the data sets and all we want to bring is the platform

is the network is the learnings that we have had as we have built foundational Indian language data sets that have contributed to things like AI kosh and money and all these things that you'll

hear about over the next 5 days and I think just I will end with like just like restoring the ability of all our communities like you know the there's no difference in uh like in the capability

between our communities and the people who currently get to decide how AI is built and I think with that belief we want to build a cheesily build a world in which AI works for all of us. I think

that's just really important. Yeah. &gt;&gt; Thank you so so much Manu. I'm so short of time. I'm going to move immediately to Diana Mascara from Diversa um to just have our Latin American input. Thank you

so much. &gt;&gt; Thank you. Can you hear me well? Okay. Thank you Alison for the invitation and I would like to be briefly because we have a a few minutes and h I bring with

me some uh reflections from Latin America and uh yeah I start with three uh pillars on the discussions on the governance frameworks local language

models and the AI development erh because from our experience Working from Latin America, we have learning that governance debates cannot be reduces to access and controlled. The

core questions is not only who can use data but uh who defines what data matters for what purpose and under what institutional arrangements. Erh governance is not merely regulatory or

administrative. It is a political topic because every data set, every classifications, every optimizations, decisions reflects power relations and in the global s these debates unfold and

in in context shaped that uh by extractivism and data colonialisms [clears throat] uh where value is and often generate local but captured elsewhere and in many

country and especially in in my country and in Ecuador and Latin America and I think this is happening in the global SA are currently developing national AI strategies. Erh the these are important

steps but uh however too often these frameworks remain uh declarative. They articulate articulate ethical principles but like uh bending mechan mechanisms accountability structures and madeful

public participations. erh we turn this opera um operationalization sorry erh principles that not shit's power and yeah the questions that bring

with me is who defines which the problems of AI should solve who sets performance standards who bears the rise and who captures the value and yeah and and I

for me these topics are important because local language modeling is frequently the framework and issues h and is and not only an issues of inclusions ensuring communities are

representing in digital systems but representations alone is not enough because language is not just data language it it carries culture memory and social meaning and if local language

are not treated merily and raw material for model training And with all community participation in how data is curated, interpretates and use, we reproduction extractive h

dynamics and h in a new form. Yeah. And yeah, true local language AI requires some participatory process. Uh communities should have a role of defining data collections, practice,

concept making, intend use case and benefit sharing. Otherwise the inclusion h becomes other form or appropriations and yeah in the end um across these areas uh one principle stand outs erh

local language models are not just and technical tools they shape how our knowledge culture and related are representative in the digital systems and yeah if if h we want um h if you

want want to equitable AI ecosystems inclusion is noted. No community must have a real decisions making power over their language are collected modeling and deployment. And so the

questions the final questions is that uh it's not only how to make AI safer the question is how uh who uh has the power to shape our language in these systems and yeah that is the reason that our

work in divers is an organization based in Ecuador. We develop uh these uh local language models, low small language models and uh we use artificial intelligence and um data analysis and

geographical special data analysis. Sorry. Uh from this critical this feminist perspective to uh find another ways to develop AI and and yeah this is this is all I

think. Thank you. &gt;&gt; Um Diana thank you so much um um for that. I'm going to ask the panelists if they want to ask each other any questions before we go back because I

think they've had so many um interesting uh intersections between their work. But I did just want to also just before we go to the audience for just one or two questions although that clock is not the

right time I must just tell you. Um so like the real time I'm serious. [laughter] Um so I just wanted to say I mean I think this was really wonderful about

what's come together in this panel is this entire um ecosystem of um of of of common values and you know community access of public access or public value. Um so the the the big model that we were

speaking about is the kind of big picture bringing together creating you know the the state creating an enabling environment for the you for the you know access to data of our public

institutions of our democratic public institutions. I think it's important for us that we've got this model on the African context continent because we have one of the most probably the most

democratic constitutions in the world. a lot of this stuff is required by the government to do and it simply cannot currently kind of keep up with these technological demands. So I think we've

got this big picture where we create this these opportunities and then we've got universities like um Maravati but also working through organizations like Leapa that are building community um

ownership community agencies. So it's not only this big statist kind of model that they but it's an enabling environment for these different innovations to be able to um do all

sorts of different things and I think their questions about you know initially making this a preferential model um it's for local development because I think a lot of what happened in some of these

earlier discussions was you know big tech coming in and saying well we can do this for you and you know we we'll take all the data we'll put you make sure that you can have local language and for

your government broadcasting and stuff. So it's really important that this is preferentially you know this is for access for Africans and in the context of the a um African uh data policy

framework. It's also there's notions of reciprocity so that on the continent we can actually get the kind of economies of scale and scope that one needs to be um competitive and build some of these

models um some of these bigger foundational models. So I'm sure that maybe the panel wouldn't mind if we just took some questions um from them. Anybody want to before we otherwise you

can meet afterwards and have a have a discussion. Any questions from the floor? &gt;&gt; Yeah. Um some very interesting uh thoughts on

access to data. uh and I had a question around this which is based on a conversation that I had. &gt;&gt; Can you just introduce yourself? &gt;&gt; Yes. Uh so I'm Ashwin. I'm from Karia.

I'm from the platform team and I focus on uh our work outside of India especially in Africa and Indonesia and so on. Um so I was having a conversation with um um a potential uh partner in

Rwanda and they were talking about how there are common languages that are present across borders of countries such as Swahili, Kenya, Yuruba and so on. uh and the African uh continental free

trade uh policy doesn't specifically talk about data trade between countries. Uh so I was wondering if you're thinking about u access to data. Uh there are data sets that are accessible let's say

in certain countries. Uh how would we uh sort of um speak with the representatives of different countries and sort of negotiate transfer of data across borders since it's not covered

under the ambit of policies like the free trade policy. So I'm going to answer that very quickly because research ICT Africa supported the African Union data policy framework

and what you're asking for for the continental free trade. The the data policy framework is developed to support the continental free trade area. It's a towards a digital single digital market.

So all the issues of crossber transfers within Africa is what the harmonization and the domestication of the African Union data policy frameworks about. It's the principles all there. Obviously the

operationalizing of it is is different and different countries are at different levels of um implementation but in the principles are completely there and the you know the the importance of that um

for innovation and but also for you know um business and trade economic development um are are very um strongly embedded in the digital transformation strategy in these uh things but the data

policy framework is really carved out for this it they governments all signed off on it all the governments signed off on So if any, you know, if it is a problem, then you you need to try and

get those um governments to um get or get the um um African Union who was meant to be here. Unfortunately, they're not on the panel. I think you probably saw there were advertisers on the panel

because, you know, they are trying to harmonize. They're trying to domesticate this all and I know there probably a lot more to be said on that. I'm going to just see if there a few more questions

and then other people can come back to these questions. No more questions. Yeah, please go ahead. I'm I'm also going to ask you if you wouldn't mind just standing up cuz

it's actually so loud behind us. &gt;&gt; So hello everyone, I'm Rome. Uh I work with conversation AI agents. Uh we mainly discussed about uh globally available public data in global south

mainly and most of it is text based data or voice based data. Are we anyways working on making video based or image based data to make such AI models available for public use or any type

which we can directly use for now? uh is this in the Indian context outside of Indian context? &gt;&gt; Uh anywhere. &gt;&gt; So we do that in India, right? So of

course we we we collect multimodal data sets. Uh we've just started doing just 6 months ago egocentric data collection as we prepare for more work around the spatial intelligence st uh space. We

also just helped open source vani phase 2 which is one of the largest uh multimodal data sets in Indian language history. uh with the help of IASC and of course our partners at Google and all of

that is on AI kosh to Gita's point that you can you know try out and download I will give it to the rest of the panel on what is the uh state of multimodal data collection uh but but we more than happy

to support it we very excited &gt;&gt; okay um I have been me I previously when I spoke I mentioned about the masakana community uh so more recently we have the Masakana

African languages hub which is now uh an arm out of the Masakano community that is um subgranting into the African ecosystem. One of our recent calls specifically on multimodel um data sets

that are culturally grounded in African languages and we are focusing on the 50 most spoken African languages. So the call went out um in the beginning of this year and it intended to collect

text, image and um audio mostly related to language. So that is the the one thing that both the image the text and and the audio has to have in common and it has to be culturally grounded in um

in an African language. So there is that effort and um it's something that we have been focusing on for um the last couple of years and the idea is to not just collect this data but looking at

the reality of most of the LLMs we have out there when it comes to how they respond to questions which are culturally grounded in in in in some of our languages. they kind of

miss if if for example you ask um the LLMs out there in um my tradition can you tell me a breakfast idea probably it will be something more English related so solving for some of those challenges

is what we aim to have with with this data set &gt;&gt; thank you so much now we really are out of time proper time um I I'm going to just see because nobody's thrown us out

the room quite yet does anybody want to make a Last comment or could you just meet informally? If anybody'd like to come up, we close off the session and let people go. Anything urgent? I'm sure

there's lots of stuff, but we'll end anyway. Thank you so much for joining us this late session. I know it was very difficult to get here for many people getting especially coming in late from

outside. Um we are going to um be hopefully showcasing once these final negotiations are finished. The concept note for the G20 um group is on the um DCDT site and you can look at that. It

was very strongly endorsed by a lot of countries not only um you know global south countries countries within Europe who were saying we also don't actually have a lot of Danish content. [laughter]

So so it really was a issue that was really very strongly supported by everyone but such lovely insights from you here. Thank you so much for joining us and um we see you during the course

of the week. Thank you. &gt;&gt; [applause] &gt;&gt; Thank you so much for just and And you should have had

anyway.
