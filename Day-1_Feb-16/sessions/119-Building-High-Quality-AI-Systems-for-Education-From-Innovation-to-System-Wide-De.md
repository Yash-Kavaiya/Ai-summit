# Building High-Quality AI Systems for Education: From Innovation to System-Wide Delivery

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 16:30 ‚Äì 17:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 16 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/qeJ1gDwCIfE?feature=share) |

## üé§ Speakers

- Jairaj Bhattacharya, ConveGenius
- Jonathan Stern, Gates Foundation
- Kalpana Sharma, Lakshmibai National Institute of Physical Education
- Marc Shotland, IDinsight
- Paul Atherton, Fab AI
- Romana Kropilova, Fab AI

## ü§ù Knowledge Partners

- Fab AI

## üìù Summary

This session examines how countries can design and scale high-quality, context-appropriate AI tools for education. It highlights key risks and opportunities, with use cases from Africa and India, and discusses quality assurance across the AI lifecycle. The panellists will share lessons from testing and deploying AI in classrooms and public services, and present insights on integrating AI into government systems, conditions required to scale AI safely and coherently.

## üîë Key Takeaways

1. This session examines how countries can design and scale high-quality, context-appropriate AI tools for education.
2. It highlights key risks and opportunities, with use cases from Africa and India, and discusses quality assurance across the AI lifecycle.
3. The panellists will share lessons from testing and deploying AI in classrooms and public services, and present insights on integrating AI into government systems, conditions required to scale AI safely and coherently.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/qeJ1gDwCIfE/maxresdefault.jpg)](https://youtube.com/live/qeJ1gDwCIfE?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

I I don't know if I'm just supposed to start. Is that it? &gt;&gt; Okay. Apparently, you were just waiting for me to pick up a microphone. Um so

welcome everyone. Um this session is titled something around uh highquality AI systems for education from innovation to scale or something along those lines. Um and uh and thank you all for for

joining us today. Uh really looking forward to having you here. Uh my name is Jonathan Stern. I'm the deputy director of the global education team at the Gates Foundation. Um, and the

premise for this session is relatively straightforward, right? The idea is that AI is not or AI in education is not just about finding tools that work, right? That's that's a

relatively easy thing to do. But what we want to think about is what is the ecosystem that is necessary in order to ensure that highquality decisions can be made about um uptake of uh of AI and

education safely at scale and that ultimately improves learning. Right? So the reality on the ground in many of the contexts we work in that the foundation we cover work in subsaran Africa and

South Asia um is that it is what people have been referring to for the past decade or more as a learning crisis right many children not being able to do uh basic numeracy or literacy by the end

of grade four but that also provides us with an important opportunity right and so one of the things that we're discussing here is that evidence-based approaches to the

foundational learning issue do exist, right? We have a good sense of what works to improve learning. There's a fair amount of literature on the impact of structured pedagogy and targeted

instruction. Um, if anyone wants to go out and read the GE papers on smart or best buys, right, there's a lot of evidence around what works. There's also obviously a lot of excitement right now

about edtech and AI in education and the question is not is there a space for AI in education but it's how can we use AI to accelerate the impacts that we know are achievable via proven approaches

right so it's about solving problems that exist I think one of the conversations that Roman and I have had a few times and others in the room as well is too often in the edtech and AI

space you end up with people coming up with solutions and then seeking a problem to solve, right? And we want to think a little bit differently around what are the pain points within the

systems that can be alleviated by the use of technology. Right? So accelerating impacts as I said by uh by scaling proven approaches um approving efficiency. So reducing administrative

burdens for teachers allowing them to focus more on instructional time u providing more access to activities and ontarget tasks for students right there are a whole bunch of opportunities for

AI to come in. But as I noted a bit at the beginning and as we're going to talk about here, AI in and of itself is not inherently an education solution, right? It doesn't improve learning just by the

sake of having it in schools, right? So we want to think a bit more critically about what does it mean to think of quality assurance for AI for education. Right? So we're going to hit on three

main topics throughout this session. Right? So the first is on quality assurance and evaluation. So what are the questions we should be asking the things we should be measuring um and

what's feasible in low and middle inome country contexts. Um secondarily the role of benchmarks and standards um so what kinds of standards can help both technical and not right accuracy is no

longer sufficient in and of itself. We need to think a bit more about the pedagogical side of standards as well for AI and education. Um and lastly, what it looks like in reality at scale.

And so we have a great example um from here in India that we'll be talking about u for for what that may look like. And so in short, what we're really talking about is

how do we generate evidence with sufficient guard rails that travel with a product from pilot into scale, right? and what is that ecosystem that will allow for scalability um of AI and

education systems. So we have three um panelists who will be uh answering some initial questions and a fourth um guest panelist as well to provide some some summary remarks at the end. Um I will

happily let um people if they want to share some additional um intros for themselves um do so. Uh Romana from from Fab AI um is two seats uh to my left. Um Mark Shotlin

from ID Insight uh in the next one down and uh and Garage from Kvagenius um at the end. And and next to me we have um professor Kalpana Sharma um who's the vice chancellor of the uh Lakshmi

National Institute of Physical Education uh in MP right and so so without further ado maybe we'll get to some questions because people probably have no interest in hearing me talk any longer um so so

maybe Ramana starting with you can you tell us a little bit about how Fabai is thinking about quality assurance in AI for education and what its implications are for scaling.

&gt;&gt; Thank you very much and hello everyone. So at Fab AI we are really looking into how can we use AI to improve learning uh outcomes especially in low and middle inome countries and quality assurance is

uh one of our key pillars of work. So let me tell you how uh how we do that but maybe just one moment to reflect on why we do that. So no one will be surprised in this room

probably when I say that already nowadays millions of children worldwide are using AI tools in schools and outside also for learning but there is a but of course we are

looking into how many of those have been evaluated. Um we have for example done a mapping of tools in um South Asia and subsaharan Africa and we mapped 352 tools for

learning and you can just think for a moment in your head how what do you think is the percentage that that had any evidence on them? Well, what we found was 9%.

So that is not a lot right because at the same time we do know that governments do need to make also high stakes decisions. We do know how quickly these developments are evolving and we

do know that also developers need to make decisions as they go on and so we want to help the others uh to be able to make confidently these decisions. So how we do that is uh that we trying to look

at quality assurance in in a way that we think of the whole product life cycle. we do think uh of a cyclical approach because as I mentioned as you all know these things are evol evolving fast so

it's not enough to do it once it needs to be a mindset and then uh we do uh want to also do it as a multi-layered approach and I have just one slide so just one slide which should help to make

it a little bit easier to follow but what I want to show here is that uh we are focusing on the tools AI enabled uh tools for teaching and learning and uh when it comes to the layers that I was

talking about. What we mean by this is you know you can have a great uh tool and maybe it passes all the safety checks but it doesn't mean that it will be a good tutor right or maybe it's

great tutor for for English but it doesn't mean necessarily will be great in other languages invahili or any other you can think of and so that's what why we do think it needs layers needs to ask

questions at the different um layers that we that we put here on the left that you can see. So starting with the the global layer where we think of things like safety or bias, right? That

that needs to be there. But then we want to look at the education layer. Is it actually going to improve the the uh learning outcomes? Um then you want to be sure that actually if it is supposed

to be an assessment tool, it is good at assessment and then you need to consider the evaluations for that the specific metrics and track those. And then one layer further and very important is the

context layer. Of course uh it can be a great assessment tool but if it is not aligned with the local curriculum, not with the available infrastructure uh or the social norms, it's not good enough.

So what we are trying to do is to find this questions and and of course then it is specific to a product but we are trying to build this ecosystem where we do uh see how the tools are uh doing and

uh where they need to improve and then as you can see we do think about it along the product life cycle. So there are different types of evaluations we we uh do and we promote and one of them is

benchmarks. For those of you who are not so familiar, um those are basically how you put the AI models to test, right? And we do have a lot of benchmarks already, for example, for content

knowledge, but there were some which are needed for education that were still missing. And one of them was pedagogical knowledge. So we did look at um how can AI models look at the practice and

methods of teaching and we develop uh the first pedagogical benchmark when we do constantly track and um at new models coming out you can check on Fabi website uh the the leaderboard and what we want

to do here is to show how well they do on uh real world teacher exams. So that's how it was built. What we also want to show is how the small models are doing because of course for the context

we are working in the cost is a big question as well right so you can track there and see um how they are doing but we don't want to stop there we did then look into translating this model into

other languages and also seen what happens and maybe you would not be surprised we did did do this for subsaran Africa but would likely be similar also in India

and other context We did see that even for the biggest languages in Africa like Kisvahili or Hosa the model performance dropped by 15% on average rate and it got worse when we looked at small models

and there was another interesting fact that we've seen um is that if we use the AI translations the performance dropped less when we used human translations with we did uh Uganda with our partner

Kan AI it actually um dropped uh even more which shows that maybe we even over rely on on the AI models right so why I'm saying this is that we are not just trying to show how

the models are doing but really uncover what are the the gaps that we need to fill and then we do talk with the model developers and try to improve those right so that is that is critical one

other benchmark which is interesting Jay briefly mentioned is uh the visual reasoning we all know that AI models are really good at solving some of the most difficult math problems and at the same

time they really struggle with with the visual reasoning for uh which is critical for uh teaching uh foundational numerousy right so again these kind of questions which are practical but if we

do solve it even in the lab setting when you are coming up with a product it is much more likely than once you get to scale and to those decision if it is built for that with that in mind they

will do much better so this is the bench benchmarks. Uh as you see, we do also look at evals which are more specific. How well do tools do on u specific task. We do also then want to make sure that

you do co-create with teachers with educators. You test it through test beds in the real environment and we will hear more on that also later. And then one one more thing that I will briefly just

mention is the impact evaluation. We do still think there is space for that. Of course, you do want to know um how well the tools are doing when it comes to learning outcomes. But there are new

questions coming up that we are also considering such as cognitive offloading right is it happening? Uh and what are the harms harms could there be? So we do need to measure this. Uh as an example,

we are currently doing studies with Google deep mind in several countries just concluded some in India and Sierra Leon and seeing like how can we do more rapid evaluations just to see if there

is an improvement right when I say more rapid is like 8 to 10 weeks also of course the cost is then lower. So it is one way which doesn't mean that there is no space for um standard RCTs for

example when you want to see uh about is is that effect going to stay right so um these are some of the things we are thinking of so we're thinking how you can think more rapidly while still um

rigorously what are the areas and I would say that yes generally our mantra is yeah what doesn't get measured um doesn't get improved and that's why we are doing Amazing.

Thanks, Romana. So, a lot on the benchmark side, which is super important and interesting right now. I mean, Mark, can you tell us a little bit about at ID Insight, how are you approaching the

measurement um and quality assurance at at scale? &gt;&gt; Yeah, sure. Um, so I guess I will first preface this by saying there's two primary I think technical teams at ID

Insight. We have our data science and engineering team and then we have our research and evaluation team and that latter team is the one that I lead but I'll try to answer that question from

both teams perspectives. Um so the data science and engineering team they help uh nonprofits and others kind of build AI into often like digital delivery uh programs that they have. So for example

and and I've also been asked to to use some of our examples from health. So I'm going to give it a health example hopefully bringing it back to to education soon. So we work with this uh

organization called reach digital in South Africa. Um they had a chatbot um that they had produced in collaboration with the ministry of health in South Africa and that the chatbot is called

mom connect and it's a chatbot for mothers pregnant and lactating mothers to ask questions. Some mothers can ask questions like, you know, what foods can I feed my baby? Or, you know, I had some

spicy food and my baby seems to be kicking a lot. Is that a problem? But also questions like, uh, you know, I haven't felt my baby kick in two days or my baby's coughing and they're turning

blue. What should I do? Um, now you want models that can basically give you pretty accurate information. So the chat, so what we did, what our team did is they helped build AI into this. What

was that substituting? It was substituting a kind of relatively small army of nurses that were manually answering these questions. And so you had a huge backlog and a lot of kind of

very urgent questions were not getting answered in time. And so the AI mo the kind of LLM aspect of it was being able to answer these questions quite quickly. Um, but you know, if you're a Ministry

of Health, you don't want answers coming from the worldwide web, right? You don't want them coming from Reddit posts or or whatever. Like, you want it to be really good quality information. And you may

not even trust like the international standards. If you're the Ministry of Health, you want the information to be coming from your guidelines um within your country. And so one of the ways

that they ensured quality was basically limiting the information that the model pulled from uh to the specific guidelines of the ministry of health. So that was like one layer of quality

assurance. Um there was also other layers of like you know kind of quantitative feedback when mothers kind of gave a thumbs up to a recommendation or not. we had monitoring dashboards

that could look at that um and you know basically say are these answers answering people questions but then a lot of times because the model was constrained to only pick up information

from the Ministry of Health guidelines if a mother asked a question that it couldn't answer it would say it couldn't answer and so then we had a whole bunch of qualitative data like what are the

kinds of questions that our model is not answering and is it not answering because these are not health questions or are not answering because our model is not picking it up correctly. And so

that's kind of another layer. We also had another layer of like urgency um respon urgency detection. So you know the example of a blue baby or a baby that's not kicking for a while like

immediately you know send message get seek immediate medical attention and so on and so forth. So these are some of the layers of quality assurance that we had. We're doing something similar with

um community health workers in Ethiopia working with Last Mile Health. Um and now tying it to education, we are working with the Ministry of Education in Sagal um to basically uh help with a

teacher chatbot, produce a teacher chatbot so that teachers can get help designing lesson plans. And again, you want those lesson plans to come from the Ministry of Education curriculum. And

you want it to be using things like knowledge graphs and other things. So like if I'm asking for a lesson plan on geometry, this particular concept, the knowledge graph will help kind of know,

it'll know that there is um you know, you have already covered these topics. It's not just going to kind of invent a brand new thing in a vacuum. It's like they will know you've already covered

these topics in your curriculum and therefore we'll give you a kind of quality answer for a lesson plan going forward. So that's the data science side. The research and evaluation side,

I realize I'm limited in time so I'll be as quick as I can. Um ultimately I think we define quality by the outcomes. What are the outcomes in foundational literacy and numeracy? For example, the

outcomes are literacy and numeracy. And so how would we do quality assurance there or quality assessment? We would do impact evaluations. So that's one thing that ID Insight is a big proponent of

like make sure that we are measuring the impact of these new models. We know lots of things work. We're going to have an excellent example of a super effective um uh product from Jay from Comius. Um

however, but you know the things that we know change, context change, language change, how do these um how do these products kind of keep up with contextual changes with scale? All of these are

questions that you probably want to reassess with an impact evaluation. Is it still having the impact at scale that it had at uh kind of a pilot stage, for example? There's also you know as models

are updating there's continuous AB testing that we can do you know is this model pro uh improving outcomes faster than others. The one benefit of education that I will say in and this is

different from health and other um sectors is that in a lot of cases the outcomes that you are measuring that you care about for example basically learning student learning outcomes are

actually measured by the app directly. Right? If you have a chatbot for a health intervention that chatbot is not measuring the children's health directly. There may be you know,

measuring, they can potentially measure the mother's knowledge or other things, but in education, you can actually directly measure some of the the outcomes that you care about. And so,

um, being able to do AB tests is is quite important. Last, and we'll probably talk about this in the next section, when you talk about, um, interventions at a pilot sk uh, pilot

stage, you want to know whether they're um, effective. when you talk about them at a systems level then you need to bring in systems change measurement and that's a whole another beast but I will

pause and hand it back &gt;&gt; excellent thank you um Ramona so clearly from this and also others in the room like there's there's a lot of work already being done in this space right

um and so how do you think at Fabai about the future direction of the work you're doing and how it's additive and complimentary to to what's happening or or has been happening thus far.

&gt;&gt; Yes. So that is right. There is already a lot of work around quality assurance and standards. You might be familiar with some of that. We are monitoring what is out there and looking how we can

learn from uh the others. Just to mention a few um great examples like there is um a tectona standard here in India by CSF foundation. Um we also have the unit AI for good framework. So there

are also frameworks not only standards out there already which can be very helpful and um for example a few weeks ago we've seen that the UK government has just re launched new standards also

looking at areas such as manipulation or the impact on mental health which are so important right so we're looking at everything there is and yet we do think there is still need for more for for

certain components so what we are looking at is bringing this uh technical evaluation layer to it build components on evaluation uh and then offer it for for the ecosystem to build on to use

that to to help them get some thresholds of what you need to aim for of course um link to what I presented before. So we have recently launched this QA fund that we started to work on. Uh very soon we

will be sharing more information on that also uh publicly and what we want to assure there is that we do build more of these components. We will build new benchmarks but uh we will also do uh

rapid evaluations um in the field and uh we will want to share this with others and we will not do this work alone either. We will work with great partners such as ID insight who as you heard they

have tons of experience in uh doing evaluations. They will help us with all the field work. We will also work with others such such as CGD who has developed a great playbook which is for

uh which is cross- sectoral uh so not um not specific for education and that's what we want to break in there and we will tie this also to other existing networks and alliances such as one um by

Dalberg which will be launched tomorrow here at the summit. So we do really want to find synergies with others and build for the ecosystem to um to get better at this all together. Yeah. to solve the

the issues that we need to solve. &gt;&gt; Amazing. Thank you. Um so we've been talking a little bit at a high level um thus far about kind of the ecosystem around benchmarks and evaluations.

Switching gears a little bit um Gajj into what does it actually take to allow for an AI enabled um product or solution to be embedded um in a national education system? Um can you tell us as

a starting point just a little bit for those who are unaware in the room despite your incredible reach already um what uh what you're working on as an AI enabled uh edtech organization at

Comius. &gt;&gt; Sure. Sure. So uh we have a platform called Swift Chat which is powering about 150 million uh children today across 800,000 schools in India which is

roughly one in two schools. uh and uh the idea here was how do we get AI to the last mile right uh like how UPI has done it and fintech how do we do that for education uh actually internet is

everywhere so it's quite possible to build platforms on top of the internet and it's a matter of time that every household every school will have AI so we really was solving the problem of you

know what's what's that possibility of building a platform which will reach the last mile the teachers have smartphones today, they have internet. Co brought that revolution right in India. So that

was the window of opportunity for us to bring the power to teach and learn on a mobile device on every single mobile device. And we went to the fundamentals, right? What is the app that is in every

phone in India? It's WhatsApp, right? WhatsApp's messaging, right? The fundamental layer in which uh internet's working and almost 300 billion messages are being exchanged a day is on

messaging. So conversational AI was there long time back before even generative AI and LLM existed. So we started with very fundamental simple uh thing like how do we bring chat bots

which where you can just message in your own language as a child or as a teacher and you can chat right and the tendency for us as humans is that if you have a message on your phone you want to reply

back. So that leads to 99% conversion rate. That's why it's an extremely sticky interface like you have conversations going whether it's a human on the other side or whe whether it's AI

you have a tendency to respond it's a human psychology right and that's very sticky as a platform to be able to teach children right so that's why AI tutors on this interface on agentic interfaces

on conversational AI interfaces was bound to scale right and with large language models coming in that was an opportunity which has already been seen now like we

have we can have AI tutors that can teach you 24/7 you can just call an AI tutor and you can ask a question in the middle of the night and so it'll help you solve the homework um so so the

scale has been um pretty much about how do you scale up messaging infrastructure at the fundamental level it is uh essentially building like a WhatsApp for education but what really mattered was

quality Right? How do we deliver on quality? When you have population scale, children, teachers actually using your platform, you cannot go wrong on anything. Right? You have quality

matters. The right guardrails, the right quality, the right way you present all the information you're presenting on the platform, the platform policies, the content policies and the guardrails and

the biases that come with it. All of those were important design considerations while you were building the platform. uh at the same time actually learning is a much more complex

problem. When we go to learning uh we define impact in various levels. Uh access access to quality education is one where you can say that you know we have 10 million users using our platform

every day. That's access but actually real evidence on learning improvement is is the kind of northstar metric for us and for learning it's essentially about subtraction right how much of the

information we can really subtract. We already had a lot of information on the internet and children could just browse and learn right but good systems are able to kind of deliver the right

information what to show and what not to show just simple two questions what to show what not to show at what point of time is is really pedagogical engineering right u and added to the

fact that we don't have enough time in the school hours so we are also playing with the variable of school time right on a limited amount of time what is the best way to deliver say 0.5 SD standard

deviation of learning outcome improvement that's the real problem that AI tutors are really chasing and solving for right so uh it's about showcasing understanding how children learn and

showcasing the right content at the right time and that's that's an exciting problem that we have been solving for context as Ramana was saying is very important uh what works in the state of

Gujarat may not work in the state of Andhra Pradesh. There's a lot of context at the grassroot level and each each of these context cannot be captured with just one agent or a one bot. There's

multiple bots and multiple transactional data from different bots in that inform the system right it's like memory is not just enough to teach and learn similarly understanding you know which school they

are in uh whether the teacher is coming to the class what they have been teaching all of that transactional data also informs in terms of how you know the AI tutors need to respond right so

it's a platform play and it's pretty exciting yeah &gt;&gt; that's that's great dra So, you know, you talked a little bit about the opportunity being there, right? WhatsApp

obviously ubiquitously used. Um, LLM's growing in popularity and uh accuracy and affordability over time. You know, Romana talked a little bit about what's needed to make decisions for what tools

to take up or use. So, can you talk a little bit about the scaling side of it in particular? So in terms of how were you able to achieve such large scale within a government system right what

what were some of the levers that were there and how did quality assurance maybe since that's the theme running through this play a role in that &gt;&gt; sure firstly I think um the most

important part was that we tried to do early early on and on WhatsApp but we had rate limiting issues uh WhatsApp business API has a fundamental rate limiting protocol which allows for uh 30

to 40,000 0 requests per minute right as throughput uh that's not enough for even a city like Delhi right to be able to run AI agents so the large problem that we were first solving for is how do we

run population scale AI agents right and it can keep scaling and scaling u like how do we do it for a state like a state of Himachal Pradesh or a state of Gujarat or Rajasthan right when all of

the students are learning at the same time and if if you are having to deliver more than 150 to 200,000 requests per minute your platform should be able to solve for that. So that's actually at

the messaging protocol layer, right? Uh so we have to have native messaging protocol so that you can scale that messaging can be both synchronous as well as a asynchronous asynchronous is

how WhatsApp operates. You send a message, you receive an AI chat can happen as synchronously, right? Synchronous you're calling you're calling the AI bot. Uh you can have a

voice call or a video call with AI. So that's even more difficult, right? And more expensive. Um so that's the first layer of unbundling of a platform which is the ability to communicate whether

it's on human on the other side or an AI on the other side. So communication infrastructure has to run at population scale. The second is that India uh systems in India have their own

compliances data compliances content compliances knowledge compliances. You have to be able to deliver for DPDP which is the data protection and data privacy act. you should be able to host

um personally identifiable information in the customer's infrastructure. So a lot of these essentially require unbundling of the application layer, the transactional data layer and the

knowledge layer. Right? So, so essentially the platform really had to solve for creating an architecture which will actually work for scale in India where governments and government systems

can run their digital public infrastructure and at the same time give the same kind of experience whatsApp delivers right so there's a lot of value in building infrastructure right

knowledge infrastructure uh learning infrastructure teaching infrastructure teaching assistant infrastructure and uh it's really about unbundling based on you know uh how do we solve it for

multiple states and as a country as a whole, right? You'll also have to comply with federal policies. &gt;&gt; Yeah, &gt;&gt; thanks. Thanks Raj. Um maybe back to you

Mark on building on what DJ was saying about uh you know the specific use case of scaling with coma genius but with the experience that you have at ID insight on extensive evaluation work and

thinking about what that means for systemwide delivery of AI in the education space. What are some conditions that are necessary uh enablers for for that to happen?

&gt;&gt; Yeah. Okay. So first I'm going to talk about the conditions on the product side and then conditions on the the system side. So for the first I'm going to very shamelessly plagiarize a framework from

Kevin Star of Maago Foundation. Um he calls this the enoughs. Does it pass the enoughs um uh test? So his enoughs are is it good enough, big enough, simple enough, cheap enough? So good enough is

the question is like does it actually have an impact and you know as Jonathan said as Gyra just has mentioned like we actually have lots of evidence on what is good enough and there's lots of

products that are good. I mean combogenius is one example of that. Um you know over you know there was a a study um by Michael Kramer uh just recently published I think that u not

yet published but recently uh released student outcomes doubled by like over the course of like relative to a control group student learning outcomes doubled in the homogeneous group over 17 months

more than doubled. I mean that's huge. So we actually and and we have other products that are showing similar things. So we have lots of evidence of what's good enough big enough that just

means is there a large enough need education system lots of children obviously a need simple enough now this is the one where I think a lot of what that gets a lot of interventions if you

have too many moving pieces too many things that like a teacher needs to adjust on like this thing needs to fall in place the teachers need to do this the administrator the more complicated

it gets the more likely it's going going to break and it's going to fail. So if it's not simple enough um it's going to be very very very difficult for it to scale within an education system. And

[snorts] then the fourth is cheap enough. And so, you know, the per student cost at a pilot stage is usually quite high um because there's lots of people kind of checking whether there's

you know monitoring whether the implementation is being uh is following with fidelity um and so on. One of the issues with LLMs is that there's not necessarily economies of scale. as you

scale up, you have more more questions, more tokens, more cost. And so scaling with LLMs becomes actually kind of a problem. Um especially if you're operating at this level and so you now

need to start thinking about okay, do we need to build our own small language model so that we're not constantly pulling from the cloud. Um so th those are some of the conditions on the

product side and then on the system side you know some of the basic things that we uh there's like a an education scalability checklist VVOB and lots of others like Prumam and others worked on

this but you know the types of questions are political economy finance um etc. I mean, I think one of the most important questions is coherence, right? So, if you have a bunch of teachers that think

their primary mandate is to get through the curriculum and then you have an edtech solution that is tailored towards the levels and the pace of actually children learning and it slows things

down, now you have a teacher that's trying to get the curriculum and a product that's trying to slow them down. That's not coherent. And so those incentives need to change and those

expectations need to change. So that's just like one example. There's also lots of issues of like social norms, right? Where teachers are not new to this idea of like a new intervention is going to

be as they're they have to now kind of uh change their teaching practices slightly. They get new teacher training every year and multiple times a year sometimes. And new things are going to

be asked, new interventions, new innovations, and they're going to look around. They're going to look at their peers and they're going to say like, is this one

going to stick or is this just going to be another one of the like hundreds of attempts that has now been kind of dumped on the heap of of failed interventions? And so no one's going to

really go through the effort to just, you know, make sure that they're complying, they're learning everything they need to learn, they're they're they're using it to its full potential

because if it's gone in a couple of months because no one's paying attention, they're not going to do it. So anyways, I think these kind of like peer effects are quite important and

social norms. And so you need to be kind of building that momentum um for the motivation quite a lot. And that a lot of that is top down. A lot of that is uh grassroots. So I guess I'll leave it

there. So we still have time. &gt;&gt; Amazing. Thanks. Thanks Mark. Um so so maybe shifting gears, Professor Sharma, in in a different light in different part of uh the sector than than we've

been talking about prioritizing the foundational learning space. Um, can you maybe talk a little bit about anything that resonated with you here that you'd like to recap or anything um you think

is essential for um for your work when thinking about AI and education? &gt;&gt; Thank you very much John. So as uh introduced I'm a vice chancellor at a university which is a

government university Lakshai National Institute of Physical Education. We are into basically teacher education and when we are talking about AI solutions for teachers and I'm sure we are the

voice to be heard for the solutions to be created and hence this voice is here. So we are into teacher education for physical education teachers, for sports teachers, for yoga teachers, for sports

management solutions and other solutions what we are giving at our institution. But what takeaways from here is that yes when we are preparing teacher educators how much our teacher educators should be

integrating their teaching learning methodology their pedagogy especially while dealing a child especially while handling that child who is going to be healthy tomorrow who's

going to be an athlete tomorrow and that leads to the second point which I wanted to place was that we are looking for solutions. Solutions largely for those

who will be handling athletes and solution for those athletes who are practicing to be champions tomorrow because that is where solutions are required. An

athletes training program can be programmed. His daily progress can be monitored. His performance can be analyzed and he can be given a very good and a faster feedback if I'm sure

certain kind of algorithms are developed for them. So this was something which to do with athletes, something to do with teacher educators, something to do with the pedagogy and yes the very important

is about the impact evaluation which you mentioned. You see when we talk about preparing teachers I was just mentioning yesterday that our scorecards our report cards our nursery kids their report

cards has got two elements major elements one is the marks they give or a grade or a marks but the second very important thing is a teacher's register if you go back and I mean many of you

must be school teachers or university teachers here the school teacher takes all the pain to describe a child the whole year. I hope AI will be able to give that

solution because that those that is the personal connect of a teacher to a child. If that connect is not created, we are not nurturing the child towards

developing him into a human being for tomorrow. So that model may look little different when I'm talking what I'm saying but that's also much needed and I want to

give you a personal uh example here because I've been doing a lot of impact evaluation research for the special Olympics international. Yeah. So I'll take you to a remotest

city called Raj Samand is a small city in the state of Rajasthan. there is a school run by parents of a child who is a 98% cerebral palacy

I mean and that school is basically for deaf and uh deaf and dumb students it's a personal visit and hence I'm sharing uh my own personal experience here we had

gone for some data collection there and those parents were running that school and in that school there was a lady Rajasthan is a very conservative state overall. Buth that lady somehow managed

to a teacher now there is a teacher managed to come to that school regularly on a scooty putting that full gungut gunga do you understand? No [laughter] gungatist whale covering your face and

still driving that scooty and coming to a school and those children who were studying. I mentioned the WhatsApp here because WhatsApp was that medium where these

children were receiving messages from that teacher answering the queries and they were passing in the examinations. I mean these are the individual examples which you'll find more and very

sensitively where the teachers are engaging themselves in the benefit of our teachers. So I'm just bringing these points uh so that when we design certain more programs we have more inclusive

programs and we have more sensitive programs especially for the ages whom we are going to look 10 years down the line or 15 years down the line. Thank you so much for that opportunity.

So, so we have 45 seconds left. Um, so my closing will be briefer than I had intended. Instead of reading my actual closing, uh, so I had asked chat GPT to come up with some memorable lines based

on the closing I wrote. And so, so instead of reading the closing, you'll just get the memorable lines and you can decide if any of them are actually memorable. Um, one is benchmarks are not

about winners and losers. They're about making decisions that protect children and improve teaching and learning. Not terrible. Um, a second was scaling isn't just a bigger pilot. It's about the

system, not the product, which I actually really appreciate. And the final one in my last three seconds is the goal isn't AI in classrooms. It's better learning safely for every child.

[applause] We're out of time. &gt;&gt; Thank you. &gt;&gt; All right. Our time. &gt;&gt; Thank you so much.
