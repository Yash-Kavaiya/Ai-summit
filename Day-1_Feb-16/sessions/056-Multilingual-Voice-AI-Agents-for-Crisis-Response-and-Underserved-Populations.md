# Multilingual Voice-AI Agents for Crisis Response and Underserved Populations

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 12:30 ‚Äì 13:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 14 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/uPYN9MmBDg0?feature=share ) |

## üé§ Speakers

- Dr Laxmi Gupta, Bennett University || PhD‚Äì IIT Delhi.
- Sachin Keshav, INDUS AI // AIT - Pune
- Shreeyash Kanwade, INDUS AI // IIIT - Dharwad
- Vivek Gupta, IndusLabs AI // IIT - Delhi

## ü§ù Knowledge Partners

- Indus AI Private Limited

## üìù Summary

When floods strike, clinics overflow, EMIs slip, or civic systems fail, help exists behind apps, portals, and English menus. For millions, that help is unreachable. This session explores Multilingual Voice-AI Agents for crisis response, reaching people by phone, in their language, handling real tasks in real time. This involves no downloads and forms - just voice that works when systems don't, especially for underserved and vulnerable communities.

## üîë Key Takeaways

1. When floods strike, clinics overflow, EMIs slip, or civic systems fail, help exists behind apps, portals, and English menus.
2. For millions, that help is unreachable.
3. This session explores Multilingual Voice-AI Agents for crisis response, reaching people by phone, in their language, handling real tasks in real time.
4. This involves no downloads and forms - just voice that works when systems don't, especially for underserved and vulnerable communities.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/uPYN9MmBDg0/maxresdefault.jpg)](https://youtube.com/live/uPYN9MmBDg0?feature=share )

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

pivot your neck and participate. Um, okay. Please take your seat. &gt;&gt; Okay, great. Um, so thank you so much for joining our session, Whose Language, Whose Model. Um, we're really upset that

we are can't be joined by our facilitator, our main organizer, Marlina Wiznjak from the European Center for Not for Profofit Law. But no worries, we have an incredible session planned. Um,

and so to kick us off, my name is Aliyia Bhhata. I am the senior policy analyst at the Center for Democracy and Technology. We're a Washington-based notfor-profit nonpartisan group. And

today we have an incredible set of speakers who are really going to contend with this question of what does it mean um to build to to to foster more meaningful multistakeholder

participation in the development of AI really across the life cycle of AI when we're thinking about um AI systems from conception and design to development to deployment and post- deployment as well.

Um, and we're going to start us off with a few sort of provocations and thoughts from our esteemed panelists. Um, and then as I mentioned, sort of kick it off to the group to think deeper about

either ways we can foster that participation. Um, but also maybe initiatives um that in the room led by organizations you represent um to sort of learn and enable that sort of cross

sector collaboration. Um and um we'll also be inviting folks to report out after each of you sort of break out into this discussion. So please amongst yourself choose a few facilitators will

be joining the groups as well to sort of see these questions. Um but before we start you know why is this important? As we know, large language models and other AI systems are already being procured

and used and sort of deployed in multiple settings um in public and private spaces. Um but more often than not these conversations are being led and sort of um centralized in the global

north in industry or G2G government to government spaces and that loses out on a lot of very valuable expertise both from civil society um and sort of policy experts um but also a lot of experts who

are the most experts and people who are the most affected by the deployment of AI technologies. And so today we want to talk and spotlight a couple of initiatives that are bringing these um

these groups into the conversation. What are some of the considerations we need to have in mind when we try to foster this meaningful participation towards what end are we moving? You know what

what is participation for and how do we make ensure that it's not a box checking exercise? And then what are policy and regulatory approaches to actually incentivize or put teeth to these

efforts um by either giving uh more standards for companies to adhere to and model developers to adhere to but also um enforce some mechanisms when they um to en ensure that when they don't we

have actual means to um make them do so. Um so first I'll introduce our panelists and invite them also to give a more in-depth um introduction of themselves. Um to my right we have Jalak Kakar who

is the executive director of the center for communication governance at the n national law university in Delhi. Um, Jalok has written, co-written and also steered the development of a lot of

resources of uh, evaluating policy approaches to the governance of AI systems, but also thinking critically about, you know, sort of who are stress testing these claims of who these AI

systems sort of purport to help and in what contexts. Um and then we next to him next to her we have Vanraj Ther um who is the sort of inaugural professor professor um and director of the

emerging technology initiative at the George Washington University and I believe the George Washington University Law School as well. Um so Jalik I'm going to start off with you um to talk

us through a few of the sort of policy or regulatory approaches where we are seeing meaningful participation sort of come up um and what these governance mechanisms either through laws and

policy but also soft laws uh voluntary commitments etc. you know what do they incentivize how have they been effective and where are we left wanting more? Yeah. Um,

you know, in in any new space, there's always a trajectory of figuring out what is relative consensus and where can we start to build norms that then build into sort of voluntary

commitments, other forms of soft law which start to then get codified in the shape of standards, in the shape of regulation, in the shape of other sort of

international binding commitments and there's always like a process and trajectory to do that. I think um there's value in having multistakeholder conversations to start to build that

consensus. But if we look at uh past experience with say social media regulation, I think we stayed in the let innovation happen, we're building

consensus phase for too long. Um and I think there needs to be a cut off point where we start moving beyond voluntary commitments to more hard forms of law whether that's standards uh whether

that's you know um sort of um laws and regulations or even which which may not even mandate particular sort of outcomes but may mandate processes at this stage. Right?

What are processes you need to integrate into the design and deployment of these systems so that we are able to at least surface what are the kinds of harms and challenges uh that we are seeing because

if we don't make that shift over the period of the next couple of years from voluntary commitments into harder uh more uh structured forms of regulation we will sort of may see a repetition of

what we have seen with the history of social media where um you know platforms ran free. There was no mechanism to tr hold them truly accountable uh to these commitments that they were

repeatedly making in various forums and and we've seen the sort of mess that we have sort of landed up in because of that. So um yeah I think I'll pause here and then you know we can come back for

more. Yeah, I think that's a really good place to pause because I think um it's a good sort of where we've come from and now when we're trying to build towards a vision of more people to have a role in

the development or in the development of these new technologies but also truly saying when they when it doesn't work for them you know what does it look like to have the seat at the table I'd like

to bring Dhanj into that part you know what are some of the effective characteristics ics of meaningful external and multistakeholder participation. You know, what are we

talking about when we're saying we need to have a voice in the conversation and and who who is this we? [clears throat and cough] &gt;&gt; Great. Thank you. Thank you, Alia. So,

uh also thanks to the uh organizers to provide a space for this kind of discussion. Um so when we talk about uh meaningful participation and how we can uh

effectively engage communities in the design, deployment uh and evaluation around AI models, um I think it's important to recognize that this is a an issue a problem that is not new. Um in

the same way Jelik was referring to like lessons from the social media regulation world, there are lessons that we can draw from when you look at other technological interventions and how they

their practitioners and policymakers have sought to uh include uh uh wider communities, targeted communities and so on in these questions. What ultimately emerges though when you look at these

past lessons is a question about power. It's a question about the distribution of power. When we talk about part participation and collaboration and building partnerships with communities

with different uh constituencies, we're in effect talking about how powers are distributed and what kinds of decisions are made made by who. Uh for a long time when you look at the the field of

international development and uh how countries in the global south or the majority world would put in place different kinds of development projects. What emerged from that those kinds of

lessons uh was characterized by a scholar named Chambers back in the based on his work in 1890s is in the supply chain in the thought proc process putting them first starting with their

needs and their concerns. That can ultimately mean for example communities, target groups defining what technology use cases are best for them which is the reverse of what we see now where

frontier model companies uh deploy models with the idea of um let people figure out what the use case is best uh for them um after the fact or evaluations after the fact. Uh another

thing that uh emerged from a lot of that work around effective community participation is recognizing that communities actually have a lot of expertise uh to to analyze their local

context and understand what's really needed. Uh and so when we think about the development of language models for example, how they're developed, what kind of specific contexts, what kinds of

uh linguistic uh uh concerns should be included in development of these models. um that is often where that kind of analysis can can lie. So uh that's kind of a high level but I just wanted to uh

bring bring in this issue that there's a lot of uh debate and research around this kind of uh what are the mechanisms for effective participation that precedes AI but we can learn from that

uh without necessarily needing to start from scratch. No, I think that's really helpful level setting to begin with because I think sometimes in the AI policy conversation there is a lot of

ahistoricizing going on of like acting like the development of these technologies necessitate is you know so complex and like uses this new jargon and

necessitates only technical experts in the room. Although we've been here before, we've built other sort of incredibly complex privacy enhancing technologies, for example, with

journalists and human
