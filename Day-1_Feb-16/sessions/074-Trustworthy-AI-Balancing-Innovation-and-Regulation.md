# Trustworthy AI: Balancing Innovation and Regulation

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L2 Audi 1 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/cNRPvHuOmZM?feature=share) |

## üé§ Speakers

- Caitlin Searle, Australian High Commission
- Inderpreet Sawhney, Infosys
- Mariagrazia Squicciarini, UNESCO
- Mr. Syed Ahmed, Infosys
- Suvendu Pati, Reserve Bank of India

## ü§ù Knowledge Partners

- Infosys Limited

## üìù Summary

This panel will explore how innovation and regulation can evolve together as artificial intelligence advances. It will examine trust, transparency, accountability, and responsible development, highlighting how these principles may encourage sustainable, human-centric AI adoption within an increasingly interconnected ecosystem.

## üîë Key Takeaways

1. This panel will explore how innovation and regulation can evolve together as artificial intelligence advances.
2. It will examine trust, transparency, accountability, and responsible development, highlighting how these principles may encourage sustainable, human-centric AI adoption within an increasingly interconnected ecosystem.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/cNRPvHuOmZM/maxresdefault.jpg)](https://youtube.com/live/cNRPvHuOmZM?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

ing innovation and regulation. Well, the topic sounds really beat up topic, right? Nowadays, everyone is talking about uh trustworthy AI innovation and regulation. But what we have is a

amazing panel which is representing industry, representing policy makers. society and regulators. So if someone can actually throw or shed some good light on this topic, it is going to be

this particular panel. So um my name is Syad Ahmed. I'm global head of responsible AI office in Infosys and it's a great uh privilege and honor for me to um

welcome this uh amazing panel. Uh in this panel I have um Ankor Ankor Singh um who is um from Fintech department in the Reserve Bank of India. Maria Garcia she's um a good friend and represents

UNESCO and Caitlyn uh from Australian High Commission. So very quickly um before we get started you want to very quickly introduce yourselves before I anchor

&gt;&gt; uh hello everyone I think you have already introduced that much is enough. So I work with the fintech department of reserve bank of India. The department is responsible for fostering innovation in

the financial sector fintech as well as working with the emerging technologies. So Maria Graces Cucherini from the social human sciences sector at UNESCO and actually UNESCO perhaps most of you

don't know because you know very well the work we do on culture for instance and the cultural heritage locations but we do a lot of work about the ethics of science and new technologies and so

UNESCO has been concerned about the ethics and I'll explain later what we mean by that of uh artificial intelligence to the point that we issued in your country in among other 193 adop

adopted the UNESCO recommendation on the ethics of artificial intelligence that has informed all the work we've been doing so far. So we'll you'll hear more about this.

&gt;&gt; Thank you. &gt;&gt; Uh good day namaskkar. My name is Caitlyn. I'm with the Australian government team in India. I've been here three years. I manage the Australian

government's relationship with the science and technology agencies like matey department of science and tech biotech. Uh I'm a public servant long time about 15 or 16 years in a

regulatory role in a policy role never anything to do with AI. I will just take this opportunity to plug that we have some amazing Australian experts in and around all week um around AI science I

AI safety and we also have a trade delegation here. So um I will do my best on this panel. If you want detailed uh sort of discussions, I would very much encourage you to visit the Australia

booth in hall 14 this week. Thank you. &gt;&gt; All right. Thank you everyone. Kathleen, maybe I should start with you. Um let's start with little what I call as icebreaker questions, right? What is

the most ordinary almost boring use of AI that you typically do? &gt;&gt; Uh well, as I said, I've been here three years. I love India. I travel a lot. Um and it sounds very very simple but the

you know the Google um autoc collage images um my first couple of months in India I'd go away for the weekend to the Taj or to to Kerala or something and I would

waste hours trying to filter through very average photos that I've taken and now it's just this timesaver top 10 photos please from my weekend away in uh Arunabad love it

&gt;&gt; have you photoshopped your photos with Taj Mahal or any other &gt;&gt; not quite yet I do I do like the Auto corrections. &gt;&gt; Auto corrections.

&gt;&gt; Auto corrections. A huge timesaver. And I mean, full disclosure, I don't think anyone back in Australia thinks I've done it. Like, it's they know I'm relying on tools, but it's a huge help

and a huge timesaver. And it gets those amazing photos that I'm constantly asked for to Australia very, very quickly. &gt;&gt; Okay. Have you inserted yourself in a photo that was not taken originally?

&gt;&gt; No. &gt;&gt; Using AI? &gt;&gt; No. No. And I I could I would never do that. &gt;&gt; The photos are nonetheless. I take your

responsibility. &gt;&gt; I do have to keep reminding myself to turn off the, you know, the WhatsApp group photos that collects in your storage bank. And so all of a sudden I

have this image of amazing collage and one or two photos I have no recollection of, people I've never seen. Um, so but that's on me. That's a that's a default I have to fix. But that's the only

hiccup at the moment. &gt;&gt; Good. Thank you. Thank you for that. Maria Garcia you spoke about UNISCO being custodian of culture and heritage and you also spoke about a lot of AI

that you work you are doing few weeks ago there was this incident of um open claw malt book and malt bots coming in within a week they had their own uh language that humans couldn't

understand it was a social networking site that was created only for um agents humans couldn't join the social networking site but we could read all the postings that were happening on the

um site that was uh there. Now within a week they came up with with their own religion, they came out with their own language, their own jokes and they started posting on their um problems and

things like that. You are in a very unique position in UNICE. If agent starts building their own culture, new language, norms and all that, would UNESCO step in to protect it

as a digital heritage? Well, actually UNESCO always steps in. Now whether we would protect it as cultural is just a different thing that comes typically from the countries

asking to support things. But let me let me underline one thing that I think is the beauty of the recommendation that UNESCO adopted in 2021. And is that the principles that were in there apply to

any type of technology as it evolves because we all know uh what AI was three years ago is nowhere anywhere near what we see today. and our digital natives that we hear here in the room actually

will know a completely different type of AI in the future. Now what was smart of the experts that informed the recommendation and then of the countries when I adopted it is to uh have a

definition of artificial intelligence which was actually related to the key components of it without having a very strict definition and having principles and informing policy areas which are

actually 11 in the recommendation which are always valid. So the principle you were mentioning implicitly the redresso if things are wrong who does what? Where is the mechanism at stake that actually

will allow anybody that is actually suffering for instance from whatever wrong done by AI for that to be stopped and be for instance compensated the human oversight you didn't mention it

but I mean we countries agreed for the good of people for the good of any individual that the last word should not be with a machine also because machine are as intelligent as those that program

them in the back. Let's never forget that. So even if now you hear a lot of things even by the time agents for instance kick into the picture we were when we were just waiting to enter here

I'm so happy to see so many people interested we were talking about the fact that agents have been with us now for perhaps more than a year in the bulk right and we were expecting the agents

to explode agents you to explode. Has anybody given a thought about perhaps the language between inclusiveness of AI and agents pervasiveness? I don't think sufficiently because I think all of you

use this uh speech to text uh facilities you have in your computers in your phone. How many times it goes wrong writing because your accent I'm Italian you can hear it by the time I speak and

perhaps I speak even fast. So the machine has an issue with that. And then so by the time you think about languages that are not really leveraged in AI and therefore cannot be really understood

well that's one of perhaps the caveat that links the lack of use or the lack of explosion of AI to what can be done because if the idea is that I have to give a command a vocal command to the to

the agent and the agent we don't understand each other we are like in a couple where one speaks and the other doesn't listen so it's not going to go anywhere and this is Why we say we keep

saying in UNESCO and I'll close it here on this point that inclusiveness does not only benefit the included. Of course it does. I'm a woman. We are less than represented in the AI world. But it

doesn't benefit only me because that enables better AI to be developed. The algorithm perform better. The algorithm can also seize a greater market uh share and they can overperform others that are

inferior. So I think this question like innovations versus regulation, innovation versus policy steering and frameworks is put in the wrong way. &gt;&gt; Okay, I will try to reframe uh when I

come back to you. But um coming to Ankor, Ankor, um again there's still a um you know icebreaker question. So I I will ask you this. There is so much of talk about autonomous AI agents. If an

AI agent were to walk into RBI asking for a loan, will it get it? And if it gets, what are the risk parameters that you will assess it with? And um what will the interest rate be?

&gt;&gt; Okay. So, sorry to disappoint you because if an AI agent walks into RBI, we will say no because RBI is not into lending. &gt;&gt; That's a smart one. Yeah.

So we don't need to assess any creditworthiness on that fund. But yeah um I understand your question in the way that uh agents are getting you know more and more integrated into the workflows.

Now a lot of banks are using agents in the back end. But there would be a time when agents will represent people entities who would you know probably uh pursue a loan application go visit a

branch not physically but yes of course through the APIs and they will initiate an application on their behalf. So the way I see it there's always you know like she said there's always a

person associated with the agent. There's always a person at the back. So you cannot uh say that okay this particular agent I need to assess. You always have to assess the entity the the

person who is applying the loan and the same process will continue to follow. This is what I feel you know the same process that we are doing right now the credit is creditw worthiness will be

assessed of that particular entity and individual how we can use AI to assess that you know we can always use alternate data we can use the behavior of a person how is

the you know repayment behavior how is the payment behavior all those aspects can be taken into consideration they can be modeled and agents can then take the task ahead but just the agent. I'm you

know it's probably like Terminator walking into your room. No, I I don't think so. We we we are you know the sentient being. We're not there yet. uh but in case if at all in in a future

something like that happens then we will have to assess the how you know how explainable a particular model is or how auditable a particular model is how accurate a model is and then on that

basis you know you'll start assessing okay this particular model deserves something or doesn't deserve something &gt;&gt; okay uh I have a follow-up question on that but I'll come back to you I mean

when I come back maybe um I'll counter that um and would be very interesting to hear your views on that. But here is the thing we we heard all the panelists and um um the thing about trustworthy AI and

this particular panel is they represent all different um you know walks of life um the policy makers the regulators the society so in your words um if I can start with you um everyone has different

vantage points and perspective from your perspective what are the key non-negotiables when it comes to um trustworthy AI I I mean I'm sure we've sort of probably

touched on several of those principles already. To add a new one more explicit into the mix. I guess that sense of transparency as a government trying to understand what the risks are, trying to

protect their citizens from harm, trying to encourage industries to be competitive and don't miss the boat. Like that's all the considerations we need to take into account and balance.

And so that transparency is a big one for us. How do we make sure um uh people understand can engage with um understand the risks so that governments and others are prepared to mitigate them or to

prevent them. &gt;&gt; So transparency goes hand in hand with um being able to explain explanability as well. So &gt;&gt; absolutely

&gt;&gt; yeah very interesting. Well, trustworthiness for UNESCO is one of the components that need to be there. That is also because we try to hook what we mean by ethical to human rights in

the language of UNESCO. What countries have adopted is actually meaning that AI needs to abide by human rights, human dignity, so human always at the center and fundamental freedoms. and trust in

someone is a component of it but in our idea it's a subset of it because then there is and the ethical principle the way of uh creating developing using implementing deploying AI systems and I

underline AI systems and not the technology itself only because we often forget that things might go wrong by the time systems go in the wild that is you have programmed whatever algorithm you

have tested you have designed it the best way you can taken into account perhaps all the particular facets of the part of the population it's supposed to abide by but then by the time you go and

you deploy it in reality that's when things go wrong now what amazes me at times is that if you think about a car and you think that you won't have any post sales service you wouldn't buy that

car right because it's like well if I'm in the street and I get stranded what way I do well you will be surprised that in majority of AI systems they are created with all care perhaps and then

by the time they go deployed in the wild tested in the wild there is very often lack of post sale or post deployment type of follow-up and that's the moment in which things can go substantially

wrong. So in our mind trust and trustworthiness is a really key aspect because I need to trust the technology also because let's remember one thing that is AI algorithms and the quality

thereof as one of the important component in it is data and the quality of the data themselves. Now if we users start saying no no no to many things by the time we interact with the AI system

the data that the AI system is able to gather is patchy by brute force because it will know for instance I'm blonde but they wouldn't know that I'm tall x cm or whatever my weight is right and so we'll

have a very partial idea about me as an individual and as a matter of fact if we put that then a scale with all the people that go and that enter the data then the data in the back that are used

for AI are actually patchy and need to be fixed which means the the likelihood that the predictions that the system are able to deliver are actually inferior and might go wrong more often so there

is also the issue of bias that is very important to the trustworthiness of the technology &gt;&gt; absolutely I I think you put it very nicely if you're able to trust the

technology trust the AI will adopt it and for you to be able to trust it you need to do a lot of things transparency, explanability, bias, everything. It's it's mother of all things that we need

to do to be able to trust the technology, right? Yeah, &gt;&gt; absolutely. It's it's not about one thing. It's it's a set of components. Sometimes they say, "Oh, there is this

that is available, the other one not, but it's okay." Well, no, with AI, you need to have at least a bit of everything for it to work. &gt;&gt; But it's actually something that helps

the technology itself and helps deliver for the people. And I think you put a very important question before that is about where do we have to watch out for well I think in order for any technology

this applies to AI but as applied to any other technology in the past in order to have technology bloom innovation to bloom we don't have to decide what do we want the technology to do because that

is left really to you know the creativeness of the scientists that are in the back etc. We nevertheless need to agree on what we surely don't want the technology to do because that's about

ensuring our rights and putting safeguard the fundamental freedoms and what it defines us as people and as human beings. &gt;&gt; That that boundary is quite important

ankor u I'm sure you will start with security but go ahead. No, no. I mean uh so when it comes to trustworthy AI especially in the

financial sector it needs to protect the system as I mean the entire financial system the sector is based on this trust. You deposit your money in a bank account and you trust that money will be

there but the you know until when you're going to take it out. What happens if you if you have an agent and you have no idea that what you know that agent is probably debiting your account

depositing in a crypto wallet or something else you know trading and then the money comes back to you it can be you know it's the same amount at the end of the day you feel that okay it's the

same but some activity happened with your money at the end of the day it's going to be accountable to you so if if AI has to be trustworthy AI has to follow what you want AI to do. Even an

inaccurate AI can be trustworthy in in my opinion, personal opinion. See, imagine a 90% accurate AI can be trustworthy because you know that 10% of the time it'll fail. You're aware about

that. But if I if an AI starts claiming that I am 100% accurate AI and is lying to you in a way, you know, hallucination is the biggest challenge because when it hallucinates, you don't know. It doesn't

tell you that I am wrong. Saying that I am wrong is still fine. But giving you an inaccurate answer, doing things on your behalf in an inaccurate way. That is where the trust goes.

&gt;&gt; Yeah. Quite interesting. Absolutely. Um totally agree with you. Let me shift gears a little bit and um I'll come to you uh Caitlyn. So sometime last year u in October

Australian government published um guidance for AI adoption which outlines six essential um practices. This actually simplifies the 10 guardrails that we had previously on voluntary AI

safety standard. What was the vision behind this and um how do you see this playing out? &gt;&gt; Thank you. Um the Australian government is um been one

of the early movers when it comes to ethical AI. I think we were one of the first um to develop a to to publish a set of voluntary ethical standards I think back in 2019. And since then it's

really been this um uh conversation with the Australian public. This is how the government phrases it. We don't want to rush into things. We want to get things re right. We want to have um our experts

develop these voluntary principles, guidance, adoption, those sorts of things and test them with industry. My home department in CRA in Australia is the department of industry, science and

resources. So it's a mega department. If we compare it against the Indian system, it's sort of combined commerce, matey, science and tech, biotech, ISRO, inspace, heavy industries, minds,

petroleum and probably six others. Mega department, but I think core to it is that industry function and our people go and engage with Australian industry. How can they be competitive in a globally

competitive environment when we're sort of down under? We we we let's face it, we're the ass end of the world. You know, distance is difficult. Like we need competitive companies. So part of

our core function that and I think that is really sort of bleeds into the approach we've taken or the Australian government has to taken is is to developing these guidance and adoption

tools because we've tested them with industry. We've said some of these things are voluntary. We've sat with experts and said how does this work? We know that supporting adoption in a

responsible way is key to competitiveness, but it's also key to our broader responsible AI toolkit. It's all this systems thinking. Um, so that was a great development uh a few months

ago as I said earlier um toward the end of last year and of course in December two or three months later we released the national AI plan of which that keeping Australians safe is a is a one

of three pillars of that. So um this is very good um initiative and um it is voluntary even now. So um is there any roadmap towards making it mandatory or regulatory in nature? Not

it &gt;&gt; not quite yet. As I said this conversation with the Australian public industry all sorts of stakeholders getting that feedback testing things. I

think the broader approach as I said over the last couple of years and we're seeing it in all countries is we said you know the technology is moving so fast. How do we develop a framework, a

governance framework that can respond to these risks nimly but also without impeding innovation? So, we are watching this all the time. We're setting up our own Australian AI safety institute

that'll start operations in the next few weeks hopefully to sort of embed those capabilities in the Australian government to better track and monitor these things as well and then go to the

policy makers and the regulators and see what needs to happen or what do we need to tweak. &gt;&gt; Okay, very nice. Um my next question is Maria

Garcia. So we actually met a couple of years ago in um a very similar panel and at that time I was very um you know um advocating our framework that we had the ethics framework and I was trying to u

convince everyone saying that there's the greatest and that time you did convince me saying that why will anyone pay to use your ethics and your frameworks or for that matter any kind

one countries. So um you are way ahead and um um UNISCO was um one of the first to come out with um a ethical model which is kind of agreed by more almost 200 countries now right so um and it was

not only the kind of um the preachy work that was there you did go ahead and um create this um um practical governance tools like um readiness assessment methodology RAM um and then global AI

ethics and governance observatory What is the philosophy behind this and um are you seeing the support that you that you expected when you started? &gt;&gt; Yes, it has been a lot of work but we

were very happy to do that. So the logic is very simple. Um I mean whomever is in a decision- making position very often you hear like oh you should improve this like for instance if you're the minister

of labor say oh it would be good to improve employment by 3%. And then nobody tells you how, right? So you're left with these fantastic thoughts that everybody agrees that that's the way to

go. But then how do you go from A to B? That's a different question. And this was very clear by the time we were discussing the recommendation on the we needed to have in the recommendation

itself not only a clear idea of the components that need to be at stake and these were frame framed in the context of the 11 policy areas to which this recommendation applies from education to

privacy to data but fundamentally and that's actually what you asked me before that is about culture the environment and gender because these are three things that are given for granted But in

the air space cannot be given for granted. And then the idea was like countries were like okay very nice. These 11 policy areas these are our principles. These are the values that we

are agreeing upon. How do we go from you know principle to practice and that's exactly what we did. So [clears throat] sorry we were asked to compile two instruments that could help them then

implement the recommendation at home. One is the readiness assessment methodology. And actually I'm really pleased and proud to say that we are going to launch the India one this

afternoon at 3:30. And uh this basically is an approach. Thank you. Well, the credit goes to the colleagues here in Delhi that have been working on

this and all your policy [clears throat] makers that have been involved in this. The idea of that analysis is to give you a snapshot of where you are in terms of endowment of infrastructure, human

capital, uh institutional setting, coherence thereof, legislation that exist, components that need to be at stake, for AI to be able to actually serve societies and for agents public

and private to be able to use and leverage AI in a way that is really ethical. Then we were also of course we are fully aware that even if we were early in the game of AI like our

countries were starting to discuss to get the recommendation already in 2019 and I mean Australia of course was also around the table but you need to you know that AI is always in the making and

there are already algorithms that are out there and systems that are out there and so we developed what is called the ethical impact assessment which is a tool that actually says regardless of

the stage of development in which an AI system is we have to ensure that you know the outcome the deliverable is actually complying with human rights, human dignities and fundamental

freedoms. To date we have 77 going and we have discussion with other four countries countries member states that have gone through the ram they either have finalized it or they are starting

now or they're in the process of completion and what have we learned from that were a lot to start with that that there is no such a thing as the best practice forget about that nobody even

those that have done AI for a long time the whole set right so there is a learning for everybody from the analysis done in each and every country and that's why we keep pushing for everybody

to go through this and we are very convinced of evidence-based policym in the sense that unless you nail down first of all whether there is a problem and which one it is and how you define

it and what are the components then solution can be worse than the problem itself and that's why we think the RAM is very important to tell countries these are areas where you might need to

improve and to offer them possibilities is based on analysis done in other countries that perhaps have that very problem sorted out in a way that is compatible with your system with your

approach and actually Ky was mentioning it before and then we have to pay attention to an expression that is a bit complicated to say but actually is very important in

practice that is regulatory inter link you the fact that it can be link linked to each other or can be actually uh used in a setting that is multilateral because AI is a technology that doesn't

know any boundaries and therefore if we start putting settings and frameworks that actually speak only to a local type of setting it means that in reality your business your users will face a number

of problems because every time they will need to go elsewhere they will need to adapt and adaptation costs actually can raise the cost of the technology itself. Um I have a follow-up question on being

a multilateral um AI but I will ask that a little later. Um but I have a comment to make um on RAM um um it is not something that is air dropped suddenly right now right I mean I know that you

have been touring across the globe um evangelizing this for quite some time and um yeah and this is um more than a year now. &gt;&gt; Yeah it's much more than that. The RAM

was ready actually already in 2022 and so we started working and UNESCO as uh priority this is called priority area so we actually started very soon with the support for instance of Japan countries

the McGovern foundation that I'm happy the president is here today with us the European Commission that actually supported us to perform the runs even in countries that wouldn't be able to

afford to do the the the the activity and then we constituted two groups one Some of them actually an initiative you mentioned that is the observatory that is by the time we create knowledge that

knowledge to benefit society and humanity has to be shared. So that was one of the principle but then of course in order to understand better the context of the rams we needed to also

work with local experts and bring experts from other places because the nuances are many. You need economists, you need IT specialists, you need lawyers, you need regulators. And so we

have created this expert uh of AI without borders, ethical experts of AI without borders. The idea being of having people that are knowledgeable about what ethical AI means and the

specific aspect that may be a stage a stake for instance a regulation on data for instance and be able to be deployed in a country that has realized actually needs to address that shortcoming and be

able to do it in a swift and in a way that is actually enabling this um this ability to advance and also avoid to some extent mistakes done in the past because Pioneers might have advantages

because they are first off to develop something but very often they risk you know not doing perhaps the perfect thing or the best thing that can be done because it's an exploration phase that

may or may not be successful. So also to learn from the good things done elsewhere but also by the mistake thus avoiding them. &gt;&gt; Excellent. Thank you so much Ankur. I'll

come back to you. I did say I have a follow-up question on um the agent securing the loan. I'm still able to get my head around that. [laughter] &gt;&gt; Now, you did say that you're not going

to govern the agent. You're going going to govern the human behind the agent, right? So, you're going to look at the creditworthiness of the human. But when we are looking at autonomous AI agents

and the skills and all that, same agent can represent multiple different humans and there is so complicated mesh that is out there. Um how being a regulatory body um what is the role like for

supervision of these autonomous agents accountability consumer protection that you know the agent is acting only on behalf of a human and not otherwise not other rogue agents and things like that

have you considered this and see we did lead um the world in digital payments right with the UPIs and others so do you think um in the so-called the agentic banking model kind of thing um are we

already thinking and is is this something that we can also take a lead &gt;&gt; take lead? Yes, of course. Why not? &gt;&gt; Uh and we should now the thing is uh the way agenting models are going to evolve.

We'll have to see. Backend agents are going to be extremely useful for banks. You know, uh take an example of a fraud prevention agent. uh in the back end it's analyzing the fraud

the transactions that are happening and if it detects a pattern which may be fraudulent it can block the transaction it it should not let it go through unless it is specifically authorized by

you know by the person who is initiating the transaction so the we can use agents in a preventive way customerf facing agents are also going to come into the picture we we are seeing examples people

are building their agents right it's not that difficult these days now what will happen you cannot But so you know when we when we envisage authentic AI it is not a sentient being it's not going to

take a decision on its own in a way uh you know unless and until you have defined the specific seat the specifics have to be defined by the person if he says that I want to secure a loan say

maybe top five banks or you know the best interest rate that is available quantum should be between this range and then there would be certain conditions attached to It's not going to just

assess oh you know uh my bank account is going down uh it's it's below a certain &gt;&gt; but the thing is the agents will learn over period of time they know exactly your behavior they are going to give you

exactly the same data that will ensure that you approve the loans right &gt;&gt; so the thing is what will happen I mean human has to come into the picture somewhere right that that that is the

key you cannot let the entire thing keep on happening through an agent. Human has to come into the picture somewhere and that that human in command is going to be key when it comes to agent AI and of

course there would be other aspects I mean we have uh you know defined certain principles uh in in the free AI framework that we have developed and those principles will be applicable to

agent AI as well you know &gt;&gt; okay all right um so I'll actually ask the next question also to you this is also on the trustworthiness of AI uh when it comes to regulatory bodies. So

I'm quite intrigued to understand how you think. So today everyone is saying whatever they're doing is AI and everything is AI powered this AI powered that and we have AI. I mean there is a

deep AI washing prevalent everywhere right and how do you protect consumers around this? I mean um have you thought about um some kind of regulations here some kind of um enforcements?

See again I mean uh so as of now the principles uh and trust is the cornerstone right? So so the principles the that's why the first principle that we identified was trust as the

foundation and yes there are certain entities where this AI washing is going on. So uh you know I think the most appropriate way should be a proper disclosure. Any entity which is using AI

or deploying AI they should disclose it. It should be disclosed to the person &gt;&gt; voluntarily. &gt;&gt; Voluntarily. &gt;&gt; Okay.

&gt;&gt; And and you know it's recommended in the framework itself. Now if as of now it is a framework it these are recommendations. There might be guidances coming as well. And then uh

you know we'll be keeping a check that who is declaring who's you know what disclosure are being made. Uh there's also a recommendation that disclosure should be made in their annual reports

as well. you know so that people are aware that what uh kind of AI and in which form you're using AI and it's not just uh it's not just a buzzword it shouldn't be a buzz word people say that

okay so so you need to you know there's also this thing each and every entity should create a repository of models you know and and they should clearly define what model is meant for what purpose

what is being used in that and that repository supervisors can always go and check that Okay, you say that you are you have these many models in place and the know whether it is actually there or

not there. So these are the ways in which we'll have to do you know we'll have to protect consumers as well. And another way in terms of supervision would be using AI itself to supervise AI

isn't it? I mean that that has to be the way going ahead uh probably you know uh if if people have their own agents we should have ours. So these are the way in which I and vis that uh that we we

would be going about this this AI washing as well as AI deployment. &gt;&gt; If I just may add on the the transparency and explanability point you were making. I think sometimes it is

overstated and other times is understated in the sense that we as users we don't really need to have the codes open also because frankly I wouldn't have a the time b the

willingness three the skills to be able to analyze it. But what we need and that you made that point very importantly is to understand what is the logic behind it. what are the principle that guide

that algorithm to behave in the way it behaves and then to be aware in the first place that that algorithm is there and that I've been facing an AI um agent in some cases and also and I can't agree

more in the past we have heard so many times oh but you know by the time the algorithm is out in the wild we cannot redress it we cannot it's very costly to fix it's very costly to stop well we

have generative AI, we have synthetic content that is algorithms that are beautiful at coding. So I sincerely continue not to understand the fact that it becomes very very costly. It's true

that with agents is slightly more complicated slightly but it is true that we can use AI to check on AI itself by putting you know parameters by putting checkpoints the

frequency the type of things that can stop the other. So actually the possibilities are many. It's just the determination the human oversight that needs to be there

&gt;&gt; and and probably that is maybe only way to do it using AI to supervise AI. But only question remains is who will supervise the supervisor AI, right? &gt;&gt; Still a human [laughter] still in our

hands needs to be. &gt;&gt; Yeah. Uh there is no audience question right now. I'll come back to you in the end if I have time. Okay. Sorry about that. Sorry.

&gt;&gt; Yeah. &gt;&gt; Okay. All right. Um so get Keline maybe I'll come to you now. So see we operate at the end of the day you did um mention saying that we need to be

in multilateral kind of um AI adoption. Many countries are taking totally different approaches. Um um there are few heavily regulated on AI like EU. there are few where um we only have

sector specific rules um like in US and um Australia has this guidance and um guidelines that um now you have published and all that. So um question is how is Australian government

coordinating with international partners to avoid fragmentation? &gt;&gt; Thank you. Um and you know it's the recurring theme isn't it? Um as you said Maria this technology doesn't have

borders. Um, as I said, this has been a multi-year conversation with the Australian government. We know lots of other governments are thinking about things as well. Inherently, our national

frameworks have to reflect our national context and habits and the risks and um, as I said, one of the three pillars of our national AI plan is keeping Australians safe. So that factors in

that what are the Australian situation and what's the framework that works for us. So to a certain extent, there is something unique in that for every country. But of course if every country

does their own thing and things are vastly different it undermines all of our efforts and it certainly undermines that innovation and competitive point uh which I made earlier. So it's really

important for international discussions like this for governments to get together and talk about like how do we embed those really important principles and norms around trustworthy

and responsible AI. Um certainly a discussion on like uh the Australian government's international engagement in priority multilaterals. How do we influence those discussions? How do we

influence global norms? How do we influence global standards? That's uh an aspect of our national AI plan as well because there's certainly this um recognition that uh it's inherently

global and we have to contribute to these discussions. We have been um as I mentioned, you know, involved in the earlier discussions around ethical AI. We've had

uh representations at all of the summits in this series to date. It's one of our priorities. That's why I said, as I said, we've got a large and very diverse Australian contingent here today. We

continue to um engage constructively in those key multilaterals, those internationals. We also progress a series of bilateral engagements. I know this sounds all public servicey now, but

of course we have key uh bilateral agreements with our key partners as well as we try and really try and embed those global norms so that all of us can benefit from um AI and its applications.

&gt;&gt; See um you have been referencing this national AI plan and um the pillar like keep Australians safe and one of the key things that uh came out of that was um establishment of um AI safety institute.

So now AI safety institute is um going to play any part in bringing all the u parties together or &gt;&gt; it so the um uh national AI plan I keep talking about is only a few months old

that's new but the commitment to prospect of a safety institute um is is is not so new um and of course as I said we've been involved we signed up to the soul declaration we we've been engaging

in those international safety discussions our Australian AI Safety Institute. It has an acronym, but I will not use it. Um, it's not a good one. Um, AI, I don't

know yet. Haven't worked it out yet. But, as I said, that's a couple of weeks away from starting operations. The government has announced funding for it in um, November. Recruitment is well in

train. We have an incredible AI um, R&amp;D base. We have some incredible experts. I'm sure one or two is in the crowd. I just can't see them. And so we really want to use this institute to embed

those capabilities, testing and monitoring of frontier models, getting guidance out to community industry experts. Um, which as I said comes back to that sort of trustworthy toolkit,

that broader governance framework. But yes, that Australian AI safety institute will um continue to to engage with the international network sharing of best practice and expertise and science.

&gt;&gt; Interesting. Thank you. Thank you very much. That brings me to you. I I think UNISCO is again taking a leadership position in bringing everyone together. There was this uh collaboration with G7

on public sector AI toolkit um to ensure that you know there is international alignment on trustworthy AI responsible AI. So do you want to talk about these initiatives on how we

can bring the entire world to align on uh you know how to govern AI? Well, governai is a it's a a daunting task, but we try to do our part in trying to align to really make it interoperable.

That's the the kind of the rude word kind of that I was trying to avoid governance system and we believe that yes regulations are important but they are not the only policy tool. So there

is a whole set of policies that can be used in order to ensure that AI is done for society and what UNESCO does is really to try and leverage each and every occasion to get let's say a

coordinated approach to the problem because of this the fact that it's a resource and can be a challenge for humanity as a whole not for a part thereof and of course we are fully aware

and we try to put first in the front also the needs of you know people that are vulnerable or people that are for instance in certain conditions but we really try to have also for instance not

only AI be and our counterparts typically are governments the first one although we do operate in a multistakeholder environment and that's how we met for instance but the idea is

really to also help uh civil servants be able to leverage the technology for good now how you do that well with awareness raising with endowing And again the toolkit we are really there to go from

principles to practice. So give handson type of um input type of uh information that can be used in a day-to-day basis in order then to be able to leverage AI for the good.

Like for instance uh by the time we have supported the presidency the G20 presidency of South Africa in 2025 we have developed a toolkit to address the possible inequalities related to the use

of AI. The question is again yeah it sounds obvious but then the question is how do you do about that? So for instance we have in that toolkit even very concrete examples about for

instance applying AI in the health care space where we realize that many of the algorithms that are built are built by uh information specialists that have never spoken to a doctor. So something

as simple as telling civil servants you have to put around the table by the time you are in the design phase a multistakeholder approach whereby anybody that will be involved and could

be made even responsible for what is done is there to learn and tell and also share aggravation. Like for instance uh everybody was finding obvious that it should be leveraging a number of piece

of information. How many hospitals records speak to each other? &gt;&gt; So of course if we don't have that very simple thing in the back and you don't address that then the design of the AI

as powerful as it can be risks being biased because you don't have all the information. I'm a woman and typically data about for instance heart failures of women are completely wrong. One

because they are under reportported and two because the symptoms typically are mistaken because the literature is based typically on men and of a certain origin and uh and color as well unfortunately

which means that by the time I have a certain pain a lot of doctors and hence also the AI will not be able to to identify that I'm going through uh a heart problem because

it doesn't correspond to the usual that the literature has you know gathered as pieces of information and on which that algorithm has been built. But this also translate into very practical

suggestions for who is going to build the system, which kind of data, which kind of part of the population, how to test the design, how often to make checks, what the system might be able to

do in reality and what it shouldn't be used to. and what you said as well, what is the error margin that I'm willing to accept or which I should be aware of so that there is always the human oversight

that allows me to actually intervene promptly and as needed. So this is the idea of having these very concrete tools but also to have harmonization in the approach because that allows us to

improve better, improve faster and address key bulk of problems that are actually very much widespread and that too often we we hear like oh but you know we are different. Yes, we are

different with nuances and so we can solve a lot of problems by taking approaches that apply in a flexible way to different contexts. &gt;&gt; Excellent. I think that consultation

with everyone and getting everyone together is um the key and I think that's a similar procedure that you followed. You have been mentioning about this free RBI's free AI framework and

all that. I do remember um consulting with industry and thank you so much. Um you have called out Infosys's responsible AI toolkit in the framework but I think that is the key um of

ensuring that um you know the consultation and getting all the people uh together and agreeing to what we do. Okay. All right. Um I've been uh shown time uh saying that I have very few

minutes left. So one last question to all of you, one common question. Um um it's been really amazing and a pleasure. What is the one thing that we have done right in last two years and what is the

one thing that we need to do going forward? Maybe I'll start with you. &gt;&gt; Okay. One thing the right thing that we have done is uh digitization I guess. &gt;&gt; So you know we have digitized a lot of

process. We have a lot of data available which is going to be useful uh when as and when AI comes into the picture and uh we have been using this digitalization in inclusion. It has

supported it has helped our cause especially for a country like India where a lot of people have to be included into the financial sector mainstream. So that has you know we we

we have been on track I would say. &gt;&gt; So this did help us uh customers with thin file or no file. &gt;&gt; Yes. um including them in the entire banking ecosystem, right?

&gt;&gt; Yes, we are we are on the process of that and uh we would be having more people into the mainstream financial sector. Uh you know that there models which are using alternate data to to

give credit to people who have typically not been able to source credit. So these things are changing this it's it's a it's a you know good way forward and in the next two years I would want more of

this. I would want the 500 million who still don't have access to get access to financial services. Also, I would uh want AI to play a key role in the accessibility because you know there are

a lot of challenges around that as well. Uh we we believe that uh it it's not exactly an equal space. So we need to create that equal space and AI can play a huge factor huge

&gt;&gt; while divide exist also be a huge leveler right. So it can actually give good access to everyone. &gt;&gt; Exactly. &gt;&gt; All right. Maria,

&gt;&gt; what in my case is actually is two words that are both positive and negative. That is awareness and readiness. Awareness because I think if we were to have this conversation three years ago,

the room will be half empty. It wasn't perceived to be the kind of challenge and opportunity that we are aware it is today. readiness because we have been discussing now and I mean we have seen

different approaches in different parts of the world to this uh to this set of transformative technologies. Now I still see for instance little discussion or at least insufficient let me qualify the

statement about for instance the implication of AI in the life of young people in the world of work of all of us and what it will mean for uh you know from the uh for people not only to be

able to participate in the award but really to thrive in the era because that's what we are heading towards and we are very much in already. So both good and bad but the awareness the

engagement that we see today I'm sure are going to be leading to uh this engagement that will bring uh good for all &gt;&gt; amazing awareness and readiness totally

agree with you &gt;&gt; um probably touching on all of those themes I think from an Australian government perspective the the what we've done well

and the what next is sort of one and the same or it's the same continuum it's on a continuum so as I said we've had this two-year cons like consult consultation with the public. We've released this

plan and it's now almost like now starts the hard bit, right? We've got to implement it and part of that's the responsible AI and tracking of frameworks and setting up this

institute. But um make no mistakes, there's lots of work to do in Australia as well. Part of the plan goes to things like inclusiveness as well and how do we make sure we can spread those benefits

of AI. It's around an enormous skilling task. I I know Indian government is focused on on that as well. Australian adoption rates in some respects are not as good as they should be. There's a lot

of support supportingmemes and others. There's an enormous amount to do on skilling. Um so the plan is out now and and uh it's time for us to deliver across a range of um things and really

as we said get into implementation, translate principles to practice an enormous amount to work to do over the next few years. &gt;&gt; Well, all right. Fantastic. Thank you so

much. And that is all the time I have. Um, so I've been shown &gt;&gt; may maybe we can catch up outside if you want. Okay. All right. Thank you so much. That has been an amazing panel.

Thank you so much for being on the panel. &gt;&gt; Take a selfie with us in the back. &gt;&gt; Yes, we should. &gt;&gt; Let's take a selfie with you in the

back. Don't go anywhere.
