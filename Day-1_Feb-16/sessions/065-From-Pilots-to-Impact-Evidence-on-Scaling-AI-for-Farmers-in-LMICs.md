# From Pilots to Impact: Evidence on Scaling AI for Farmers in LMICs

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 13:30 ‚Äì 14:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 19 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/XOuO5KDaWgw?feature=share) |

## üé§ Speakers

- Dr. Francis Xavier Rathinam, Athena Infonomics
- Dr. Kavya Dashora, IIT Delhi
- Dr. Monisha Lakshminarayan, Athena Infonomics
- Dr. V . Praveen Rao, Kaveri University
- Ms. Deepa Karthekeyan, Athena Infonomics
- Ms. Zeba Siddiqui, Athena Infonomics

## ü§ù Knowledge Partners

- Athena Infonomics

## üìù Summary

This session will host a high-level panel at the AI Impact Summit 2026 to examine what works in AI deployments in Agriculture while being informed by a Multi-Country Landscape Study across Low- and Middle-Income Countries. The panel integrates Evidence, Practice, and Policy, highlighting India's Saagu Baagu system, and addresses Bias, Digital Exclusion, and Responsible Governance. It will frame AI for Agriculture as one of Development and Public and will shed light on challenges and deliver lessons for Responsible Scaling for Smallholders and inclusive agricultural innovation globally.

## üîë Key Takeaways

1. This session will host a high-level panel at the AI Impact Summit 2026 to examine what works in AI deployments in Agriculture while being informed by a Multi-Country Landscape Study across Low- and Middle-Income Countries.
2. The panel integrates Evidence, Practice, and Policy, highlighting India's Saagu Baagu system, and addresses Bias, Digital Exclusion, and Responsible Governance.
3. It will frame AI for Agriculture as one of Development and Public and will shed light on challenges and deliver lessons for Responsible Scaling for Smallholders and inclusive agricultural innovation globally.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/XOuO5KDaWgw/maxresdefault.jpg)](https://youtube.com/live/XOuO5KDaWgw?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

scarce public financial resources subsidizing design, innovation and delivery of artificial intelligence services. There's a value for money question,

right? Is there value for money from this investment today? Do we need to wait? There is a safety question, right? Which has been a really large part of a lot of the discussions that me that's

that I've seen since this morning. And there is definitely an inclus an inclusion question, right? Which is you could say, oh yeah, this is great. There is value for money here, but it may not

be inclusive yet, right? And achieving those goals require us to go back and think about questions of how we collect data, how we build models, how we finance those models, um, and how we

actually drive adoption. We have some phenomenal panelists today, so I want to really, and if time permits, I know 55 minutes is tight, but really allow for some sort of audience

interaction and Q&amp;A as well. But I want to kick us off. So we have here with us Zebas Sadiki and Francis who are both evaluators who are going to come from the perspective of really what is the

evidence telling us right so there was a systematic review that was funded by FCTTO that Francis and Zeba were part of leading and delivering at Athena Infinomics and they're going to share

Zeba will share the results and then Francis will share how that's shaping our thinking as we think about AI evaluations. We're really honored to have Dr. Singla join us who's secretary

information technology the state of Jammu and Kashmir who's really thinking about questions of how do you do this at scale and how can we make sure it's inclusive and what do we need to get

right in terms of the digital infrastructure on the upstream and professor Cavia who's joining us from IIT Delhi who's going to touch on this very critical aspect of adoption which

will not come without the trust infrastructure at the last mile and the human interface and what we're learning learning through the work that she's being leading and delivering on with

with that I'm going to hand it off to Zeba to talk us through uh yeah what we're learning from the FCDO um systematic review. &gt;&gt; Uh thanks Deepa. Uh thanks a lot for

situating Athena's work in this landscape. Um as she mentioned uh this was a rapid review that was commissioned to us by the RCC FCDO government of UK, University of Birmingham and

international initiative for impact evaluation. Uh the idea behind this was to map what kind of AI solutions or AI enabled interventions are being used for what kind of agricultural problems. Now

having said that we were also cognizant of the fact that we not only want to map it in a very technocentric manner but we also want to understand what are some of the welfare related indicators uh

related to agriculture. Um I am drawn towards the point that one of the panelists in the previous uh health related uh uh discussion they alluded to is that you have to also measure the

right kind of outcomes. So in order to do that we embedded rapid review a very rigorous methodology with more qualitative and nar narrative based methodology in order to call out the

more relevant the more uh uh well-informed and well-rounded sort of details in terms of how does it impact smallh holder farmers um across global south across lower and middle inome

countries. Um I'd quickly mention what are some of the key uh uh evidence base that we found in this study and then I would also discuss a little bit about what are some of the qualitative or

narrative based details uh that came or that were generated through this study. Uh we looked at over 55 journals. We also looked at around 19 to 20 repositories both academic and

organizational repositories and we also looked at over 100 gray literature just to ensure that we're not missing out on anything relevant and the time frame that we included in this study was from

2019 to 2024. Uh we realized that there is a lot of dialogue around effectiveness of the AI models of the AI interventions. However, where a critical gap lied was the fact that we didn't

have much dialogue around what is its impact on poverty reduction uh livelihood decision-making power and who does the decision-m power rest with. There is also um we did find that uh

there is a lot of impetus on using AI models around crop production, pest detection um precision agriculture models, large language models but they were directed to or the studies or the

evidence were essentially directed to understanding how are these effective how are these solutions addressing or fairing in terms of performing or not performing. Um again there was a lot of

in in in previous discussions we see that there is a lot of dialogue around uh you know not just measuring the pilot but also measuring uh the sustainability of those interventions. This is this is

something that we realized when we were doing the rapid review and which was sort of also came up in uh the case studies and the deep dives is that um the AI models especially in agriculture

are much at a very nent stage um at a very pilot stage. we do see surge of a lot of uh supply side designs where uh uh you know AI uh is sort of being seen in agricultural practices. However,

those models do not sustain. Uh I'd briefly like to touch upon why do they not sustain or what are some of the challenges that we encountered and these are the gaps that we identified during

our uh analysis. Firstly, adoption related challenges is essentially driven by lack of trust. Um the limited amount of trust is because we do see uh uh you know agriculture is essentially a very

conventional a very traditional field uh wherein we uh see that you know people from a certain generation they're not ready to take that financial risk in order to take up a new technology. Uh

hence there is lack of adoption and there is also the lack of trust in terms of you know adapting to something that may or may not lead to u the desired sort of outcome. So uh uh we we also

realized that you know behavioral uh changes are very difficult to um overcome. &gt;&gt; Uh sure. I'm actually not reading through the slides so that's fine.

&gt;&gt; You're not using the slides. &gt;&gt; No I mean it's just &gt;&gt; I I'll just because I have my notes made. So yeah. &gt;&gt; Uh yeah. So in in one of the case

studies that we studied that we that we did in the African context is uh based out of Kenya where we realized that a lot of cooperatives farmer cooperatives that engage um farmers are also

disseminating a lot of information in terms of how to use AI enabled solutions for financial services for banking services and so on. While this is a good avenue to percolate information to the

right kind of audience, what we realize is that these cooperatives also called sakos in the local context uh did have high amount of male uh membership or male concentration as opposed to women

uh who were not traditionally part of these organization. Now that brings us to my second point is gender disparity or gender inequality. AI that essentially has been sort of brought

into any field even in agriculture to uh balance out that inequity uh in a way also sometimes not always perpetuates these inequalities in the sense that uh when we are trying to model anything in

a particular context it also has to be uh cognizant of what kind of context it is being tested in. It also has to be aware of what are some of the uh cultural gradients that are you know

that are prevalent in that particular environment. Uh what we also realize is that human in the loop design or human validation is something that is a challenge and that is that is not being

talked about enough in in in terms of the evidence. uh we do see inclusivity is uh something that is missing in the evidence base or in the literature and we um uh you know when we talk to

stakeholders, we talked to large cohort of people from academics, from donors to research organizations and uh there is one thing that they definitely uh debated about or they sort of argued

about is that human validation or inclusivity in that sense is something that should be at the very core of the design of any AI solution. uh and u any solution that is being designed for a

related uh problem should not just have uh uh technical experts but should also have people from gender from uh from you know local community or community champions. Uh then we also realized that

there is a big capacity building gap in terms of providing that kind of training to farmers to be able to u not just adapt but also understand these solutions. Digital literacy as we all

know is a big challenge and that also hinders the adoption of these AI uh related solutions. Um at a large scale what we realize is that governance or governance related frameworks AI

frameworks exist in a lot of geographies. However, a specific frameworks are missing from uh the discussion. So this is something this is this is a definite policy takeaway uh

that you know of course Francis would talk about it later when he talks about the horizon mapping uh from this entire project but absence of a related governance or a related policy framework

are a definite um uh evidence gap uh absence of localized data or using average assumed data from you know national data sets or uh absence of consent or taking consent from the

farmers in terms of how the data is going to be used is also one u sort of dialogue that is missing from the evidence base. Uh we also realize that um there are financial constraints there

are financial sort of functions indicators that are attached to using any AI enabled solutions in agriculture. While a large scale farmer may use um may function at economies of scale, a

small scale farmer may not do so. Which is why there is a definite inertia in terms of adapting to uh you know these solutions. Uh again uh coming back to the gender point there is um gap in

terms of ownership of assets, ownership of land, ownership of smartphones or even basic uh uh you know uh these kind of paraphernelas where uh women are sometimes at the fringes and not at the

very core of these solutions. Uh financial inclusion is also a big problem when we're talking about enabling financial services through AI interventions. uh because a lot of times

women are also left out from the banking sort of uh you know sector or formal banking um networks. So these are some of the gaps that were uh flagged during our study and I think I would just leave

it to the fellow panelist to sort of allude to these points and also talk about them in details. So yeah that's all from my end. &gt;&gt; Thank you Zeba. I can I a quick question

before we go to the next panelist. Is there something that surprised you from the systematic review? We've we know about the digital literacy stuff. We know about the finance and scale stuff.

Is there something that came out of that systematic review that you went whoa I didn't expect that? &gt;&gt; Uh I wouldn't say surprise. there were a lot of expected sort of evidence that

emerged during the study. But something that really does um I' I'd say that you know a lot of these solutions which should be directed at small holder farmers which form the majority of the

group um are not directed towards them are not made for them or even women who do not own the land however they are sort of forming a majority of the labor who are sort of performing you know the

daily labor at these lands. uh why I say this as I mentioned also is that they're not part of the you know the circle who owns that particular agricultural land and hence they're not part of the

solution as well uh which is why they could be at the other end of the spectrum using these solutions but they're not at the other side wherein you know uh they can contribute to the

design side or the you know the supply side or how do you want these models to look like and all of those things. So this was definitely not surprising I'd say expected but yes this is perplexing

in a way that you know you're not really addressing to the very core of the problem uh uh or you're not addressing to the larger group which are going to be your majority sort of you know the

user group. So yeah that is something that has come in. Um one thing that really surprised me uh in the literature was we we have shortlisted about 450 studies

and then included about 51 studies but the number of studies that did not report even basic uh what type of data they used for uh training those models and what are the ground truthing and uh

what are the ethical uh issues that they looked into was really surprising like uh there's very few studies I've actually kind of like looked into and uh reported that in the final uh like a

report. Uh so that kind of really calls for u um um a sectorwide um um like a checklist or like a reporting standard that everybody should follow. &gt;&gt; I love that. I think so we're hearing at

least three things, right? We're sort of firstly we don't know. There isn't a lot of evidence on impact yet where there is some evidence the impact hasn't lasted or sustained. It's very temporal. It's

very projectized. So it's clearly this and this is such a great segue Dr. singularity, right? Because now as in government when you're starting to think about how do you build systems and how

can you approach this in a way where impact is delivered where it matters and is sustained and that's a question that's true beyond artificial intelligence. I think we can draw draw

from literature on public service delivery. We can draw from literature on good governance and where that's worked. I'd love to hear from you building on your experience on yeah how you're

thinking about it in Jammu and Kashmir. &gt;&gt; Thank you so much for having me. Uh I think this is a very pertinent point to discuss. We do have pilots across the sectors. So do we have in agriculture as

well but is issue is institutionalizing those pilots and that's where comes the biggest challenge. I see it very differently uh from the AI use perspective. There is some sort of FOMO

fear of missing out that if you are not doing anything you are missing a huge thing. For sure we are missing the huge thing but most important is to do what is actually required on the ground which

has the adaptability which has the uptake from the local population. For example, if I talk about Jammu and Kashmir, I've been there for last 14 years working in different capacities uh

in the senior administration. uh the farms of saffron farms in Pampur &gt;&gt; is very different from the apple orchards in Soapor. So it is very different in the rice fields of Jammu.

So we have very diverse geographical regions, very diverse uh needs, very complex behavioral uh issues. So we cannot actually put in just one dimension that look whether this pilot

will upscale or not. I remember we were doing when the PMKAN was launched. So we were interacting I was a district magistrate of Anantanag district in Kashmir. So we were interacting a lot

with the farmers small marginal farmers they have their own set of needs own set of uh requirements. So unless any AI model speaks the language of a farmer that upscalability will always be I'm

not saying a technical language per se but how the trust develops. &gt;&gt; So in government when we talk of scale we talk of trust. So it is a service actually it is not a small pilot you run

in one district and suddenly it fades off in one year that will not be adapted. It will only be upscaled adapted when it is as a service. When farmer needs it, you provide it. So it's

a transaction. It is everyday's need. So if they want the weather advisory, so because the weather the farmer will not wait for the seed sewing. So if he needs the weather advisory right now, very

accurate. So he need to get it today. So if I say okay, there is some algorithm problem. So my model drift is there. So I'll wait for 3 days. So his time is gone. So he'll lose a precious time of

seed swinging. So I believe this is the real practical challenge which we see in AI these days. There are very beautiful pilots around and very with a great intention just that it has more

adaptability on the ground. The system is adopting that uh models and we are upscaling it in the interest of the public. So the last mile is benefited. I love that and I think this is why it's

always exciting when government's in the room, right? Like because that perspective and mindset and is so unique to a public sector leader. What is Jamo doing something about this already? Is

are there initiatives? What are some what are what's being done for instance to address the last mile advisory that without latency that is highly reliable

&gt;&gt; that's the most challenging part of it actually so we uh educational institutions especially higher educational institutions have a bigger role to play we have IIT Jammu uh so we

are collaborating from the Jammu and Kashmir government side uh to come up with the center of excellence again uh the mandate of that COE would be to create use cases which are actually

upscalable and replicable and based on the needs of the ground. So we all must be knowing about the duisan uh that there are a lot of AI solutions, AI platforms where weather advisories and

other kind of things are given but to have it more comprehensive without latency or minimum latency uh and suiting to the geographical needs of Jammu and Kashmir. The farmer in Jammu

needs a very different advice than the my farmer or horiculturist or orchardist in Kashmir. So that variance is huge. So we have to have those models which actually help with that. So our COE

would be taking up very few case use cases rather than what actually feels from our side it is it can be taken. No we are thinking from the maximum problem perspective. So when you have

unscheduled rains when you you know uh snow untimely snow and sleet can damage the full apple crop the full season is gone. So we are trying to work on those use cases and trying to come up most

important is the data in my opinion right now. So we are coming up with a good data sets so that we know what is the trend of last 20 years or 30 years about the weather advisories uh how the

forecast has been what my farmer needs in that space. Then we can feed that data to the models in collaboration with the academia uh industry and can come up with a real use cases which are

upscalable rather than just pushing very uh less data from small district uh level sample size which we do not want to do. &gt;&gt; Lovely. So this I think and and I

struggle with this right as someone who's operated at the at the intersection of research policy and practice. We need policies to be designed to be

scalable. But the reality is it has to be highly customized and bespoke, right? And that's a difficult that's a difficult intersection to navigate, right? Because

when you're designing a new program or a policy, you're making some assumptions about what impact could look like and you're operating with certain principles of how you will deliver that. Now, in

the absence of feedback loops, right, we're never going to really know if the policy is really working or not. And that's a really, and you know, this is a book that I love. It's called Seeing

Like a State, which kind of talks about why public sector schemes fail, right? And at the heart of it, it's not because of intent or even complex political economy dynamics. They go on to say it's

because we just don't learn. We have no way of learning cost-effectively on what is and isn't working. So that our policies end up being static documents and systems that are stuck in

bureaucratic inertia rather than allowing for dynamic engagement in terms of what is and isn't working. And I think that professor Cavia probably is an area where I'd love for you to come

in because you've been thinking and working on questions of how do you do that in practice? We all know it's important. We know there are challenges, right? Like none of us in this room will

say otherwise. We need feedback loops. But how can we build those systems of feedback loops and dynamic accountability and policy responsiveness?

Uh thank you for having me here and uh the the work done by Ethina itself speaks so much about the need of the concept itself and then the scalability the data which they have collected much

appreciated. So coming to the question I would say that agriculture is agriculture health care and welfare schemes they are the source of big data in our country and they should be

treated like a big data source. They should not be treated like uh a lab scale work. We make policies but then if you see our trajectory, our trajectory is from pilot to policy. It this is a

very wrong way because pilot is a very very controlled experiment. I do experiments in my lab and the same thing when I take it out in the field I know there is a small field there is a

village a a a cohort a specific uh demographic I am addressing to I know the crops and I am handholding that particular small group so that is a pilot which I want and then pretty much

I'm also interested that these are my expected outcomes so everything is kind of framed in a predictable manner whereas and then we very merily compile those pilots and then go on and make a

policy for the population or for the public. Now this is where the disconnect happens because we do not have multimodal data. Pilot is very very limited to its frame boundaries or to

when we can say it has its own um boundaries which is which it has created. Whereas agriculture is different agriculture I'm not touching upon healthcare but it is no different

than this. Uh speaking for agricultures exclusively it is a multimodal sector. You just can't look at a picture and say that all right this is late blight of potato. You need to know which month it

is, what variety it is, what is the soil condition, what weather you are growing in, what state it is coming from. But when we are making develop uh when we are developing the models, we do not

have a point where this multimodel data is integrating or collecting. So what miss is the um accountability because even if you see the advertisement of the chat GPT and all what are they saying

you ask a question and then they respond but at the back end there is a whole lot of training which goes inside and if this training is not on Indian system if this training is not hyper localized if

this training is not repetitive that means uh feedback models as uh she rightly mentioned if there is no feedback loop or a constant learning. We we do not have uh you know saying it is

self-improvising that would be technically little too alarming but yes the system should keep on improvising itself because the continuous data is coming in and where is this data coming

in from the multimodal sources are which are at different positions in the country like rice for example uh pan India we are growing rice pretty much all hybrid rice we are growing so what

is the problem in collecting the data from the different states we would try and have our own area. This is our area where we are collecting the rice from and then we have this data 10 times same

area being repeated. There is no diversion or there is no um uh there is no extra data which is coming in or an alternate. It could be a flood bone. It could be a zinc heavy soil. It could be

a farm practice which needs to be improvised. Not everything needs a flush of pesticides. But generally um a static trained model will give you a static trained response. And the the worst part

is there is no accountability. Wherever we are talking about trust factor, farmer feels all right. Now earlier you used to come and talk to me. Now you have a device which is coming and

talking to me. But what if it goes wrong? Even when farmer is standing in the field with traditional knowledge with his all uh all seniors and ancestors and very well experienced

people still things go wrong and there is nobody to hold accountable to and then we expect him that this is the device it should replace all your wisdom all the experience and this is the best

thing to be the world is just moving on moon right now with this device so you just take it and if you don't take it he rightly said there is fear of missing out you are no more the the mainstream

person so there itself. We are creating the layers and these layers are kind of filters which are uh filtering the profit which are filtering the benefits which are creating barriers to

accessibility and also to improvisation. a person or the group of people or the villages which are technically um smart uh accessible having a good bandwidth of internet near to city having good

smartphones uh women usually excluded because either they do not have a smartphone or they do not have the time to do it. So we are kind of narrowing down with the data with the users and

also with the area uh from which we are trying to train our problem which we are trying to train our model. So in a way um I would say all of this again this becomes multimodal itself. If we have to

make a policy it should just not be pilot to policy it should be policy at scale. scale data should go into developing the policy public to policy not pilot to policy where trust is

embedded. Um I strongly um speak for embedded AI which is akin to embedded finance. For example, your WhatsApp and AEL phone, they were not traditional banks, right? But then they allow you to

make payments. Google, they allow you to make payments. As simple in your existing smartphone, you have a payment making agency sitting there as simple. You don't need uh that you don't need

the knowhow of technology. You just need to have a bank which is somehow linked to it and somehow you can make a payment. That is the user aspect of it. If we are able to make embedded

agriculture, embedded AI for agriculture, the farmer should not feel, oh god, one more app, what do I do with it? It is not helping me anymore. And then

gradually there is a trust deficit. So and then it all feeds into whether we want to acknowledge it or not, it all feeds into shallow policies. There is no feedback mechanism. There is no impact

assessment of these policies. And then there is no um no improvisation or recovery mechanism that okay this didn't work let us do that. And the last and the most critical thing is if something

goes wrong who's to be held accountable because he has everything which can go wrong and then he has nobody who will compensate or hold his hands for. So highest takes lies at the last mile.

&gt;&gt; I love that. So, I sit on the board of a crop insurance company and we've been joking about this and maybe it's not going to be a joke too soon in the future is an insurance product for AI,

right? So, what happens? Who takes the liability of an advisory going wrong and what's being built into the into advisory agents today, right? For instance, I'll give you an example of a

a pest management platform, right? They don't want to take the responsibility of what pesticide you use. So the farmer still makes the decisions. You simply provide a connecting bridge to, for

example, a drone based service or a a mechanized human facilitated service. So it's still just a matchmaking facility, but you're not taking responsibility for advisory yet. Uh I think that's a really

powerful point. And I also want to I think you touched on this so elegantly, exclusion by design, not inclusion by design. you talked about how you know and again I we've talked about this

sometimes poverty is a policy status quo it's not that by design you are perpetuating or maintaining uh a state of uh exclusion these are such powerful points I do want I know Dr. sing I mean

one of the disadvantages of being the only public sector leader on the panel means I don't know like these are very complicated issues right like as researchers it's easy to sit here and

think about it and write about it and I think there's a there is a a role that we play in a way as mechanisms of evidence and accountability but when you start thinking about practice

what does this what do these yeah how what's the thinking in government today about questions like these. &gt;&gt; I think uh the the most powerful point was accountability. So you cannot let uh

let AI to drive you a car and when someone you know if that car hits someone you you someone can just get scot-free. Someone is has to be accountable. That's why in government

when the systems are designed especially uh all the pilot projects very carefully it is seen that whether that has a relevance for the last mile. It may or may not touch but is it is there a

relevance for the last mile? Here comes the role of data is very important. So I personally see we have so many departments which are data rich &gt;&gt; and but unfortunately the data is not

granularized in a form and shape where there is interoperability. So to have that data layers interoperability we need to have more systems of data

sharing. In JNK we are attempting to have some data lake concept. Uh data lake concept is a new concept where every department pull in their data. If you put AI layer over it then there's a

uniform reply. So we we have seen a a case study where if we put AI to one department the response to a same query will be different than if I put AI to other department's data. It's the same

query but the response will be different. Why? because the data is in a different form and shape. So datas are not talking. So we have so much of data. So I think the most important critical

right now in our opinion before we put any AI layer for any use case is to have good data interoperability, good data exchange which data can speak to each other, good form and shape of the data

which can be fed to the systems for training our models. So that we all talk of model drift we talk of model hallucinations very common words but if our data is like that what model is

going to do they're going to behave like that only &gt;&gt; absolutely I want to and I know Francis you've been thinking about &gt;&gt; I just like to add one point uh sorry

for this interjection there is a if you just ponder upon it there is a little bit of a stark difference when the models are made for healthcare because there the jargon remains with the

doctors uh and that is consistent anywhere in the world you would have typhoid called as typhoid and TB called as TB and cancer called as cancer but when it comes to agriculture the jargon

sits with the farmer and that is extremely extremely diverse I mean we have language we have dialect and then we have household language generational word for a thing so creating a data lake

and interoperability of the data becomes so crucial and critical in agriculture and this should be addressed first because for the same thing you will have so many different words which are

coming. It is just not how you describe your problem. Somebody would say stomach ache, somebody would say, somebody would say I'm not feeling comfortable and then doctor would understand based on the

treatment uh reports but in agriculture it doesn't happen this way. So it is very very sensitive like a thin glass we are walking on. So data pipelines should be very well structured culminating into

data lakes and then data talking to each other may possibly a be a way wherein we are addressing the big data of agriculture including all levels of dialects and even a household language

for a word. Amazing. Gosh, maybe Francis, I'm gonna make your job harder uh then in a way, right? Um

if you because as an AI evaluator and as a sort of having spent a lot of time thinking about this and working on this Francis, you've been trying to come up with almost like a framework to navigate

this complexity, right? That ties in the interests and the incentives and the practical considerations that government lead with. governments lead with but also what we know is important from a

technology governance regulation standpoint and finally an impact standpoint right in terms of what we know and what matters right like while the language might change we've now

worked across different states the two biggest things every farmer wants is better prices and affordable inputs right in fact credit is the third like if you could address these two and then

then credit in fact dependence on credit goes out. So it at least the needs are universal. At least there's enough convergence on some of the core things that has a huge impact on their quality

of life. But Francis, how if you were to sort of think about a framework, how would you go about doing it and do you have advice for governments and practitioners and researchers?

&gt;&gt; Thanks Deepa. Yeah, [clears throat] both Dr. Singla and also professor Cavia ended their like part within very difficult question like say the accountability question when something

goes wrong who's accountable who's like responsible and they also like talked about like there are several challenges that actually kind of leads to like say lack of interoperability of data or lack

lack of feedback from the end users all that kind of like leads to this like a problem but like put the question different differently uh like we have like lots of pilots from that's what we

see in the um literature review as well. Uh but then almost like none of them have actually kind of like moved on to uh like kind of scale to kind of become part of the like a public

infrastructure. So what what would we need uh for a pilot to become a full scale uh like like project like say um like what type of like evaluation or governance architecture that we need to

like put in place uh like so that the that we are kind of like confident of uh the the final like results. So along with the literature review we also did like series of case studies uh in Africa

and also in India. So from those case studies like what we have actually distilled like three like a buckets of uh like issues uh that um that we would need for uh ensuring that the the pilots

when they move to like a scale uh we could be uh like relatively like more confident of the results that like could like come out of that like so the first uh like a pillar is actually the model

safety the model verification that pretty much almost like all the um uh like a model like builders their application like engineers would actually do they would be like looking

at uh uh the consistency of the results that coming out of the model uh the efficiency of the model and so on. But um our in in the in the framework that Athena has actually developed uh the

question that we actually asked is like beyond like model uh like like safety u like we asking like model safety like like for whom like um this has been like say uh um the engineers do like a stress

testing like for different types of inputs that like professor Kavia talked about like say the inputs could come from in varied like fashion because of the language actually changes and so on.

So the model could be like a tested in the in the lab like testing but like was this really tested with like a people in the real world uh like testing. So that's like for the basic like block for

model safety um like say a government that is uh expecting um um an AI model to be scaled or like a donor that's actually aiming to fund this should be asking like a series of like question on

the internal validity of the model itself like what data this has been trained on uh is is that being trained on like localized like a data that's specific to the context again like

quoting like professor likeabia u in in AP that's what like in Andhra Pradesh like within a vicinity of like a 20 kilometer we see there is a massive difference in terms of like say the pest

incident in like palms like because of like a difference in um soil like moisture like a soil quality like weather and and so on. So the uh the model needs to be trained on ultra like

microlevel data. Uh so that the kind of like checklist that we should be looking at to begin with. The second block again um um Dr. Singler talked about it's actually the the trust and usability. Um

so we should be actually asking question is the model being tested in the real world with the people who would be ultimately like using it. Do they really understand the model? Are the model

producing like say it could be like a chatbot and advisory. Does it really produce outputs that are um like relatable to them? Is it culturally uh contextually like like relevant like to

them? Um and then there is another angle. So um the end user is one group of like stakeholder. Then there is also the last mile workers who work with the farmers who are another very important

stakeholder in this uh human in the loop like whole process. These are the people who could actually like build the trust. So this uh like say extension workers like who've been working with the uh

farmers there is actually a level of trust that uh they enjoy and now if we like build this models jointly with the uh the last mile workers like say your uh like say

like the support team or like the like red team as we call in in AI like language that if this team includes the last mile worker themselves and if the last mile workers own the model and

could really interpret the final output that will increase the level of trust uh like for the like farmers to uh like take the uh like like results and then these two blocks once we have once we

know that the model is safe and the model is like working well in the real world like like a setup and this is also like culturally and contextually like relevant and it's like and it's also

ethically u relevant as well then we should be looking at like what is the ultimate impact these models are creating that's something that we see there is a massive

gap in the literature that's very little that is actually kind of looked into like what's the final impact on the yield or like say on like a farmer income and so on. this one uh like a

like a challenge like even in the morning in Athena's like session on like benchmarking we were talking about um the ultimate impact is a distant goal uh but a is so fast that uh it can actually

the version two can come in like say four months in four months very little changes in agriculture yield may not change like soil quality like may not change but in in in impact like what do

we then look at like we should be looking at like at least like some of the intermediate uh outcomes like so for example Example that say incident of like pest or like say the the pesticide

like a residue those are intermediate like steps but that will be absolutely important for us to reach the ultimate goal. So once we know that this intermediate steps work then we could be

like relatively confident of like the the final step like in one of the one of our ongoing work in Andhra Pradesh that's what our idea we actually looking at the intermediate outcome in in the

second phase we'll be looking at say what's the impact of the precision spraying that we are like promoting and on and the productivity and and the like residue and so on. So just to summarize

like all this so the a donor or a government that is actually looking at uh like a funding or like scaling like AI should be looking at like three like things like say is it really like a safe

to like implement that that's there's an internal validity of the model and then is it really working for the people who actually are intended to like use that and then we should also be like sure of

like what's the impact that it's creating. &gt;&gt; Wow thank you so much Francis. So I do think so what to measure I think consensus on the what to measure in the

context of AI is a good question for us to all ask and find a good answer to and align on and say make it so simple at least you're not having to go back and think about what this means so not

everybody has to figure it out in their worlds. I know we have very little time but I'd like to take at least one or two burning questions from the I'm not taking anything from the Athena team.

I'm sorry. Yeah. Thank you. I'm Dr. Silender. I'm CEO of Agri Gati. Agriati. We have uh deployed we have prepared the model to use the DPI

and UFI going to be from government of India. And while doing that I want to just share one uh example. Javier mentioned about extension worker ownership of the

model. So that accountability is there responsibility is there. Someone is there there to just see what is the result. What happened? We have a we are NRA and we are taking care of our native

place and for native place native block we have selected and in our native block we have developed this agriati and we have increased four to eight uh time income of the farmers. Oh lovely

&gt;&gt; four to eight time we are just converting information into income not only just knowledge we have seen the agree stack of government of India it is static we are building we have built up

the dynamic one so that there is a soil master sensor there is a coordinator and it is going delivering directly to pesticide to the farmers and that dynamis should be there because it is

day-to-day operation market is there market rises there. What we have faced the problem that the data data at a block level, district level from government of India that coordinate is

not that much uh uh precise drone is going to somewhere else and these things are there and we make sure that we are our model is from bottom to bottom up. So that we have we have uh

selected our native place because we have to be accountable for our native place. &gt;&gt; Okay. First say congratulations. I know I saw another hand go up and I'm okay.

I'm going to can we just get a round of comments and questions and I'll come back. &gt;&gt; Uh amazing discussion and uh just to introduce myself. I'm a general manager

and uh CTO of Sardar AI we AI readiness company. We have already trained 10 million people across the globe and we are creating the personalized AI role-based courses and certification. So

one of the point that you have mentioned and I would like to echo on that as well. Uh I feel the the mechanism which is missing is a reward mechanism in India. You know Indian runs by heart.

So you know you if you want to have an ambid AI if you want to have an inclusive administration if you want to have a proper framework I feel that reward mechanism has to be driven by the

government so that &gt;&gt; mean incentive &gt;&gt; exactly ma'am because see uh in India I think it's it's like it's always you know what's in it for me so you know if

we can figure out that route I feel we will get the last mile information from every single farmer whatever you want. The reason everybody's on the WhatsApp I tell you uh we seeing that uh there is a

digital literacy problem. Uh we have done a survey of more than like 10 million people in India. We see everybody out of 10 million people like 98%age people are using WhatsApp.

So I feel that it's not about the uh the ecosystem, it's about making the reward mechanism much more stronger. But the amazing panel it was and topic was really touchy. Thank you so much.

&gt;&gt; Thank you so much. Gosh quite a few hands. I'm going to only going to be able to take two more. I know he had his hand up before and then you and I apologize for that. I'm going to have to

&gt;&gt; Yeah, madam. This is Guru Raj Mahajan. I'm the coordinator for smart agriculture and entrepreneurship program in India for Tampere University Finland. So we have been working with

agricultural universities from past 14 years. So as you mentioned we worked on participatory development. So my question to you is you mentioned about this is the era of embedded AI devices

which are happening for example one of the Pune based company they're looking for the soil testing as the soil testing cannot take place across the India. So there are limited labs. My question to

you is how can we what is the solution to reach we we reach out to the final last mile farmers ma'am I mean the specifically uh final marginal farmers ma'am

&gt;&gt; I'll come back after that &gt;&gt; one more &gt;&gt; this is the last one &gt;&gt; yeah thank you very much for giving me this last opportunity to interact with

wonderful panel uh yeah absolutely so it's more of a question or I would not like to bias this discussion by giving my introduction immediately but I'll hold it for some time but I can give you

an experience that I have an experience of meeting or managing the inputs from two and a half 25 million farmers all okay now my point is that uh I'm also a practitioner of AI and from UT Austin so

I keep working on the problems I always believe that agree is very complex in India why don't we take lessons 5 years 10 years back which happened in banking and health sector see what happened was

when the AI got introduced banking and health never went for solving everybody's problem on same day. We don't need to boil the ocean. We just need to pick up two clearcut problems.

Maybe state wise, maybe central wise. Like look at banking thousands of problems but they picked up only that how do I manage my fraud system? They solved that topnotch and then they

created an web of solving the other problems. Similarly, healthcare if I go back 10 years or 8 years back when the AI started building up before it coming to India, it was primarily how do I

solve the breast cancer problem nothing else [snorts] and whole lot of exercise across the US and other part of the world's directly or discreetly were focused only on collecting the

information around the same nothing else no else to be solved and they just nailed it that created a ecosystem the environment the confidence so What I'm trying to say can we portray that and

bring out agriculture issue one or two and focus only on that. &gt;&gt; Thank you. There's a data quality question how particularly government of India there is an incentive question

right there is a question of and maybe that's what we end with what's that one burning thing we should solve for in agriculture and then there is a question of feedback loop

can we do rapid who can take can I give it yeah maybe the incentive question &gt;&gt; small part &gt;&gt; so I yeah just &gt;&gt; each of you could and also the burning

question what is that one problem that you think for too close. &gt;&gt; I think it was discussed about the health and the finance sector. It is about creating the DPI digital public

infrastructure which is like a pipeline which can be used for any different kind of purposes. So and many use cases can be drawn to it. Where we are heading is is creating a DPI structure. So which is

based on trust and you can use any number of cases over the years. Over to the next speaker. &gt;&gt; Thank you. Uh very quickly I just want to respond to your uh question. uh when

I said uh making uh the last mile workers part of the design team uh I meant was uh they would be part of the trust building process and feeding into that not making them as accountable but

like this human in the loop would actually having um the last mile worker would really kind of help design and also help the workers like wound this and then would be able to like build the

trust of the like farmers and then in one of the ongoing work that we are thinking about like involving Luxmile workers who would also be empowered to override the uh the results or like the

advisory of the uh like AI and they would feed that information back for the next round the model to like a develop. So that's the human in the loop that that would want would make uh the whole

process more trustable and accountable. &gt;&gt; Yeah. Um I would answer your question about how to embed AI into the systems. So um it is not impossible but it is not that easy. uh we are doing it in

different areas like I said about finance I also said about u like your communication for WhatsApp but agriculture is little diverse and agriculture is very very personal to the

last ground and the um impact is huge not only for the farmer but even for the nation it it's a cascading effect the crop loss converts into food loss and then dollar loss so on so forth so um

what I can say is right now that In order to make embed AI for agriculture, it should be the layers which need to be strengthened and um it should be a top- down approach. The problem definition

should be bottom up but the framework should be top down wherein the government or the institution the responsible institution like IICAR or maybe IT Delhi who's working on that. So

would just know that in which area what is the problem who are the stakeholders just connect them make a small nugget of all the information which is coming up and then create layers empower each and

every layer and there could be a feedback loop which is created. So that is the only way we can have backward and forward talking of the information which is moving and that actually embeds first

it will embed in the pipeline and then it will embed on the device. Uh thanks for that discussion and one last as as Deepa said one final thought before we close. I think inclusivity is

definitely one thing that would be a key takeaway for me. Uh as we talked about having a sweet spot between you know context specific but also you know intersection of policy and practice. Uh

I think participatory designs more uh as opposed to handme-down approaches would definitely be a key takeaway here. So yeah that's it. Thanks. Huge round of applause for the web contic

[applause] review again, we'd see very different results. In anticipation of that, thank you all for being a wonderful audience and for being here with us and hope you

enjoy the rest of the conference. Thank you very much. Okay. Uh and do do the audience have to say for that? &gt;&gt; Go have lunch. Yeah. &gt;&gt; Thank you.

Thank you so much.
