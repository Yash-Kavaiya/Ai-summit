# Democratising Access to AI through Data Infrastructure | Models, Governance and Market Design

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/f_slkb57yFw?feature=share) |

## üé§ Speakers

- Dr. Gokul Krishnan, CeRAI - IIT Madras
- Dr. Nishant Chadha, Policy and Research, ISB
- Dr. R. Srinivasan, Center for Digital Public Goods (CDPG) ‚Äì IIM B
- Mr. Abhishek Kumar, Product and Engineering, Wadhwani AI
- Mr. Arun Prabhu, Cyril Amarchand Mangaldas
- Mr. Ashish Aggarwal, Nasscom
- Mr. Gaurav Godhwani, CivicDataLab
- Ms. Aparajita Mridha, Department of Post
- Ms. Astha Kapoor, Aapti Institute
- Ms. Sreenidhi Srinivasan, Ikigai Law

## ü§ù Knowledge Partners

- Vidhi Centre for Legal Policy

## üìù Summary

This workshop examines how equitable access to high-quality data can enable inclusive and responsible AI development, particularly in emerging economies. It brings together experts to explore data infrastructure, governance frameworks, and market incentives that support scalable data ecosystems. Through focused discussions on technical models, market design, and regulation, the session aims to generate practical recommendations for reducing data access barriers, improving interoperability, and ensuring that AI development benefits diverse communities, sectors, and local contexts.

## üîë Key Takeaways

1. This workshop examines how equitable access to high-quality data can enable inclusive and responsible AI development, particularly in emerging economies.
2. It brings together experts to explore data infrastructure, governance frameworks, and market incentives that support scalable data ecosystems.
3. Through focused discussions on technical models, market design, and regulation, the session aims to generate practical recommendations for reducing data access barriers, improving interoperability, and ensuring that AI development benefits diverse communities, sectors, and local contexts.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/f_slkb57yFw/maxresdefault.jpg)](https://youtube.com/live/f_slkb57yFw?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

OCDI principles in 2019 and but the the challenge or a challenge a major challenge was has always been turning that principle into something that's operational that's uh uh comparable and

that's genuinely useful uh for policy makers and for the public [snorts] uh so the as well as the companies in fact and so the Hiroshima AI process um which was launched under Japan's presidency of the

G7 in 2023 was a a major step forward in uh in improving transparency. And at the center is a code in the international code of conduct for developer developers of advanced AI systems. And that code

sets expectations from uh from governments to developers of advanced AI systems um across the AI system life cycle. And I'm very pleased that uh Yoichi who is really the critical force

the momentum behind the the Hiroshima process uh in and shaped this work [applause] uh is so we we're we're lucky to have him with us today. Um so to show or then uh the

next the following year to help organizations show how they implement the code in practice the OECD worked with uh developers uh a number of which are here too uh [laughter]

pointing to no one researchers and civil society to create the Hiroshima reporting framework and that's the the first international voluntary and comparable mechanism for organizations

to demonstrate how they manage AI risk. s and uphold accountability. And so far we've received the submissions of from 25 organizations across nine countries. Um they're all publicly available at

od.ai/hiroima. And today we'll discuss a little bit about what we've learned uh how shared reporting practices can complement diverse different often times different

national approaches and importantly where this framework is this reporting framework is heading next. So before turning to the our panelists, um I'll maybe give you

Okay, I was going to give you a brief preview of what's coming uh of what we're planning for the hype reporting framework 2.0 know and I was going to show you but I think that I'm not going

to show you I think I will uh talk you talk you through it uh just a few of the of the uh of the key points from this uh Hiroshima 2.0 O which uh will be Um,

more comparable and aggregate a aggregable data. Um, second, we've linked the reporting interface directly with uh the OECD.AI AI cataloges of tools for trustworthy uh uh tools and

metrics for trustworthy AI which is uh also online at o.ai/ over 700 tools. So the major tools uh and metrics um uh and uh that are hosted on the platform. And so when

organizations describe their practices as well the com the reporters can suggest uh new tools directly from within the interface. So that also means the catalog itself stays up to date uh

and grows uh with every reporting cycle. Um so this integration is also helpful for smaller or less resourced less well-resourced companies um and because it helps them find and learn about

state-of-the-art tools uh and others uh that others are already using and the reporting itself becomes a way to share good practices between companies uh of all sizes. uh and third work is also

underway to update the framework alongside technological evolutions and tailor reporting to organizations rules across uh the AI life cycle. So uh for example uh the first round focused on

developers largely and uh now uh deployers uh such as uh uh Infosys and others are are part of the reporting framework and um and uh with uh we with that we as I said we expect to release

the new version uh in the quarter two of this year. Uh we're launching a pilot we hope to launch a pilot in March. Um and uh and we'll be organizing information sessions to help uh organizations

um um get familiar with the new format and especially give us feedback on what's what we need to fix, what doesn't work. Um so keep an eye out for that. So with the this context in mind, let me

turn to our introduce our panelists. So first we have uh to the right to my right your right uh Yichi IDA um minister's special in policy envoy at Japan's Ministry of Internal Affairs and

Communications otherwise known as MIC who has been at the heart of the Hiroshima process from day one as I said um we have uh ne Paula Goldman next to him who is uh chief ethical and humane

use officer at Salesforce very important for in particular for SMMES uh but for all companies companies of all sizes. Uh we have Paola Goldman who's chief ethical sorry um Joel Pino uh who's

chief AI officer at Coher and Amanda Craig um general manager of the office of responsible AI at Microsoft. uh and I also want to contribute the to acknowledge the contribution of Infosys

uh with whom we were co-organizing this um this workshop today uh and who's uh and in particular of of Ashish Tawari um uh who's worked really closely with us the team at the OECD in preparing this

session uh and also in in uh in helping us uh with the V2 uh that's underway. So uh and Infosys was also the first organization in India to submit uh uh a Hiroshima AI process report. So and we

hope not the last. So um even though he's not able he wasn't able uh to join us today, we really really appreciate his contribution and that of Infosys. So

thanks for all being here and let's dive in. Um so I'll start with uh Yoichi. Um, Yuichi Japan's championed the Hiroshima process from the start and has been instrumental in setting up and

growing the uh a parallel initiative very closely associated called the Hiroshima AI process friends group. Um, what has been most encouraging uh to you based on other countries interest in the

reporting framework? Thank you. Oh, thank you very much Karing for the kind introduction and good uh morning everyone. My name is Yoja uh uh kindly introduced by the

moderator now and I was chairing uh the uh G7 working group and also Hiroshima process working group when G7 agreed on this framework. So uh in the beginning uh we discussed and agreed on this

framework uh in G7 but uh let me little bit go back uh to the previous history. uh we started the discussion international discussion on AI governance in the year 2016 together

with OECD and we uh walked worked all through the process uh uh up down to 2026 until now uh the OECD has been the great partner for us.

We agreed OCD AI principles in 2019 and also G20 AI principles and India was a great partner uh in that discussion when we discussed G20 AI principles. After that

we were very happy to see you know the some of the kind of coherent uh uh recognition uh orish but uh in the year 2022 before we took the G7 presidency once

again uh uh after 2016 uh we saw uh a kind of diversification of approaches across countries. between US and EU were spreading out. So we want it

and that was why we took the uh took up uh this topic in G7 uh in the reg. So after following the rapid rise of generative AI uh we started the

discussion on Hiroshima generative and the intention of the discussion we wanted to share how we can uh promote coherent and consistent uh with governance framework across different

jurisdictions. So now the uh mentioned by the moderate discussion we are Hiroshima process report. We wanted to share how we can along with promote wea governance framework across more

different government together with more than private organizations. We are running. So in group that is also we are having the next in meeting next

government with more than 30 people more than 30 people are gathering to discuss how we can promote growing very we will be more different countries people

and also more private section different countries, every jurisdictions have different conditions, different backgrounds. So in the details we have to add different diversification

approaches. Still we want different people share every countries every different value different but still we want I was very happy

I saw and what is providing not only from the government but also from private sector. I think we I was very happy we discussing uh I saw many and also joining us not only from the

government but also private experiences understanding and also the challenge and and [clears throat] also joining us intero the challenge and

interoperability and common understanding on AI governance. So that is the most thank you encouraging. Uh I have a follow-up question for you which is that last year we received many you

know the first round of questions for you which is not just last year many you know the first round of company submissions not just published insights from that report last September

we published and I wanted to ask you from that report the first round um and I wanted to ask you what lessons did for policy makers thinking about transparency for for policy makers

thinking about advanced systems for uh for uh advanced AI systems. &gt;&gt; Yeah, thank you very much. Uh the uh it was exciting to see you know more than it was exciting to see you know more

companies and we how we can make how we can make use of this moment for this moment for policy for policy makers it is still understand

this must be uh containing a lot of abundant information uh to to to leverage But but uh in many cases we need a lot of a lot of understand to reflect all

those uh disclosed disclosed information and very important information police. So we need uh we need capacity building not only for the not

only for the government also but also for uh for uh AI AI including ordinary ordinary user citizens because all different all different players need

to increase the literacy governance governance. Uh uh the one of the major challenges major challenges how we can promote building reflect reflect the outcomes and

achievements achievement of policy making. &gt;&gt; Thank you very much. Thank you very much. Part of that part of that comes is is a message also is a message also to

us to to clarify clarify some of the key points. get into and not get into too much details too many details the details we love the details we need to we need to bring up the the key

points the salient orientations orientations public policy but thank you for that but thank you for that my next I'll turn to I will go I will go I'll turn to Amanda

Amanda from Microsoft from Microsoft Amanda and Microsoft was Microsoft was to submit a very comprehensive very comprehensive and detailed and question for you is questioncess

process reveal internally internally how Microsoft you know is operating is trustworthy trustworthy trigger did it trigger how did it change the way shape the way your teams thinking risk

managing companies within the company &gt;&gt; thank you thank you thank you and you know it's a It's a really it's a question that it's one that I plan to answer to answer about the values that

that Microsoft internally as part of a broader part of a broader context for the value for the value that we see the reporting

serving the wider really because what is help through the process with there's a real value going always going deeper shared to have shared understanding

language a shared understanding shared understanding of what practice practice implementation of practice implementation of practices really many different product groups groups

with different functions with different function we have the same we have the same need in the broader ecosystem and so you know um and so you know what I what I would what I would offer is from

we heard from we heard the kind of the kind of line that we've been that we've been on working on working on AI take a step back from the relative from the relatively early days and even if

you think about 16 from 2016 the technology itself the technology itself changed that much in that so as we govern what the details mean in practice means

the technology keeps up in the early days we're in the early days it very iterative conversation governance norms by these government how do we really this and how do we really this and how

do we really drive that common understanding so one example I could so one example I could offer from our Microsoft Microsoft responding to the providing a report providing a framework

under the is a real difference between on paper on a risk management framework a risk management framework [laughter] for any organization for any organization necessarily necessarily

distance it sort of on paper it's going to look like this We're going to identify risk, we're going to identify risk, evaluate it, we're going to evaluate it, and we're

going to mitigate it. And in practice, of course, in course iterative very iterative and also um and also the methods for doing that risk assessment, that risk assessment, that risk

mitigation, there's a lot there's a lot of commonality, but there's also some difference, right? just in terms of the specific technology specific technology or scenario that you're looking at. And

so something that where you have that kind of risk management framework that really drives that really drives that internal conversation internally where there are

where there is where there is deepening the conversation and that's again connect the value of the framework as well as well in the broader ecosystem.

&gt;&gt; Uh thanks Amanda. Thanks man. That's really helpful. That's really helpful. Um I have another question another question for you as we're as we're engaged deeply engaged working on 2.0

2.0 as we reporting reporting framework and Microsoft Microsoft the entire life cycle cloud computer applications. I think the question for

you is the question for you is what do you see the opportunity for this you know new reporting framework reporting framework more integrated more all the different

stages how do you see that how do you see that as an opportunity an opportunity beyond trust beyond just a developer just a developer level and to include the include the application

that's more and more that's more and more relevant &gt;&gt; thank you yes I'm really I'm really excited about the direct and really allowing and really allowing

us to work on these different parts of the value and what transparency I think it actually relates to I think it actually relates where we started opportunity opportunity to drive common

understanding common understanding shared language shared language for how we do across the broader across the broader and I think you know and I think you know relatively early relatively

early days of finding all of that having a shared understanding shared understanding of it. Right now a lot right now a lot of organizations have implemented AI governance and um and

there's been there's been an effort to start understanding of how organizations should govern this model. This is what model developers what application developers

application developers do some expectations for some expectations for deployers. What we really need but what we really need is a really holistic really holistic piece of conversation

conversation all that all that works together in practition and that drives and that drives a lot of common need for common understanding in a really sort of uh iterative uh

iterative way and it's obviously going to get like even more important with a Gentic AI, right? And so there's just this really big opportunity now to work on seeing the kind of connections across

the value chain, what we have as expectations for developers versus deployers. Um, and really seeing where there are gaps, maybe where there's work to do and making sure that all the

actors in the value chain have information they need to be able to make their own risk decisions. Um and so it's a really good opportunity um going forward with forward with 2.0 and I

actually have been really excited to see that there's been so much shared like recognition that this is exactly what we need right to provide greater clarity through the value chain really is a

foundation for trust and trusted adoption. that thanks Amanda and that point about uh the trust and transparency across the entire uh AI system life cycle and value

is really important connects well &gt;&gt; I think it connects well Salesforce perspective um uh and uh uh because Salesforce is working you're working with clients across multiple

geographies uh uh multiple types of clients and multiple sizes of organizations And uh do you think uh a shared reporting system I mean you have actually I know you do but maybe you

could elaborate on on how you think a shared reporting system could uh like like this one can help structure some of the conversations that you have with your own clients because you have you

know we talk a lot aboutmemes but the we can go through tomemes directly but that's very difficult but in fact many of thesememes are going to be adopting AI via Salesforce and other comparable

tools. Um, &gt;&gt; yeah, thank you for that question and and also just I want to just start by saying thank you for the leadership that went into the Hiroshima framework um and

its continued iteration. It's really really important and and I and I think um sometimes when we're asked about at Salesforce why we care about these frameworks, it it helps to

sort of take a step back and and talk about why it's not just the right thing to do, it's also the smart thing to do for business, right? To have these to have these shared frameworks. So um for

those of you uh who um well just to say a little bit about uh Salesforce. So we um as as you noted we um provide a aentic AI technology to businesses and organizations of all sizes. So from

small businesses to very large ones um and uh and within that for a variety of different functions from sales to service to marketing and so on. And um you know, I'm uh in my role, part of

what my team does is to test all of our products uh before they go out to market and make sure that our AI is working the way it should and to give and design controls for customers to be able to uh

understand what's going on and observe what's going on and and make adjustments. And um when our customers come to us as they do and they say, "How do I know

whether I can trust this product?" while we walk them through all of the work that we've done. Um, but it is uh much better to be able to say here's this shared language as you were just talking

about. Here's this shared framework that we have globally. It's not just us making it. It's uh a whole bunch of different organizations, governments, companies, nonprofits, and so on. And

we're speaking the same language. And it's very very important because then it's not just one company grading its own homework. It's a shared framework around how this how risk gets managed.

So that's point one. The second point that I want to make is obviously things are very very dynamic in the market right now right the technology is moving at an incredible pace and the regulatory

frameworks are also shifting dynamically and so in that kind of environment having this framework that's adaptable that as the technology evolves we're able to adapt the framework with it

becomes all the more crucial because regulation is very important important and also once it's codified it's codified hard to change but frameworks can adapt as the technology evolves and

so I think it's a just a critical part of the equation &gt;&gt; thanks Paula I'd like to take you up on that one uh on that last point about the the pace of evolution and particularly

ask you about uh how do you see agentic AI developments reflected in a framework like uh the the Hiroshima uh AI reporting framework. &gt;&gt; Yeah. Well, I guess I would say a few

things there. First, I just want to plus one uh your earlier comment um Amanda about um the sort of importance of the evolution even before we get to aentic the importance of having different sets

of standards around transparency and risk management for different parts of the ecosystem. Right? So again, SA at Salesforce, we do develop our own models, but we're an open platform and

we work with all the major uh AI providers and we're also putting aentic systems on top of those models, right? And so our set of requirements and what we do is going to be different than if

we're just simply developing a model, right? Um and uh I think having the shared understanding of what's you know what's the model provider's responsibility what's our responsibility

what is our customer's responsibility to your point right that's also a key part that I think bears further elaboration key part of the whole process and that provides the building block for when um

as is happening now as we are adopting agent systems at scale within businesses. So just to paint a picture. Okay. So we do customer service AI as one of our verticals. So if you have a

customer service AI agent handling inquiries, you want to know um and you've delegated to that AI agent that it's going to be doing so autonomously.

You want our customers want to know what's our responsibility in developing that and what are the tools we've provided them so that they can execute on their part of the responsibility.

Fast forward, you have a customer service AI agent interacting with someone else's customer service agent. Those two agents need to be able to speak to each other and that whole thing

needs to be auditable and governable and so on. If we don't have these building blocks in place, how do we get to those right? And it's very very important that we're adapting those that those

standards quickly again to the point of this everchanging environment. It's not just a nice to have. It is it is critical to unlocking adoption at

scale for the agent to agent economy. Thank you PA. I and the point about Agentic AI and uh and uh agents speaking communicating and being able to communicate uh with each other is one I

expect we'll hear a lot about this year. Um so turning to Joel Joel I um as someone building and shipping these systems at Coher uh which is a Canadian company for sorry for those who who

don't know Coher um based in Quebec um sorry tech little technical issue um I wanted to start by asking you uh about um you know as varying regulations

uh for AI are proposed and or enter into force around the world um what value do you see in these voluntary uh voluntary reporting international frameworks for companies operating globally and in this

case one that's accompanied by an actual Uh thank you and and pleasure to be here with with this panel today. Um I'm going to pick up in particular on the word international here. You know we have

several companies operating on the global stage represented on this panel and that definitely poses a challenge today. Um given the current geopolitical situation I think it it's getting

increasingly harder to land on regulatory frameworks on which we would agree. So frankly voluntary commitments can serve that purpose of essentially getting the whole community in

particular across enterprise to adhere to similar similar commitments and similar practices. Um even though regulation may take longer to to come into play. We're seeing a lot of

fragmentation on the regulatory side between the EU between some what's happening in the in the US in Asia and so on um for various reasons. And so through voluntary commitment we actually

can evolve towards common standard which in general is is a good thing in terms of transparency. It's a good thing in terms of people understanding what AI actually does, how their data is used,

what are the properties of the model and frankly it's a good thing in terms of accelerating innovation from an economic point of view for companies who do operate on the global scale and in

particular upand cominging companies such as Coher. it certainly reduces the burden to have a common framework. So I think from that point of view um it is much more feasible to have international

alignment when we go with voluntary commitments in the current situation. It does take leadership at a global scale and that's where I really salute the work that the OCD is doing the

leadership of Japan and bringing us together. Um that leadership has to has to be there for this work to happen but nonetheless it gives us a lot of flexibility. I think my my co-panelist

talked about the the question of agility, faster adaptation. It's absolutely crucial if we look at where AI was just 3 years ago versus today. Um this is on a completely different time

scale than the one in which we're able to land regulation on an international frame. So we just have to be pragmatic about that. Um the the last point I want to make is through these voluntary

commitments in many cases for enterprises there's an opportunity to reinforce trust with the public and when done well that actually reinforces the competitiveness of these enterprises um

especially you know coher is an enterprise that delivers uh enterprise AI solutions um that have high guarantees in terms of confidentiality, privacy, security and so our ability

ility to adhere to these kinds of frameworks actually gives a lot of credibility to the product that we're building and and to the to the innovation strategy and we're not alone

in this respect. I suspect many upand cominging companies benefit from that. Um so o overall you know I don't think this is a substitute for regulation but I think there's actually a lot of

reasons why it makes uh business sense to do so and it's good for customers and citizens as well. Yeah, I I I very much agree with you and I also think uh I also think that it it

can help inform policy because the evolution is so rapid as you say that uh policy needs to be informed by by those evolutions. Um and what do they mean? We're back at at sort of the point we

made earlier on. Um I also wanted to ask you how how the uh how this kind of reporting framework can support better engagement between um AI developers and policy makers. Um because we have groups

they're they're linked and they but but they they're somewhat separate and somewhat linked and I think both are important that they be somewhat separate so that those conversations can happen

in trust uh and open conversations on both sides between different communities but then they'll come together. they do come together uh and then but not not always so that you know when when

progress has been made real progress then it gets presented to policy makers policy makers take time and react to it and so on uh but there first there's that consensus building on both sides on

well what's important to our us as a community &gt;&gt; and I suspect you know you talk about the the conversation between the the the people who developed the technology and

and the policy makers but I think even within a lot of organizations certainly my own company probably that of my co-panelists that conversation happens even within within the organization so

we have frankly you know it can be pretty siloed what are the teams that are developing the technology the teams that are handling the government affairs public policy types of topics and so

this type of work has to bring all these stakeholders to the table together the ability to have these conversations about you know what are the trends in terms of the technology to articulate

the capabilities and the risks of this technology in a way that speaks beyond just the the language of engineering and and and computer scientists um is very important and so that gives us an

opportunity to develop that common language to develop that common understanding of what it is um and similarly you know I've I've worked for for many years with model developers um

who don't always have the same frameworks to think about how to put guard rails around their models to think about how to develop them in a way that's responsible that meets some

specific commitments. Um, I've had a chance to see a lot of that work in the context of open sourcing AI technology. And so, because you are leaning into a process that has, of course, um, an

intent to be very transparent, but it doesn't mean that open sourcing a model, you know, is sufficient in terms of of transparency. So it gives us an an opportunity to to really lead these

discussions internally and then take them out externally with a broader community. Um I I will also point out that for a lot of organizations you do need to develop more internal

maturity with respect to these governance processes. Um we didn't have these kinds of AI models just a few years ago. We haven't had the chance to evolve as organizations. And so through

voluntary commitments, we have often, you know, new functions that are established, new processes that are established. It gives us this the time to build that maturity internally that

will then set us up to to be much more responsive to to long-term regulation. &gt;&gt; Okay. Thank you so much. Um, so I think we're running a little tight on time. I'd like to uh have a light a round of

lightning sort of interventions sort of one minute maximum for each of you uh before we open up the the floor to the audience. Um, so my question is, you know, as as as we've been discussing,

we've been we're developing this version two, which I'd hope to show, but um you'll it'll come it'll it'll you'll see it soon enough um of the uh of the hype reporting framework version two. And

looking ahead, what in your view is the one concrete improvement um whether it's procedural, technical or or um policy related that you think would make the framework more useful for uh uh your

country or your the group of countries uh and and or for your companies. &gt;&gt; Okay, thank you very much. quickly. Um because [clears throat] this is you know whole voluntary framework uh everything

is voluntary. So we need a kind of incentivized uh in incentive mechanism uh where the uh organizations who submitted the report can benefit from their action

voluntary actions otherwise you know people will leave the framework. they made a lot of efforts and then you know there should be some uh feedbacks uh from uh the uh as trust from the market

or trust from the government, trust from the investors. This type of uh uh positive cycle uh as incentive mechanism should be uh implemented or uh accommodated into this uh uh whole

structure and the uh uh uh we uh government need to uh make more uh effort to realize uh this type of uh incentive uh in this uh framework. &gt;&gt; Thanks UI. Um um PA

I guess I'll just reiterate one of the things I already said which is I think the clarity of the different responsibilities of different actors within the ecosystem. Just like security

is a shared responsibility between the entities that create technology and the entities that use technology. It's the same here. And um I think that just needs to get much clearer much more

quickly. Thank you, Joy. Um, I will I will offer that I think it's important that that we're very thoughtful about um how do we increase the the multicultural aspect

and the accessibility aspect of this technology right now. It's a technology that's developed in relatively few places in the world and yet the technology is being deployed at scale

across the planet rapidly so um and so having an opportunity to build in uh considerations of uh accessibility, multilinguality, multicultural aspects into that is uh I think uh going to be

important. &gt;&gt; And last but not least uh Amanda. Thank you. I I think the one thing I would say is I hope that going forward we continue from a process point to see this as a

living framework that we can continue to iterate on. I think the first version has served us like very well in starting this conversation and starting this work. I think the next steps to really

think about the roles across the value chain and figure out how to do that in practice. I know that you have been doing a lot of work in that regard already but it's not you know it's

non-trivial to figure out the sort of seamless way to figure out especially when actors sit across multiple roles in the value chain how to how to actually enable that in through a seamless

reporting sort of function. So that's that's work still to do and the work around sort of showing the direction that you're going on, you know, not just having the unstructured open field data,

but but accompanying that with the kind of more structured data that's going to allow for comparability, that's going to allow for um really consensus best practices to emerge. Those are all good

steps, but like the real value of this framework is that we can continue to build on that, right? as the technology continues to evolve, as Agentic AI emerges, there are going to be new sort

of questions and new needs that we're able to sort of work on through this framework. And so that's really the the opportunity. And then I would be really really remiss to not call out there was

a really interesting report um published last month by Brookings um at CDT. We have Elam and Cam in the room. Um and that has a lot of really good insights into ways that we could improve the

framework going forward too. that thanks Madan and uh yeah I echo that and uh we've uh taken a lot of notes from that report so expect to see that reflected um in in the in the

second round. Uh so now uh I'd like to open up the floor for questions from questions from the floor. &gt;&gt; Uh okay my name is Dr. Patnayak uh I live in Mumbai.

So uh my question to you any one of you can answer um how is uh how would OECD OECD uh is going to help large emerging market like India, Brazil and Indonesia

in terms of uh AI tech adoption? &gt;&gt; Uh I think that's the a question to the moderator. Uh but we we were actually asking for questions to the panelists but that's okay. Um uh

actually the the OECD is the secretariat for an initiative called the global partnership on AI which is uh already quite a lot quite a bit broader than the OECD membership itself. Even the OECD

itself has its members but a lot of participants that are not members. But the the global partnership on AI uh is a an initiative that has uh at present 46 countries standing on equal footing

which include India. India was uh is is very committed to the global partnership on AI or GPE as we call it. um [clears throat] uh a as is Brazil, as is Argentina, as are other uh other current

members and in in some in Africa in across all continents today. Uh and we have uh already uh five applicants uh uh that are will probably become members very shortly. So this is um this is this

is a growing sort of membership and I think from the OECD from the OC is just the secretariat for this initiative. Um we but uh beyond that of course the the real force is not the OECD the OECD and

the GP are just groupings of countries uh but the countries themselves have uh are taking great initiative and that's where Yoichi uh Japan's initiative and the the friends of the Hiroshima process

have said are so so so important and already has as Yuichi was saying as I think you know 60 it's close to six 60 61 countries and but it keeps growing so um so so I don't expect it to stop

because uh is very dedicated to it and is working very hard thanks &gt;&gt; thank you &gt;&gt; sorry so sorry for the time is over so any questions you have you can ask the

panelist on the slide uh and the panelist you guys have come together for a photo uh and I'm so sorry That's the whole procedure right now. &gt;&gt; Okay.

&gt;&gt; Okay. No problem. [applause] &gt;&gt; There's the photographer. She right now she's Thank you. I'm sorry.
