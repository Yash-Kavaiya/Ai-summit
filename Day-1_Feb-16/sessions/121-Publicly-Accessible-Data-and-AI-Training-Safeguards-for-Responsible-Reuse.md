# Publicly Accessible Data and AI Training: Safeguards for Responsible Reuse

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 16:30 ‚Äì 17:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room No. 6 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/sSEr5E0gkjg?feature=share) |

## üé§ Speakers

- Fola Adeleke, Global Center on AI Governance
- Renato Berrino Malaccorto, Open Data Charter
- Vinay Narayan, Aapti
- Violeta Belver, ILDA

## ü§ù Knowledge Partners

- Open Data Charter

## üìù Summary

This session explores how data governance shapes ethical, transparent, and rights-respecting AI systems used by governments and private actors. It shares early findings from a research project examining the legal and ethical use of publicly accessible data in AI training, with insights from multiple global contexts. Through interactive discussion, the session invites audience perspectives to deepen understanding of emerging challenges and help inform future research directions and policy approaches for responsible, inclusive AI development.

## üîë Key Takeaways

1. This session explores how data governance shapes ethical, transparent, and rights-respecting AI systems used by governments and private actors.
2. It shares early findings from a research project examining the legal and ethical use of publicly accessible data in AI training, with insights from multiple global contexts.
3. Through interactive discussion, the session invites audience perspectives to deepen understanding of emerging challenges and help inform future research directions and policy approaches for responsible, inclusive AI development.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/sSEr5E0gkjg/maxresdefault.jpg)](https://youtube.com/live/sSEr5E0gkjg?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

to the conversation. My name is Renato. I'm the research manager of the Open Data Charter. The Open Data Charter is a global civil society organization that was born 10 years ago. We were born

actually as a charter with six principles and that different governments and civil society organizations adopted on how to collect, publish, and reuse data.

So, I'm not going to spend time, but these are the principles. You can check it in our website if you're not familiarized. [clears throat]

And we have been working in open data and we have been reshaping a little bit our mission and vision trying to understand data governance and the intersection it has with the new

technologies. So we have started working also in dialogue with digital public infrastructure artificial intelligence and also trying to balance the right of access to information and personal data

protection. So that's how we started four years ago to work in the agenda of artificial intelligence and our projects are all always with a focus on data how data is regulated the data frameworks

and the intersection with the AI strategies or policies or regulations and also the data quality that fits artificial intelligence systems nowadays. So we are trying to develop

research for for mainly for our network of governments and adopters but also for different different forums and different different organizations and governments that want uh that want to yeah

understand how data it's uh dialoguing with these new technologies. So particularly now about this session h it's connect connected especially to we have many ongoing research at this

moment but one of them is connected it's uh connected to this session specifically that is supported by Microsoft and it explores the legal and ethical boundaries of using publicly

accessible data for AI training with a focus on the boundaries that we can found in especially in data protection and copyright and it's something new for us because We always work mainly in open

government data and and now we are exploring a first project in public accessible data that it's a concept that is a little bit wider. So we want to and really try to understand uh what happens

with that data that is available what are the boundaries to use or reuse it in a responsible way. Uh so we are going to share different reflections. The the project has just

started. So we are going to share some initial findings but it's going to go on during several months and um we are also going to hear perspectives from colleagues from other organizations uh

from Asia and from Latin America. So I think it's going to be a really interesting conversation. My speakers here are FA Adele. He's the executive director of the global center on AI

governance. the governance center and on AI governance is working together with us in this project. So it's a it's a really fruitful collaboration. We also have Bini Narayan is policy

senior manager at API and Betta Bel is a communications manager at ILA and we are going to I don't know if you all have Wi-Fi or you all have access to internet but we're going to try to do a few

interactive questions through menty. So I hope it works. If it doesn't works well, we can talk in the end of the session. But I think men is a nice tool to to generate engagement.

So before we move in into our first presentations, there's a first question. If you want to scan DQR and tell us what sector do you work in, private sector, civil society organizations, academia,

government just to figure out a little bit uh how our audience is. So you can scan the QR and just send your your answers if it works well and if not we can talk in the Q&amp;A session

and then I'm going to share with you our first question our first deeper question [laughter] and then I move to my speakers but please feel free to scan the QR and then

I can show it again in the end. So if you use publicly accessible data now we're going to explain a little bit of the context and the frameworks but if [clears throat] you use uh what kind of

data are you using for analytics or AI training and for what kind of analysis in your work in your research in your studies in your university we are really interested in knowing a

little bit of your perceptions and and your experience. So you can scan the QR and then I we have more questions but we are going to come back for them after we have our presentations. So first of all

I'm going to give the floor to FA. Let me introduce him. Fa is the executive director and co-founder of the global center on AI governance. He leads the knowledge hub the African observatory on

responsible AI. He holds a PhD in international investment law and human rights from the University of Waters and completed his post-doctoral research as a Fulbright scholar at the Colombia

center on sustainable investments uh in the Colombia University and the human rights program in Harvard University. So FA thank you so much for being here and for joining us and we if

we can switch the presentation. Thank you very much Renato and good afternoon everyone. Um we're quite grateful that you are joining the very last session of the day. We know it's

been a very long day and the room is also a bit quite cold. So um thank you so much for for braving the weather um to to be in this session. So like Ronaldo mentioned um so we I um

colleague the global center on governance and we are partnering with ODC to to work on on a project on publicly accessible data and its use in AI training and and the focus of the

research really is to essentially look at you know the regulatory safeguards that are available for responsible use of public class data. And we are in terms of the the context

um for this work really we recognize that AI training you know is increasingly being is increasingly relying on data that is available on the web. So it's focusing

on open data sets but in the utilization of this data the rules are really unclear about whether folks have the right to analyze data that they're assessing publicly even

when copyright regimes we know have specific regulations in place to manage the right to access data. And the question then really becomes well when the copyright regime doesn't really

speak directly to data is already available does it mean that it is free to use? What also happens with data protection laws which nevertheless still apply to personal data even if

they are publicly available. You know, the fact that, you know, you can publicly assess people's personal data on social media platforms doesn't necessarily mean that you can use that

data for training models. And so you've got this governance gaps which essentially creates uncertainty for innovators, for public sector users and communities. Increasingly you would have

seen that there's a there's a conversation around governments serving as a provider of data for AI and that's largely because especially in in global south context governments essentially

have the most diverse data set available to them and some of these data sets are publicly available as well and the governance regime that govern the responsibility of

that data uh needs to be assessed. How do we enable legitimate development when protecting rights, privacy and trust? So the main research question really in this project is to understand the extent

to which publicly accessible data can be reused in training while respecting data protection, copyright and imaginary regulations. So we are focusing on three core frameworks as you can see data

regulations. And within that main research question, we're trying to understand how organizations both private sector organizations, non-state actors as well

as state actors interpret exceptions within these three frameworks, especially in terms of text and data mining. We are also trying to understand perceptions. So this is not just a

desktop based research. We want to understand whether stakeholders themselves believe copyright restrict analytical use of public data and what then safeguards and mechanisms

can be used for responsible reuse. So the focus of you know the research is initially on these three countries and oranto will speak more to whites specifically these three countries but

you can see that you know it's essentially spans the globe. We are looking at Brazil in Latin America, you know, in Japan, in Asia and and Australia as well. And across these

three countries, our focus is on law guidance, practice perceptions and safeguards. This research is still ongoing. So, we've got we've done some initial desktop research and the

perceptions, you know, interviews and and surveys is is going to come later on. So, it's it's a it's a it's a mixed method approach that we're taking to the research, right? We we've done the

initial desk research looking at loss case laws and industry practice. Well, I should say it's ongoing and then and like I said the service and interviews are going to come later on. And so just

as a brief introduction in the Brazilian context you've got a copyright law but there's no explicit text and determining exception within that right. So nothing really that governs this question around

responsible reuse of public liability data. You've got a very strong data protection law um which requires you know purpose good faith and public interest in in the use of personal data.

um you've got an AI governance law that is emerging which speaks about you know AI use and and oversight because it's still emerging there's a

potential opportunity there for the law to potentially clarify text and data mining and then there's an open data policy within the Brazilian context which has an open by default approach

especially in relation to you know um government generated data Japan has a slightly different approach, right? Japan has a very, at least from my own interpretation of the corporate

tax in Japan. It certainly creates, you know, an avenue for potential, you know, reuse of publicly available data. It's it has a very broad permission for information analysis provided that the

user is not using it for the unjurments. And then they also have a data protection law which Yes. I mean the point uh I was h when we are using public h public available data

where we are reusing that data and what we're trying to say is not free of limitations even if the data is anonymized it doesn't mean that for example it won't contain any sort of

bias any sort of um you know um different aspects of what they chose to include in the data and what they chose not to include. building that data. So it has uh as we say

consequences especially when you are using that data uh in the cross and intersection with more data for analysis. &gt;&gt; Okay. I don't know if we have more time

for one more question or it's we have to close. No, I think that we don't have more time. Well, I want to thank really everyone for being here in this long day

and I hope that some of the ideas uh really reflect on you. Uh for us in this research is just the first step. So we we will be happy to to keep in touch. Um and yes, here's my my email if you want

to keep on contact. We are just starting. We are going to be sharing uh the results as we advance and we hope we can keep the conversation. We we we ran out of time and we didn't we couldn't do

all the questions that we wanted but this is just the beginning. So I'd be happy to catch up and chat with you later. Thank you so much.
