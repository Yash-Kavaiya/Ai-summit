# Building Trust: Digital Infrastructure Fit for the AI Era

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 16:30 ‚Äì 17:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 A |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/y5-7BnPfIMQ?feature=share) |

## üé§ Speakers

- Dr. Arvind Gupta, Digital India Foundation
- Dr. Tomicah Tillemann, Project Liberty Institute
- Robert Opp, United Nations Development Programme (UNDP)
- Sarah Nicole, Project Liberty Institute
- Supheakmungkol Sarin, AI Safety Asia
- Vidisha Mishra, Global Solutions Initiative

## ü§ù Knowledge Partners

- Project Liberty Institute

## üìù Summary

AI is reshaping how sovereignty is understood for individuals, communities, and nations. While governments played a major role in building the early internet, private actors have also shaped the digital economy. Today, AI development is largely led by the private sector, raising questions about how to align innovation with broader societal goals. This panel will explore how to build trustworthy infrastructure through public-private alignment and governance approaches that prioritize users and accountability. Key takeaways will be distilled across international policy platforms.

## üîë Key Takeaways

1. AI is reshaping how sovereignty is understood for individuals, communities, and nations.
2. While governments played a major role in building the early internet, private actors have also shaped the digital economy.
3. Today, AI development is largely led by the private sector, raising questions about how to align innovation with broader societal goals.
4. This panel will explore how to build trustworthy infrastructure through public-private alignment and governance approaches that prioritize users and accountability.
5. Key takeaways will be distilled across international policy platforms.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/y5-7BnPfIMQ/maxresdefault.jpg)](https://youtube.com/live/y5-7BnPfIMQ?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

probably nine 10 platforms in the world. That's what DPI breaks. And I think um the lessons can keep going on on on technology interoperability protocols. But I think at a high level the

credibility and um trust factors building organization and um institutions around it leadership vision executed with a bottomup you know human-centric approach and taking two

large no pilots large scale implementations. Of course in India large scale means size of a country mostly but uh some other country but uh that is that has been the core

success formula for us. Um and u and lastly I think u the amount of headwinds you face one has to learn to navigate. uh the headwinds in any DPI implementation whether it comes to the

AI world and now the the last world that we are seeing part of uh the India stack for example is a layer called DEPA it's called data empowerment and protection architecture which is going to be used

heavily in the AI layer that we are building the AI stack we are building because that's personal data how do you share it how do you use it to your empowerment but not give it away the

point that you made and that is um you know that again requires um both legislative backing regulation backing. &gt;&gt; You think about the values that undergur democratic societies. We care about

openness. We care about accountability. We care about transparency. We care about opportunity. The technology that we have seen emerge from platforms is largely centralized. It's

surveillance-based. It's increasingly autocratic in in the way that it operates. And so there's a gap that we need to solve for there. And unfortunately, if you look at some of

what is happening with artificial intelligence, we're just on uh track at the moment uh to speedrun the mistakes that were made in the last iteration of technology. And so we believe there's an

opportunity to do things differently to build out an alternative socially and politically. We're going to need countries and jurisdictions around the world that care about these values to

put forward a different vision for a tech stack that is aligned with our value stack. Uh and we think that's entirely doable. Uh we think we can build technology that is better

optimized for the decentralization of trust that was referenced uh a few minutes ago. The second component of this is is the technology itself. And there are a few specific pieces of this

when it comes to AI. We has anyone uh followed what has happened with Molt Book and the Claudebots over the last little while? It's been pretty wild. Uh for those of you who've seen this play

out, you now have AI agents that are creating their own social networks and talking to each other. We are going to have a proliferation of AI agents. And there's a big problem at the moment,

which is that in any other domain, whether it's sports, whether it's real estate, whether it's entertainment, if you hire an agent, that agent works for you. But in AI, if you hire an agent,

that agent probably works for Sam Alman or it works for Elon Musk or it works for somebody else, but it doesn't work for you. We're going to need agents that work for us, that help us manage our

information and our data in a way that is consistent with our wishes and also uh provide clarity around uh who different actors on that agentic web are representing. So that's going to be one

piece of this. We will need to build out sovereign agents uh that are accountable to us as individuals. The second piece of this more broadly is we will need to ensure that there is data portability

and interoperability as uh Arvin was talking about a moment ago. We have seen a huge issue again with the last generation of platform technology where once those platforms capture you and

your data and your network effects, it's almost impossible for you to go anywhere else. And at that point, you are no longer a customer for these uh platforms. You're a product. and and

that's a lousy situation. We don't want to be in a a position where we are the products of AI companies certainly because all of the issues that we've witnessed with the last iteration of the

internet will be magnified by orders of magnitude going forward. So we need to design systems where we control our own information and we can move that information around to whatever model or

whatever agent solution is going to meet our needs best. This is going to require technical code. It's also going to require legal code. And we are championing legislation in jurisdictions

around the world that is designed to give people control over their data. Lastly, we are going to need economic models that make all of this possible. Some of that will have to do with the

procurement structures that Mongol was talking about earlier. Governments need to put in place good standards for how they're going to purchase AI. And some of it is going to do with how we as

individuals choose to expend our dollars uh to purchase AI systems. If we do these things, not going to be easy, but we think there is an opportunity to build a technology stack that is better

aligned with our values. &gt;&gt; And before I get I I I announced it at the beginning. So we'll have uh to do a Q&amp;A. Uh I'll I'll keep my word. Um so we'll take two question from the

audience. But before we do this, um I I wanted to go back again to all speakers to get uh your thoughts. Uh that that would be for after. So keep it and and and I'll get I'll get back to you. Um I

wanted to go back to all speakers uh including Vidisha. Um and ask uh so a question that citizen have a lot in mind is uh um all of this is really accelerating. All of the harms are

accelerating. The development of AI is also accelerating. Some believe uh AGI will be there in a matter of month, matter of year. Anyway, uh the threat is palpable and is there. Um and yet a lot

of what we're discussing is actually not so new. A lot of it is about data uh that have been here since uh the origin of the internet and we've been basically with our uh uh activity on the internet

for the past decades have been feeding also those AI model. So what would be uh good framework and good model that could keep lasting regardless of the innovation that comes out regardless of

the next model of AI. How can we build truly resilient system so that citizen also don't feel that government are lagging behind uh that technology are the forefront of technology and that

they are truly helpless. Um I'm going to head over to to you Arvin with this tough question and then we'll hear from Robert Tama Vidisha and Mongol. I uh I think um first of all before I

answer your question I must say that if there is a uh I know there are many great advocates of DPI but uh what uh uh Tomaya just uh summarized for us I I just said not one but 100 votes to him

if he can just replicate that that vision is what we have been saying but now it's nice to hear others uh saying that so you know um uh you know uh and and the reason I say that is I was part

of the earliest earliest internet that you can imagine and we did everything wrong ever since the world values of web 1.0 2.0 to it's all destroyed right so I think there is a there is a chance uh

these AI impact summits happen once in um once in 12 months and that's too long because uh that's now two more cycles so by the time we meet next time um everything would have changed completely

so to your point the resilience um angle has only two aspects to it o overall it's it's a credibility and trust but that has two components to it one is um who owns the data. How do you because at

the end this is the data war. Uh whether now today that becomes the platforms were sucking it up for for advertising or surveillance or data capitalism or now it's it's the AI which is uh taking

your content your personal data to to make agents for you which which are sucking it up every day. So number one is how do we um how do we create technolal frameworks for data personal

data to be protected with technology with and and make it uh you know as I said the day APIs and make it interoperable because boundaries won't exist and don't don't exist any longer.

So that's that's number one. And number two is how do we have international safety standards and and non-weaponization um both in commercial and non-commercial

uh um usage uh of um agreements. I think we have to have this now um uh in place where where more u more and more people have to sign up to that um and and this is going to be very key because those

are the two three frameworks that we can do which will last uh technology. &gt;&gt; Yeah. Um just to maybe pick up on that last point from from Arvin. Of course um the United

Nations has a process ongoing around AI and the development of AI and the governance of AI which is um you know subject to the speed of the multilateral system um and the divisions that are

inherent in the multilateral system. So it's challenging but there is progress and there is a annual policy dialogue that is implemented. There's an international scientific panel that's

just been formed. Um and so there is a kind of at the the the intergovernmental level there is a global discussion happening on that. Um but the speed is a a huge challenge. Um but my answer to

your question uh Sarah would be um the ability to create sustainable models will depend on the agility of institutions and the agility of institutions depends

on the capacity of the people in them and the ability of um what you know civil servants or others to to be able to really quickly be able to adapt to the new realities but keep the kinds of

core governance um positions and the values at the center of that. So there will be you know quantum and all of the rest of the you know bioengineering and everything else is going to just

accelerate more and more and more but um if you don't have that that agile institutional capacity it is just not going to be possible for national governments to keep up um and adapt uh

quickly. So I think that's what I would say in addition to um as Arvin said it all comes down again to credibility and trust which means part of that agility that you want to build into your

institutions is being able to ensure that you've got voices from different constituencies and stakeholders across society to keep it focused on the values that you have as a nation.

&gt;&gt; And I just pick up uh where Robert left off. If you think about again going back to where we started, who should be driving the process of evolution uh of this technology right

now? We are on a trajectory that is going to benefit a very very tiny handful of people who sit on top of the frontier model companies. Even when you talk to those people and occasionally I

have the opportunity to do that, they are very uneasy about what that looks like for the most part. Generally speaking, these are not evil people, but they are being driven by really bad

incentives. And we need to own up to that and do what we can to change those incentives. Instead, we need to focus on building systems that are going to work for the communities that they are

intended to serve. And if we can make that our guiding star, the institutions will need to adapt as as Robert said, we will absolutely as as Arvin said a moment ago, need to ensure that people

have control over their data because that is going to be a through line. You know, here uh five years ago we would have been talking about DPI. Today we're here on AI. In five years, we'll be

talking about quantum. Data is going to be the through line through through all of those. So control of data is going to be foundational and fundamental to that. But ultimately we need to build systems

uh that are designed uh and and build movements uh that are going to ensure that there is good governance uh of these technologies uh by the communities that they are intended to serve. There

is a small window of opportunity left to do that with AI. Uh I hope we will take advantage of that opportunity. We'll hear from Vidisha and from uh Mughal but uh reminder that I'll get

back to you right after. We'll take two to three question maximum and I'll need you to be sharp in your question so that we can hear from all of you. Uh Vanisha. Oh, well thank you Sarah and I mean I I

will just echo what has been said already but um you know my organization we were involved a lot in the EU AI act and given how long it took for that act to actually come into being and then it

was immediately outdated even before it came into being. So the point on agility I mean absolutely we need a basic minimum standard broad broad global resilient framework that centers some

values that are non-negotiables and those have been beautifully captured by Tomica already. It is important to center public interest. It is important not to incentivize this profit

maximization mentality as we're racing towards AI development. So yes, that resilient broad framework needs to be in place and that is non-negotiable. But at the same time, we have to recognize the

fact that a lot of these processes take a long time. So there needs to be some sort of a mechanism that is agile enough to react to these developments as they're taking place. There's also the

uncomfortable truth that that's often repeated and it's not necessarily true that oh the people making policies don't really understand technology and technologists don't really understand

legalities and policies. So we recognize that there's a bit of a silo and and is important to bridge that silo maybe in small steps. Um and then finally there's a lot of global fora at this moment.

There's a lot of good work being done by the G7 by the G20. Of course the UN modalities resolution is a huge step because that remains the UN remains the place where the smallest countries have

representation and a vote and a voice. So these are all good steps in the right direction but there needs to be more interoperability even within these global fora and standards. Don't stop

there. &gt;&gt; Okay. Thank you. I think the the panelist has done a great job on uh elaborating what does it mean. Uh I would just want to double click on what

uh Ralph mentioned earlier. I strongly plus 100 to that. Uh AI assurance is uh institutional assurance. So we need agile inst in um institution to uh be able to cope with the rise of AIS and

and whatnot. Uh a couple of points that I would like to add is that empowering the user. We have to put the user up and center and that means we need to educate the user as well so that they understand

what does it mean? What does trust mean to them? What are their rights to uh use this technology and not use this technology? What can they do uh to empower their agency to decide and adapt

to this new technology? Um the second point is on um we should leverage researcher and scientists. Uh that's also congratulation to the UN on the panel of the 40 uh distinguished uh

expert on on scientific uh independent scientific panel on AI. I think we each country should look at their researcher and uh their scientists to leverage what they can do to help in term of um

creating new benchmark, adopting technology, uh creating trust in their own local uh context. Uh the the third one is the civil society. Civil society also play a huge role. They are the

angel of the society. But at the same time right now as we know that uh the funding is really uh constant uh they are also themselves will need to catch up with this new technology uh because

many of them are coming from I mean ourself also coming from human right background and we need to catch up with this new technology we need to understand what is technical alignment

what is reward hacking uh what is multi- aent uh coordinations and and whatn not so we need to catch up with this technology and there are really Muslim funding for uh civil society. Uh so uh

we saying that there's less than 1% of the funding on on safety research and and civil society and the 99% is on just accelerating this technology. &gt;&gt; Yeah. Have concluded.

&gt;&gt; So it is about cross- sector collaboration. Uh it is about interoperability. Um agility uh of government and uh more AI impact summit as well. uh if I recall

correctly uh if somebody is taking notes about that. Um all right, time for questions. Um I Okay, so we'll go through one, two, three, and four. Please make your

question super fast. We have five minutes sharp and I'll probably give you my mic and I'll They have a mic. Okay. Do you have a mic? &gt;&gt; You don't you don't have a mic. Okay.

&gt;&gt; Yes. &gt;&gt; Oh. Uh thanks for the great talk. So um one question I had was like there's a lot of assumption that AI would be a complimentary technology in the sense uh

it will always empower humans but with AG and the rate at which it's improving we can there can be a case made that um the rate at which it's improving is higher than rate at which people can

upgrade and upskill and also the bar to uh re uh like upskill is also getting high only like the access to upskilling is restricted to a small set of people. So how would um just giving access to a

is one thing but also being able to leverage and um use it for their like their own empowerment is much harder. So how would um governments plan to um like give like broad access to this

technology? &gt;&gt; Thank you. We'll take all questions all at once. So there was uh one next to you uh one behind as well and then one over here.

&gt;&gt; Yeah. Myself Januk Makon. adopterate research in geni I'm studying that uh like we we know that like there are the big gaps between the two AI tools and the real adoptions of those so I think

for empowerment trust and awareness like why we are not thinking about AI with people instead of AI for people where like people contribute to the AI initiatives and again I think it will

generate the some some income for those individuals as well so that's idea &gt;&gt; thank you very much there was behind. Uh yeah. &gt;&gt; Hi Praep. This side we are working on

IPR intellectual property right and genai also. So there should be like any infrastructure when we are saying like uh infrastructure as in like there should be a norms like uh that should

that should be a must be legal framework basic understanding. These days multiple startups are like uh taking data and there is no norms for that. So basic minimum infrastructure from government

side as a international level that should be complied with that is my question is there already governance in US is going on as you guys have already told. So like is there basic norms can

be like white paper can be released first. &gt;&gt; Thank you very much. Uh we'll we'll take your question because I didn't see your hand. So I'm sorry about that was like

your question and your question and then we'll get a a mix of response because your your question are all good and very complimentary as well. &gt;&gt; Thank you so much. Uh I'm with Consumers

International. We're the global membership body for consumer groups around the world. Um and in hearing the comments around the importance of frameworks, global frameworks as well as

importance of local contexts was wondering if you could speak to the role of consumer advocates and um what they can do to help bridge that gap. &gt;&gt; Thank you very much. And there was one

uh here. Yeah. Okay. And and and I'll give you my mic and you can give me back my mic. &gt;&gt; Uh thank you for the session. Uh uh in um in this work uh you said that the

states are predominantly they are moving towards building sovereign first models. Uh if they are the foundational models uh then uh the interoperable interoperability is one is going to be a

big bottleneck. uh and then the these things are going to create a silos again. Um um especially uh when we take about building the trust um of the citizens to use these models or sharing

the data. Uh do you think that uh we need to be building uh a solutions which are predominantly be taking those quantum of communications building the data layer

solutions where these intermediary layers would cross across can be sharable can be usable across all these models. Even though if the models by themselves are

uh are standalone models uh sovereign first models. Okay. So we have question on sovereign creation on infrastructure question on consumer questions on AI for people. So who wants to take what in uh

really a sentence per speaker? Who would like to start? &gt;&gt; Arvin. &gt;&gt; Yeah. Quickly take two uh two if you don't mind. one is on the sovereign

first or data localization is going to remain a regulation and um it it is verticalized and it's going to be a regulation everywhere uh as and when um u the sovereign first models or SLMs

they get developed data will remain uh something that uh both uh politically as well as socially uh governments will be obliged to protect localize so a kind of that what I talked about a data um

empowerment architecture which is consentbased sharing uh time bound and for a particular uh purpose will will really become very very important in going forward on the consumer advocates

um I think u consumer advocates in my experience put uh are the real check and balance for for um safety and trust especially so uh they can't be left out um uh it starts off as a little bit of a

forp especially I can wear my previous hat as a policy maker. It's a prickly discussion to have consumer advocates but eventually you come do come to realize that it is it is something that

um that really is uh part of the feedback loop to improve and and uh give us the check and balance. So thank you &gt;&gt; and I'll say just a quick word on uh norms uh and and uh some of what was

referenced earlier. We are seeing this start to roll out. So, in the US state of Virginia, uh, last week we had legislation that mandates data interoperability and portability for the

context of your communications with AI models. It passed unanimously in the Virginia State Senate. Uh, and we're seeing similar legislation roll out in many other places. Ultimately, it's

going to take a movement uh to to make that happen. We will need a lot of consumer advocates in that movement. Project Liberty has about 200 organizations that participate in our

alliance, which is our movement arm to make that happen. Uh if any of you are interested in being part of that movement, please come talk to us. We would love to have you uh be part of

this broader community that's working to build a prohuman future for AI. &gt;&gt; Robert in Mongol, very quickly because there's a red sign saying time is up. Super quickly just on the access uh to

upskilling issue. I mean we tend to see this in terms of ecosystems. Um so it's not just access to up uh upskilling or capacity building but also access to compute that's affordable. Uh access to

data that's reliable, accurate etc. But I will say the requests that we get from our country partners around the world really capacity is at the top of the list and it is absolutely necessary to

make all of what we've talked about here today a possibility. um to make agile institutions to have a flourishing innovation ecosystem and so on and so forth. We are seeing some ramping up of

this. Some of it's coming from private sector companies who are looking for workforce. Others are being rolled out by government but ultimately we definitely and completely agree with the

person who asked the question that this has to be a priority for countries around the world. &gt;&gt; Want to add quickly on the role of consumer um international advocacy. I

think it's really important uh to Tomica what Tomica is saying that we don't want to be the products uh of this uh advanced system uh and model and one things that consumer international can

do well is the working on the redress mechanism because there will be incident how do we help consumer when there is an incident so the redress mechanism will becoming very important in the coming

future Thank you very much. This was a very loaded discussion. Uh we've ran over time. Uh but very fundamental discussion. So thank you very much uh

everybody for joining and please join me in applauding our manif [applause] panel. Thank you. &gt;&gt; Thank you.
