# From Buzzword to Blueprint: Engineering Sustainable AI at Scale

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 11:30 ‚Äì 12:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 18 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/nxc1XDyljP0?feature=share) |

## üé§ Speakers

- Archana Joshi, Xoriant
- Dr. Gayathri Aaditya Eranki, Sir M V School of Architecture, Design & Planning
- Dr. Niladri Choudhuri, Green Computing Foundation
- Jaskaran Singh, Birchlogic
- Naresh Choudhary, Infosys
- Srinivas Varadarajan, Vigyanlabs
- Vineet Mittal, Ziroh Labs

## ü§ù Knowledge Partners

- Green Computing Foundation

## üìù Summary

This session brings together distinguished thought leaders from industry, academia, and the startup ecosystem to explore how AI sustainability can transform from an abstract ESG aspiration into a measurable engineering discipline. The session will draw out practical insights, frameworks, and actionable guidance that practitioners worldwide can immediately apply. The questions asked will elicit specific expertise from panellists while building a cohesive narrative.

## üîë Key Takeaways

1. This session brings together distinguished thought leaders from industry, academia, and the startup ecosystem to explore how AI sustainability can transform from an abstract ESG aspiration into a measurable engineering discipline.
2. The session will draw out practical insights, frameworks, and actionable guidance that practitioners worldwide can immediately apply.
3. The questions asked will elicit specific expertise from panellists while building a cohesive narrative.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/nxc1XDyljP0/maxresdefault.jpg)](https://youtube.com/live/nxc1XDyljP0?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

No, let's let's answer it. It's a fair question. Uh so so I mean Japa is a very very new concept. Uh it is still under wraps. Yanakun has been speaking a lot about this. Now if we look at where is

the relevance of Japa and why the talks are even coming. This is more about how do we define artificial general intelligence. So is human intelligence around language processing or is it much

more than that? That is where Japai is heading and when we want to build systems which are physically aware uh which are really able to take real time decisions the the question is is are

LLMs enough or do we need a new world uh architecture I think things will move there but I would say it's still early stage. uh the second thing that I want to tell audience here is while there are

these talks of AGI and advancements there's a lot that can be done with the existing advances itself so I would highly encourage students to first learn the existing technologies pro possibly

and see how you can put it to good use &gt;&gt; namaste my name is and we are also trying to bring closer academia and industry. I was working for last 18 years in industry and uh as a

machine learning architect till September 25 and now I'm working with the students in the real project based learning. So I'm I a question with the uh all of you probably uh that how the

people like uh we are working right now on a very small scale and how we can collaborate uh for the job or uh for a job market like Aperna with the tabs.

Um Roma you talked about lot of initiatives which Google is taking and funny when you are talking about that government is taking lot of initiatives in skill upskilling. So I a question

with all three of you how we can or how uh uh what are the ways where the where where the industries of our scale can collaborate.

&gt;&gt; Thank you. So I'll give you a prime example of uh talking about collaboration with a small scale uh company with item has already uh is institutionalizing within its

ecosystem. It's a um uh without disclosing the numbers suffice it to say it's a small company based out of Silicon Valley but with really good technology okay that could be

potentially disruptive and we have partnered with them company called Blaze and uh putting up a center of excellence in uh ICOM headquarters right and we are looking at on the other end of the

spectrum we have partnered with u Pearson which is a 5 billion ion dollar curriculum company and we are partnering with the likes of Google and whatnot and all of that right so we the whole

philosophy that um I'm creating uh and under the vision of honorable uh chief minister Rayundaru and honorable IT minister Srugaru is uh to create an open platform where

we can spread our tentacles to the rest of the ecosystem that includes the industry academia and research So I'm more than happy to uh take an offline conversation with you and connect you

with the necessary people on uh my team uh to uh have a program in place with you. &gt;&gt; Thank you. I'm just conscious of time. We

wrap this pan for now and we look forward to engaging with many of you offline. &gt;&gt; It's also very grateful to all the speakers for making time to be here. We

have a small momento which we would like to share with all of you. Take take a moment for that please. I think you want to pull up on the scene.

Indonesia. But what we have learned, what we have actually seen, what we have made different students, startups, corporates to actually perform during our green

mind sustainable hackathon which happened from 31st October to 15th of November in Bangalore. And in my panel we have Archa Yoshi. She's a AI strategist currently working

with Zoran. We have Nar Chri, senior vice president infores who looks after not only the the DevOps tools but also the AI implementations throughout the

organizations. Not only he is a senior chief architect of Aadhaar but he has his own company called Vidyang Labs which is a completely green data center

where CPUs, GPUs everything runs &gt;&gt; in around 100 plus kilow not even near to a megawatt right we have with us Dr.

3 U she is the principal of SM school of architecture design and planning where we have launched our sustainable AI center of excellence. We have Venel he is the senior vice presidents of zero

labs. Zero's created quite a amount of noise because they are the ones who work with Madras and now working with various organizations and Intel where they have modified the open-source LLM to run on

CPUs with equal performance as that of GPUs which we use for our hackathons and we have current Singh he's a person from your city only. So all of us others have come from Bangalore or Pune. So

Jascaran is co-founder of a company called Blogic and we have a tool called sustainity which we have used to calculate the carbon footprint water usage of it and AI and we use that in

our hackathon also. So the question here is can AI sustainably be measured as precisely as latency or accuracy? What do you think?

&gt;&gt; Yes. No. So can we move beyond treating sustainable AI as a marketing checkbox and instead make it engineering discipline? So sustainable AI with

concrete metrics, framework and measurable outcomes. So here our panel brings together the architects and evaluators of green mind sustainably hackathon whose empirical findings now

inform sustainable AI practices globally. So just to give you some example I have put two slides of two different use cases which has happened during our

hackathon. One is a cancer treatment recommendation within 15 days. Obviously cancer treatment is big. They give it only for the breast cancer using small model and models from uh zero lab and

you can see the figures there. Later on I might come back to this if you want. And the other one is the RTI search assistant which is from a company from Gujarat and this is also running there

where details of the documents are put into the system and anybody everybody instead of going through the processing for I mean filing a request then somebody government official look at it

send it across it's not like that anybody can just look at it v it and get it. So my question to you, what percentage of your organization's AI teams track energy consumption as a

metric? So anybody where more than 50%, can you put up your hand? More than 50% of your projects track carbon footprint of your AI projects.

Okay. 25 to 50%. Okay. I have one or two nice we should talk sometime and less than 25%. &gt;&gt; But more than zero

&gt;&gt; okay I still have that's good. Um so the first question that I go to just is about the measurement because we talked if we what we do not measure we

cannot improve right so you find the term energy intensity score and break the sustainability to measure it in real time across all

hackathon teams in simple terms what is EIS and why does measuring energy per unit of useful work matter more than measuring total energy consumption. How did real time measurement change how

teams approach optimization during the hackathon? So here on the screen I have put some dashboard from the but essentially means is that we measure

total energy but then we also measure total work. So EIS is total energy divided by total cost. In a way you could say it's very similar to if you guys are acquainted with the concept for

unit economics and synops just measure total cost of the cloud or the data center. You also measure the business outcome of it and you correlate to that. So EIS does that. Now why is it

very why it's needed is that we have different use cases in AI. We have NLP, we have classification, we have vision AI. So for all the specific use cases we have different work done for some it

might be total number of tokens consumed let's say for a chat application will be total number of token system for a financial application using agitic system it will be total number of

transactions so at the end of the day teams were competing not on the metric of total energy they were competing on the metric of total energy by total work done.

So what we saw is that if the if there were if two teams had a similar use case let's say a chatbot but we discovered that two there was 0.6 to 1.2x differential for the same which means

even the usage was the same even though the total work done was the same the total energy was vastly different because of the different architectures. So that was a very good playground for

the team to some creativity get like how to optimize the model how to optimize the whole architecture so that's why EIS was introduced and that's how like our team

get around that &gt;&gt; thank you Jas so we go to Acha now as a hackathon jury member evaluating solutions how does having concrete sustainability metrics like EIS change

the conversation with leadership does it shift sustainable from minds to have to business imperative And given the government's emphasis on AI as an economic multiplier, how can

organizations align sustainability metrics with broader business and governance goals? Now you already know that there are multiple ways of calculating carbon footprint I mean the

the whatever metrics we are looking at blocks and so on each has its own positive and negative right so we have to choose number one number two we have to have kind of a multi-level

calculations just not one single calculation of a number right yes &gt;&gt; thanks for that &gt;&gt; so I would say by taking an example. So let's assume you are flying a hot air

balloon and during hot air balloon you would probably look at the direction of the wind and you say okay is it cloudy is it not whatever and you kind of start flying.

Now the same thing let's say you are now flying the air or going and imagine you are giving instruction to the pilot saying hey outside the weather looks cloudy be careful when you

land versus giving an instruction to the pilot this is the wind speed this is what is the visibility like this is how much fuel you have in your plane left and now make a landing right so if you

are not calculating the metrics of the way you are using AI it is like selling the final provides cloudy lines which doesn't help at all. So if you're using AI at enterprise scale, if you're using

AI to scale and actually get benefits that you are supposed to get, you need to know how much my AI is costing. You need to know how much efficient my AI is. You need to know how much.

If you look at the budget 2026 which happened few weeks back in there was lot of tax benefits that have been given over there

tax benefits until 2047 but you have to claim those tax there's a clause there which says make sure you are giving efficient How do you define the efficient dynamic?

So it's looked at from what we call as the intelligence that you can gain for the rupee that you spend. Now if you are doing efficient which is also energy efficient automatically this will start

increasing if you don't do that you also spend lot more time energy money all the energy resources on your bills all of that &gt;&gt; so if you are not tracking metrics like

in your company I would say it's going back to like telling the pilot land in a cloudy weather without giving any kind of information and benefits. So if you have to go and not just get tax

benefits, look at how your PCO of your uh AI implementations are, ROI of your AI implementations are any kind of these metrics are crucial important. I think moment you start implementing AI better

start implementing these metrics as well. &gt;&gt; Thank you. Very important point and if you look at the thought process that is here the three sutras. So we are

touching on the planet sutra right and if you look at the seven chakras we are touching the number five chakra which is innovation resilience and efficiency and if you

don't have resilience you don't have efficiency also right and if you are looking at any startup if you're looking at any corporate profitability is important and where is the cost the cost

with it is mostly resource cost compute resource cost if you can optimize the compute resource that's where your cost also comes from imagine a situation where today a GPU costs the newer

versions around $60 to $70,000 whereas you are getting a newer version of a Intel Xeon 6 generation chip at around 12 to $15,000 see the difference

where you can get four chips you can get one GPU chip Now PM is talking about AI for all inclusion of everybody. So if you look at the other chakras where we are

talking about the the social empowerment, we are talking about everybody's access to AI only the GPU it is not going to work. How muchever government wants to give the GPU they

will give it for only for the trying out part. What about the actual production? It doesn't work that way. Right? So we come to the point where we are talking about use of a network of micro data

centers which are green which are much less costier which is much more efficient and that's when we have founder of bigam labs Mr. Raas Varad Rajan. So Sri the press conference

highlighted that sustainable AI isn't just about energy water usage for data center cooling and it is not just significant there. So how does edge computing and distributed infrastructure

address both energy and water efficiency? What measurements matter beyond just electricity consumption? &gt;&gt; Yeah. So one of the things you know as I just look at the AI world right it's the

training part in part training is going to be done few people small training when we do reinforcement majority is going to be in the edge infants a small infrastructure

looking at the kind of population density we have we have 100 right infant what does grass industry Right? We need to look at a new form of production just

like you know the PC revolution the computing right computing we need this in the edge to revolution everybody today as of look at the traditional model of you know edge

infrastructure is very expensive resource consuming India is a country with you know you know limited scarce land resources scarce water they don't even power the rat

How do you design infrastructure which is energy efficient to the core consume minimal amount of natural resources same time we made water

so our learnings came from you know from designing other and building such infrastructure around the world small countries these basic 1 million population 5 million population

there was no need of money to build a very occur to me that why can't you start building one show the world so what We have been designed a micro data center.

What's the definition of microenter? It consumes less than a megawatt of power or 50 racks roughly. And what we do while building it, we reook at the way

data centers are built because we have been designing and building for decades. Let us reimagine everything. So every company of data center re reinvented. So my fundamental approach was have a piece

of land. How much solar energy we can generate. So you bought a piece of land a small piece of land 602 precise how much energy can generate we can generate only 60 kg can redesign everything to

consume lot more than 50. So we went to other engineering designed the building reduce the cement by 70%. Also use special thermal materials to keep the building naturally cool.

Next we elevated bus parts we change the chillers. We our goal was to use zero water for cooling. We use air conditioners

again model typically energy of the air conditioner came down almost 80%. We ach

everything the server storage comput and one year is address 35 k we have got 5070 devices of data 2 60

we're in GPUs it all our a CPU And I'll tell you example one of our large customers let's say B model of power and point model

and what's the kind of energy you consume per right is 013 W per ter and so we have reimaging you can build you can build this one in 96 months a small corner plot

you may need you He did today the batteries become very very affordable. We don't need water. So that's what we are showing the world that you can build very sustainable cost effective reliable

green is it efficient relable what kind of work you run you do 9 billion a month a small lot of workloads

messaging banks of course First set of customers who were to India then slowly

running out of amount of energy is about 5 million of water and our tech runs you know banks in everywhere and we have proven that we

can build as a country we can millions thousands of such energy efficient sustainable and weune right we offer the same we offer the

same SLA service quality and delivery as Google demonstrating that you can be sustainable profitable at the same time the same thank you

&gt;&gt; thanks so [applause] I don't know if You have heard we talked about a 1.1 PU generally big data centers a very good one is around 1.2 most of it is 1.5 and above.

So you can see the efficiency power usage efficiency and another thing that we talked about is the size. Today's big data centers we are talking about hundreds of acres. So

with that hundreds of acres per acre what is the amount of work that is getting done is something which we have to start measuring. So now that we have learned about measuring now we will talk

about optimizing right in the hackathon we talked about a four layered architecture where layer one is design and data. So right sizing models efficient data handling layer two is the

training and tuning using things like lora quantization efficient finetuning layer three is inferencing and servicing serving which is like using rack using caching using prompt optimization and

fourth layer is infrastructure which is edge computing and efficient hardware selection. So with that we will come to the perhaps the most surprising hackathon finding out the layer three

optimization which is rack semantic caching and comp engineering reducing energy consumption by 60 to 80% before teams made any infrastructure change. Can you explain why these software level

architecture patterns deliver such massive gains? What should the development teams prioritize? Is it model optimization, architectural pattern or infrastructure upgrades?

&gt;&gt; So I'm from a company called you can look at the website www.com. So the reason we are having first of all the sustainability discussion because GPU is very powerful single GPU consumes

the same wattage that your diesel consumes at home 1 kilow now when something consumes 1 kow per hour we all should be really alarmed right you know and many of these US data

centers they are coming to India because they run out of power The question for us in India is that are we just going to sell our power that was meant for resential use and give it to

these large American data centers for even more what do you call this bad air in my view. So we started questioning some of these things and as already mentioned one major advancement that

Shini and his team has done is to create these micro data which you all heard. The second point I will make is what zero labs is doing which is to make AI available on GPU.

Now you all have been hearing that AI is only run on GPU. That is not true. The main thing that AI needs is ability to calculate two matrices and CPU Intel fifth generation six

generation are very well equipped to actually calculate matrices at clock speed. I can multiply 2.3 billion matrices in 1 second and then we can have more code. So now suppose you can

do AI on CPU. What is the real benefit? First the real benefit is that your cost will reduce one in terms of power from 1 kilowatt you will go down to 250 W that is a very very clear.

The second point is uh that your cost the initial capital investment one GPU costs about 20 lakhs server grade GPU u Intel GPU will cost about you know let's say about

&gt;&gt; so the cost infrastructure also massively now to address the Maji's question which is you [clears throat] know what we saw at the hackathon

what what we saw in the hackathon is that when you are building AI applications, you have to be very cognizant of your data pipeline. You have to carefully engineer them so that

you are not creating too many long contracts and what you can take from the cache. Why ask LM all the time the same question, right? So there are various middleware techniques that the

participants were able to use. They were able to use small models as effectively as the dark models and they were able to run it on C. So I highly encourage all of you to look at our website. Uh it's a

game changer. We don't really need any changes. Thank you. I think now we will go to the we have looked at the infrastructure but

software is also important. So Asha talks about the application and that's where I'm coming to N. So from an enterprise perspective, what would it take to integrate energy efficiency

metrics like EIS into the standard dashboards that your AI platform teams already monitor for latency and accuracy? What resistance do you anticipate from engine teams and how

would you address it? You have been working with the DevOps SR kind of area, the observability kind of area. So how does the sustainability related observability also play a part here? And

it's certainly and I'm building on what my colleagues on the panel have said purely from an enterprise lens. You know the idea is to sort of look at it in the same operating rhythm. Uh all

enterprises right big small uh large have some sort of engineering metrics that get tracked all engineering teams track. uh very likely you are tracking now for

accuracy for throughput and you know things like that right uh so if you can sort of bring in some of the EI related metrics that we spoke about earlier sort of into the same operating rhythm I

think that's first second important thing I would say is the ability to instrument this now uh you you perhaps need to build hooks into your containers into the hardware right and again GPU

CPUs whatever you eventually end up using uh once you build those hooks you have some of this data actually coming coming out right and once that data comes out the ability to actually look

at this data in a single frame of glass u so you're looking at your engineering metrics you're looking at the efficiency metrics together the uh second aspect is sort of thinking

about this from a cultural unlock perspective because a lot of times engineers sort of focus so much more on the other aspect right we through and the velocity and those kind of things.

So helping them to sort of see some of these metrics and these metrics look a little different, right? So you may be looking at what does it cost or how much energy am I expending every time I

inference, right? Every time I go back and forth with the model, small language or large language model, right? Uh how many jewels per inferencing for instance, right? So if you start looking

at some of these metrics and then bringing them in line with your other engineering uh metrics that you are actually already tracking, you can in some ways drive the culture of unblock

where all engineers, engineering teams, leadership, operations teams, all of them start to look at it uh in a single thing and sort of think of this. The other thing we are constantly doing is

uh uh you know driving this balance right. So if I were to optimize, if I were to actually uh change my performance parameters and move the needle on performance,

uh how much do I you know sort of from a benchmark perspective go and uh look at other aspects of the model, right? Or other aspects of the hardware that I'm consuming. So how do you draw this

balance and once your metrics are in place, you have the ability to actually benchmark. So I would say uh one bringing these on the single pane of glass. Second, ensuring that these

benchmarks are actually used in decision making. For example, I would not let a model get into production beyond my development and testing if it doesn't follow some of these benchmarks. So, I

think that's what I would say sort of helps in terms of enterprises looking at this at scale. &gt;&gt; Thank you. I think every developer also needs to start thinking of sustainable

activity along with whatever else they are thinking today then only things will change not it will not come as a fit later on right now coming to the layer

one which is the design and data now we saw in the hackathon that 7 billion parameter models with Laura finetuning matched 70 billion general general purpose model at just 10% of the energy

consumption there was a 1% uh decrease in the QC um this directly supports the economic surveys position against a very resource inensive approach the west has followed

can you explain the right sizing principle how does task specific specialization default &gt;&gt; so before coming to the Um I think this question is a proper

personification of it saying that we have jack of all is a master of learn and so that applies to large models also by the way so I think an hour ago I was having conversation with zero and we

were discussing how let's say for a homegrown project if you're using of 80 parameters that's essentially you have data and knowledge of the whole British library do you need that knowledge or do

you think couple of books for a particular unit that's exactly what righting is right sizing can be divided into two parts qualative and quantitative qualative comes first and

is also most important part right sizing in quative you choose exactly what type of models do you need for your use case it's a stat not by default jump to let's 70

solution you have better data available for training. So and quantitative is if you got the data if you got the model now you try to write something architecturally technically you try to

optimize the instances on which it is run you try to optimize the data that's the quantity and what we saw at the hackathon was there was 50 to 80% of energy reduction

once the team did take the quality and quantitative qualitative assessment and approach their use accordingly Yeah, that's about it. And another point for enterprises also for most of the

industries there are around 70%. So essentially for all you do not need models you need. &gt;&gt; Thanks. It's an important point that even Google said that the searches that

happens in Google I'm talking 80% of the searches are &gt;&gt; it's not something making the to work for you. You don't need it to work. Right? You can always

keep something in a separate go through it which is already there. You don't have to do the entire processing again to find things. Right? So back to Nar on the training and tuning where

profiling is critical. The hackathon showed teams who systematically profiled their training and inference pipelines achieve two to three times better improvements than those who didn't. With

budget 2026 supporting 80 India AI labs and 10,000 technology fellowships, how can we institutionalize profiling as a standard practice? What does this mean for AI engineering education?

Thanks. So u inte has has to be seen as a base engineering. So just the way we train folks on tuning, training models, working with

models, profiling also has to be sort of falling into that same uh skill and more importantly it should also be something that we teach people ahead of you know sort of getting into some of the

advanced segments right so so that is one and what I have seen right within the enterprise working with customers that a lot of times we sort of go and tend to point fingers at the hardware

and things like that But a lot of times when you actually go deeper you'll find that sometimes there are misconfigurations. Sometimes the data pipelines aren't uh

designed the right way. The workflows aren't uh as efficient. Right? So there are other problems than you know just pointing fingers at uh uh the hardware and things like that. There are a lot of

things above that layer which actually you know sort of suboptimal in profiling is perhaps the best way to actually identify many of these I would say ahead of time. Second if you actually go to

the design pattern you can simulate a lot of these right and then sort of look at uh this and that sense. Now from a skill perspective the ability to actually read uh you know through the

traces understand and analyze the traces uh look at these graphs that actually come through right I think those are skills that we need to develop alongside you know all the other things which are

perhaps more glamorous in in nature you touched upon the budget uh part also right uh uh so look I mean from my perspective I think this is a huge unlock in terms of allowing people

access to um environments that usually you know people would not have access to these labs and then the 10,000 plus uh technologies that you spoke about I think that's a great way of enabling

massive scale capability building across the across the country and again from the skill perspective I would say look at profiling as one of these days alongside all the other things from an

AI perspective there that people can actually look at uh this right through the value which means you're looking at uh artifacts about profiling as part of your architecture and design decision

making you're looking at these as part of the gating criteria you're looking at this as something that you'll make decisions and approvals based on right and once it is embedded as part of the

value stream you embed it as part of your standard gating criteria you will notice that you are essentially not looking at optimization as later point in time right when things have actually

gone wrong but you're looking at optimization you're looking at driving value right through the value through through and through so the massive shift left can happen because of this and I am

very hopeful that the announcements that have come in the budget whether it is these labs 80 plus labs the 10,000 plus uh technology related interventions I think those are going to be a big help

in driving this capability &gt;&gt; thank you and that's what we are trying to do also in our sustainable AI center of excellence partnering with all of them. So Archa coming to the layer

related to the governance and framework. So from your experience and advising organizations and evaluating the hackathon solutions, how should companies integrate sustainability

criteria into their AI development life cycle using this framework? What practical checkpoints should be built in at each layer from design through infrastructure? And how does this align

with the summit's focus on safe, trusted and inclusive AI? So this is what I would say right &gt;&gt; nowadays there are lot of titles looking around which is called

&gt;&gt; and if you go deeper and actually look at what those guys say it's probably at a very cultural level in my mind when enterprises look at truly bringing AI into their ecosystem

the whole ecosystem architecture of AI needs to span across four years The first and some of our panelists have referred to as this first one that it's about the design and data which means

are you truly using the data that's needed or do you have all the junk data which may not be even needed under the sun which is used for your training time all of that and if you just make the

data whatever is truly needed you not just make it more sustainable you also reduce the risk of hallucinations you also So reduce the storage requirements. So all of that is there. So I would urge

that for layer one the enterprises should actually start looking and tracking their data metrics diligently in terms of what they are doing. Things like how much is the mileage of data. So

just to put things in perspective which means that how much is your data traveling to get that inference out. So some of these things is what enterprises need to start looking at. If I look at

the layer two of architecting that AI system which is about the model and customer refer to it to say that hey what are the kind of models that I'm using I don't really need large scale

MLMs for every single query that I'm running a small one is good enough for me I don't need to boil the ocean just for a query of two not needed so think twice what models

you are selecting do you really need that becomes crucial also. Let's say if you are in the business of training models yourself or fine-tuning models &gt;&gt; for every 1% accuracy that you are

inching towards you might start seeing that the performance is getting degraded and the energy requirement start exponentially increasing. So these are the kind of parameters that you need to

start putting it at layer two. If I look at the layer three of the architecture which is more about thinking of how your complete inferencing is happening on a day-to-day basis because training and

all may happen once a week probably at some periodic intervals but you are using those apps you're inferencing them on a day-to-day basis you are putting those queries so things like caching

looking at do you really need to make sure this query goes to DL and what kind of caches you are using what kind of optimal solutions how you're architecting that becomes crucial and

then comes the layer four which is your hardware which is to say that I don't need GPUs for everything I can have a combination of GPU and CPUs I can have some other edge AI solutions which are

also coming into play so if you incorporate your architecture in all these four layers and put metrics at each of these four layers that's where I would say that your enterprise is truly

looking at sustainable AI, efficient AI and also AI which is giving you true ROI and not just wasting money. &gt;&gt; Thank you. A quick mention to uh uh one of the things that we see is that

when we talk about GPU, we are talking about so much of performance but the point is 60 to 70% of the uh GPU time is idle. The reason is because the data is not residing on the GP. The data

is residing somewhere else and the latency of the network is not good enough to handle what GP can process. So don't why have GP? So from this point of this GPU starvation problem

and this becomes more complicated when it becomes a RA architecture that constantly retrieve context from the knowledge base. So how does micro data centers address this bottleneck? by

colloccating compute with data. And given the hackathon's findings that contextualize small models with RAM can match large models at a fraction of their cost. How does edge infrastructure

make this architecture not just feasible but optimal? &gt;&gt; Yeah. One of the things in what happened opened AI people started using open API but their dating

amazing you know speed thousand of operating are you able to feed data the same and there are multiple parameters which affect historically all

limited capacity network so large amount of infants I don't think better GPU network getting more than 30% is very

hard adding more and more GPUs look at you look at application some of the workloads are straight some of the work stateless and you need to keep data to the GPU

right you of course can keep in your v is limited expensive your local RAM local drives and you need to fetch data from the storage is not good enough looking of need to get out

the need to so you need to both north south traffic and east west traffic east west traffic has to be hundreds of gabb

network you need to look at your network for low latency because we have many many right many kinds of technology available able to handle this right from

motherboard to the bus to the memory to the storage part every other box in the market not good enough high

not good enough. So today PCI and own much higher performance much because you know running 35 30%

of waste of one year right and I think all of you running starting before What's the bottleneck? Very often data is a bottleneck. People waiting waiting

for data for somewhere else in a chance for a model store request in it takes many times takes

seconds to load the model. So we need to look at the whole life of get closer to the GPU and the CPU again

understanding some Python code understanding more engineering how the computer the data is sending I see I see that is a big problem and I think we need more

insights metrics people to measure theation of your infrastructure rather than asking for more and more right and that's the way forward country why can't you utilize better right

more and more developers IO it's happening data that's one of the customers PCB

sucks the model from server storage model huge take seconds for come seconds cheaper put in a RAM disc so that you interesting solution to work this GPU thank you thank you Even one interesting

point is that today's API structure with the API coming in might not be very suitable because we are talking about stateless scenario whereas in we are talking about stateful

scenarios right so that also needs to be reused. Now coming to N uh quick question on uh so 2026 proposes a committee to assess AI impact on

services and jobs. How can large organizations like inforces balance optimizing existing AI systems for sustainability while preparing the workforce for this transition? What

hackathon techniques scale well and which face challenges at enterprise scale? &gt;&gt; I keep it short. U so I mean what we saw in the hackathon was you know small use

cases uh impactful but small right and enterprises obviously the scale complexity it's of a much much different order much higher right uh so essentially we will have to take some of

those learnings back into the enterprise any organization any size right so first and foremost do you have the inventory of uh all your AI workloads right and you'll find that There's so much work

happening in enterprises right sometimes you don't know everything in every pocket every place in the enterprise so do you have the complete inventory the second aspect is do you have baseline

right we spoke about metrics we spoke about these measurements do you have the baselines for how these workloads are performing and across uh elements you may be

running some workloads within you may be working with some external partners hypers scalers etc right so do you have baselines in terms of cost, energy, etc. for these different workloads. The third

important thing is do you know which workloads are uh less expensive, more expensive, less performant, more performant, right? And typically I mean the 80/20 works everywhere, right? So

you'll find that 20% of your workloads or 15% of your workers are actually the one which are you know sucking out a lot right out of efficiency, cost and so on. So once you have identified those then

sort of you know the measurement in some ways creates a baseline for you which can align your leadership your engineering teams your operations teams and everybody's on the same page in some

sense. The second thing is uh the ability to actually separate out in the in where your BAU operations right business as usual operations run and where your innovation experimentation

happen sort of a lab or a co and at some point you take stuff from the CO and put it into the main how effectively do you do this right ongoing consistent basis. Third element is uh with respect to

techniques right now for enterprises we spoke about rag uh very useful uh right you can actually bring down a lot of the cost using rack right second element is caching reusability again works very

well with the way enterprises typically design systems applications uh we refer to API right microservices uh these are concepts that work very well right you can actually You don't

have to reinvent the wheel. You can optimize in a substantial way. The third element is prompts and I think Archa touched up on this right I mean the mileage uh how many back and forth uh

transactions do you have to do to get to a certain output right you can substantially reduce that by better prompt engineering and you know designing your prompts and systems a lot

better. So I would say I think from an enterprise standpoint these are some of the things that you need to sort of focus on and drive some of these things. the uh thank you. So now that we have

seen on the corporate side and all now let us go to the academia because without academia this is not going to scale up to the extent that you know so Dr. I think

Green mind has exemplified communitydriven innovation and broader summit that this summit has pioneered a bidari approach with 550 across 115 cities in the 300 I mean 300,000 plus so

this grassroot model is very different from any tech conferences how can we sustain this momentum what role should academic institutions play in ensuring AI development remain inclusive and

accessible especially as we scale the hackathon's learnings nationwide and along with that I would also like to ask that um that um the budget also creates a

massive AI education infrastructure and how can we ensure that green ebook and learnings are built into AI education from the ground up What should the sustainable instead of in your uh

location prioritize to shape these labs and should EIS become a standard as a courses? &gt;&gt; Thank you so much for having me here. I come as an all

as an aggregator of all. So we have started a center of excellence in sustainable AI at the school of architecture in Bangalore. &gt;&gt; So the whole idea where we started when

when all were talking about running a LLM for like a train which consumes almost equivalent to seven lakh lers of water. That's something which can be a supply

for a small neighborhood. So this is the awareness what everybody should have you know when the students are coming so with the certain engineering students where this AI is becoming the foundation

grant where 16% raise has happened in the last few years but this is something which we as have to really take into consideration is what we started with center of excellence now coming to the

resource inclusivity is one of the main objective that we are focusing as we see the GPU requirement for model AI models. So what we are encouraging our interns or our students to kind of

use the CPU based the compact AI and so the three ways we are looking resource inclusivity is in three ways like with technology agencies where we kind of use this compact AI and have taken help of

zero labs. So these are also like kind of using them and bringing out the models is what we are looking at and second is the localized intelligence. So the AI co

brought in 7,000 plus data sets. So can we use these local you know to solve local problems can we use these local solutions than depending on the global models. The third thing we see on the

academic stewardship. So that's where we are looking at where we can kind of have the students working on the local problems is what we have achieved. &gt;&gt; Thank you. So uh before we open it for

the questions one point just want to say that there are opportunities in AI to make a good data center you need mechanical skills you need civil

engineering skills to solve the problem that we are solving at zero labs I have 10 PhD in mathematics and 10 very good system engineers who can code assembly for writing applications. Uh and India

is a country for writing applications. You still need lot of good engineers to invent more middleware and data pipeline mechanism. That will actually help you write AI

applications in a better way. AI writing good AI applications is not easy. So I encourage once all of you look at our websites and we stay in touch more of

&gt;&gt; Thank you. So now we will open it to any questions that you have here. GPU is sitting inside the architecture and even GPU car does not have access to more than 40.

So when it wants to load large models, it needs a higher degree of bandwidth between the GP and that causes another million dollar of technology that we have to throw at the problem.

So the point that you all have been arguing is that don't think like hyperscalers. Hyperscalers are not here for our benefit in India. They are thinking about their countries, their

scale. It's a different problem here. In India we worry more about and his work in the micro data centers is really inspiring. You all should visit level and see what they have done

right and I I can give all my models work for you guys to become familiar with this. But when you get to the core of the problem and you will realize that hyperscalers are sometimes over

engineered and maybe we are solving something else and we are not the right country. &gt;&gt; Okay. Uh see thanks foundation we are building a large number of

migration in the country. So just in the next quart ISIT IT and couple of educations having work is on right now in construction phase. Next quarter quarter the government has

the education in country. You have a model of one I one NIT one I couple of institutions five education included maybe next couple of months we'll make announcement that my mission is that can

can we create 10 to such every student every startup has access to affordable thank Congratulations. I think uh the question is what

methology you adopt right I think we lose a fundamental aspect of you know energy wastage
