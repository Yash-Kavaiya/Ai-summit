# Impact of AI on Tech-Enabled Services: Redefining India's Next Growth Engine

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 15:30 ‚Äì 16:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 14 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/zgWebiuw1zk?feature=share) |

## üé§ Speakers

- Akshay Khanna, Avasant
- Chandrika Dutt, Avasant
- Jagdish Mitra, Humanizetech.ai
- Som Chatterjee, Prsimforce
- Swapnil Bhatnagar, Avasant

## ü§ù Knowledge Partners

- Avasant

## üìù Summary

India's tech-enabled services sector‚Äîspanning IT, BPO, and global capability centres (GCCs)‚Äîplays a significant role in economic activity and employment. AI is reshaping this industry by influencing service economics, delivery models, and talent structures. As AI systems advance towards greater autonomy, this session will explore how India can navigate this transition to support higher-value job creation and strengthen its position in the global services economy.

## üîë Key Takeaways

1. India's tech-enabled services sector‚Äîspanning IT, BPO, and global capability centres (GCCs)‚Äîplays a significant role in economic activity and employment.
2. AI is reshaping this industry by influencing service economics, delivery models, and talent structures.
3. As AI systems advance towards greater autonomy, this session will explore how India can navigate this transition to support higher-value job creation and strengthen its position in the global services economy.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/zgWebiuw1zk/maxresdefault.jpg)](https://youtube.com/live/zgWebiuw1zk?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

antage both for the industry as well as for academia. So without further delay as we are running crunch at time now.

Okay. So there's a demand to have a photograph before starting everything. So I would like to have all the speakers. &gt;&gt; Okay. Then I would like to have all the

speakers stand up in front of this and we can have a photograph. &gt;&gt; I also need Okay. Uh without further delay uh let's start our session. So our first speaker

is professor Virginia Dicknam. Professor Virginia, professor of responsible AI at UMAI University in Sweden and also affiliated with Pacific AI lab back at University of Amsterdam. So Virginia,

the floor is yours. I'm going to put your slides in and we can start from there. &gt;&gt; Oh well, no, you have 10 minutes. &gt;&gt; 10 minutes. Oh, wow. Okay, great. Uh,

thank you for inviting me. I'm a computer scientist turned social technical advocate and today I will talk from the perspective of the social technical importance in what we are

doing in AI. Uh first thing to remember every time but especially as from the perspective of the social societal and human impact of AI is that AI doesn't happen to us. It's not the weather is

not an uncontraable uncontroll controllable force is something that we people design that we decide and is shaped and formed by our choice by our data by the incentives and the

governance that we put or failed to put on it. The current AI approach to AI is not necessarily the best maybe is not inevitable and we do need to take a much more stronger

perspective about how to co coordinate the technical advances with the social technical requirements needs and expectations. AI doesn't exist in a vacuum is something which is shaped by

our choices and mostly is also should be shaped by the question why. Why are we using AI for this? Why are we using AI for that? And those are questions that are basically not technical questions.

Typically an engineer like me doesn't learn how to answer why questions. We learn how to answer how to do questions, how to solve problems. So starting by asking the question Z the question why

is one which is core to this understanding of AI as a social technical system and therefore the core is governance. AI is not neutral. It can

help us. It can undermine us but at every time it embodies human choice. Governing AI means at the end that we are governing ourselves and we need to understand what do we want to have as

the result of this governance. Uh technology will tell us more is better. We need more data. We need more algorithmic power. We need more computing power and then we'll get

better AI. We'll hear this message again and again during during this week here or everywhere else where we talk technology of AI. the society will ask is it really

better? Uh data availability is not the world that AI sees from the data that is available is not the world where we live is definitely not the world where we want to live and more data is not going

to necessarily improve this skewedness of the data. Computing power comes with costs, energy costs, uh resource costs, but also one which often governments fail to tell us investment costs. money

that goes into AI doesn't go somewhere else and with deciding that and how our governments are making those choice are things that we need to question ourselves and algorithms are as powerful

as we are because for a large part what happens is mediated by those that are curating and managing the data but also increasingly by those that are babysitting the chatbot and making sure

and self-driving cars and whatever do what they should be doing and without these people we don't really have um AI as we believe that we are using so the artificial part of it is not

completely true and AI impact means our responsibility the concerns that we need to talk about and concerns that you will hear again and again this week here are mostly social technical concerns the

idea of datification It's important to have data and no one disputes that. But reality is more than data. We are more than our data. And by focusing on the data, we are somehow

commodifying and quantifying our existence. Much narrowing it much more than what we people are capable of. Data is always constructed is something that we build and therefore is always also

historical and biased. And data availability is unfortunately becoming the measure of the importance of a problem. If we have data then it's a problem that is worth to address. If we

don't have data probably is not really a relevant thing to do. So becoming data rich and insight poor is something a concern that we really need to address from the social technical part. The

other one is the issue of power. Who is developing AI? What are their motivations? who is deciding and who is accountable. Those are all questions that we need to address from a societal

and human perspective as well as sustainability that I just talked about in the previous one. Social technical governance is institutional is about going beyond the principles and

guidelines going beyond the declarations and the signing whatever recommendations will come here is really embedding governance in the institutions that we have uh around procurement rules around

the accountability within the public sector around the ensuring an independent oversight and audit capacity clear allocation of responsibility. It can never be that governance of AI comes

down to the answer the system has decided beyond it needs to go beyond the technical robustness of safety. Of course, robustness and safety are important but at the end of the day the

core is is in the sea. Who is defining what fairness means? Who is deciding what safety means? Who is deciding what trust working means? If we are not discussing that ourselves, someone else

is deciding it for us. What are the risks they are prioritizing? Who is participating on deciding what are the tradeoffs? Who is benefiting and who is bearing the cost addressing AI impact is

not about controlling technology is about governing this power responsibility and collective choice at the end of the day. So we might start thinking about a new AI paradigm. One

which recognize that AI is not a universal solution is not the solution to all our problems. Which recognize that we need to start by the why question. Should we be using AI here?

Why is that? What other options do we have a paradigm which address the innering erent risks of bias and discrimination? mostly a paradigm that goes beyond the disciplines integrate

social and technical expertise in the design of AI from the onset and not as after the technology has been developed needs to address the systemic societal challenge and involving many more actors

than just technologist. Of course, it also requires robust technical standards for those very societal issues such as verifiability, trustworthiness, participatory. So this

new AI paradigm needs to be a social technical paradigm just then just moving to the yet the next step in the technology. Thank you so much. [applause]

&gt;&gt; Thank you Virginia. This was really awesome and uh really helpful in understanding that not only technical measures are indeed useful but a combination of understanding social

technical needs is a way to go forward. Okay, as we are running short on time uh I would like to introduce our next speaker. Our next speaker is Harry Pis. He is the ambassador for AI at the

government of the Netherlands and he has something for us to share as well. Thank you. Thank you very much for this introduction. Good afternoon ladies and

gentlemen. Thank you for joining this event today. Um and it's really a pleasure to stand before you on the topic that just a year ago it was in the dark for me and slowly and slowly but

surely I start to get get grips with with the subject. I think um the fact that I've been here in India for the second time in just a few months uh tells you something about

the Dutch India relationship, but it also reflects India's growing importance on the world stage, but also its central role in shaping global thinking on emerging technologies.

The Netherlands had the honor of serving as co-chair of the working group on AI for economic growth and social good at the AI impact summit and it was my privilege to represent the Netherlands

uh in that role and contribute to shaping a shared vision on how AI can serve society. This visit also carries personal significance. The Netherlands is

reshaping its international approach to AI and within our ministry [clears throat] we have established a dedicated AI task force which I now have the privilege of

leading as the Netherlands ambassador at large for AI. So this is my first official visit abroad in that role. So in a very real sense this summit is where my mandate begins.

The theme of today's event, the societal societ sociote techchnical turn on AI captures something important and I think still not fully understood in policy circles. We've become quite good at

talking about AI is a social technical phenomenon. The language is everywhere in strategy documents, academic papers and summit communicates. But here's the paradox.

The more widely the concept is used, the more its meaning becomes unclear. And unclear meaning leads to fragmented governance. And that is precisely the gap this event is designed to close and

precisely why dialogue between researchers, civil society and policy makers is not a luxury. It is a necessity. Understanding AI as a sociote

techchnical system is not just an academic insight. It is essential for good governance. So let me explain why I believe this is this so strongly not from theory but

from experience. Several years ago the Netherlands experienced a serial serious institutional failure. Our tax authorities used automated risk

profiling to identify suspects that fraud in child benefit claims. The system worked from a technical perspective. It flecked cases efficiently, but it did so in ways that

were opaque, discriminatory, and deeply harmful to thousands of families who lost their benefits, their savings, and their stability. This was not a technology failure in the

narrow sense. The algorithms functioned as designed. It was a social technical failure. A failure to understand how a technical system interacts with institutional

power, administrative culture, legal safeguards, and the lived realities of vulnerable citizens. That experience did not make us skeptical of technology. It made us

serious about governance. It taught us that innovation without accountability is not progress. It is risk shifted on those who can least afford it. The Nether's approach to AI governance

rest on a core conviction. AI can only succeed if it's trustworthy and trust must be actively built. We have developed a governance framework for AI in the public sector that applies

across the full chain of implementation from developers and procurement offices to policy staff and legal advisers in open source continuously updated and designed to evolve alongside the the

technology. So our public algorithm registry now documents over 1350 algorithms and AI systems submitted by more than 320 public bodies at every level of government. This transparency

allows citizens and civil society to see which automated systems affect their rights. So for five years we've been learning from our impact assessment for

algorithms and human rights developed with UT University's data school. We are now updating it to reflect generative and agentic AI as well as the EU AI act. What makes this assessment

valuable is that it was co-developed with researchers and practitioners and it is actively used by people making real decisions in government. So these tools matter because the

process behind them, one that brings together government, industry, academia and civil society, multistakeholders collaboration is the foundation of our AI policy.

In addition, the Netherlands has established as ethical, legal, and societal aspects of AI in so-called Elsa labs. 12 labs are now in operation and each focus on a specific domain, media

and democracy, public safety, sustainable food systems and since December three labs dedicated to AI in healthcare and each lab brings together

researchers, public institutions and civil society to work on shared challenges not just to produce not to to produce reports but to deliver real world impact

beyond governance. We are investing in the infrastructure and talent that responsible AI requires. Under the Euro HPC initiative, we are establishing an AI factory in the Netherlands. And this

gives researchers, startups, and public institutions access to the computing power they need while keeping strategic capabilities in public hands rather than concentrated in a small number of

private platform. GTPNL our Dutch large language model built on trusted data by public research institutions. It shows that innovation and public values are not in conflict if

you design them for both from the beginning. And through NOL AI, our national education lab for AI supported by 80 million euros from our national growth

fund, we are embedding AI literacy in education. Because ultimately the future of AI will be shaped not by the technology itself but by the people who understand and

guide it. So let me be clear about why I'm here in this setting with you as an audience. The social technical turn has produced insights that governance urgently needs.

But the translation into practice is not happening fast enough. Policy makers use so technical language without always fully understanding its implications. Researchers produce findings that do not

always reach those and positions to act. Civil society raises important concerns but these are not always fully reflected in system designs. So this event is a deliberate effort to change that dynam

dynamic and Indo Dutch dimension is important. Our countries have different histories, administrative cultures and relationship with technology and in institutional

trust. This difference is not a barrier to cooperation. It is a strength. Governance framework that only work in one context are not true frameworks. They are examples.

So in conclusion, ladies and gentlemen, the future of AI governance will not be shaped by any single country, institution or research tradition. It will be built carefully step by step and

together by people in rooms like this one who are willing to speak honestly about what is not working and seriously explore what might work better. The Netherlands is committed to that process

not because we have all the answers. Our own experiences show it clearly as I explained but because we believe that shared learning is the only path to shared solutions. I look forward to the

discussion ahead. Please do reach out to us, to Lisa, my colleague, and to Justin, my embassy colleague here. Challenge us, share your perspective and let us explore how we can move forward

together. This is yours. Thank you very much. Thank you, Harry. This was really useful. Uh I'm sorry we don't have time for questions, but Harry will be here uh

till the evening. So be ready for the questions then. Okay. Uh moving around with the next speaker. So we have uh our next speaker online. I'm trying to dial in. If we succeed

then it's going to be all right. Otherwise I'm going to take that uh myself. Thank you so much for the internet. I hope it works.

Okay, no worries. Then let's just go together. Great. Uh, can we close the door please? Thank you. So, oh, innovation center for artificial

intelligence from the Netherlands. Why we even submitted our session request to be a part of India summit? Because we believe that in terms of how current approaches

for technical domains are being followed upon, it's really urgent to take a social technical stand where the cultural, societal and the norms of each and every geographic region can be taken

into account. That's why we are here as a part of the team. Martin D Reich is the director of the institute and I'm here as an impact officer leading this event.

So our belief is that AI will impact all aspects of society and in that open society including technological power should be in the hands of many not a few and when we say that there's a clear

vision towards it to have a shared ownership of knowledge creation innovation and talent development specifically thinking Netherlands as a job protector indicator then finally the

mission is to build multistakeholder collaboration in AI between knowledge institutions predominantly universities or medical centers, industrial partners, government partners and societal

partners and our main instrument towards this is focus upon value exchange. What we can learn from universities, what we can learn from industries and what we can learn from NOS's or public sector

organizations to have a clear coherent overview in order to move forward towards a specific societal problems. So how do we do that? We have different labs and within different labs we have

five PhD students who work on site at nonacademic partners for one to two days per week. Which means it could be industry organizations, it could be government organizations like police

labs, defense labs and there are two lab directors and a burn manager for each and every lab. It runs for five years. So each and every PhD have a tenure of five years to finish their PhDs and

their research agenda is determined by all the stakeholders not just the people from industry also from the universities as well as from the other societal partners as well

and not just labs we are also thinking in terms of like next progress towards the AI units where there's a local innovation ecosystem of full path looking towards with medical

organizations like university medical centers large organizations, large MNC's based in the Netherlands, government organizations, not just with the PhDs

but like 50 plus staff members. So this will be like a full AI unit with which can combine multiple labs and we try to run it together towards like a specific sustainable development goals and the

first lab uh sorry the first unit was already launched uh late in 2025. So how do you define success? When we think of of innovation center for AI is all can gain and no one is left behind as well

as all can contribute. It's not just about having PhD as a part of the universities but also thinking about how they can contribute towards nation building specifically. So on the one

side we do have research questions, publications, talent coming in for evaluations doing internship with organizations. On the other side, what it leads to is core design of relevance,

co- production of IPS for defined success. So the industry has a different success criteria, university have a different success criteria. We try to map it together to have a same defined

success. Where we are today, these are the big numbers. We have 59 labs and units working across the Netherlands with each and every university being a part of it.

Thanks to the funding from multiple sources, we have received 300 million plus euros of funding in investment of knowledge creation and talent development as well as 158 industry

partners, 653 PhDs, postocs and PD engineers have been a part of a Wi-Fi program and really interesting thing which I think is really useful in this uh global south

context is the talent retention. So people who actually was a part of a 85% of them stayed with a as a part within the Netherlands to contribute back to the society.

So our biggest labs and units by domain is health followed by strong institutions like police or defense mobility and logistics in terms of transportation or the railway

organization services again thinking about services which are useful for common good that industry infrastructure and food follows within this ecosystem. If we try to

divide it based on cities then Amsterdam has largest uh labs altogether followed by DEL I think it's a general transition which is also related to the university of Amsterdam and the technical

university based in Dell and then other in like redbound university and then cloning so it's a you can see it's not just one lab which is a part of a single city

perhaps but we are trying to make sure that the whole country is represented in this uh as an overall ecosystem and these are the partners that we have. It's really hard to fit them all in a

single screen but uh 158 partners all the industry partners along with the universities or the societal partners which have been really helpful in terms of leading this as a bigger channel.

Now talking about our impact. So we see impact at five different levels in terms of community. There's a national ecosystem of local multi-stakeholder networks which mean there's a network

which you can actually talk to a PhD if you're working in an industry or if you're working in the public sector organization retaining talent we already talked about that and there's ecosystem

level in the next slide. Societal is specifically related to the sustainable development goals. scientific levels at the lab level what is the co-production in terms of knowledge like research

papers patents and at the ecosystem level thinking about trustworthiness of AI which is really important for social technical setting and then finally at the economic part generating business

out of all of these things and the startups which comes up by the end of the PhDs or end of the course of contracts of the students so that's a really nice slide according

to me in terms of like talent impact so if we see how many people actually came in from different parts of the world and where they actually landed up. So overall let's say we have 602 students

as per the current April to May 2026 program 403 are in progress and in terms of completed so out of 243 who completed at 206 state in the relevance which means the knowledge that they have

attained came back to the society in terms of fulfilling the different societal needs as well as thinking about how AI can be a boom as well as an advantage as follows.

Okay. So what's next? U I think uh I don't have much time to go into what the next plan for this but we all are here always together and uh as an impact officer for AI I'm really happy to speak

uh with all of you in terms of thinking what's next where we can contribute towards understanding whether such a ecosystem can be a part within India and how we can proceed with the further

scales. If you need more information, these are the contacts. Uh you can click a picture. The slides can be shared later back on the impact website. But uh this is what we are for to thinking

about how such an ecosystem can be translated not just in Netherland but outside of thank you. And now I think uh we need to move

towards the panel discussion. So we have Lisa. Lisa is a senior policy officer for AI back at the government of Netherlands. And then we also have Priy Bunson sorry Pavi I'm so sorry and Pvy

is also the part of inclusive cultures lab back in university. So the panel discussion I'm going to moderate it and uh I'm going to have the seat over there with all of them. Give me a moment.

Great. U thank you so much and I'm going to lead this panel discussion focusing upon the theme of this session itself which is social technical AI. I've prepared some questions so I'm going to

use my and just read. So first question is for you Virginia. I'm going to start with that. Uh as the limitations of the approaches to AI safety are becoming more apparent, social technical

perspectives are emerging as a promising pathway to increase technical considerations with societal organization and institution. How far do you think we are? Are we

still in the big or we have made some progress? Good question. I think yeah, it's working. Uh I think we are as far as the fact that this question is being asked,

which is already a bit further than what we were before, but it's still very far from where we should be. uh AI solutions are solving nothing if they are not grounded and built with the societal

aspect around and therefore focusing on also on pure technical aspects technical improvements is not necessarily actually there is a saying which I forget said that is if you think that

technology is the solution to all your problems you definitely don't understand technology but even worse you don't understand your problems and I think that really to start what are the issues

that we are tryinging how can AI possu what are we gaining by adding AI to the set of solutions but also what are we losing what are the

issues that we are not addressing by focusing on AI solution and in many cases and many issues we don't necessarily have a need for a completely complex AI when it can be

used much simpler and understand me good I'm working in AI for 40 years if I didn't really believe in AI I either I'm very stupid or I could have been doing different. So it's not that I don't

believe that there is a role for AI and I've seen many different generations of AI around but it is very clear and especially now in these types of types which is not the very first type that we

have had but especially in types of types we really need to take the time take the step to ask ourselves is this really what we need are we just doing AI because everybody else is doing AI I'm

from the Netherlands Portugal, but I live in Sweden. I was in a meeting with and I'm taking a bit too much time. Just an example as meeting with Nordic ministries a

couple one year ago or so and they were all rushing to say by next year our government will be using AI for 90%. And then the other one would come when in 18 months we'll using it for 95%. And I

just asked them why. They kind of wanted me to get out of the room if they could. But the point is that we are most of the things we are talking about AI at this moment is very much this fear of missing

out. We don't really know what we are doing with it but everybody else is doing it. So let's rush out and it is very important at this moment and that's the answer to your question to not just

move forward but also take the time to reflect why are we going. &gt;&gt; Thank you so much. This was really interesting insight and uh if I can take uh the the last part of you what you

said uh with respect to understanding of each and every government taking a stand on it like we need to push this. So my next question is to thinking in terms of like policies.

How do you see uh in respect to both India who's hosting this impact summit as well as Netherlands when it comes to this strategic type of war around AI and with having us and China as also

partners? &gt;&gt; Yeah. Is this working? Yeah. Okay. Um well, thanks for that question. Um I think in that sense uh the Netherlands and India have a bit of a similar

position because currently the power concentration of a small group of companies that are developing the most advanced AI is not in our hands. Um so we are confronted with the same issue

that there are these developers uh I think also pertaining to what you just mentioned that are developing solutions to problems they don't understand because the problems is what we see in

our societies um and that's also why it's important that we uh on the one hand I think we invest in our own capacities so we are capable of understanding the technology

and also thereby determining how we want to use it in our society. So in the Netherlands and the EU um we have uh um published a series of strategies in the past year, the EU AI continent action

plan. Uh obviously we have the EU AI act and the way um we envision positioning ourselves in uh on AI in the world is really putting trustworthiness at the center because um we see a condition for

adoption is for people to be able to trust the technology. And I think here we have actually um a nice um shared uh sentiment with India because India released their AI

governance guidelines in the past year. And here uh you can also read that uh they share this insight that innovation and uh regulation are are sides from the same coin. So it's not

necessarily one or the other. Um while other actors do sometimes um take that assumption. So for us having a set of rules in 27 countries for the EU then that are rights respecting um it not

only enables um better innovation and it's good for the market because it's also good for companies to know that they all have the same rules that apply for the whole market. Um but it's also a

way for us to say before we rush into uh this full-fledged AI adoption, we already agree um these are the risks that we uh determine high or these are certain risks that we even do not

tolerate in our society um before we start developing them and deploying them. &gt;&gt; That's a lovely answer and uh I really appreciate your thinking in terms of

like uh how India Netherlands share a same governance perspective in terms of the guidance which have been produced. So uh my next question is to you

thinking about uh your experience with the digital labor and your you work. So do you think uh a social technical turn also employs a geopolitical turn which simply means that if there are countries

who are thinking AI as a social techchnical entity does it also needs to shift towards how geopolitics can be thought of like some countries coming together who see as social comparison

&gt;&gt; uh thank you Sadhart for your question um I think I'm going to speak more about the digital labor perspective and what Lisa has already shared. So uh yes, India and Netherlands I think are in are

sharing that similar sentiment because uh technology is currently being developed uh by nations who have rarely experienced power cuts or broken roads. So uh based on my empirical research in

India on ride healing platforms, there were a number of issues I realized uh which AI does not account for and I think uh that sort of includes your geopolitical angle also. uh that you

know we just have to adopt something which is given from outside and uh there's lack of development from inside lack of understanding of what is happening based in our country our own

country so that's one of the major issues I would say so uh one of the examples I think I would like to site over here is I did my research we had research taking into account women uh

cap drivers and um I realized that uh women cap drivers are those kind of marginalized drivers who are not very confident driving on uh roads which are new. So uh they would

want that if they know the route beforehand that would just help them. Now this basic thing for instance does not apply to Uber or Ola model which we have. Now here uh you just get a

notification that you have to just take on some uh passenger and you have to drive on a new route altogether. So women passengers, women drivers are not comfortable taking that new route. So

where does the technology where does the AI actually account for these things? This is just one of the examples which I have uh cited from empirical data but there are plenty of other examples which

I can site. So uh that's what I wanted to just say that um I think uh everybody's talking about the socio techchnical aspect. We also need to understand that what is happening with

the global south and the global north uh perspective over here that information is lying in the global south. There are issues over here. Uh but again technologies developed rarely from our

nations. Yes. So that's what I would like. &gt;&gt; Thank you so much. I think uh this is a really critical take and uh I'm trying to link this back to public's trust.

public trust in technologies basically and uh I would like to go back to Virginia on this one. So this is bit technical also coming from my background.

So it's like deep learning specifically is uh looking at the past since uh it trains from existing data. How do we guard against the risk of indexing from the past which is a

typical example from Uber and to ensure that people have an appropriate level of trust in their systems which means not too much of trust but Thank you. Uh I would like to go back to

one of the comments that you made that AI is building countries that never experience broken roads and power cuts. And actually it goes much further than that. AI is building countries that come

from a philosophical and academic tradition based on the curtisian. I think therefore I am. So we built systems to reproduce that type of

thinking, the individual, the individual thinking is core. And if you think about how AI is and how we try to build AI forward, especially going into the AGI, what are we trying to do to build one

big god who is going to solve all our problems and we can just delay relay all our problems to that god and it will solve it first. This is our responsibility and it solves it all for

us. I think therefore we come to the glo Especially in Africa where I have lived many years. The core of the tradition and philosophical is I am because we are we would have built AI based on this. I

think that we would have developed a completely different type of system. Going now back to the machine learning and deep learning and indeed we are kind of

limiting ourselves to the reality of so data is constructed data is what is the reality for system. So we are providing a system that lives in imaginary reality the capability to change our lives our

decisions our environment so that's something we really need to think about also from a research at this moment and I say that to my students all the time we are taking an extremely lazy approach

to AI research we are really taking this idea that we need more data we need professional power and things that that is the what we have now and that is the lazy what we really need if

we talk about innovation is thinking about what are the alternatives what is the AI what AI means when we think about I am what does AI mean when we think about

distribution about inclusion about diversity How can we combine? So what we have and I I I refer to that

in my new book which by the way I'm very happy start is out today. [laughter] Anyway, [applause] the approach we have today is the approach of the play-doh. We put all the

Play-Doh together, we create a huge bowl. That ball is becoming less and less clear. There is no color there, no shape there anymore. But if you really want to to a diversity and inclusion

approach to AI and that is a plea to researchers and innovators in the world. We need to think about the Lego approach build all these different colors, different shapes, different things that

still manage to all fit together and creating a much bigger thing and a much different thing than ever everybody thought about. So that is the answer to your data issue.

Let's completely think about a different way of doing AI. There are other alternatives. We are just being too lazy and follow the easy and the most followed route. Let's go and explore

other roots that have not been explored before. &gt;&gt; And congratulations again on the book. I think this is a perfect moment for you. [laughter]

&gt;&gt; Sorry. &gt;&gt; Great. Uh so uh just moving forward uh I really like your uh response in terms of thinking uh how we are still tackling the issues based on the past data and uh

moving on those sides u thinking about the role of the government organizations right in terms of like policies. So these are just questions for you in terms of like larger organizations which

often glorifies people or you know fairness issues all together but on the other side we see from the government which is promoting for equity justice as well as equality right so

how do you deal with this sort of like distinctions on the one hand there are organizations which want to have On the other hand, the government organizations want to promote justice.

How do you deal in your day-to-day work? &gt;&gt; Yeah, thanks uh for that question. So, uh I think one uh one of the distinct approaches that we have in the Netherlands that we're quite proud of is

what we call public private partnerships um and also multistakeholder approaches. Um and our ambassador mentioned that we have these so-called ethical uh societal legal uh labs on AI where um uh

researchers uh but also private sector entities and and government so this could be local policy officers uh come together to look at societal issues and determine how AI can provide a solution

and by developing that jointly um they are also holding each other accountable. It's rich because you get these diverse perspectives that uh you co-create a societal solution uh uh with the

technology. Um and this is actually also a very uh core part of our uh foreign policy. Um because um also when you look at international governance processes, I'm from the Dutch Ministry of Foreign

Affairs. So we are also looking into How can we um work on global uh global governance of AI? And we support a lot of civil society organizations because we think also in these processes like

the United Nations um civil society has to be heard because they bring in other perspectives than governments. Um they hold governments accountable uh and they ensure there's legitimacy and the public

is heard broader from the government interest or the private sector interest. Um and I think one thing that may be nice actually to mention is that sometimes

um interests are also um put like um sometimes it is assumed that the interests are uh are opposing each other but that's not always the case. So um I also used to work on the on the Gulf

region h and in the Netherlands we for instance have a very well organized labor inspection as well and we organized uh visits from abroad to the Netherlands to show how the labore

inspection actually works very closely with companies so they are able to adhere to regulation um and to ensure that they don't get fined. But this is like a uh very

collaborative process and in the same way um we also developed these things called um AI regulatory sandboxes. So for the EU AI act now we are in the phase of implementation. So a lot of

companies are looking into how can I uh adhere to the EU AI act and what is allowed what isn't allowed and this is something that both the regulators as well as the companies need to figure

out. Um so uh for instance in December we held we organized a really big conference around the implementation of the EU AI act where we invited uh uh the private sector and also uh local

regulators and and and policy implementers uh to have a discussion and there was like a real invitation uh to companies uh to come to these regulatory sandboxes. So the it

basically means if you're developing an AI tool uh you can come and have a dialogue with the regulators to see how your products or service can comply to the EU AIX. So you are sure that when

you bring it to the market it is compliant. &gt;&gt; That's a really great way of looking at it. Specifically thinking in terms of like startups who do create AR systems

and have to have those regulatory approaches and if there's a wealth of environment already from the government so I think I'm going back to you again thinking the example that you gave on.

So on the one hand side we do have interpretations on the We just have users who have faith in these apps. For example, if I'm booking Uber from here to go to point B, then I'm relying on at

the same time. Do you think the organizations who are developing these apps are giving enough cues to the users so that they can appropriately trust especially thinking about the women cap?

&gt;&gt; Um, thank you uh for your question. I think um trust is an interesting word in terms of technology itself. Um you know uh the the very basic example first of all which comes to my mind is that can

you even trust Google maps for instance you know I'm sure all of us must have instances where uh Google has landed us in some ditch where we wanted to really go to a particular location. So uh trust

and technology are very interesting terms and together they come up with new meanings altogether. When it comes to Uber drivers being able to trust technology when it comes to passengers

being able to trust or uh when it comes to that these apps are they providing sufficient cues. So um going back to that example I think uh humans still trust humans more than they would

actually trust technology. So I spoke to because you mentioned women drivers. So I spoke to a few women drivers and uh they told me that if you know an app is narrating them that this is what you

need to do or this is how your rankings are going to be decreased or increased. So they don't feel that comfortable. So they really want to interact with human managers especially women drivers who

would really happily just listen to a human manager than actually trusting that technology to tell them that this is where you should go. This is why rankings are getting u increased or

decreased. So but we of course cannot ignore AI over here. So that is why we propose a term uh where we say that there has to be that human uh AI collaboration and human managers should

be included as part of our AI system so that when drivers or users for instance are in that limbo they really want a human voice. Going back to chat bots, I mean if you have a problem then you do

not want an a aentic AI telling you that this is what you should do. You want to interact with a human. So yeah. &gt;&gt; Thank you so much. Uh this was a really uh interesting insight and uh as you can

all see uh we really need to wrap it up. I just want to say one last words that uh thank you so much from the organizers from India. I somewhere to have IKA as one of the sessions to be uh over here

and thank you all the speakers. panel members. It was really nice uh having all of you over here and till next summer. Thank you so much. [applause]
