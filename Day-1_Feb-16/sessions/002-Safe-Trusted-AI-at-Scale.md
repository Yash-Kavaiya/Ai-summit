# Safe & Trusted AI at Scale

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Bharat Mandapam | L1 Meeting Room No. 14 |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/ANrK8Ko6J-I?feature=share) |

## üé§ Speakers

- Arvind Kumar, STPI
- Ashok Meena, Ministry of Jal Shakti
- Dr . Piyush Singla, Govt of J&K
- Dr Rajiv KN, BWSSB
- Dr. Ravi Gupta, Elets Technomedia
- Mohammed Safirulla, India AI Mission
- Sid Sheth, d-MATRIX

## ü§ù Knowledge Partners

- Elets Technomedia Pvt Ltd

## üìù Summary

As AI adoption accelerates from isolated pilots to enterprise-wide integration, attention is shifting toward the creation of safe, trusted, and scalable ecosystems. This high-impact session examines practical implementation frameworks, governance architectures, and leadership strategies that reconcile rapid innovation with accountability and risk management. The emphasis is on operationalising responsible AI in ways that deliver measurable outcomes while safeguarding security, regulatory compliance, and long-term resilience. By convening policymakers, industry leaders, and technology experts, the session advances a systems-level understanding of how AI can be deployed at scale to drive productivity, institutional trust, and inclusive growth in an increasingly AI-driven global economy.

## üîë Key Takeaways

1. As AI adoption accelerates from isolated pilots to enterprise-wide integration, attention is shifting toward the creation of safe, trusted, and scalable ecosystems.
2. This high-impact session examines practical implementation frameworks, governance architectures, and leadership strategies that reconcile rapid innovation with accountability and risk management.
3. The emphasis is on operationalising responsible AI in ways that deliver measurable outcomes while safeguarding security, regulatory compliance, and long-term resilience.
4. By convening policymakers, industry leaders, and technology experts, the session advances a systems-level understanding of how AI can be deployed at scale to drive productivity, institutional trust, and inclusive growth in an increasingly AI-driven global economy.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/ANrK8Ko6J-I/maxresdefault.jpg)](https://youtube.com/live/ANrK8Ko6J-I?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

also from different um uh places in the world as a as a possible way of how to deal with the frontier aspects of AI development because instead of u detailing in the legislative act um the

uh every aspect of the risk mitigation that we ask now to the big developers. Um, we decided to put in the AI act the provision of having this code of practice that would come as professor

Benjo explained very clearly from a colleisative process involving civil society developers, small, medium, big enterprises and academia in a exercise that would allow to um build a more

adherent to the present situation and evolution of of the AI uh um landscape of a set of rules to actually prevent uh existential risks but also we call them systemic

risks that deal with our democracies with our uh freedom as uh citizens. I mean with the code of practice, we try to um build a culture of restraint um in the uh functioning of systems that can

um prevent uh risks of uh um uh damaging our democratic processes by spreading misinformation or um uh uh contrasting the uh cyber bullying or uh the criminal criminal actions through uh the use of

of AI. Uh and um we um I think we built a very clear framework um because I think it's very important to be clear not to have vague um uh proposals that are uh very loosely

interpretable but uh maintaining a certain degree of flexibility. we are clear on what we want to pursue. However, I think it will be very important and so I need to subscribe to

what Professor Benjo said at the end of his speech that and this is our effort from the parliament side that we provide the European AI office all the means to

actually implement this code of practice because it's true that as it was said many companies are already complying with many of the risk uh mitigation aspects that are in the

code of practice. But we need to be sure that we can uh be at the same level of these very powerful private actors to do our part in making the um rules that we decided applicable, effective and so

build trust. In the end to conclude this is our objective. We want the code of practice to contribute in building trust among our citizens on the fact that we can innovate without sacrificing human

rights and protection of uh our uh fundamental values. Thank you. &gt;&gt; Thank you very much Brando. Now we still have very few minutes left. So I would like to exploit the opportunity of your

presence to ask you um maybe if you can say in one minute. Um Sean you have already said this but maybe you can reformulate or come up with a one recommendation for the leaders at this

summit uh on a way that we can govern AI in the future. What would you say to them? In one minute I would say the role of our leaders, the role of us

as scholars, the role of us as governance experts is to create the conditions for the safe and beneficial development of AI right now. I do not believe those conditions entirely exist

because exactly of the things that the CEOs of the leading companies say. They say they would like to be able to take additional steps, but under the competitive geopolitical pressure

they're in, they do not feel that they are able to. We should be hearing that. That should be a red alarm bell for us. And so what we need to do is figure out how do we create the conditions where it

is possible for them to take these additional steps to put additional focus on safety to um share expertise if needed um to coordinate and potentially even to slow down before critical points

and that doesn't just mean European companies it doesn't just mean um US companies it also means our colleagues in China who are making such um you know impressive progress we need to figure

out what is a way in which we can bring everyone to the table as equals and figure out how to cooperate on this challenge of our time. &gt;&gt; I would say focus on the use cases. So

right now there's a gigantic gap between sort of our perception of this incredible power of the technology and how quickly organizations can deploy it and the bottleneck is about how they

know how to trust it in the right context because it's ve the answer is very different in medicine than it is for customer service. And so I think when we start to focus on context, the

right use cases, what trust controls look like in those domains in local context, that's where we unlock not only productivity but trust in the same in the same breath.

Well, in my opinion, we need to again as it was said earlier by professor a it's very difficult for me to figure the pronunciation but anyway um we need to uh not contrast not put in in contrast

uh safety um at the highest terms and the focus on diffusion on action on impact the the the the title of this summit. I think this can go in parallel and it must go in parallel because there

are um um areas of uh deployment of AI where without international cooperation we are facing huge risks. We we hope that the code of practice will be a way to enlarge this discussion and build a a

reference point as I said but we need to go even further. We have uh issues regarding military use of AI. We have issues regarding uh uh the loss of control risks that also professor Benjo

has been looking a lot at with his research that are um uh in need of further cooperation. I don't think this will come from the business but not because they are bad. It's not their

role. It must come from uh the uh public institutions. And so we need to uh send this message to our leaders. Don't lose any more time. You need to sit down and use these occasions to do uh progress.

We need that uh and we do not need to lose any more time on this. &gt;&gt; Thank you very much. So I would like to close this very interesting panel simply to say that what we have tried to

discuss uh and conclude in this session is the fact that innovation and uh uh trust can go together and we can find different ways to make sure that trust is ensured or enabled in a particular

country and in a particular continent. But we will need to continue working together and we also happy to have presented to you some elements of the code of practice. Please take a look at

that code of practice in particular look at the safety chapters and you will see that these are uh probably standards to which other countries can sign up to and uh thanks a lot for your participation.

We look forward to continuing this discussion with you and with all the colleagues in this summit. Thank you very much and thanks to our panelist. &gt;&gt; Yes, sure. Nice to meet you.
