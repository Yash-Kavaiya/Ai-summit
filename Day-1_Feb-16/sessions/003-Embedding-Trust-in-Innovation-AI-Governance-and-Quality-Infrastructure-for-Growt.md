# Embedding Trust in Innovation: AI Governance and Quality Infrastructure for Growth

**India AI Impact Summit 2026 ‚Äî Day 1 (2026-02-16)**

---

## üìå Session Details

| | |
|---|---|
| ‚è∞ **Time** | 09:30 ‚Äì 10:30 |
| üìç **Venue** | Bharat Mandapam | West Wing Room 4 B |
| üìÖ **Date** | 2026-02-16 |
| üé• **Video** | [‚ñ∂Ô∏è Watch on YouTube](https://youtube.com/live/vmOIvF3IjvM?feature=share) |

## üé§ Speakers

- Amanda Craig, Microsoft
- Ashutosh Bahuguna, CERT-In
- Chakravathy T Kannan, Quality Council of India
- Jagdheesh Manian, Bureau Veritas
- Richard Skalt, AIQI Consortium

## ü§ù Knowledge Partners

- TIC Council (Headquarters- Brussels, Belgium)

## üìù Summary

This roundtable convenes policymakers, regulators, industry leaders, and global experts to shape trusted pathways for AI adoption. It examines how AI-enabled Quality Infrastructure can strengthen governance, accountability, and global acceptance. Through applied use cases and international perspectives, it highlights interoperable assurance frameworks that reduce compliance friction, boost MSME competitiveness, enable cross-border trade, and position India as a leader in responsible, innovation-driven AI growth for inclusive, secure, and scalable digital transformation.

## üîë Key Takeaways

1. This roundtable convenes policymakers, regulators, industry leaders, and global experts to shape trusted pathways for AI adoption.
2. It examines how AI-enabled Quality Infrastructure can strengthen governance, accountability, and global acceptance.
3. Through applied use cases and international perspectives, it highlights interoperable assurance frameworks that reduce compliance friction, boost MSME competitiveness, enable cross-border trade, and position India as a leader in responsible, innovation-driven AI growth for inclusive, secure, and scalable digital transformation.

## üì∫ Video

[![Watch on YouTube](https://img.youtube.com/vi/vmOIvF3IjvM/maxresdefault.jpg)](https://youtube.com/live/vmOIvF3IjvM?feature=share)

---

_[‚Üê Back to Day 1 Sessions](../README.md)_


## üìù Transcript

We have our AI engine create a digital twin model and from that digital twin model we then calculate all the volumetrics that is required for the customer present them immediately

whereas our inspectors in the office review those data and create a report thereafter. Okay. So we have in terms of benefits we have brought down inspection time by 80%. So from five to four four

to 5 days we went to merely hours. Okay. And uh the data accuracy is 99%. Okay. So if you know for those who know the conventional method I think we could only reach up to 80 to 90% of data

accuracy. Right? So 99% is the data accuracy and uh one major achievement has been that we have been able to provide this in a safe working environment for the inspectors. Okay.

Now that's that's a very good story. Okay. But when we tried to scale this and today we have this operational in Europe in multiple warehouses but when we are trying to scale this we found

some barriers. Okay. Which is what I would like to talk about. So barriers I would say in three domains. One is regulatory framework. What can be done at accreditation body level as well as

cab level and finally uh at an international level. So when we look at the regulatory framework, most of the regulatory framework today is designed for manual inspection. We are starting

to see more and more about uh you know elements about AI but there is no holistic or as Amanda said a system view that needs to come from the regulator assisted inspection. I think that part

is still under development and the problem we faced is even we when we produce these reports since there is a missing regulatory framework the legality of that report is challengeable

right second uh when we look at the accreditation body and cab we do have a good example of ISO 421 and also I know there is an ISO development uh 23894 on AI risk management system that's going

on so these are good foundational blocks But as Amanda mentioned right how can we expand it and adopt it holistically across supply chain is a very important point because today we have a way to say

that okay my calibration measurement device is accurate because I have a calibration report or certification I know how to you know measure it accuracy but how do I trust the results coming

out of AI am I going to rely on Microsoft who are themselves providing the AI engine so I need a way to basically establish a language a framework where I can say

that the results from AI is validated. &gt;&gt; AI and analytical AI productive AI basically to improve the speed in which we do things. So for example copilot has been integrated with uh

office suit uh basically uh uh teams powerpoint Microsoft word excel etc. So in this way the speed in which our staff are able to work has increased has improved the content writing has

improved so forth. Uh on knowledge AI platform what we do what our scientific or technical team does is that they use now ch

G GPT is there. So you are able to get more information on complex methodologies. You are able to review scientific documents more efficiently. Right? And the third thing which is

something that's very interesting is the analytical AI where we have started to integrate AI into the analytical work that we do. And one important uh uh one transformative

area where we were able to deploy AI is in sensory valuation. So when you hear of sensory evaluation generally we think about human panels where uh experts smell or taste food and then describe

the aroma. Now here we have uh we have an a digital sensory laboratory where we have an electronic nose and an electronic tongue and I will be speaking more of the electronic nose.

Now the electronic nose generates lot of chromatographic data, fine fingerprints, chemical fingerprints of uh volatile compounds that are being released by uh different food products or uh consumer

products or any anything that has a smell. Now this chromatographic data remains as a data by itself and that is where AI has helped us in converting this data into meaningful

information. So we have been able to create profiles of the aroma of different products. Now the electronic nose has now been built with a database of almost

275,000 order causing compounds. Invariably you will be able to using the electronic nose you will be able to identify the smell of any product just

like a human sensory expert would be able to do. The equipment uh analyzes the product the volatiles and that chromatographic pattern would be analyzed by AI and it would give a

sensory description. It can be also used to identify off order. So why is that important? So once there is an off order even subtle off order can be picked up by the equipment and then it helps you

in making decisions whether the product has started degradation or spoilage. It can be used in benchmarking. It can be used in comparison batchto batch comparison or if you want to compare a

product against a benchmark product. It gives statistical information. Statistical analysis happens in matter of few seconds. In fact, data is analyzed statistically so that you get

very objective, repeatable and reproducible data which helps to validate what the findings are. And very important is that we have been able to create a digital

library that can store the expertise of human sensory experts. Now generally the expertise of a human sensory panel remains with that

person. But here we are able to digitally store it. For example, if you have you you have a food product that has been manufactured today and if

you want to know after 25 years whether the same the same product has the same smell that was manufactured in 2026. This is the tool that we can always use. Now does it replace humans? No. It's it

only helps to uh enhance the understanding and uh the judgment. It also helps to improve the human judgment over data that you get but the scientific

accountability remains with humans. Thank you. &gt;&gt; Thank you. Thank you very much Abraham. Now let's move to the third pillar of the session that is going to look to the

solutions. Now here we're looking at accredititation bodies to policy makers. So for those that are not that familiar with uh quality infrastructure accredititation bodies verify the

verifiers right. So they verify that conformity assessment bodies. So all the speakers you just listen they meet impartiality requirements independence competence technical knowhow. So uh

we've listened that many of the challenges now that the caps face is in terms of accredititation and regulatory fragmentation. So uh Shannan starting with you what what is currently what

what are you currently looking as the quality council of India in in assessing how caps are using AI any ongoing projects? What can we expect from accredititation bodies in in this new

topic of how AI has been integrated in conformity assessment services? &gt;&gt; Thank you. Good morning everyone. Uh most of you might have heard uh the clarion call by Prime Minister Vikshit

Bat and all of us know a robust quality infrastructure is going to accelerate our Vikid Bat journey. If you look at uh companies which have

or countries which have successfully uh transformed their supply chain and manufacturing, you take uh for example Germany or Japan. What is the status of their quality

infrastructure? One, it is very very accessible in every pin code and also uh it is very affordable because quality is not seen as a barrier. It is available in a very democratic way.

Even though these two are there but quality is consistent between multiple assessors and because of this consistency there is a trust in the quality infrastructure.

This is what we need to do. But to do this can we copy pasteuh what has happened from Germany and Japan? What are the key nuances where India is different from Germany and Japan?

Uh number one is uh these countries have evolved over time. When global quality infrastructure was also maturing now for India you have a time clock we need to get it done in next four five years

otherwise India will cannot leave fro. Number two India is also a very complex country. uh every state has its own nuance, every district it has nuance, every institution has its own nuance.

Given that can a traditional incremental uh approach will that uh enable quality infrastructure building? What we need is a system which is going

to leaprog what happened in the data paradigm where we move directly to 3G 4G. You take another example of UPI. How UPI transform the payment infrastructure.

What we need the quality DQI digital quality infrastructure need to have that level of capability to leapfrog few generation so that we become globally competitive

we have done in UPI we have done in DJRA why not in quality infrastructure it's very uh easily possible that's where the role of A comes in if if I look at AI how has it evolved?

In the initial cases, it was more or less uh it was use case based. You take a use case, try to embed a AI, how to deliver a productivity. In the second uh uh uh era, it became

personadriven. Look at a person, how do we reduce the friction? Now if you see most of the developing countries and developed countries the focus is two and three which is

personadriven and process reino innovation. So thinking a process as if legacy doesn't exist and try to build a new process which is AI or digital ready that is where the opportunity for Indian

quality infrastructure is going to be humongous. Coming back from uh say from quality council of India since we cover uh many uh uh boards of standards. How are we

looking at AI? Uh today we are developing as part of DQI. Soon you will see government uh rolling out uh DQI. As part of DQI uh as of now we have four agents.

uh again this will benefit most of the cabs and IBS and eventually to the end market who are the beneficiary of quality agent number one is uh each one of you have multiple papers systems but

uh the current systems are asking you to type how can we develop smart scan so that any type of documentation there is uh we want to make our system accreditation system keyless so that uh

when you have any sort of document documentation system will scan it will take the relevant data so that uh whatever time we spend on entering data is eliminated.

Number two is uh in our uh PDCA what we notice is most of the time uh you go to object element and there is a lack of clarity or there is information asymmetry problem. So the second agent

why we are developing is a voice enabled agent where if you are stopping in objective element one can we immediately showcase some of the best practice can we indicate a video can we indicate what

courses you have to take so that the journey is frictionless. The third agent what we are developing is uh like uh my speakers from the previous session what they spoke about

everybody every institution has their own systems. So how do we eliminate the friction between your system and a national system? How we can make smart API? That way we can uh seamlessly work.

Today audit or any surveillance is seen as a burden. From that it has to become like a daily work management where if you are working we should be able to give you certification, inspection

anything what you want. &gt;&gt; Sorry. The last one is about the knowledge which is about uh building a repository of partala which is also specific to each one of you depending if

it is a rural customer what is the type of essence we have to give if it is a evol customer what do you need to give thank you &gt;&gt; thank you very much I don't know if this

is working now let's jump to the policy makers perspective shuto I would like to ask you what are the the the AI assurance approaches that from the ministry of electronics and information

technology you have in mind how quality infrastructure plays a role in this and what are going activities are you planning for the next uh year or or even over

&gt;&gt; uh thank you sir uh on this uh the cyber risk or the cyber security and interaction of the AI that uh uh we observe that uh and working on there are three dimensions.

The first is the application of the AI of course on the solving the cyber security challenges and problems. And one of our case study is the well published in the world economic forum is

the how to deal and how to you know uh do this incident response quickly and how AI can assist you in doing that. Another is that you may be aware that the entry to the cyber attacks and cyber

crime due to the LLMs and AI system is lowered because it's easy for anyone to you know the uh write a malware write a code or conduct a sophisticated fishing attempts and so your incident response

and the how we are helping and enabling the entities and sectors their incident response should be the AI aware that mean there should be the SOPs in place and they should be aware that this what

can be done through the AI systems uh to assist the attacker in conducting the attack and third is the third dimension is the attack on the AI system itself. So other than the classical information

systems uh uh vulnerabilities and uh the risk uh the new types of specific risk to the AI that are broadly uh we are covering and looking at the following for three uh domain. One is the

poisoning attacks, another is the extraction of the uh models and configuration and third is the evasion attempts. Along with that, one of the challenge in the of the AI system is the

opacity or I mean their explanability very in the way and uh you know when uh then it's difficult to conduct the root cause analysis and investigation. So for us

the uh following four priority areas to secure the AI system and their deployment to have a trust there. The first is that uh the as adjusting the autonomy based on the cyber risk

assessment. So how much autonomy you want to give to your system based on the sensitiveness of that operation and the outcome. The second the secure by design of that application.

Third is the explanability that support the audit auditability. You can audit and get the assurance okay this is safe and secure and free from uh vulnerabilities and that also support

conducting root cause analysis if something goes wrong or some incident do happen. And the fourth is the the AI bill material that help in your supply chain and maintaining the visibility and

the ingredients what is there in your AI system. It should not be a black box. Then only you can have a assurance over your supply chain and if there is something on the ingredients you can

take action on. So that transparency through the artificial bill of material for for that we also published a technical document how to do that and we are also working along with the global

forums. So the harmonization in this domain is crucial and that's why this bill of materials transparency in supply chain along with the uh major economies led by the CIS USA and India we are we

came up with the joint guide guidelines on how to maintain this transparency and bill of materials for software for AI and this thing. uh we worked with the uh French uh led by the French national

authority along with around 20 economies and came up with the joint principle to have a trusted AI app uh based on the cyber risk approach and that provides a high level uh uh principles along with

the checklist for the who are implementing uh and developing the AI system and the u uh along with that in India we initiated a working group uh along with the our impanelled auditing

organization and industry to came up with the how to come up with the framework methodology uh of course in sync with the what already done by the NIST ISO and uh uh

the OASP AI testing guide all I mean the international organization what they have given but this group is trying to come up with the India specific cyber security assessment and assurance of the

uh the AI system. So uh combining I mean combining all these approaches and working in with the international uh cooperation collaboration is very important to you know the ensure the

security safety and bringing that trust by transparency and transparency and bill of the materials. We're also looking forward for the something uh uh the NIST has done the they called

Dopatra. It's the test bed in which you can place your AI system and you can get it tested for the cyber weakness and cyber vulnerability. So such kind of the quality infrastructure and uh I mean we

need to put up in the place and planning to put up in place. Thank you. &gt;&gt; Thank you very much Ashto. Yes. Moving to the last pillar we have very little time less that is standards the key key

actors in quality infrastructure and for this we have the bureau of Indian standards and the British standard institution very similar acronyms but different in nature so uh let's talk

about how the role of AI standards with your Chanel what are the current gaps in AI standards uh that was the role of AI assurance also here and uh tell us a bit more what are you planning in the next

in this year in terms of developing new AI related standards. &gt;&gt; Yeah. Uh thank you Edel. uh we've listened to everyone from CAP accreditation uh regulators and if

everything there's something common that binds all of them is the standards and therefore it is very important that uh standards keep up to the pace with which AI is uh developing and especially in

the QI uh industry the tick uh industry we have so many use cases of inspection prioritization we've heard about shoulduling risk scoring uh then our anomaly detection etc. Uh there are many

use cases of AI and therefore we need to have standards which are reliable which are traceable which can validate all the actions that they do. We've heard about two standards that uh Amanda uh talked

about and uh talked about was ISO 401 and the risk management standards that is 23894. Of course these are now well appreciated uh by the industry and uh they are working on it. Uh but there are

whole suit of standards that is under development currently and we talked about the need for uh you know testing and validating the AI uh systems. So uh those who are from the industry know

about the ISOIC 29119 standards on software testing. uh similar to 29119 there's a series of standards under development uh called as 4 to119 uh which is specifically on AI uh testing

and uh the part two 4 to119 part 2 is already out or in the stage uh which is equivalent to the 29119 and how the software testing and AI testing relate to each other it presents the

overarching uh framework of AI AI testing. Uh the next in line is part three which is on verification and validation of AI AI systems and I'm happy to share that it is being uh

developed under India lead. So India uh is leading this uh project and there are other parts coming up one on red teaming other on text prompting hallucination metrics etc. So there's whole lot of uh

standards that are coming up which will support uh the governance and the risk uh structure. Uh as far as India is concerned uh AI uh is a space uh which is global or persuasive. Of course we

need to have standards uh specifically for Indian context also but uh we are primarily engaging our experts are engaging at the ISO and IEC level some of the areas where we've taken uh lead

is on of course I verification and validation I told you then output data quality for generative AI reliability assessment so these are some of the areas that uh we are working on u I

wouldn't say that there exist gap uh areas in the sense but uh of course there is always a scope for having more standards which can provide the real-time solutions uh to problems uh

two things that come to my mind easily uh is one uh the Indian startup ecosystem uh we are and the other also we have to you know depend lot on synthetic data uh because of DPDP act

etc we can't have the privacy guidelines etc. And therefore it is very important that the synthetic data practices the synthetic data validation uh we have common platforms uh so that uh you know

we can scale uh this kind of information. So we are working on that. uh another area which I'm sure we'll be working on is uh most of you will appreciate that all these standards and

the models that we are talking about or AI systems we are talking about are English centric uh whereas we have 22 official languages in India. So something which can give us an Indian

context how to test the Indian centric or Indic languagecentric uh AI models is an area where how to avoid biases uh in this indic language etc. So there is something a need where we could work

upon together with all the stakeholders who represent uh on the BIS committees that is an area that we can uh look forward to and uh also we talked about the success of UPI we feel similar to

because it was able to scale because of its open structure uh interoperability. So similarly we are also proposing at the ISO level in the forthcoming meeting of having something like prioritizing

common data formats metadata structure some interoperable data frameworks which will help the AI models scale uh with trust and reliability. So there's whole suit of

work that uh we are doing in this area and of course the next thing is the smart standards that uh we are working on and I think probably Tim is going to speak on those otherwise I'll be happy

to share if &gt;&gt; I think we have very limited time because I saw the time limitation. &gt;&gt; Thank you very much and then last but not least Tim maybe with a focus more on

AI assurance how AI assurance can help regulators quality infrastructure in bridging the the gaps. No &gt;&gt; yeah so I'll be quite short around this.

So it's been referenced out that the uh standards ecosystem exists already and it's been going for at least 10 years. So we're very far down the line and one of the standards that hasn't been

mentioned is 4206. So 4201 is the management system but 4206 sets the rules out for the certification bodies and we've heard various references about this today. So this ensures there's a

consistent quality level of um certification around the world which is then reg managed by the accredititation bodies and this means that the certification bodies have to have we

mentioned about set days have to have certain days to ensure that we're really consistently uh assessing those organizations. We have to have the right people. So you

have to have skills around cyber security um data protection obviously understanding management systems but also working experience of AI systems. And one of the other things that's quite

good references some of the points earlier on is about the need to have um remote audits. So remote audits are good for a number of reasons. It makes it easier for the clients. It makes easier

for us and also it's less carbon. And the reality is around AI, it's not like you're going to visit a factory where you have to be on site or see it via a drone. Actually having that greater

perspective is important. The other thing I was going to reference was around um regulation. So there is also particularly more of a European context a closer link between the

standards for AI and regulation. So the big example is around the European Union. So the EU came out with the first comprehensive um regulation for AI a few years ago and the regulation sets out

the what but the reality is that the actual how has been done through the standards organizations. So within the European context there are Sen and Sench who developing those in the same way

that ISO and IC develop internationally. So they're taking through the standards that dictate the how around things like risk management around um human oversight and the like. And that's the

kind of work that will help the organizations who need to work with the certification body and also the certifiers too. Although reality is the regulation sits back. The other thing I

was going to mention is also the UK context. So around the world for the last few years there's been a lot of discussion around um AI regulation. So there's kind of two sort of twin poles

of do you let regulation um come now even though AI is moving incredibly quickly and build in regulation to avoid any future problems or do you wait and see and allow innovation to flourish and

there's been a huge debate on this has been going through and different countries have different views. So the UK perspective currently is the fact that regulation sits within different

regulators and there isn't an overarching piece of AI regulation but the government is also pushing towards standards and assurance as a way of proving that you're doing good a AI

governance. So for example 4201 is referenced in the UK government regulations and previously uh the NIS risk management framework in the US has had a lot of reference elsewhere as

well. So the whole infrastructure is very closely linked as well. Given time happy to finish there. [applause] &gt;&gt; Thank you very much. With this we we

conclude just in time. I think what's clear is that we have to keep collaborating all together industry developers, quality infrastructure organization of course with policy

makers and accredititation bodies so that we can advance the recognition of AI and conformity but not only AI but other emerging technologies also in the future so that we can help uh com

companies and manufacturers to receive better data better smart uh compliance and and other things. So with this I thank everyone. I thank the panel especially for your participation. Uh

we'll be around during the the summit. So please don't hesitate to come to us if you want to to speak about this topic. We have published this paper that we showed the QR before. So I also

invite you to to read the paper and I think now we will take a &gt;&gt; group photo &gt;&gt; a group uh picture. So &gt;&gt; all the speakers to please uh join here

and everyone. So let me group photo and help you please join please join.
